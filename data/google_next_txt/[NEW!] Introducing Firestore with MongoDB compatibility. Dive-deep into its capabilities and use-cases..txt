 Hello, everyone. Welcome to the session where we are going to introduce Firestore with MongoDB compatibility to you. So let's just go ahead and get started. First, I'd like to introduce the speakers to you. My name is Vabhuv Govil. I lead the product management for non-relational databases at Google as well as AI-enabled developer experiences for databases. I'm joined here with Fani Vemurul, who is the engineering director for Bigtable and Firestore. And last but not the least, Stacy Manning, who is director of product management at Mayo Clinic, is joining us. And thank you, Stacy, so much for co-presenting with us. Here's the agenda. So first, I'm going to introduce the non-relational databases GCP portfolio to you and talk to you a little bit about which services do we offer as non-relational databases. Then I'm going to dive a little bit deeper into Firestore, discuss with you Firestore with MongoDB compatibility. Then Fani is going to go under the hood for Firestore and talk to you a little bit more regarding the architectural details and things like that. And finally, Stacy is going to take over, and she is going to discuss Mayo Clinic's use of Firestore with you. Okay. So non-relational databases and Google Cloud database portfolio. So this slide presents the overall portfolio of database services within Google Cloud. As you can see, we have a good mix of relational and non-relational databases. In terms of non-relational, starting with in-memory, we have Memorystore, which is an in-memory data store service. We support Redis, Valkey, and Memcached as in-memory data store engines. Then we have Bigtable, which is our key-value white-column data store. It has HBase API interface. It also has Google SQL, a very popular database service for key-value workloads. And finally, we have Firestore, which is our serverless document database offering within GCP and is the main focus of this presentation. Underneath all these services, you will see a whole bunch of Gen.AI enablement, which we have done for databases. Please feel free to attend multiple other presentations, which we are doing in regards to Gen.AI enablement of databases, like vector search and how we have integrated with our Vertex.AI LLM models and things like that. But let me first talk to you a little bit more in detail around Firestore. So Firestore, as I mentioned, is our serverless document database service. It's extremely popular. It's fully managed, JSON-compatible. And when I say serverless, what I mean is exactly pay-as-you-go. There's no over-provisioning or anything like that involved as part of Firestore. It's extremely highly available service with up to five nines of availability, zero RPO, zero RTO guarantees. There's no concept of any maintenance window or things like that. You can just run your service and set it and kind of forget it, that kind of operation. Typically, with a GCP cloud-native database service, you will expect all kinds of integrations, whether it's IAM, cloud logging, auditing, monitoring, those kind of things. It comes enabled with all of that. Also, it has a number of differentiated capabilities. For folks who have used Firestore for developing mobile applications, it comes with an offline mode as well as real-time sync notifications. Some of those capabilities, which typically will take a lot of development effort, but Firestore just provides out-of-box for you. As I mentioned, very popular, more than 600,000 monthly active developers, and more than 8 million databases already created in Firestore. In fact, Google has a rich history of document database development. We launched Datastore in 2008. Since then, we have been innovating in this space. And while we were doing our document databases approximately at similar times, MongoDB was also launched, has a popular API, and opens ecosystem and community of MongoDB users. And we have been working with GCP customers who want that choice so that they can make the right trade-offs for their workloads. Hence, we are happy to announce Firestore Firestore with MongoDB compatibility in public preview. Now, what we are doing, it brings together the MongoDB API and tools with the scalability, availability, and ease of use of Firestore. That's our key intent. Now, as you can see as part of this graphic over here, Firestore is at the center with a lot of its differentiated capabilities. You can now use Firestore with MongoDB compatibility, and then you have other options to use it as well, like Datastore API as well as Firestore native API. This is a high-level architecture diagram of Firestore. It means we have not covered all the layers in there, for example, load balancers and things like that. We wanted to keep it simple. But as you can see, there's a client represented there. A request is received from the client. There's Google front-end, and then these are the three APIs which I talked in the previous slide. There's an advanced query engine, and then there's storage. The key aspect to note here is the separation of storage and compute. Again, Fani is going to go more in details on this, but this is a differentiated capability from architecture standpoint, which enables us to quickly scale out and scale in depending on your workload. Now, let's see what Firestore with MongoDB compatibility means from a compatibility aspect if we overlay it as part of this architecture. So first and foremost, we are offering compatibility with MongoDB API, with MongoDB versions 3.6 to 8.0. And then in terms of the query, we are definitely supporting query dialect, aggregation pipeline queries with stages, aggregations, functions, operators, definitely asset transactions, something which you expect as a document database developer. And then from a storage aspect, customers really rely on the data fidelity and everything. That's why we are going to support the data types, different kind of indexes, whether it's multi-key, sparse, non-sparse indexes, metadata, and metrics. So all of this comes to our customers with the Firestore scalability, consistency, availability, performance, and manageability which we offer. There are various kind of use cases folks who have used document databases are familiar with. I'll highlight some of them. By no means, this is a comprehensive list of use cases for Firestore. But in this case, Firestore with MongoDB compatibility can be used for data catalogs. Like, it's a very common use case where the flexibility and data model really helps the customers to develop their end applications. User personalization is a very common architecture for Firestore really supports that. We have gaming. A lot of popular games are built on Firestore already, and we have a number of customers already engaging with us for using Firestore with MongoDB compatibility for that. Real-time analytics is another very popular use case. And then content management, which is really the bread and butter for document databases with the JSON and the flexibility of data model, which a lot of customers use Firestore for and now Firestore with MongoDB compatibility with. This is just a quote from one of our customers, HighLevel. They are a marketing tech company. HighLevel shared how Firestore helped increase their developer productivity by 55%. They operate also at a very high scale, as you can see from the quote, with more than 250,000 requests per second, 30 million documents. And they mentioned that seamless scaling with Firestore helped them quite a bit. So now let me talk about other areas of innovation where Firestore has been innovating, including enterprise and security capabilities, because that is equally important for our customers as they develop their applications. So on the enterprise features perspective, first and foremost on the security and compliance aspect, we recently launched customer managed encryption key support for customers who want to control their keys. Typically, all your data is encrypted anyways with Google Managed Keys, but in case where you want to use your own encryption key and manage it via KMS, CMEK provides that capability to you. IM access, private service connect, all kinds of capabilities are available to you. In terms of auditing, I already talked about cloud audit logging, monitoring, those kinds of supports are there. In terms of disaster recovery, this is where we continue to launch new and improved capabilities. First and foremost, manage backups. Then point-in-time recovery with one-minute granularity for a period back in time up to seven days. And manage import-export. These are some of the capabilities which our customers have demanded from us and we are able to offer. On the developer experience side, we have database center where you can get a unified view of your inventory, not just for Firestore, but pretty much all database services which are part of Google database portfolio. And then there are certain other developer capabilities like query explain, query insights, and some of it, Fani will touch a little bit more in detail. And one other thing, as you will hear in Stacey's presentation, how some of these capabilities are leveraged by our customers like Mayo Clinic as well and how they come to life. Now, the other aspect of a GCP cloud native database service is getting all these compliance certifications, especially for customers who are more sensitive from a regulatory compliance area. So you can expect Firestore to support pretty much everything which is out there in terms of SOC compliance, PCI compliance, FedRAM. The service supports it all. So if there are any particular requirements which you have, we'll love to hear from you on that. But one of our goals is to make sure we are compliant with all these certifications so you can not worry about them and just focus on your application logic. Now, we have launched this wonderful capability of Firestore with MongoDB compatibility. How are we pricing it? That's a key question. I wanted to share what we are doing in this space. So as we launch this capability, we are also launching this as part of a Firestore Enterprise Edition. So we are introducing a new edition of Firestore. We are calling it Firestore Enterprise Edition. And there are certain unique aspects of Firestore Enterprise Edition where from the get-go, we are trying to offer more controls to our customers. And some of those changes which we are making, first and foremost, we are not going to index your data by default. We'll pass on that control to you and we'll give you the tools to make that decision which data attributes which you would like to index for better improved performance and manage your cost accordingly. So that is a key way where you can control your cost. Second, we'll offer advanced capabilities in Enterprise Edition and we'll continue offering that as we continue to roll it out. Third, you can expect improved performance from Enterprise Edition, especially in terms of tail latencies. If you're looking at P99 and your workloads are more sensitive to that, you will definitely notice better performance from Firestore Enterprise Edition. And finally, on the pricing bit, we are launching a pricing model via which, depending on your document size and index size, you can control your cost. So let me talk to you a little bit more in detail what do I mean by that. So from a pricing perspective, there are two main operations, as you will notice. First and foremost, we are still staying very much serverless. That's a key unique selling preposition of Firestore. It's exactly pay for what you use. But the two operations are read units and write units. So current Firestore has write units and delete units. We are just combining them in a single thing called as write units. A read unit is defined as a document which is built in sizes of 4 KB. So if you have a document which is 7 KB, we'll round it up to 8 KB and that will be two read units if you are going to do a read lookup for that particular document. We'll continue to offer a free tier, a very healthy free tier for our enterprise customers where 50,000 read units per day will be free, 40,000 write or deletes units per day are free, as well as 1 GB of storage will be free for customers as well. The pricing for the read unit and the write unit is mentioned on the slide. Now, we have done a cost optimization on behalf of our customers, and there's a slight nuance to it, and I'll walk you through it. So when you do a doc lookup, or basically you're reading a particular document, that's when we charge you one read unit per document, depending on the size of the document, as I said earlier. But if you're doing a query scan, we aggregate all the data, which is scanned, and then divide by 4 KB. So we are not rounding up on a per document basis because that will be more cost to you. In fact, we scan the entire data, whatever that data is, then we divide by 4 KB to get the number of read units for you. And it will become more clear as I walk you through some of those examples. So for example, when you look up the first one where we are querying 10 documents and returning those 3 KB item size, that's 10 request units for you. When you are scanning 10 documents of 1.2 KB in size, that's 12 kilobytes in total. You divide by 4, that's 3 request units for you. So it's quite a marked difference. If you were rounding up every document, it would have been 10 request units for you. And the third example is a combination of that where you are scanning as well as returning. That's why the 10 request units are there for the scan part and two request units are there for the ones which you are returning documents. So that's how we are optimizing and making sure you get more control depending on how you architect your database in terms of cost. Now with this, I'd like to pass it over to Fani who is going to talk to you more in details about Firestore. Okay, there. Mike is working. First of all, thank you, Vaibhav. And more importantly, thanks to everyone over here for coming in right in the middle of your lunchtime. So I appreciate it very much. Let's get started. So we're really excited about this. We've worked really hard. We're really proud of what we've done here. We're launching, you know, Firestore at MongoDB compatibility. It's choice for you. You know, a lot of our customers have been asking for this and we are happy to be launching it right now at Next. It's choice and it's made for you. So how does it all work though, right? Let's go through a little bit of like, you know, a teaser kind of a thing as to how this works and talk about the value that Firestore provides and try to see if you can bring it all together. Well, first of all, it's integrated. It is Firestore, right? It's an evolution of Firestore. You just go to Firestore, try to create it like any other database. You give a name to the database, select Enterprise because that's a new thing we're creating, right? That's the one in preview, right? And you can see that, right? Enterprise. And then say Create Database. That's it. And your database is created. This is your Firestore with MongoDB compatible database. It's ready for you. You didn't have to do anything complicated. You didn't have to select what kind of machines, how many machines, how much data, nothing. That's the ease of Firestore. That's what we're really proud of, right? And once you've created your database, you can see it over here. That's the connection string that is created. That's the string that you use if you have existing code that used to talk to MongoDB or MongoDB tools that you're used to or any new tool or code that you're going to write that is going to use the MongoDB API. That connection string is key and we'll be talking about this throughout the course of the talk. Of course, I did simplify the creation flow for you a little bit. It is still Firestore under the hood as Vibo showed in the picture, right? It's in the center of everything. It still is our enterprise database, you know, native managed. It has got multi-region capabilities. You can select which region you want the database in. You can select whether you want CMAC encryption, you know, your own special kind of encryption and so on. So it's still the same database. Anyway, I digress. Let's come back, right? Well, now you've got a connection string that you can use so that you can connect and use Firestore with MongoDB compatibility, but you can also use this command line that we introduced called with G Cloud, G Cloud connection string, where you can give the database that you just created as a name and it'll basically output the connection string that you can use to connect with this store. Well, okay, great. You created a database. It didn't take much. It was pretty easy, pretty seamless. Let's try to get some data into it. Well, how do we get some data into it? Well, I've just stored the connection string in the URI and I'm going to use Mongo import tool. I mean, it's one of the tools that, you know, people use all the time to import data. So I'm using Mongo import and I'm giving a file catalog.json in which I have a bunch of catalog items in JSON and there you go. That's it. You give the command line. You can see over here. Oops, sorry. You can see over here. It's connected. There's something about auth that we still need to talk about, but you give a password, it'll connect and it'll upload the data. Are we sure? We don't know, right? Let's check it out. Here again, I'm using Mongo SH, giving the same URI to connect, giving my password and boom, that's it. It's connected and it's ready. The Mongo SH shell is ready for you to use. Let's try something. Okay, we connected to the database, but did it actually upload the data? There's the command. We're using dbcount and we are able to see that we uploaded 41 documents over there. We can do more. Let's get more and more querying tried out, right? Here's a group by clause where we are trying to figure out how many items and how many items and how much inventory is there for every category that we just uploaded. So it's a group by clause with a sort and a limit and as you can see, the querying just works and just as the way as you've been using before in Mongo SH. We can go even more creative, all right? And we have also implemented stages in our pipelining, in our pipeline queries. For example, over here, we just looked at this group clause which I showed you in the previous slide that already found out how much inventory you have per catalog item. Now, I'm going to use that group by clause in the next stage to compute average stock per item. Then in the next stage, I can compute, well, which stock is actually running low, right? And then in the next stage, try to figure out, I want to figure out how many categories are running low in stock and how many categories are running okay in stock, right? So we can get pretty creative. This is something that you know you should be, you know, you probably have used before in your tools. It just works. We can also use regex, but we can keep going on. It's not going to get fun for you, right? You all skipped your lunch to be here, right? We have actually implemented 120-plus operators and stages for this launch. We're coming in strong and we'll continue to, like, you know, improve on this. I'm really excited about this. Of course, I talked to you about Mongo Import. I talked to you about Mongo SH and any other tools that, you know, you're used to before, but we also have, you know, we have choice here. We also are launching our query editor in preview. You can do pretty much everything I've just shown you on Mongo SH in our query editor as well and this will be available to you in Firestore Studio. So, again, lots of choices. Well, of course, index. You need indices to be efficient with your queries. I know I gave you some example queries just to get you started on the power of the query engine that we have but obviously, you know, to make them performant, you need to have indices. We are also supporting non-sparse and sparse indices and multi-key indices which are used to query arrays at this time in preview. We skipped a little bit of the whole thing about auth over here, right? Like, I simply said Mongo SH, Mongo Import and I don't know if you guys have noticed, I've given a username over there as funny. Well, how did the user get created? We simply talked about the database creation. We didn't talk about how the auth works. We didn't talk about, you know, how did the user get created and so on. Here's where you have more choices, right? You can use passwords or you can do things without passwords to authenticate and authorize and let's go over those choices quickly. This is a command we used, you know, previously where we said Mongo SH gave the URI which is a connection string and then we authenticated using Scram and a username funny and the question I'm posing to you is where did the where did the username come from? Well, to support Scram because a lot of a lot of tools out there which you might be using, you know, you could be using Scram and thinking about as username passwords, we actually created our own auth system in Firestore where you can create users per database. This is also launching in preview at this point. So you can go into this UI, you can click on add user, create the user and we'll give you a one-time password that you can record. Over here, we're sharing Vibos password, not mine, right? So this is it. So once you create the password, you can use your familiar username password scenario in your tools and it will work. These users are not something specialized that we're creating just for Firestore. They actually integrate well into the GCP ecosystem of IAM and you can actually see them as principles in the overall GCP ecosystem. Again, well integrated into the GCP ecosystem overall. Well, what about without passwords? Well, MongoDB drivers support OIDC and you can use VM identity or service accounts to do that. For example, remember our friend connection string command, right? Over there, you can go and indicate that, hey, I want to use my auth as GCEVM's auth, right? And now you can use the same connection string and when you use your command like MongoSH over here, you just have to give the URI and the command where it runs in that VM, whatever service account is attached to it, will be used to authorize and authenticate, right? So no more giving passwords over here. All right, so that's the primer, right? We just talked about how robust our query language support is, how the connection strings work, how easy it is to create databases and again, I want to repeat, right? I mean, you have existing code that used to talk to MongoDB or you have your favorite tools that used to, you know, work with MongoDB, MongoDB, you know, they should all just work with the compatibility that we're supporting. All right, so this is all great. We're all happy with this launch, but let's also talk about the value that we provide in Firestore, right? We got a little bit of the primer from Vaibao and I'm going to retrace some of those things with a little more detail over here. A lot of the essential value of Firestore is not really coming from which API. We're supporting multiple APIs and we want to be the document store of your choice in the future, but essential value comes from things like availability, scalability, serverless and ease of use, the price at which we can offer all these things and I want to like show a peek into like how does Firestore achieve all of this? So, part of the answer is we are able to in Google use disaggregated architectures. So, when you're sending requests from your clients over here, oh, by the way, I'm not playing red light, green light over here. I'm just trying to notate that different APIs and different clients are accessing Firestore. When these different clients are accessing Firestore, we have compute and we have storage which is completely disaggregated under this whole APIs. What that means is like if your traffic increases, we can decide to add more compute. if your data increases, we can decide to add more data in a disaggregated fashion. Essentially, what that means is, you know, if your traffic keeps going up or your data keeps going up, we are able to dynamically react to it and more importantly, save and not actually have all this compute and storage when you're not using it and pass on the savings to you, right? So, you can grow your traffic and we will grow with you and we will cost you for only the things that we're actually using. So, that's pretty exciting. So, that's all about like, oh, good, how are you able to scale? Well, we are able to scale because we are desegregated and we keep adding compute and keep adding storage as we go. But, what about availability, right? Well, we are actually synchronously replicating data using Paxos in Firestore. So, you know, your data is actually split. Actually, data and indices are split and then they are put in like zones, like three zones in this particular example that I'm showing. And since it's Paxos, we have leaders in, you know, sprinkled all over the region and it's all synchronously replicated. What this means is if you have an availability and you lose some part of the computer storage in like one space, like this particular point over here, the system notices it, Paxos, right? It notices it and moves the leader into some other location and this all happens seamlessly without you mostly noticing it at all, right? And it's not just for like, okay, some parts of the data are gone. Let's say this whole zone is gone for some reason, right? It happens, right? Rare, but happens, right? Again, we can figure out all the places where we don't have leaders and see over here we realize that, oh, this thing doesn't have leaders and immediately move the leader over there and it's all synchronous replication so you have zero RPO, zero RTO and you keep going. So it's worth repeating what's there in the slide without all the diagrams, right? We have industry leading finance SLA, right? We can have three replicas or even have four replicas with a witness depending on region or multi-region. We have zero RPO, zero RTO and no downtime maintenance, right? This is all value that we're adding for your availability, right? I just talked to you about, this is an example of a regional setup, right? One of the zone goes down, you're okay. Here's an example of a multi-region setup. One whole region goes down, you're still okay, right? So that's the availability value that we're providing. There's also value in simplicity, right? Firestore prides itself on how easy things are. We just showed you the flow of how easily we're able to create a database and manage a database, but also friendly from developers-wise. I know there's a whole Firebase ecosystem as well, so more for later on that. We are continuing to invest in this. That's the short of it. How are we continuing to invest in it? Well, in the operational simplicity space, we are generally available with database center integration. What this means is you can have your fleet management, as to how many systems do I have, do I have backups enabled on them or not, and recommendations, all of that in one place. We also are launching, this is for developer friendliness, we're also launching query explain now. You can now look at your query and debug performances, as to how exactly the query is being planned, and debug your performance right there. We are also launching, sorry, a lot of launches at this point, so I had to keep going, I wanted to go through all of them. We're also launching query insights. This is how you can actually see which queries are actually popular among your users, and what are your users doing, and all of that. There's also a whole value in ecosystem. I just refer to Firebase as an example. GCP, we gave a little bit of hint on IAM integration, and we talked about CMAQ and other stuff, but there's a lot more value, and there's a lot more to talk about. We have webs, we have mobile SDKs. We can't talk about all of that in just this one talk, but you can continue this journey in the rest of the talks that we have over next if you're really interested in this. I would recommend, again, by the way, this is just an introduction, so I know there's actually going to be demos in some of the future sessions. I would recommend, for example, this session, dialing in, Firestore with MongoDB compatibility in action. It's on Thursday at 1.15 tomorrow, and we also have a spotlight session with the demo, so there's a lot more going on. If you're interested, please take a note and attend this other sessions as well. With that, let me invite onto the stage Stacy, who's from Mayo Clinic. She's going to talk about some of the innovation that Mayo Clinic is doing and how they use Firestore. Thank you very much. Well, that's going to be a little bit hard. I'm competing with both a launch and lunch, right? Let's see here. Let's get caught up. So thank you, Fani. Today I'm going to walk through a high-level overview of our Mayo Clinic cloud journey and share how we're leveraging Firestore and other managed services, empowering the developer experience to leverage the latest cloud-native technologies. Our Mayo Clinic cloud journey began in 2019 when we announced a 10-year strategic partnership with Google to redefine how healthcare was delivered technology technology. We're moving forward and accelerate the pace of innovation and using the latest digital technologies. Though we've had some hurdles and some bumps along the way, we are now hitting our stride. We're moving forward and we're building momentum. 2025 is the halfway point of that journey and this journey is taking us to the next step to innovate, collaborate, and scale, and push from possibility to our practice. Let's explore how this cloud technology, like Firestore, align with our strategic pillars and drive us forward in our 2030 vision. These pillars define our 2025 strategic initiatives, particularly within IT and our Mayo Clinic cloud. Our products and services collectively enhance all four strategic pillars. As we bring new innovation and technologies to life in the cloud, this impacts the practice by enabling the work of our physician and research teams to improve the value of our patient care experience. Our platforms are also aimed at easing our administrative burden. The primary value that we deliver in easing that administrative burden is to allow all of us to focus on our customers and our main value that the needs of our patients come first. Mayo Clinic cloud products are designed to achieve the vision of being self-serve and leverage the best of native cloud technologies. We use integrated security tailored to the specific needs and purpose built for each of these products that you see here. The purpose built boundaries and security protections for each of these products allows our customers in these spaces to move farther, faster in the cloud, while enabling connectivity across them to use the benefits of each of these ecosystems. Our ecosystems are built around three key areas. Our advanced data lake, which includes our longitudinal patient record, which is used to access data, analyze data, and visualize the multi-mode of data we have in our data lake in the cloud. Our AI factory is where our users experiment, build, train, and validate AI models using their own data or public data sets that they bring into this experience. The cloud app factory is where our application developers are building, testing, and deploying production grade applications with enterprise security baked in and seamless access to data and AI models. Beneath it all, the cloud foundational products and cloud foundational services offer our learning platforms, our automation technology building blocks, and additional components to help our developers and meet them where they're at on their cloud journey. The decisions made in the early days of our cloud journey had a heavy focus on security and data. This was to achieve the high bar of chaining the high trust compliance that you heard about earlier. As we progressed along the way, we found that we focused overly on the tightly dependent infrastructure through ticketed but disparate operational teams. And this created a scenario where this over siloed sets of protections began to inadvertently limit our agility and ability to innovate in our cloud space. So in solving this problem, the cloud app factory was formed. And instead of utilizing disparate infrastructure provisioned as a series of tickets and treating it like infrastructure requests, we instead use embedded infrastructure within cloud app factory, building those product spaces and project spaces for the developers and giving them additional permissions with the security guardrails already baked in so that they can do the development work using the same security controls that Bob have just talked about. Private service connect, identity and access management, and additional security and boundary controls. Earlier, those same security and compliance applications that were part of Firestore were illustrated. These same items that you see here are also the primary foundational elements of our organization and our security components of the design of our cloud. In setting that boundary protection, we can isolate each developer to have their own project experience among the developer team, isolating any security risk to that project and that developer team alone. We also allow them to connect across into the data lake, AI factory and other realms through some of our built-in templates and embedded infrastructure as code components that we share openly on our open developer platform network. While balancing the needs of these developers to have more flexibility within cloud spaces, our hybrid cloud strategy also benefits from partnering with cloud native partners and our partner solutions and other vendors partnered with Mayo for faster innovation and streamlining our compliance tools. We want to focus on the development work so that we can build more quickly. Each time that we focus on security and infrastructure provisioning, it's time lost that we're not spending on innovation. So baking that security, some of the scalability, the price transparency that you heard about through Firestore becomes a key component in allowing, as Fani and Viva said, to really focus on the developer experience and less on the underlying infrastructure worrying about provisioning and scaling. Having these features as part of the Firestore with MongoDB compatibility will make it easier for us to enable these functions for the developer teams, knowing that the security standards and policy enforcement that we're looking for for HIPAA and HITRUST and other regulatory components are already built in from the start. Now you've heard about our security and boundary protections and the event-driven architecture of Cloud App Factory. Many of these components for 80% of this data is stored within Firestore. The provisioning that went from two to three weeks from those individual ticketed systems is now down to two hours. The data stored in Firestore is a key component of that. We use additional project labels and customer metadata as part of the Firestore components used as a repository for this automation. We also use version tracking of the automation so we have no breaking changes when rolling out features to our customers as part of this developer platform. Backup items for disaster recovery are also stored in Firestore. As we look ahead, the VPCSC controls and private service connect along with the IAM rules are already baked into our security platform. So with Firestore having those enabled out of the gate, it means earlier enablement of Firestore with MongoDB compatibility to be enabled quickly upon GA launch and our additional testing. That allows the developers to have newer technology sooner, working more quickly for their applications. Now let's take a look at some of those applications. Maya is our AI-assisted, rag-like chatbot experience. We have two flavors of it. Maya is developed as a horizontal platform to deliver domain-specific AI knowledge to address the clinical needs and employee needs in our enterprise. The clinical domain agents allow our clinicians to bring in the best of healthcare IT, enabling additional insights to focus on the decision-making so they can spend more time caring for the patients. The enterprise domain-specific knowledge agents unlock a new level of productivity because they've been trained on portions of our HR systems, our knowledge bases, and other components of Mayo data, so that we have a new level of productivity, efficiency, and self-service for our Mayo Clinic employees to find the right information at the right time and get more done with Maya. Maya is available both as embedded into our collaboration tools and a standalone browser experience. It's a rag-like experience using Langchain, Python, and React, leveraging the Redis memory store you heard about earlier for caching and vector storage for common components and questions. We're using Firestore to keep track of the chat history and maintain a list of recently accessed patients, which is where the privacy and protections built into Firestore become very important. We're storing this additional feedback from users, leveraging Vertex AI LLM's agent builder along with search, Vertex AI search, Vertex AI search for healthcare, and using these for our agent functionality. We log all these interactions to BigQuery, which we use for our downstream analytics. Using these models within BigQuery SQL has been a really powerful tool to run LLMs at scale for these use cases, such as user question analysis and questions that can be asked by content loaded into BigQuery. The Firestore and Maya is used to maintain this information, and you see their current use cases here, along with the future use cases that they're hoping to build in upon today's announcements. As the team looks ahead, they would like to add some of these advanced capabilities that you've heard about earlier, and the creation of a macro library with predefined lists of questions and enhanced chat history management. Storing alerts, notifications, user preferences, and additional information within Firestore will provide a better user experience, building resiliency within the product, and scaling more quickly. Now let's look at our second application. Our Mayo Clinic TV is a product that redefines how we provide information to our on-site patients. It's delivered via set-top box in each of the patients' rooms, where we provide access to curated content relevant to that exact patient's experience. So we tailor their product learnings, their training on home health care or items post-surgery, specific treatments, or other things coming up. We also have meditation channels in our most popular channel. Our Falcon Webcam is part of our ecosystem, training our Mayo Clinic Falcons. But anyhow, we provide patient experience programming, general information, information on Mayo Clinic, history videos, and other specific targeted information to that specific patient using Firestore as our primary database. We also weave in some local TV channels and networks and on-demand complementary movies and music channels. So MCTV is using Firestore as its main backing database. As I mentioned, this is a location-centric system which tracks key interactions of the patient and movement within clinics. So if you started in one bed pre-surgery and you're now in another room post-surgery, that information follows you on your TV, and your tailored experience follows you also. All of that information is stored in Firestore and retrieved through some of these other items. Though the data points might sound insignificant, each of these represents a region in our facility, a department, room, and bed. We map these also to our real-time tracking system inside of our event tracking integrations and other tools within Mayo Clinic to ensure both patient safety and a tailored content experience that has a common component across all of our campuses. At the core of this MCTV system, we listen to HL7 events and bring in events off of our medical records, processing them in Cloud Run and maintaining them in the Firestore database for those location-driven items I just mentioned. Streamlining this, as you see, will bring current read rate to 70K a day, and we also have a write rate of 3K a day. Information being connected through the set-top TV is then delivered through Android, through the MCTV application, so it's using some of the Firestore components in the mobile and content space as well. Making this all possible without having to build these functions in and scale ourselves becomes very important as we begin to expand our campuses beyond our current boundaries and walls. Each of our campuses has an expansion underway, and as we change our building footprints as part of these planned campus expansions, our MCTV and Firestore can scale with them. Future use cases will provide also your care team information directly at the set-top so that as your treatment team changes throughout the day, your information is reflected for that staff as they rotate through shifts up on the TV screen that you see in your program area in your bed. Also, the items you see here, Fannie mentioned, they're going to make our developers very happy, because most of the items from our wish list for the regex search expressions, ability to search database and object properties, are already part of today's announcement. So I'm going to take some good news back home to Mayo for our developer teams. So as we prepare to close, the footprint and use cases for FirestoreDB are not just limited to these application teams. Our Mayo Clinic laboratory teams are looking to possibly leverage this within their lab ordering system, which brings some high availability into clinical areas scope for high trust. Our AI factory that you mentioned is already planning for additional functionality for AI and LLM capabilities, expanding current Firestore and Vertex AI uses. Finally, our own team inside of our products, our automation technology teams, are potentially levering additional building blocks and event-driven architecture, leveraging the power of Firestore, much like I shared with CAF, through the exploration of software delivery lifecycle and developer experience tools. These announcements today will help us drive additional value to our business areas. It meets us where we are and keeps us in line with future technologies. We're excited about the announcements and look forward to the journey ahead. I want to thank you all for having us, and I'd also like to thank the Mayo product and application teams for allowing me to highlight their terrific work. Before I close and hand it back to Vabev, I'd like to also thank the Firestore team who's been hard at work behind the scenes to make this all possible for us today. Thank you, everyone. Thank you, everyone. Thank you, everyone.