 Welcome, everyone. This is implementing a cloud detection strategy for effective incident response. We'll go through some quick introductions, and then we'll dive right into it. So I'll start off. Hi, I'm Dan. I've met a couple of you. So I'm a manager on the Security Transformation Services team, specifically in the Cyber Defense Group. We focus in the people processes element of transforming your cyber defense. Our big claim to fame is the Defender's Advantage. Please go down to the Security Hub. Go down to the Manion Cafe. Get some coffee. Get one of those books. If you find me, I'll be happy to sign it. I am one of the authors. And what we're talking about today is I want to save you some money, which my boss is sitting right there, and he's probably raising his eyebrow at me like, what in the world are you talking about? You're going to come to us and say, hey, what Google Cloud log should I have? What log should I prioritize in order to be secure, to be able to detect what I need to detect? And I'm going to tell you, it depends. Let's talk about your Google Cloud architecture. Let's talk about what kind of resources you have going on there. So if you don't want to spend money on that conversation, take some notes, take pictures of the slides, and you can probably do a lot of that before you have to come talk with me. Awesome. My name is Will Silverstone. I'm a senior consultant with Mandiant. And so my team within Mandiant, alongside Dan, kind of works with clients also in two ways. First off, doing incident response remediation. So we're coming in, helping clients during incidents, helping with containment eradication recovery from incidents. And then on the other side, we're doing kind of security architecture of building proactive strategies for preventing, detecting, responding, based on kind of lessons learned from those incidents. So I'll go through the kind of quick agenda, like Dan mentioned. We're going to go through kind of a detection engineering methodology with a focus on cloud. And so we'll go through kind of where organizations are struggling with this, and then what are the cloud threats that we need to be worried about as we're starting to build that detection strategy. And then kind of how we can build that detection engineering methodology around those. And then lastly, we'll go through kind of a maturity roadmap across logging, detection, and response in the cloud. So if you're used to doing detection and response in on-premise environments, there's kind of a few key areas we want to cover off on how cloud gets different. And I'll go through three of them, starting off with risks of kind of hybrid identities, where kind of our top focus, when talking about protecting cloud environments, is on identities. And especially with hybrid environments where identities are synchronized from on-premise to cloud environments, we have an opportunity of a compromise of an on-premise environment to lead to a cloud compromise and vice versa. The second one we see a lot is ephemeral cloud assets. So this idea of treating servers like cattle instead of pets, where virtual machines get spun up and down rapidly, get auto-scaled in and out. And what that means from the detection side is the virtual machine or the instance that causes, spins up an alert on the detection side may be auto-scaled out by the time you go and investigate it. And that kind of leads into the last one of, you know, EDR doesn't necessarily tell the full picture. In cloud environments, we've got an entirely different control plane that we need to have logging available for, and especially if we're talking about serverless or container environments where there just isn't really a place to deploy EDR, we need to have those logs and detections available to account for that beyond just EDR. So kind of why are we talking about this? It's an area that we, you know, see organizations struggle with that are running both on-premise and cloud environments. This is a stat from Google's State of Cloud Threat Detection Report from a year or so ago, where 63% of organizations here were using either exactly the same or most of the same approach to detection and response in the cloud than they are for on-premise. And what that looks like in practice is that organizations are largely not accounting for those three areas that we went through on the previous slide around identities, ephemeral cloud assets, and kind of over-reliance on EDR. So in general, kind of what are the common challenges that organizations struggle with relating back to those? Also kind of three areas that we'll go through from threat modeling as kind of the big one, where when we talk about threat modeling can mean a lot of different things, but really it's understanding what are the specific threats to my cloud environment and using that to then build the baseline of what do I need to detect and then using that to understand what logs do I need to have available. If you haven't done that threat modeling, it's very difficult to understand what do I need to build my detection strategy around. On the piece of logging enablement, oftentimes the logs required to do effective incident response in the cloud are not enabled by default. And so when we talk to clients about enabling these types of logs, things like network flow logs or storage account access logs, there's always a balance between what do I need the logs for versus the high cost of storing those logs, which kind of leads into the last one of detection versus investigation use cases, where organizations often use detections to justify enabling certain logs, but oftentimes investigation use cases can be just as valuable and also kind of candidates for cheaper storage. So we talked about the importance of understanding first, what are the threats to my cloud environment before starting to build off that kind of detection strategy. So we'll cover off on kind of common cloud threats first. And we have an article coming out in the upcoming M-Trends report where we go through kind of the common cloud compromise scenarios that we've seen in the past year or so, and we break those down into three key areas around identity protection, on-premise integrations, and an expanded attack surface. And so I'll kind of go through each of those, starting off with the weak identity protection. And this is really referring to areas where we see organizations are not properly mitigating the risk of compromised credentials. And so with the prevalence of, you know, phishing and info stealer malware and token theft, there's an increasing number of ways that we're seeing attackers steal user credentials. And for cloud identities, you have this risk where, you know, if an attacker can compromise credentials, they can largely reuse them from anywhere. And so we recommend to clients is to kind of implement controls that reduce the impact of those compromised credentials with things like, you know, phishing-resistant MFA and device validation and location validation of each sign-in. The second one we talk about is on-premise integrations. And so here we're looking at those kind of key integration points that could allow an attacker that's compromised an on-premise environment to move laterally into a cloud environment. And within that, there's two key areas of first one being kind of trusted service infrastructure or kind of tier zero infrastructure, if you know of kind of the tiering model, of, you know, thinking about the management tooling and platforms that are used to do support and administration of the overall environment. And because these are already, you know, trusted within the environment and they have wide-ranging permissions across the environment, they become perfect targets for attackers to abuse. The other piece of the on-premise integrations is, you know, just things like compute and network integrations where, you know, if your cloud virtual machines are domain joined to an on-premise active directory, if an attacker can compromise an active directory privileged account, they can use that to, you know, impact a cloud virtual machine if they share the same network, you know, just RDP to that system. And so this really comes from a cloud architecture where your cloud infrastructure is tightly integrated with your on-premise infrastructure and kind of the risk associated with that. Lastly, expanded attack surface. So when we talk about attack surface in the cloud, one of the main challenges that we see is not just thinking about attack surface as a network boundary, where in the cloud we have, you know, the risk of publicly exposed resources that can be accessible from the internet, but we also have, you know, the sprawl of keys and credentials, things from, you know, service accounts or long-lived non-expiring credentials that can get, you know, accidentally published in code repositories or SharePoint sites or, you know, Google Drive folders or kind of other insecure locations. And it creates this expanded attack surface where attackers can use to get a foothold into your environment. And so we'll go through a quick incident case study that Mandiant responded to it. I think kind of ties some of these cloud threats together. In this case, we had a service account that was created with project owner permission. So we kind of talked about long-lived access keys over permissive access keys. That private key of that service account was inadvertently published to a public code repository. And this organization was using Security Command Center. And so in Security Command Center, they're, you know, scanning public code repositories for credentials. And so it actually generated an alert here of, hey, you've published a key within a public code repository. Go and take it out. Unfortunately for this organization, an attacker got to that key first and was able to use that to authenticate to the Google Cloud project and eventually perform their, you know, impact, what they were looking to do of exfiltrating data from a cloud storage bucket. So this is where I'll jump in for a little bit. One of the things we see a lot of organizations do is they say, hey, the cloud is just somebody else's computer, right? So we have these VMs. We're going to put EDR on those VMs. Great, the cloud's secure. We're done. We don't need to do anything else. But what we leverage EDR for is insight-driven detection, typically written by vendors, sometimes written also in custom alerting from your detection engineers, but it's insight-driven. And our incident responders, our analysts, may look at the right-hand side and they're like, hey, I have a PowerShell alert on an endpoint, and I know that's bad because I have a native intuitive insight as to how this endpoint works. I've been working on a Windows machine my entire life. I'm IT-savvy, and I know Outlook should never spawn PowerShell, and it probably shouldn't have a hidden window with an encoded command. And maybe if I'm really brilliant, I can start to decode that base 64 in my head and know, eh, maybe this isn't good. But we don't necessarily have that intuitive native understanding of the cloud, especially within the security analysts just out of college. They are a new hire. They have not been working in the cloud. They don't necessarily understand all these different resources, computes, identities are, more so how they've been constructed and architected for your organization. So if you want insight-driven alerting, the very first thing you should be doing is turning on Security Command Center or AWS GuardDuty. Turn on the cloud vendor's version of EDR for your environment, because there is insights available from the vendor for you to take action on. And in this case, we had account has leaked credentials that is an insight made available from the cloud provider so that the security team has something to activate on. You could spend a whole lot of effort trying to come up with your own detections, trying to prioritize your own logs, but if you aren't leveraging Security Command Center, GuardDuty, you're going the harder way and arguably the more expensive way. So the first homework, go ahead and just turn this on. Easy mode. I'll take the... Oh, it's me. I'll hand it to you. Go ahead. So we're going to go through a roadmap of what it means to actually mature in this detection space, particularly within cloud. So we had different maturity milestones. If you want to take a picture of any of our slides, this is probably the best one to take a picture of. Take it back to work. Say, hey, boss, I came up with this great idea. This is how we're going to actually do our security in the cloud better and how we're going to iterate through it over the next couple of years. Feel free to say you wrote it. Happy to let you have that. But if you need help implementing it, give us a call. We'll be very, very happy to help implement it. And we're going to go through different elements of this. The top one is threat modeling. Threat modeling is the it depends answer. In order to give you an effective answer as to what actually needs to be logged, you need to know what the threats are actually going to be doing. So if you know what the threats are doing, then you know what detections you need, which defines the logs you have. That brings us into our detection engineering methodology. And I'm going to repeat what I just said. If you know what the attackers are doing, then you know what detections you need, which drives the logs you need to have. So often organizations start with logs. They bring in all the logs, and then they give it to the detection people or the security analysts and say, hey, here's all the logs. Build detections off of it. And the analysts are like, I don't know. What does this application even do? What are we worried about? So I want to flip that script. I want you to start with the threat actor's intent. What is the threat actor going to do with your cloud environment? What are they after? Are they after the data? Are they after the compute? Are they trying to install crypto mining into your containers? If you answer that question, then you know what you need to detect. If you know what you need to detect, then you can define those logs, define those signals that you need to bring in in order to drive those detections. This is the it depends. So when you come to me saying, hey, Dan, what logs should we prioritize? I'm going to say, well, let's go through this. And if you really want to pay me to walk you through this, happy to do it. Or you can do this ahead of time. And then we can speed through that process and get you those answers significantly more quickly. So let's talk about threat modeling. Threat modeling starts in different areas, oftentimes in the compliance level of a maturity model where you're just trying to, you know, pass the audit, there's not really much of a requirement for specific threat modeling. You may be using the generic threats that have been provided by the compliance provider, saying, yep, we've got malware covered. That's a threat. Yep, we've got identity compromise covered. That's a threat. But that's not really sufficient for the efforts, the workloads that you all are trying to put forth in the cloud. So level two is penetration testing. Hey, we want to understand a little better what the adversary is actually going to see, what it looks like, what they may be after. And we're not experts in this threat space. We're going to hire somebody who can emulate that threat actor and work through those processes and show us where we're weak. We're good at penetration testing now. We've been practicing that. What we're not necessarily good at that is taking the results of that penetration test and actually handing it to the security analyst group and say, hey, this is what you missed. The number of organizations I've seen that keep those penetration test reports secured, limited, for only the necessary eyes only, and we don't trust the security analyst to actually get better by reading the report, we need to be a little more transparent as to what the threat perception is going to be with your entire security team. Now we've got an industry-level threat profile. Okay, so you're working in finance or you're working in healthcare. This is where you start to work with the Mandiant Intelligence GTI team to say, who are the threat actors that are actually oriented around my industry vertical? And what are they after? What are their techniques? What do they focus on? Some of that is also going to be not necessarily threat actor specific, but opportunistic, particularly in the cloud space, particularly in the container space. Opportunistic threats don't care who you are or what data you have. They just want to make money. And if they can find a way to inject their code, their compute, their crypto mining into your cost center, they'll be very, very happy to do that. So understanding that those threats are out there and they may be targeting either you as an organization or you as in your compute availability really defines what your next steps are going to be. Then lastly, threat intelligence program. This is where you start to define specific to your organization, specific to your data, your crown jewels. Hey, what are we worried about? Because at the end of the day, there's a million threats and you only have the resources to address a hundred of them. You cannot boil the ocean, so you need this threat intelligence, you need this threat modeling in order to identify and prioritize what you need to address in order to secure your application, your cloud compute, your on-premise environments, your users. So I have a simplified cloud application here. Obviously, all of your clouds are significantly more involved than this, but what I wanted to highlight here is here's a very realistic tool, realistic service that somebody might build in the cloud and you'll notice that there is not a single virtual machine listed in any of these resources. So I'm going to hit home. EDR is not the solution for cloud security. It's not the solution for cloud monitoring. So in this case, we've built a application that's going to really scrape data from people who are submitting resumes, but for the resume submitters, they're going to get some feedback on how to improve their resumes. They're going to submit it through a web application. There is static web hosting, goes through content delivery network, and then there's an API interface with a cloud run function that's going to interface with a Cloud SQL backend to pull some pre-written recommendations and also dump in some data scrape from those resumes because data is king. We all, our organizations all love data. That's how we make our money. There's also this authentication piece. If you were in the previous talk, the previous speaker said that over 50% of the cloud compromises are identity oriented. Over 50% are identity oriented. And what Will was saying is we have this hybrid identity issue. So being able to administer and pull insights out of our scraper application is going to be highly tied to are these accounts being used by the right people and are they being used in the right way? I'm going to give it back to Will for a second just to talk a little more about identity. Yeah, sure. So yeah, basically just showing kind of what a common identity architecture usually looks like for, this is kind of for administrative access or developer access to your cloud infrastructure where we have an on-premise directory service, usually active directory. That's kind of the source of truth for identities, right? And then those identities are usually synchronized to an identity provider, usually a cloud identity provider, something like EntraID or Okta or Google Workspace. And then from there, traditionally we'd have kind of single sign-on to the cloud infrastructure. And so a compromise of either your on-premise active directory or that identity provider and taking into account the risks there can allow an attacker to then get access to your cloud infrastructure. And so that authentication piece that Dan was talking about in the sample application is key because you can put all these controls to enhance the security architecture of that application, but if your active directory gets popped and your identity that gets compromised there has administrative access into your Google Cloud project, then game's over just from there. So the identity architecture piece is a key component of that overall threat model. So let's get into threat modeling in a little more tactical arena. I'm a big fan of the Microsoft Stride threat model. I've been using it for a while. Microsoft had this published a long time ago. And it became more and more relevant as we moved more and more stuff to the cloud. The idea behind the Stride threat model, any threat modeling element, is as you are designing, as you are writing the application, you are starting to ask yourself, what would an evil user do? What would they be attempting to accomplish? And I like to use the term evil user stories because developers often operate in user stories. They build the UI. They build the workflows in terms of what does a normal, legitimate user want to accomplish, and how do I present the information, the interface, in such a way so that they can do that? Well, if I want to derive some security insight from my developers, the people who know the applications well, I want to talk to them in terms of evil user stories. So going back into our simplified application and knowing that authentication effectively should be assumed, compromised, in order to recognize where we want to detect everywhere else in the application, the basis of our detection is going to be who is doing what, what actually happened, and how do I know? So in other words, if there's changes to the website hosting in the Firestore, who did that? What did they actually change? Where did that authentication come from? If there is data that's being retrieved from the Cloud SQL interface, what was the query that actually executed? Who ran that query? When? These are not the type of logs that we're used to in the endpoint on-prem environment. And these are logs that may not be enabled by default because you did a generic cloud logging instead of a resource-specific logging. And the one I really want to hit on is the cloud run function. By default, cloud run functions, Azure functions, whatever the cloud version is, it logs the function ran. Maybe by default, you might also get, and here was the HTTP request that was passed to the cloud function when it ran. But this is custom code. In other words, you have to define in the cloud run function what it needs to log so that you can have the appropriate insight as to what it's doing. One of the things we're worried about as an industry, particularly in the LLM space, is prompt injection, correct? So cloud run functions are being used generally to process the data before it's presented into the LLM or in this case presented into a SQL server. Just like old school SQL injection, we now have prompt injections. To understand what that prompt was, we need to actually log it. To actually log it, that has to be codified in the cloud run functions code. So threat modeling is hard. Mandiant does offer a threat modeling service. We're happy to come in, help work through these evil user stories, define what the process is going to be that a threat actor would want to go through in order to achieve their actions on objectives. And in doing so, we will define the use cases, the detection requirements that you need in order to be effective in your monitoring for that cloud application, which then defines the logs that you need to bring in so that you can be effective in monitoring that application. So logging and aggregation, what does that actually look like? Great question. Awesome. So before getting into the, kind of zooming into the logging and aggregation section of the roadmap, I think it's important to cover off on two quick definitions of what we're referring to. Control plane, data plane when it comes to cloud environments. Control plane being the actions of administering the resources, creating, updating, deleting a new cloud resource. Data plane being actions related to kind of the running function of that resource. So the very common one is reading or putting an object in a cloud storage bucket. And the context that we're bringing this up in is logging related to the cloud control plane and to the data plane. So we'll get to that in a second. But kind of zooming in on the logging and aggregation portion of the maturity milestone. So level one is really kind of what comes out of the box when you spin up a new cloud environment. The logging is very much those control plane audit logs. So things like Google Cloud audit logs, CloudTrail, Azure Activity logs. It kind of gives you that management control plane access log. So a user created a new virtual machine. A user deleted an S3 bucket. And from the storage side of that, you know, the logs are generally available in the console with some sort of default retention, but, you know, probably not sent to a storage bucket, probably not sent to a SIM solution yet, right? So it's really what comes out of the box. You get some initial data, but you don't really have the ability to do any correlation, build any detections, or get any kind of granular detail. Level two is kind of starting to define what the requirements are for the organization. So putting together kind of policies and standards of what do we need visibility into in our cloud environments. And then maybe from the storage side, you've started centralizing those to a SIM solution, right? And then at level three is where, like Dan mentioned, we've started to do that threat modeling to really understand what logs we need in order to detect those threats that we've identified. And from the logging side and thinking about the control plane versus data plane, we've started to selectively enable those data plane logs to get that more granular level of logging that we need. So we can now see if an attacker accesses a storage bucket, what data did they access within it? And maybe we've done that threat modeling to understand here's our sensitive storage buckets, here's where my most critical data is, and that's where I need the more granular level of logging. And then level four, I would say, is really kind of continuous feedback to tune what logs are needed and how long to retain them and really understanding the use cases of what we need those logs for, whether that's for the security detections or maybe it's just we'll need them in the future to do a full investigation and kind of tuning where we're storing, how long we're storing those logs for. So breaking that down, logging at all levels, control plane audit logs, so these are the ones that are generally enabled by default, not too much that you need to do there besides, you know, centralizing them to a SIEM solution. Audit logs, CloudTrail logs, Azure Activity logs are kind of the main ones. Data plane audit logs, these are the ones that are generally not enabled by default and need to be configured, so things like network flow logs and firewall logs and access logs for databases and storage accounts. And then lastly, application logs where if you think about our sample application where we have, you know, serverless or containerized applications and the logs that need to be built into those applications to understand how that application is running because we're not necessarily going to have visibility into that either from the cloud control plane or data plane about kind of how that application is functioning. And so this also kind of ties back to the first slide of, you know, can't just rely on EDR. We need to have kind of the logging at all levels of control plane, data plane, and the application itself. I'll just quickly go through a sample attack of kind of how all those pieces go fit together where maybe, you know, initial access is MFA fatigue where the attacker, you know, sends a million push notifications to a user's device, gets them to accept it. Where would we see that? We would get that in the identity provider sign-in logs, right? So that would be something like Enter ID or Google Workspace of that user accepting an MFA push. Maybe the attacker then adds a new MFA device. We would get that in the identity provider audit logs of user X added a new MFA device from this location. Then probably logs into a single sign-on portal. So that could be in Microsoft and My Apps or Google Workspace to the single sign-on portal. Again, we would see that in the sign-on logs. And then kind of correlating that, so once they go to the single sign-on portal, maybe they click on the Google Cloud tile or the AWS tile and they access the Cloud Console and they start browsing around in there. Now, we need to have that ability to do the correlation from identity provider logs into now our control plane logs where we would see, you know, maybe they created a new S3 bucket. Maybe they created a new user to maintain persistence, but those kind of control plane administration-level logs. And then lastly, if they, you know, start to download data, exfiltrate data, that access to specific data within the resources, that's where we're not necessarily going to get the logging by default, and that's where we need those kind of data plane-level logs. So like in AWS, that would be data management or CloudTrail data events rather than management events. And Google Cloud very similar of access logs versus just the general audit logs. And so I think this kind of shows across the full picture of node logging at all levels of control plane logs, data plane logs, and then from the threat modeling piece, the kind of application-level logs that we need. So with that, I'll pass it back over to Dan to finish off the detection and response side. All right, so detection and response. So you've got the logs. Great. Now what do you do with them? So we kind of put both of these maturity elements in there because detection and response happens hand-in-hand. Your responders should be talking with your detection engineers and the detection engineers should be talking with the responders, and there should be, again, that continuous feedback loop. So again, level one compliance. Vendor tools, out-of-the-box detections, and you're leveraging general infrastructure staff for your response team. So this is typical. This is most organizations. As soon as they have security, they've purchased some security tooling, and now they're relying on those vendor supply detections. Hopefully by this time, you've turned on security command center. You've turned on guard duty because that's the easy button. Yes, it costs a little money, but it also saves a lot of money if you can interrupt these attacks because you got that insight-driven detection from a intelligent vendor who has already the signals in your cloud space. Next is best practices. Now you're starting to actually define your detection tools, and you're starting to orient them around your environment. You have initial use cases and playbooks, and I have that on the detection side. I have the playbooks on the detection side because I think it's incumbent on your detection engineers to work with those analysts to predefine what the response needs to be in order to drive those detections into something that's effective and functional. Then on the response side, you might have dedicated analysts or you might have an MSSP. More and more organizations are doing a hybrid solution between both. All the more reason why you need to have that documented use case and playbooks because your MSSP is covering multiple clients, and for them to have a tailored and effective response to your organization, they need to have documentation written for your organization. And then you have that initial incident response plan. We're practicing that. I'm not going to talk too much about that. Next, again, that industry threat profile, which means you're going to orient your detection and response around that threat profile. You're onboarding intelligence feeds, and you're leveraging those intelligence feeds to know something more about what happened beyond what the log just told you. So what do I mean by that? Hey, there's an authentication event for an authentication of an admin coming in from an IP address of such and such. Your threat feed tells you that that IP address is actually associated with a nation state that you're actually worried about, and it is known to have been used in other attacks. So that's context amplified beyond what the original log is going to tell you. Now, some log sources are really good about already having that context built in, particularly in the SSO provider space. Other log sources, they're not. So you're going to be dependent on your SIEM or your log aggregation tool of choice to help combine that context into the log and drive the alert because that's going to define your responder's response. It's going to help with that triage, low priority, high priority, true positive, false positive. You now have those established use cases and playbooks. They're beyond initial. They're practiced. They're validated. I want to emphasize that. Your use cases and playbooks are validated, which means they're tested and you can confirm that they actually work. You can confirm that your forensic tools, your insights, your training is actually applicable to the environment as it's architected. On the response side, you probably now have a multi-tier analyst system, tier one, tier two, tier three, and you have a very established IRP that has been practiced, exercised, tabletopped, renewed, et cetera, et cetera. And then finally, full on the threat intelligence, we have purple team activities. And by purple team activities, I do not mean, hey, let's try something random that's malicious that I read in this article the other day and see what happens. What I do mean is I'm going to emulate a threat actor that we're worried about. I'm going to emulate an opportunistic threat that we're worried about and we're going to see what happens in our detection environment. Do I have the signals I need? Do I have the visibility I need? Do I have the response plan I need? Don't just tabletop it. Practice it. Execute it. And then you're taking those response learnings, ideally proactive, sometimes reactive, from actual incidents, and you're reincorporating it back into the entire platform. And what does this have to do with detection in the cloud? Because this is going to be how you find out that you're missing logs. Because the logging environment in the cloud is changing daily. The resources that are available in the cloud are changing daily. Your own cloud architecture is changing daily because that was one of the big proponents of moving to the cloud, that flexibility. I was talking with one of the individuals here just before the presentation, and he was saying, hey, we did this cloud thing, and we want to do it better because it was a little too flexible. It was a little too agile. And now we want to be more prescriptive in how we're managing the cloud. And that's critical. So the security plan, this is effectively your security plan, is your path to level up through that maturity level. So wrapping up, I want to leave you with homework. Because this isn't a good presentation if you don't actually go back and do something with it, right? So I want you to model your threats. Even at a low level, even at a unpracticed level, I want you to model your threats and say, all right, if I was a hacker, what data would I want to steal? What data would I want to tamper with? What identities would I want to compromise? What non-repudiation type of thing would I want to repudiate against? In other words, is there activity that I'd want to be able to say, hey, that wasn't really me? And then you have an initial list of threats that you've defined. So now you start to engineer the detections to intercept those threats. And that's going to be a brainstorming session. All right, I'm worried about the threat actor doing this. What could we do? What changes to the environment? What logs might be available in order to see that behavior? For example, one of the initial thoughts with ransomware detection was process compute or container compromise. It's expensive. One of the most common ways of discovering that containers have been compromised is the bill went way, way, way up. Okay, that sounds like a signal. The bill is normally here, and then today it went here. Maybe one of our detections should be based around billing, which doesn't normally sound like a security signal, but it's something you derived from this threat modeling process, and then you defined the detection that you wanted, and then you drove into the logging. And I have it listed here, enable, because not all the logs are default enabled. That's what Will talked about. Make them. If you've got custom code running in the environment, your custom code needs to actually make those logs. It needs to define what's being done by who with what authority. Save those logs into some sort of data lake, sim, etc., and then search those logs. Enable, make, save, and search the logs to support the detections that you defined by modeling the threats. All right. Again, feedback. Really appreciate it. Let me know how well we did, how poorly we did. If you have any questions that we didn't answer, that would be great to know because then we can renew this presentation for the next time. All right, everybody. Thank you very, very much for coming. Really, really appreciate it. Thank you.