 Really great to have all of you here. This session is going to be about the future of AI, and then we have Target telling us their story of how they have transformed their retail experience using AlloyDB AI. So let's first get started with some very quick introductions. My name is Amit Ganesh. I'm the VP of Engineering for Databases here in Google Cloud. Joining me today is Sudha Adarsh, Senior Director of Database Engineering at Target, and my colleague, Barry Morris, who will be joining after her, who is the VP of Product Management for Databases in Google Cloud. Now, operational databases, we all know, play a pivotal role in AI. They contain the most critical enterprise data and are the foundation to build Gen.AI apps that are accurate, relevant, and grounded in your enterprise truth. Now, we already see a number of customers building generative AI applications that are helping accelerate customer engagement, and there's a huge momentum and impact that is being had across industries. If I just take two examples, banking and retail, each of these industries sees several hundreds of billions of dollars of upside from using AI. Now, why might that be? The rich, accurate, and contextual customer experiences that Gen.AI apps provide is helping enterprises create differentiated value for their users. Now, despite that, business leaders are worried about the infrastructure they need to run AI and data. So, I am excited to share with you today that we have built the industry's leading AI capabilities into Google databases to help you do just that. And then later on, Sudha will speak about how Target has already deployed AlloyDB AI in production at scale to greatly boost customer engagement across billions of their users. For Google's own apps, we have infused our products with AI for richer and more helpful customer experiences. All of Google's billion user products make use of our state-of-the-art Gemini models and run AI in production at scale. For example, Google Maps utilizes large models to deliver contextually relevant results for you to use. Google Lens, if you have used it, uses AI to expand search to take multimodal input. Beyond text, you can enter images and video to truly transform the search experience. Now, to power these apps, Google has been leading the frontier of research in AI for more than a decade. You're already aware of the Gemini models and Google's pioneering work in large language models. You heard yesterday about our next-generation TPUs that power those models. And then I want to give you maybe one other example of one of these AI advances. For more than a decade, Google Research has pioneered state-of-art vector search for use in our own products. So every time you go to Google Search or you get a recommendation on YouTube, it is our vector search capability, the state-of-art vector search capability that is serving you those results. Now, these advances in AI that Google has achieved have unlocked entirely new possibilities for apps, enabling seamless integration with a diverse set and types of data, and creation of richer, more intuitive, and contextually relevant customer experiences. Now, let us see how we are bringing these state-of-the-art AI innovations to you so you can similarly build great new AI apps. So first, Google Cloud has the most comprehensive portfolio of database products to meet every application need, from in-memory databases such as Memory Store for Redis, to key-value stores to document databases, to industry-leading SQL databases, such as AlloyDB and Spanner, that run at any scale and meet all the needs of your mission-critical apps. Now, to enable apps to leverage AI, we have infused AI directly into databases through built-in support for state-of-the-art AI models, next-generation natural language support, state-of-the-art vector search, agent space, and agent-tick framework integration, and many other things that we will share with you today. Now, all these innovations are really enabling you to build intelligent AI apps with your trusted enterprise data. Now, let's focus on AlloyDB. AlloyDB is our 100% Postgres-compatible database that brings the best of Google to Postgres, enabling you to have industry-leading performance, price performance, availability, and a slew of enterprise capabilities. Traditionally, the two main pillars for databases have been transaction processing and SQL, which is analytics. Now, in transaction processing, AlloyDB is up to four times faster than standard Postgres. It is the fastest Postgres database across any cloud. Similarly, in analytics, AlloyDB features a columnar engine built into the product that provides the world's fastest query performance of any Postgres database, up to 100 times faster than standard Postgres. Now, I am excited to share with you today that AlloyDB is the first operational database to add a third new pillar to the set of core pillars that form the foundation of databases. We believe this is a fundamental new focus area for databases for years to come, and that is AlloyDB AI. We have seen tremendous adoption of AlloyDB AI already. In just the last year, since we announced state-of-the-art scan vector index and vector search in AlloyDB, we have seen seven-fold increase in consumption of vector search in our products. And a little later, I will have Sudha share with us how they have deployed it internally at Target as well. Now, this year, I am thrilled to share with you a step-function advancement in AlloyDB AI. AlloyDB now features the most comprehensive set of AI capabilities in the industry, while each of these capabilities is also state-of-the-art in their individual areas. So let's just dive in. First, in partnership with Vertex AI, we are announcing that agent space and agent development kit that we announced yesterday, you can use them to now search for structured data in an AlloyDB database. And now with that, with that built-in integration, you get the full power of Google-quality search and geminize reasoning capabilities and not just against documents and other unstructured data, but also against operational structured data in your live database. Second, we are introducing the next generation of our natural Lackavage engine in AlloyDB that enables interactive text and voice-based experiences for you to add in your applications. Continuing on our leadership in vector search, we are now the second big innovation that we are launching this year. We are launching industries' leading performance not just for vector search that we announced last year, but for vector search combined with structured data in SQL. I'll talk a little bit more about that in a moment. And then the one last thing that I want to speak about, and it's one of the really amazing developments, is what we are calling the AI query engine. For the first time in the history of databases, specifically operational databases, we are bringing the power of AI to the standard query language so that every database developer has the full power of Gemini at their fingertips. We'll give you some examples and show how exciting this is. So why don't we jump straight into that? So this is the, like I said, the first database in the industry to feature an AI query engine. We're bringing the power of generative AI to SQL. So now you can write SQL queries where parts of the SQL query get executed in an AI model. Behind the scenes, you don't see it. You're still writing the SQL, as you can see from the example on the right. With AI query engine, we have built a set of query operators into SQL that invoke Gemini AI models to execute and operate and run those SQL filters and join operators. So for example, if you look at the example on the right, something would be really hard to do in SQL if you didn't have the AI query engine. So of course, I can search for a product that costs me less than $50. That's a straight out standard built-in query filter predicate. But what if I also wanted to look for only products that are coming from a well-known skincare brand? Well-known skincare brand is typically not known to database schemas unless I took all the effort to figure out what constitutes a well-known brand and add it as a column in a database. Now just imagine the challenge of this. This is just one example. You can ask other queries in plain English in your applications and you would not have been able to pre-compute this in a database. Now, as easily as that, we have this AI namespace where you can just simply say AI.f, put your column name, in this case it is brand name, in the table, and just say, hey, show me all brand name values that are well-known brands in the skincare industry. And suddenly, SQL, by working together with Gemini, executes those SQL statements as if they were a standard SQL and produces the results for you to consume. This, I believe, is one of the fundamental step function changes in the history of SQL for the last 50 years where the power of foundation models is transforming the capabilities of the standard query language. Now, in addition to doing filters and joins, which are standard query things, imagine now you could do some new, even newer, more exciting things beyond that. So we have introduced, and I will speak about that next, we have introduced three new models, three new AI models that are now integrated in SQL that give you even more flexibility and power. So let's get to those. So first, we are introducing a semantic ranking model in SQL. This semantic ranking model, think of it as, is your companion who you can ask in SQL questions about the relevance of data. So if your SQL query, let's say, returns 100 rows of related products, now I can do an additional order by and say, hey, by the way, this order by, I want you to do this using the semantic ranking model. What it will do is it will compute all the 100 results for relevance to your query and then give you advice on which are the most important ones. And of course, it does this using a scoring function that you can easily put in an order by clause in SQL. So you can see this is really powerful. Now, in addition to adding this powerful capability to SQL, the really great news of being with Google is this semantic ranking model is also the state-of-the-art model in the industry. Proven by the standard Bayer benchmark, it is the number one model. You can go on Google and look for it. It's the number one model in terms of accuracy and relevance. That kind of brings me to my next state-of-the-art model. We are introducing a second state-of-the-art model in AlloyDB AI. We are introducing what is known as Gemini Embedding Model. This is a model that we just launched in March, which provides the highest quality embeddings across any embedding model in the industry. As proven, through the results from the industry standard MMTB benchmark, in addition to being a really powerful text embedding model, it also supports more than 250 languages. So it's a multilingual model. So no matter where you are in the world and what your users are using to interact with your systems, now you can use this model in SQL to find relevance. So for example, there's a question that the user asked saying like in French, like give me a specific skin care product. Now you can find products in your database that are in English that happen to match that query in French. Now, we always knew that you wanted to, you would probably want to do many of the things that we do ourselves when we add multiple modalities in our applications. For example, you may want to work with images and videos. Typically, databases are working with structured data, maybe text with natural language. But what if we enable the ability to use all the modalities that Google uses in its own apps for any of the applications that you're building? So with that in mind, I'm excited to share that we are also launching a multi-modal embedding model in SQL. With this multi-modal embedding model, as you can see in that graphic on the left side here, you can have an image and a piece of text both mapped into the same vector space. So now when you're doing search, your application might provide, you might take a picture of something and provide that picture to the database and the database would retrieve text for you. Or you can provide text and it will retrieve images for you. So now suddenly, the modalities with which your applications can interact with your users can be truly transformative. That brings me to the second big area that we are announcing, which is this next-generation natural language. We all know SQL is very powerful and all those capabilities that I spoke about that bring the power of Gemini and AI into SQL really open up a whole new world for you. But what if the kind of interactions that you want to enable are also natural language interactions, not just structured query interactions? For that purpose, we are now introducing in AlloyDB a second adjacent interface to the database which is based on natural language. And through innovations that we have done together with research teams at Google, we actually are now at the state of the art in providing highly accurate results for your natural language queries surfaced through AlloyDB, but at the same time, results that are both flexible so that they can use the power of the natural language, say English or French, to answer your queries, but also secure and privacy preserving. There are a set of really powerful capabilities here that are available in preview and we would love to invite you to participate on them. Next, now that you have a natural language interface in the database, wouldn't it be really nice if agent space and agent frameworks like the agent development kit that we mentioned yesterday, if it just came integrated with databases so that you can work with structured database data using natural language. We have done exactly that with agent space assistant and agent development kit from Vertex AI. Now you have immediate integration with the AlloyDB database. Now you can use both these products to securely search AlloyDB as well as build custom agents for your own agentic workflows. Now the crucial advantage of having a direct integration is that agent space users can get access now directly against the real-time data that you have in your database so that when you are interacting with these agents, you now get accurate and up-to-date information that is reflecting the true current state of your business. That brings me to the last but a really important area that I want to share with you. Last year, we launched the Scan Vector Index that I mentioned earlier, which is the state-of-the-art vector processing capability in AlloyDB. I'm thrilled to announce that this year, we have search, vector search, combined with SQL filters in AlloyDB, that also has reached industry-leading quality and performance. And we have done that across the entire selectivity spectrum. So whether you have low selectivity filters, mid-selectivity filters, or high selectivity filters, because, you know, query processing actually has lots of variants, we ensure that we automatically pick the right execution mechanism to ensure that you get the highest quality and the highest performance for your hybrid SQL plus vector search type of queries. To give you a little more insight into that, imagine if you have a mid-selectivity query. So you have lots of rows coming out of your filters. And now you have to also use a scan index. What we have done is we have created a collaborative system that runs the filters and works collaboratively with vector search to ensure that you get the highest quality results. Now, we didn't stop there. We knew that in the real world, data can be really varied. And static decisions that often database optimizers take may not be perfect. So in preview, we are also launching what we call adaptive query filtering, where in runtime, we learn the selectivity of the query for the exact query that you're executing with the right bind values and then dynamically adapt the query plans and the execution mechanism underneath. For example, we may end up using the columnar engine to go accelerate your vector queries. So as you can see, with the work we have done with scan vector search index last year in collaboration with Google Research, together the work we are launching this year with SQL along with vectors, we are now providing you with two state-of-the-art capabilities around vector search in the AlloyDB database. With this vast array of capabilities, there is no better validation of it until we hear it from a customer. So now, please welcome Sudha to share how they have infused AI into Target.com's retail search experience and transformed Target's ability to reach their customers. Thank you, Amit. Welcome all. Good morning. I'm Sudha. I manage the operational databases at Target. So before I start, how many of you shop at Target? Wow. Great. So I don't have to talk about the shopping experience you will have at the stores. The first part of our opportunity was how do we bring, at least to start with, that kind of experience in the digital world and more, right? And when I say more, it's about how do we get closer to our, we call our customers as guests, guest preferences in our digital world. So we start with search. And what does search mean to a person who's doing shopping in a digital world? It's the first touch point till you build that experience till you do the purchase. So it's critical and how you, you know, deliver that. So search at Target means that you bring in relevant, faster, seamless experience and be able to engage the guests all throughout. So our digital journey began a long time ago and I'll talk a little bit about that. But let me start with why does it matter? Why does a digital platform matter for Target? Our digital platform is 20% of our business. It really matters. And when I say it matters, it is important for us to deliver more contextual, relevant results for our guests when they shop faster and obviously and obviously you don't want no results when you're searching in the digital platform and then more personalized and contextual products are provided and basically you're able to deliver a smarter shopping experience in the digital world. Okay. So what is hybrid search? At Target, we've been working for some time to build this capability of what we call as hybrid search and it means two things. I mean, it means two capabilities coming together. One is a straightforward keyword search which is traditional and other is what we call a semantic search which is more about meaning-based search which is where we talk about contextual relevance and everything. So we've been building this for some time on the capability side and what we wanted next is a database. So we needed to choose a database to deliver this capability that we were building at Target. So at Target, innovation is at core of everything that we do and as part of that, experimentation is the key part. So we evaluate our solutions, multiple options looking at what's the need and what's the performance need in this case of the database and then compare it with multiple options. And we started with some guiding principle that we'll start with Postgres compatible and we needed AI capability to build that guest experience. And let's go back to the problem that we started on the digital world. I'll not say problem, it's an opportunity to stay closer to our guest preferences which is seamless experience, faster delivery, relevance, personalized experience and contextual buy. Right? And including the engagement in our digital experience. So I want to call out that AlloyDB fit in that completely for everything that Amit was mentioning. I want to call out the scan index and filtering was the two critical features that helped decide for us to, for our digital search for AlloyDB. Okay, so key outcomes, pretty much everything around performance on databases. But I want to talk about the second point where I'm saying that it enhanced the natural language search by 20%. What does that mean? It means that, okay, today our guests come to our digital platform, they are able to search with like a natural language queries like, okay, give me an eco-friendly bottle, which is less than $20. So we saw a 20% increase in such searches. And we're also talking about when you're searching the results, you always get a relevant result. So that increased by 20%. And we are also talking about the engagement of product discovery and the sortment that options that were provided for the guests increased by 20%. So that's what it meant. So great geek outcomes and what it means from a business terms. We have more shoppers finding what they want. They're buying more of it and they're seeing obviously relevant results faster and fewer not found from an experience standpoint. And if you're a retailer, it means business metrics are on. Conversion rate is up. You have a revenue uplift and your click-to rate is increasing. Okay. So I want to demonstrate this if you go to target.com. So I want to demonstrate before and after. So before. Before we implemented hybrid search with Alloy DBAI. If you go and broadly search Home Decor for one of our brands, it gives you a very specific result. After that, you can see that there's a diverse and relevant set of results coming out as part of the search. Let's take one more example. So let's say I want to shop for my daughter, a toddler dress, and it gave me before. Before this implementation, you can see the results on the left side. On the right side, it is identified that I stay in Minnesota. It's winter and then it's looking at seasonal relevance and showing long sleeve dress type. Okay. So what's next for digital search at Target? I'll quickly talk about a couple of things that many things that's coming. What Amit said is pretty exciting. And one of the things around ranking, the semantic ranking, and let's talk about the previous example. what it means if you're applying on top of the toddler dress, so let's say we have 50 results that's coming with this relevance. It's ranking based on my insights, deeper insights around my past history, and my preference about it should be a red dress and something less than $100. It's going to pop up the first 10 results, which is my preference. Right? So I don't have to go and look at 50, 100 results and figure out. It's telling me I think this is what you prefer, Suda. That's exceptional. And the second part is the natural language and the query. It's amazing. From an engineering mind, I can only look at the superpower it's going to bring in. Just look at it this way, right? If you are in developer building AI applications, you go to the database, you don't have to leave the database stack to do anything. You are running your models then and there. And then all the complexities of retrieving data, applying your model, do what you want, is all taken away and is at the data layer. And what you get is amazing. It's the real-time reasoning right there. And what this is changing is the way our architectural designs are being changed. So it's AI plus vector plus SQL. That's an amazing functionality that we are looking for over to. And thank you very much for Google for partnering with us. Thank you. And I am calling Barry for the next part of the session. Thank you. Thank you. Thank you. Thanks, Sula. Super impressive. Super impressive. Getting the 20% improvement on search accuracy in that way. and as Sula says, actually seeing that relating directly into actual retail sales. I think that's an extraordinary thing going from essentially traditional search into hybrid search. So what I wanted to do is to just spend a bit of time and it went through this AlloyDB AI and the things that we're doing there. And I wanted to make sure that first of all I provide some context for why we're doing that. Really all of our context when you talk to us about our long-term strategies, where we're going, what's our vision, it's not that much of a surprise. It's the data cloud. And what is that? That's a set of database services, a set of analytics services, AI, BI, layered on top of the Google infrastructure, which is battle-tested, again, as Amit said. And so taking all of that and everything that you've seen us announcing really is something that's layering on top of that in some way or other. I hope to give you some context for all of that as we go through. But I wanted to start with this topic of AI. That's really the sort of central issue for the session and the topic for the session. And people ask us, why are you doing this stuff in a database? Isn't a database a thing of record where I can set some SQL queries or non-SQL queries? And that's it. And our answer is, no, that's not it. There's a change in the application stack and there's a change in database role. And we think that this is the biggest change actually in database and their role in applications in decades. And so it's all about this emerging application stack and what is that all about. The essence of it is that it's about essentially AI plus data. And we've all seen some applications like this already, most of them not particularly sophisticated or mission critical. But applications where you're, they might be chat bots or something like that. but where you've effectively got a bit of orchestration, you've got an LLM and you've got a database and maybe you can do some actions like send some emails and stuff like that. Is that going to be a pattern going forward? Yes, of course it is. The question is, how big is that pattern? How important is it? What's the relationship of that to traditional applications where people are writing a lot more business logic and so on? And essentially what we're saying is that we expect databases to be much more collaborative with AI systems than they have been in the past. And so it's not for the AI system to do all the clever stuff and for the database that's got all the data of record and all the ability to analyze that data and to process that data. It's not for it to sit on the side but for it to be a collaborative partner in that application. This is particularly true in the context of agentic applications. And so what does that mean? It means that you do want the database to speak the same language as the AI systems which by the way don't speak SQL. Well you can ask them to speak SQL but they're not very fluent. It's the database that knows about SQL and it knows about its schema and it knows about all the context of it. What it doesn't have is the ability to talk to it in terms that the AI system knows how to do. And that's what the natural language stuff is all about. Don't have time now to go into all of it and I know Emet covered quite a lot of it but it's not just about NL2 SQL as such. It's also about all these other things. It's about intent characterization so that if there's ambiguity in your natural language which there very often is the database needs to come back and say hold on a minute you could mean A or B which one is it? So it's all that kind of stuff. It's also that the database needs to be able to participate itself in making these queries on the AI models. And so again we talked about that earlier. Why is that? It's because you're wanting the AI systems to be delegating certain things to the database to say you go off and do this stuff and I know that you're able to go and ask the LLM something if you need to. And it also is about this ability to do AI style queries, nearest neighbor kinds of stuff, similarity search kind of stuff, all those things that we're talking about. So you are going to see us working on this, big believers in where this is going, big believers in the fact that databases are going to move on in this particular dimension. A related topic and it turns out to be a topical topic is the issue of MCP. Model Context Protocol. If you haven't heard about it yet you're going to hear about it soon. Everybody's very excited about it in the context of AI and particularly on the client side. What that means is AI applications of one sort or another that can connect to data sources and get them to do things. And what there hasn't been is a lot of development on the server side which is delivering the thing that that client can talk to. And that is what we're announcing here. We're announcing an MCP toolbox for databases. It is the ability for MCP applications to access tools as they call them to do things. I'm going to say a couple of things about that if you're not familiar with it. A tool in the MCP world is essentially an API like a network API and in the context of a database it's essentially a query. So if you want to think about this in simplified terms it's basically a thing that allows you to write a simple configuration file with a SQL query in it or a natural language query in it for that matter and for us to take that and turn it into a network API so that that API could be tell me what the current status is on my checking account and the query will be run in the background but you don't need to know any SQL you don't need to know how to connect to that database MCP takes care of it all. So that's what that is all about. Another piece of that data cloud that I want to talk about is about Firestore and some work that we've been doing on Firestore. Firestore of course is super, super successful. It has I think around 1.3 billion users a month. That's on a planet that has 8 billion people so that's a fairly decent number. A very, very successful system. And it's a JSON-based database and so we've got lots of customers using it. The request was that there's a lot of tools, a lot of ecosystem, a lot of skills, a lot of things out there around the MongoDB APIs. And so can Firestore support MongoDB APIs? And the answer to that is yes. If that's what you need, we'll build those and we have. And so what this is is an announcement that customers now have a choice if you're going to build an application that uses MongoDB compatible APIs and semantics and so forth, you've got a choice. You can use MongoDB. They're a great partner of ours. You can also use Firestore if you want to. And of course, Firestore has many characteristics that are quite attractive for certain kinds of applications. So providing customers for choice on that is another puzzle piece in that data cloud that we're talking about. We would say that Postgres is emerging as the leader in open source SQL databases. I think if you look at what's been happening over recent years in terms of even things like Stack Overflow surveys and so forth, there's just been increasing popularity of Postgres. Many of our customers that are running commercial databases are looking for at least some of those databases to move to Postgres. How do you do that? Historically, we've had a tool for doing it. By the way, the easy part is the data, moving the data. The hard part is how do you map schemas, how do you map database resident code, and all of that. And we do have algorithmic, deterministic ways of doing that. We've had that for some time. It's very good technology. It's got some limitations. What you're seeing us do here is to bring AI into that to give us that last mile capability and allow people to move SQL server applications to Postgres much more easily. This can support both Cloud SQL and AlloyDB, which are both Postgres-supporting. Excuse me. One of the things, the convergences that are happening in this data cloud is data model convergence. And this is an interesting thing because a few years back, and I've spent too many years in the database industry, but a few years back, if you talked about multi-model databases, people would say, why? They're no longer saying that, and primarily because of AI. And so we announced last year that now Spanner supports Graph in addition to supporting SQL. Of course, it also supports vector search, it also supports search, and it also supports key value. So Spanner has become very much this multi-model database. Why? Because people that have got a SQL application are wanting to add graph functionality, are wanting to add vector functionality, and so forth. What we're announcing here is visualization for that. Why do you do that? Well, because with SQL and with tables, it's pretty easy to imagine tables. It's easy to visualize tables. It's not easy to visualize a graph. Having a tool to do that is super important, and so we're announcing Spanner graph visualization. If you're using graph technology on Spanner, we recommend that you take a look at that. Jumping back into infrastructure conversations, this is a super interesting one if you happen to have an interest in infrastructure, which is that Google has been working, as you may know, on our own ARM-based microprocessors. And so the instances that you can run our databases on today are Intel-based, and they're great products, but in the background, we've been building our own microprocessor called Axion, and so now we have the C4A VMs available and available for both AlloyDB and Cloud SQL. This is extraordinary technology. We were thrilled when we saw the results in the database teams because, as you can see, in terms of price performance, it delivers 50% better price performance than the current N-series, which are the Intel-based instances. Also, as compared with a major competitor's own ARM processors, which are called Graviton 4, you're looking at up to 2x the throughput for similar workloads. So, really an amazing thing. If you are running Cloud SQL, AlloyDB, or you're looking to do so, please take a look at the C4A VMs. So, we announced a great partnership with Oracle last year, and we've been building on that. What we're announcing here is that we've extended that in terms of Oracle products. So, Oracle BaseDB, Oracle's Exadata, X11M, an expansion of our regions by 11 incremental regions where it's supported. What is this about? It's about customers that are running Oracle. They don't want to change it. They don't want to do anything else. They do want to be on the cloud. They do, on the cloud, they want to be connected into Google's other systems, applications, and so forth, and that's what this is. So, a big, big, big piece of what we're doing in terms, again, of that data cloud that we're building. We've heard all this wonderful stuff about AlloyDB, the piece, and I don't know if there's anybody in the room that doesn't know this, but one of the things that we did with this is customers said to us, love the product, but it's not available elsewhere. And so, AlloyDB Omni is about it being available elsewhere. You can download it, you can run it on your laptop, you can run it in your data center, you can run it on other clouds in all sorts of self-managed fashion. We also announced last year that we were doing a partnership with this company called Ivan. Ivan does managed services of databases, and they are announcing, right now, they're announcing availability of Omni on the three major clouds. And so, if you want a managed Omni service, AlloyDB Omni service, they can help you. And then, just to turn to database center, so, we always, I don't know if it's a mistake or not, we always tend to talk about this last, and our customers get very excited and wonder why we didn't talk about it first. When you're talking about a data cloud, one of the most important things is a single pane of glass aspect of that. And that's what this is. So, this is basically fleet management for all of your Google managed databases, and it's AI driven, so it can give you recommendations on this or that instance that you're running. Is it under-provisioned? Is it over-provisioned? And so on. Again, announcing GA of that product today, this week. Do take a look. So I just wanted to kind of finish with going back to this. All of the things, all of the announcements that you're seeing around databases are really all part of this big picture. Central to that, and you would have seen it in the keynote yesterday, you've seen it again today, central to that is our big investment in AI, because we think that database AI is really a sort of a game-changing thing. And then, just to leave you with, if you do want to go further into LOADB, there's some QR codes you can chase down there. Also, we have a database migration wizard that you can take a look at, and that's a thing which you can walk through, and it can help you understand which Google database to use under which circumstances. So with that, I want to thank everybody, and thank you for coming.