 So we'll keep it interesting so that you have the right appetite to fulfill the database insights as well as get a good lunch. Myself, Gurmeet Goindy, I'm a product manager for IDB and a few other services. It's a pleasure for me to be joined with Ravi Moorthy, the man behind the product. He built it from scratch and it's an absolute honor for us to have Sanjeev from Manhattan Associates and Giuseppe from Intesa to share their journey and their perspective on IDB and what that has done for them. We started this journey almost six years ago, so we'll talk a little bit about what brought us here, why did the world need one more database and why did we build it? So we went out on this journey six years ago with the intention to build the world's best Postgres. That was a goal. Now, how do you define what's best? Some of you will say, well, a best database has to be the most price-performed for us. And that's where we said, okay, we built LIDB to be the most price-performed Postgres out there. Right now, we are two times better price-performance than self-managed databases. So if you're self-managing Postgres on any IaaS and you move that workload to LIDB, you will save money. Never happened before in the history of open source. Second, you will say for a database to be a real database for me to serve machine-critical workflows, business-critical workflows, high availability is extremely important to us. And we said, you're right. So by default, when you configure LIDB database, you get four nine SLAs, always RPA zero. We manage fast failure. We do all you need to do for recovery of the database. And we give you near zero downtime updates, sub-second downtime updates. Only possible commercial databases, we brought that to Postgres. Last but not the least, security is the key aspect of all machine-critical, business-critical applications. And we brought the goodness of Google security to all LIDB and made sure that you have all the capabilities you need to manage a database seamlessly in a very secure manner. Our promise was, let's take the goodness of Postgres, the community it has, the openness it has, the momentum it has for the developers, back it up or forge it with what Google does really best. And we brought these two things together, which made the real Alloy, the best of Google and best of open source. And that's what gives us the name LIDB. One very unique thing we did, which you will not see any cloud provider doing, is to release an on-premises version of a cloud database. Why would we do that? Our goal was to meet you where you are and provide you the best of goodness of these two worlds that we are building for you. And that was the birthplace of LIDB Omni, and you hear a lot about this from Ravi as well, in which we give you a downloadable version of LIDB that runs everywhere. It runs in Azure, it runs in AWS, it runs on-premises, it runs on a laptop, it runs on Google distributed cloud as well. And today we also announced a partnership with Ivan so you can get a managed service on these clouds running LIDB as well. Very unique, once-in-kind in the industry. How did we do this? No better person to tell this than Ravi, so I'll ask Ravi to come on over and take us to the journey of LIDB. Thanks, Ravi. Thank you. All right. As Gigi said, we set out with a very lofty goal of building the world's best Postgres. And I think today you'll hear the facts that prove the theory. And really when we started off, we wanted to build a database that is really for all of your workloads. And today, LIDB is by far, and as you will see in the rest of the slides, the best database that you can pick, not just for your transactional workloads, that is our bread and butter, of course, but also for your OLAP reporting analytical-type workloads in a HETAP type of a scenario, as well as the new emerging set of applications around Gen.AI that need the highest level of vector search capabilities as well. So it's really the one-size-fits-all type of a database here. Before I get into the details, just some headline numbers that you may have heard before but worth looking at again. AlloyDB today provides four times higher transactional throughput compared to open-source stock Postgres, and this is on TPCC benchmarks. We provide up to 100x higher performance in terms of latency for analytical reporting-type of workloads thanks to some deep innovation we have done in the Postgres engine. And last but not the least, when you're building Gen.AI applications, you want to store vectors and search them in the database. We provide some unique indexing capabilities that give us four times faster vector search, ten times faster write throughput with a much lesser memory consumption. So really fantastic results here. I just want to touch a bit on the price performance that Gigi spoke about. This is something that is very, very important for all customers. Thanks to the superior architecture that we have built AlloyDB with, and I'll speak a little bit about that later, we are really much more efficient in terms of consuming the resources that are in the machine. So you get a much higher performance. In this case, like with an 8 vCPU, not only do you get a higher performance than a 16 vCPU stock PG, but you actually end up paying half the cost. So really fantastic price performance. And that is on top of all the things that you get from a managed service. So when you think about self-managing Postgres versus having a managed AlloyDB, we think that the choice is really clear. So before I go deep dive into some of the recent work that has happened over the last year, just a reminder about how the architecture of AlloyDB sets it up for us to be able to deliver all of these amazing capabilities. It all starts with an architecture that cleanly separates the compute layer of the database from the storage layer. And you've got a primary compute, a standby compute, and any number of read instances that are all connected to a very high performance storage layer that is built on proven Google technology at scale. And what this allows us is provide a very unique architecture for getting very cheap, fast read replicas, as well as a very highly available primary node for your database. All right. So now let me jump into some new exciting things that we are announcing this week. One huge announcement I'm very happy to share is we have just launched in preview AlloyDB on our latest Axion processors. That's our Google's ARM-based hardware. And AlloyDB running on Axion. We just ran these benchmarks recently. Delivers 3 million transactions per minute. So that's just from a headline number. It's an amazing accomplishment for us to be able to provide that with a 100% Postgres-compatible engine. But beyond the 3 million transactions per minute, it's also, compared to the x86 architectures that we have, it's 45% better price performance. And the thing that I really like to point out is we also did some comparisons with some of our friends over in AWS Aurora running on Graviton 4. And what we see is a three times better price performance compared to Aurora running on Graviton. So really impressive numbers here. Another one that I want to talk about is a new feature that we recently announced in preview called managed connection pooling. And this is a case where all customers do run into, at times, issues with connection spikes and how do I handle connection loads and so on. And with managed connection pooling, just out of the box, you get a very fully managed experience of a connection pooler that not only improves the reliability of your database and being able to weather connection spikes and so on, but also it ends up improving your performance and latency because of having to avoid creating heavyweight connections to the database. And in this particular experiment that you see the graph, if you just do direct connections to the database, it may top out at, say, around 5,000 direct connections to the database. But with this managed connection pooling, transparently from an application standpoint, you're now able to scale to much higher numbers of connections and drive a much higher throughput as well. So this is available in preview this week. One of the areas we've really invested a lot with AlloyDB over the recent years is in observability. Because at the end of the day, when you're running a database application, you really want to know what is going on. You want to know what are the queries, what are the system metrics, and we've got some really exciting stuff to announce, both by way of advanced query insights that has gone GA now, where you get a very fine-grained set of metrics at a very fine granularity, as well as a lot of query plans at your disposal. So it's a very easy-to-use console experience that shows you all the queries that have been running in the system, the various metrics around them, the query plans for it. But we went one step further and said, okay, what if we use AI to really detect anomalies and surface these things to you proactively? So with the AI-assisted troubleshooting that has gone preview this week, using the same flow, you will now start seeing deeper analysis of your database system, anomalous behavior, whether it's slow queries, spikes in resource utilization, along with recommendations as to what you can do to fix them. So again, when you think about price performance, this is one where, if you're managing large fleets of databases, autopilot capabilities like these really help reduce the cost from an operational standpoint. So definitely encourage you folks to go check this out. With AlloyDB, we've gone even further. Observability is the first step, but folks who are used to sort of what we call sort of traditional relational enterprise databases are used to this concept of performance snapshots. And this is where, as a database administrator, you have a lot of control to be able to take snapshots, detailed set of metrics, reports on what's going on in the database, and you take these snapshots at different points in time, and the system lets you now compare these snapshots across these points in time to say, hey, what has changed? This can be a real lifesaver when you're trying to debug something that's going on and really want to quickly get to the bottom of what's going on and how do I go fix it. So this is a feature called performance snapshots, and it's very easy to set up, and with just a couple of commands, you can set it up to automatically take these snapshots, and then when you do need to debug, it's easy to compare these snapshots and tell exactly what is going on. So another really cool enterprise feature that helps with debugging and operations. Again, continuing on the theme of, like, what we've been doing over the last year, when AlloyDB first launched, we were supporting a specific Postgres major version, and over the years now, we are supporting multiple Postgres major versions, and so the obvious question is, how do I go from a version to the next version, and we have made that now really, really simple with a truly one-click, in-place, major version upgrade. So with a very simple set of commands, you can go from Postgres 14 to 15 or 16, and 17 when it comes out fairly soon, and at the end of it, it's fully automated, and from an application standpoint, you don't need to change the endpoints. It's exactly the same transparent experience. And I won't go into all the other amazing stuff that the team has been hard at work over the last year, but just to touch on a few highlights of what we have been, again, listening to a lot of feedback from customers and working closely with a lot of you, we have made onboarding a lot easier. We've now got a concept of free trial clusters that you can very quickly spin up an AlloyDB instance free of cost, try it out, see the value for yourself, and we've also made it very easy to bring your data into AlloyDB through what we call a fast restore from Cloud SQL backups. So if you have a Cloud SQL for Postgres instance, you can just go to a backup and with one click restore it into an AlloyDB instance and this happens really, really fast. We're talking about like many terabytes an hour type of restore speed. So even for some of your larger databases, you can very quickly create an AlloyDB instance and start playing with it. We've also added BQ federation. So if you have BigQuery sitting alongside AlloyDB, you can play with data across them. On the connectivity side, this is an area we know there's a lot of friction, so we've tried to simplify it through a public IP support that you have now, but also a lot of work with PSC, where we have done advanced PSC and outbound PSC that just makes it easy to set up networking. HA and DR is, of course, the bread and butter for any database, and over the last year, we have enhanced our ability with cross-region replicas, where you can now create multiple up to five regions, where you have a regional replica for your primary AlloyDB cluster, as well as improvements with the way we automate and manage encryption keys. Last but not least, on performance and scalability, on the very high end, we added support for 128 vCPU machine instances. These are, as of today, our largest instances on which you can run AlloyDB, and we continue to push the ball forward on that. But also equally important, on the other end of the spectrum, when you're just getting started, you just want a dev instance, a test instance, we, this week, announced the support for 1vCPU. So now you can create your smallest AlloyDB instance to get started with is a 1vCPU instance. On the database size aspect of things, we go all the way up to 128 terabytes, which is, and we continue to push the boundary on that as well. And the columnar engine, the secret sauce behind a lot of that 100x improvements with analytic queries, we continue to expand the feature set for that and have it do even faster with more and more of your queries. All right. No talk would be complete if I don't talk about AI. So, of course, AlloyDB AI is a huge part of our focus over the last year because we have heard from a lot of you that you want to build Gen AI applications, and you really want a database that understands the components of a Gen AI application. And with AlloyDB, we really are focusing on three main pillars. When we say AlloyDB AI, it really is three things. One, the best possible vector processing engine where you can store vectors, query them, and manage them. But we've also recently added two more things, and I'll go into that in a bit. One, what we are calling the AI query engine, the ability for you to unlock the power of LLMs right inside your SQL. And then the last pillar is natural language interface, the idea that you've got a database, you can talk SQL to it, but what about natural language? And how do we bring a natural language interface to the database? So these are the three pillars. But over the last year, it's been amazing to see the number of adoption of just using vectors within database. Embeddings is the bread and butter foundational aspect for all Gen AI applications, and we have seen the adoption of vector search grow by 7x in a year. So what does vector search in AlloyDB mean? This is the ability for you to store your vectors in a vector column. But what we've improved is now your ability to combine vector search with the rest of SQL, because that is really the power of storing vectors in a SQL database, is I can do vector search, but then I can also combine it with SQL filters, joins, aggregations, all the power of SQL. And that's a hard problem, because this is a brand-new data type, and what we've done with AlloyDB is enhance the engine, the optimizer, to really understand vectors to the point where we're happy to report up to 10x faster filtered vector search queries, where you're combining vectors with SQL filters. And all of this is powered by what we call a scan index. Scan is a Google technology that was developed many years back and powers the core of Google search and many other Google experiences. And what we did was took the scan technology and put it as part of AlloyDB. So now it's as simple as creating an index, which is the scan index, and with that you get the superior performance, and you get much faster index updates, you get much better memory consumption, and we look at scan in comparison to other options that sometimes may be a good option, things like HNSW and IVF flat. So the takeaway here is AlloyDB comes prepackaged with a whole set of vector capabilities that as you build out your application, just working with SQL, with indexes, you can unlock all of this power. AlloyDB. I said we did something called the AI query engine, and what this is is really the ability to call LLMs from directly inside your SQL. So the first use case of this was to generate embeddings. So you have a piece of text, you have an image, you have a video or an audio file. Right inside the database SQL, you can call into the LLM and turn it into embeddings. But now we've gone one step further. You can use things like AI.if, which is a function, filter function, and use that to invoke the LLM to do things like sentiment analysis. The example here is like, hey, I've got a review. Is it a positive review? And this is where the entire power of LLMs and the knowledge of the world that LLMs have is at your fingertips as a SQL developer, which is amazing. And then you combine it with all the rest of SQL, like, yes, it's a positive review, and the price is less than 50. So that's really a huge power that you get by combining LLMs, and we're making it really, really easy for you to call into LLMs, not just Gemini models, which, of course, is our first-party models, but any model that you have. You can call into any third-party models using the same simple syntax. It really doesn't get any easier than this. And last but not the least, as I said, we also have introduced a natural language interface into the database. So the way to think about this is SQL is great. If you're a developer, you know SQL. SQL is amazing. But for all the folks who are not the SQL experts, how do they talk to the database? And now it's become as simple as just using natural language. So you can walk up to an AlloyDB database and just, in any language, just pose a question, show me my orders in the last three months, and the database just figures out what that means based on the schema, based on the context, and gives you back the results. So this truly reduces the barrier for everyone to be able to interact with databases. And we do it in a way that doesn't violate any security and privacy and all of those things. I want to touch very briefly on AlloyDB Omni. So when you think about AlloyDB, there's all this amazing capabilities packed into it. And what we did with the Omni edition of AlloyDB is bring it everywhere. So if you're running the managed service on GCP, that's awesome. But if you really need this capability running on, say, a different cloud, AWS, Azure, or you want it on an on-prem setup or on the edge, with AlloyDB Omni, you have the ability to get all of these capabilities anywhere your applications are running. And we've seen over the last year a lot of customer interest and adoption of this. And again, to touch on, like, why is Omni amazing, it's got all of those capabilities that I talked about, but the proof is in the pudding. And as the data shows, it's Omni running anywhere is much faster than standard Postgres. And as of this week, we are announcing the preview of a brand-new feature called Atomic I.O., which is an amazing innovation on the data path for the database engine, which is now making Omni four times faster than standard Postgres, and this is running anywhere. So you can take this, run on any cloud, run on-prem, and get the benefits. And the last thing I'll talk about Omni is beyond just the core engine, we've also got a Kubernetes operator that lets you manage Omni in all these other environments where you can use the Kubernetes operator and you can set up your management service around it. And we've done a lot of improvements to the operator over the last year, making it very easy for you to set up Omni with HA, DR, and deal with all these sort of the day-to operations using the operator while we continue to expand the set of platforms and versions that it supports. So hopefully this gives a bird's-eye view of all the stuff that we have been working on with AlloyDB, but I'm super excited for you to hear not just from us that are working on AlloyDB, but really our esteemed customers who have walked the AlloyDB journey and are here to share their experiences with us. So for that, I am excited to welcome Giuseppe from Intesa. Thank you. So good morning, everyone. First of all, I'd like to thank you to Ravi, Gigi, and Google to give me the opportunity to share our experience with Google Cloud and in particular with AlloyDB. My team is responsible for all infrastructure that support data. So from storage, traditional block storage, network storage, and cloud storage to database solution, both mainframe and open technologies, and big data platform and analytics, and also data protection. All of this support Intesa San Paolo, the leading bank in Italy, and one of the most important in Europe. In June 2023, Intesa San Paolo launched the EasyBank, the digital and fully digital and online groups bank. EasyBank was built as a cloud native platform directly on Google Cloud with a core banking system developed by our partner, Toth Machine, and a lot of applications developed on our native cloud framework in-house. But how did we get here? It all started in 2021 when Google and Intesa San Paolo became partners. With the first approach based on the lift and shift EAS migration, we began with non-critical workload because at the time, Google had only European regions in Frankfurt and Amsterdam. And regulations didn't allow us to store sensitive data outside Italy. Plus the latency over than 30 milliseconds, not acceptable for many services. The game changer came at the end of 2022 when Google opened the first Italian region in Milan and after six months, the second region in Turin. Google became the only cloud provider with two regions in Italy, which was huge for us, especially for legacy application and integration with mainframe systems. When we started this bank project at the end of 2021, we quickly realized that on our EAS infrastructure as a service solution wouldn't scale for more than 10 million customer accounts. So in summer 2022, we began evaluating a solution also recommended by our partner thought machine. The migration wasn't without challenges. Let me share some examples. The first example is about networking. In Testa Sao Paulo as a particular topology, network topology, and so initially, communication between application layer and database required the cloud VPN. But for a core banking system with an high-volume transaction, this wasn't a viable solution. So working with Google and our network architecture, we identified a better path. And in December 2023, Google released in private preview, in private GA, sorry, the PSG support. And this enabled us to design the right network solution and architecture for our needs. The second example is on the business continuity. We required the regulation to test our disaster recovery plan at least once per year, ensuring RPO equal to zero and the minimal RTO. And with the YAS infrastructure, this was very easy. We have a stretched cluster. We had a stretched cluster based on Postgres between the Q and Milan. So you have to move just the primary services on a virtual machine. With Alloy, these initially, AlloyDB initially didn't allow these. And so, if you move the services on the secondary region, you have to rebuild the recreated cluster. So RPO is never equal to zero. Also, RTO is not minimal. As well as required by regulations. So for this, Google released the cross-region replication with replica inversion and released for us in private GA in December 23. Now is in general available for all. Now, so this means that we can make failover and failback safely with RPO equal to zero and minimal RTO. Last but not least, something about performance and cost optimization. On the performance side, AlloyDB truly impressed us. With alpha resources, as you can see, 32 cores against 64 of the EAS infrastructure, it delivered equal or even better performance. Look at also the disk size. in infrastructure services to get the EOPS we needed, we had to allocate 10 terabytes on SSD disk. In AlloyDB, you pay just one to use and in that case is two and half terabytes. Last point about performance is about restore speed. We passed from one terabyte per hour restore speed to nine terabytes per hour. An amazing result. So, today, EasyBank is fully running on AlloyDB and thanks to close collaboration with Google, we overcome technically, regulatory, and performance related challenges. It's been a demanding journey but also a very rewarding one. Thanks again to Ravi, Gigi, Google Cloud Italy that support us every day and all of you for your attention. Thank you. Sanjeev from Manhattan to speak about his AlloyDB journey and experiences. Over to you, Sanjeev. Thank you, Ravi. Thank you, Ravi. Hi, guys. I know I'm standing between you and lunch so I'll try to be quick. So, let me start with who we are. Very quick introduction. We are a public software company been around for 35 years. Those of you in supply chain probably know us well. Those who are not may think from our name that we are a law firm from Manhattan. We are actually based out of Atlanta. We're about 5,000 associates overall. Now, in terms of software we provide, there are four categories of software we provide. For those of you who are not in supply chain space, the easiest way I kind of describe us is when you go to a website and press the buy button. We essentially take over the transaction until the package gets to your home. We provide every software which is required to make that package show up at your house. Specific products we do is auto management, which essentially takes that order, figures out where does it get sourced from. We provide everything on a warehouse management space where we figure out how to pick, pack, ship that order, put it in a box, and then we manage the transportation of that thing to your house. Recently, in the last two years, we've also got into the stores and we provide a point of sale solutions. So there are a lot of leading retailers using us from that front. We do play in a lot of different verticals, retail being one of the big ones. 37 of top 50 retailers use us. Pretty big presence in grocery. 17 of top 20 grocers in the U.S. use us. Almost every freight forward uses us. So pretty big presence overall in the supply chain industry. So moving on from who we are to the challenges we are trying to solve with LIDB. So a couple of things. I'll give you a context and I'll talk through these two problems. So the first one was I'll give you a little bit of context on where we are. So for each of our customers, we actually create a separate database instance because we don't want any data mixing up for these customers. So we run about 2,000 MySQL instances in production today. That includes the replica and the core. If you look at the data size of this combined, it's about two plus petabytes of data. If you take any individual instance, it ranges anywhere from 100 GB data to close to 35 terabytes of data in any given instance. If you take a single production environment, a single customer, our core setup, pretty simple. You've got your production database, which is your read-write database, and then you have replica, which is your reporting database. And most of our customers are very reporting heavy. They don't allow their operations because every customer has their different unique needs. We provide them a lot of dashboards in the application, but typically that's not enough. So they land up writing a lot of custom sequels or reports, essentially, to look at the data. The size of a single data, about 10,000 tables in the schema. There are tables which expand about 500 plus columns in a given table. So pretty complex set of data tables and database. I just kind of, I didn't mean to read this thing. This is one of the sample sequels coming out of it, and this is probably a simpler example. So a lot of these reports have extremely complex sequels. Sometimes I look at it and say, okay, somebody has to have a PhD to be able to write this sequel. They're extremely complicated sequels. So our challenge was really, and these sequels, when you run in reports, sometimes takes a really, really long time to run. So the challenge I had for the Google team was, how do we make this thing perform? What can we do? And we were on MySQL running this thing in MySQL. And we started looking at LIDB. And can LIDB really help us perform any better? So what we did was, we took a customer, we took their top 30 sequels which were really badly performing, and we took exact same sequel and put it in LIDB. So we copied the data, replicated the data from MySQL into LIDB. So you saw the diagram with replication going to MySQL. So we switched the replica to an LIDB. The production is still running, the rewrite is still running MySQL. The replica is running a lot, data being replicated. And these are the numbers we saw. These are real numbers on the top 10 queries. So you can see on the MySQL side, there were queries which were running for 20 minutes plus because of the SQL I showed you guys. And some of these things have 350x. Most of these things came down to three seconds. And our challenge with our customers has been these are operational reports and they need these answers in a minute to know what's going on in the warehouse versus waiting for 15 minutes by the time things have already moved on. So LIDB, and I think the core of it was the columnar engine which helped us a lot in getting this performance. So we are kind of getting into the stage where we are trying to replace a lot of our replicas to LIDB so we can gain from this performance. So that's kind of one challenge I think LIDB has helped us from an overall latency perspective. The second problem, I'll kind of build the context a little bit. So I talked to you about we are about 5,000 people. We do a lot of projects. So a lot of these companies, we have a services team which is about 1,200 people and they run these projects. We run about 600 projects a year for various companies. So somebody's working for Michael Kors and doing a project. Somebody's working at Loblaw and doing a project. Now, as you can imagine, these project teams, they're disparate project teams completely isolated from each other. They don't talk to each other. So left hand doesn't really know what right hand is doing. But a lot of times they're doing a lot of repetitive work because a lot of our extensions they're building on the product are quite similar. A project A may want something but project B is also doing the same thing or somebody may have done it over a period of time. We generate between these teams, between these 1200 associates, about 10,000 documents a year. These are design specs, how do you do an extension, what do you do with it. So there are about roughly 10,000 artifacts which we generate on a yearly basis. so our challenge was how do we make these teams efficient, how do we make one team learn from experience of the other team and how do we collaborate between these teams so they can share knowledge. So what we did was we took all our documentation, the 10,000 documents our effort to, and we indexed them into agent space. so all of the product documentation everybody's producing, that goes into agent space. Now, and I'll get to what we've kind of done eventually with it, but what we also did was, and these documents are written by different people, so you can imagine, even though we try to use same templates, the style which is in there is different, the language is different, somebody gets a different table, so it's not exactly the same set. And a lot of our queries needed some structured answers back. So we took these documentations also using AI, we extracted a structure out of it. What's the customer ID? What's the extension number? Think of the webhook, we call it extension points. What's the webhook on it? What is the purpose of this extension? So we extracted this thing into a columnar data, apart from the unstructured piece sitting in agent space. And we kind of built an agent which has interface, so any of these 1,200 folks can go to this chat bot and ask a question, has anybody extended a label for shipping for UPS, which requires XYZ, right? Or they can ask, and it gets an answer. So we have kind of two good sets of problems. So sometimes these questions are very general, but you're just basically querying, hey, has anybody done this? How was it done? And you want, sort of an English description of whatever was done? And some of these questions are very specific. Hey, for customer, I'll use Chick-fil-A. For customer Chick-fil-A, what was done as part of extension 05? Or how many times a label has been extended? How many customers are extended? So some queries are very structured queries, and some are generic answers. So in between, we have kind of our own agent framework, which basically takes this query and routes it, figures out whether it's a generic question or it's a very specific question. The generic question gets routed to agent space, and the chatbot would kind of show you the response. And the specific question goes to LIDB, where we fire the query. So in this example, I kind of asked the question is, what's the extension point used for Chick-fil-A? And this is the query which essentially gets farmed, providing that answer. So what we have done is, and this has helped us tremendously across the organization, where when somebody does something, it gets indexed, we can search it from agent space, we can search it from LIDB, and put together the answer back. So that's the overall solution we have kind of built. And I have three minutes, so I'm going to talk a little bit about a vision. This is where you're trying to go with using LIDB, this is where we're trying to go. So this is a pretty complex dashboard, I'm not meaning for you guys to understand all of this stuff up here. But this dashboard, the data you're seeing, the columns you're seeing, comes from various data sources. So in this example, this is about an order, it can go through different states, and when it goes to different states, it creates different kind of entities and objects in the database. To run a query like this to create this dashboard, the query I showed you, extremely complicated query, probably eight pages long, would never kind of really perform. And it probably takes somebody three, four days to even, get to the point on what query to write, understand our database schema very well. And what we are attempting to do, this is not in production and we are still kind of shooting for this, is break this down into natural language, right? Break this out into five or six questions where somebody can ask a query saying, okay, I want to see a release and allocated status from an order table. From a task table by an order, I want to see, get me all the data here. And then we will create a framework on top of it which would kind of take all of this stuff and put the data table together. And then we'll use AI as a visualization tool saying, once I have this data, visualize it in this form. Create a pie chart, create a table which would reflect this data. So our goal is to reduce this two days, three days to kind of create this complex dashboard, and sometimes three days may be a lot more, to a few hours where somebody can ask a natural language query and a set of natural language queries which we can all put together and create dashboards like this. So that's the core goal. That's where we're headed, and that's all I have for you guys. Thank you. Thank you, Sanjeev. It's really inspiring to see all the amazing things that our customers are building with AlloyDB, and we really appreciate the close partnership. So just to close things off, you've heard a lot about AlloyDB. It's the new way to Postgres. It's for your transactional workloads but also for your analytical and your Gen AI applications, and a lot of new announcements this week, so please do go check it out. And there are a few more sessions that I would like to draw your attention to. There are two tomorrow. If you want to continue the learning journey, we've got a session on AlloyDB Omni and AlloyDB Vector Search and AI. So these are further deep dive sessions with demos and a lot more detail. So if you're interested, please do check those out. And if you have feedback, please do share that. And with that, thank you all.