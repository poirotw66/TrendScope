 Thank you for taking time of your lives to come to Vegas. I know you all have your families to worry about, maybe parents and kids. So it's fantastic that you're coming here for like level 300 conversation about open telemetry. I'll be honest. Four years ago, I didn't know anything about open telemetry. Now it's like almost my full-time job. And it's really exciting to see so many people interested in the topic. And the fact that Google is talking about open telemetry and we really care about open source, I think is absolutely fantastic. It's one of the things that attracted me to work at Google. We have a fantastic session for you today. We're going to be talking about how Google is working with open telemetry. We're going to be talking to one of our partners, BindPling, about open telemetry. And then I'll tell you a little bit about our customers and how our customers are implementing open telemetry. And then we'll leave a little bit of time for QA and also be outside of the room after the session is over to continue the conversation. So who is using open telemetry in production right now? Raise your hand. A lot of hands. Wonderful. If you are not yet using open telemetry, hopefully it's happening for you very, very soon. And we're going to tell you how to do it and how to manage open telemetry at scale. For this conversation, first, myself, Jose Andrade. I'm a customer engineer. I work with a lot of Google customers on the implementation and observability. I also help with SRE. And I'm going to show you a few of the diagrams of the work that I've done with some customers. And I see some of the customers that I work with in this room. Then we're going to have one of my friends and cloud observability PM, Sujay, speaking. And then Mike from BindPlan is going to tell us a little bit of what BindPlan does. So with this said, Sujay, why don't you come to the stage? So Jose asked about how many folks have OTEL in production. I am curious about how many of you are using the OTEL Collector. All right. About a fourth of the room. What about the OTEL Instrumentation Libraries? How many of you are using that? Around the same. Interesting. Cool. So what is OpenTelemetry? Now, OTEL, or OpenTelemetry, OTEL for short, is a open source project under CNCF, which is the Cloud Native Computing Foundation. If you don't know about that, Kubernetes is part of that project. Lots of popular projects are in there, and OTEL is a part of that. Now, before I tell you about what OTEL offers in terms of tooling, I actually want to talk about why OTEL exists and what's our goal. Now, you know, back in the day when you needed monitoring and observability, what you had to do was use a lot of proprietary agents and things to get telemetry flowing from your applications. That is changing. OTEL has sort of changed the game there. And what the norm now is and the industry standard now is, is using OTEL to generate, collect, and export telemetry using the set of tools that OTEL provides, which are instrumentation libraries, SDKs, and a bunch of tools like the OTEL collector that Mike will talk about in more detail. Now, for a project like OpenTelemetry, for large enterprise customers and others to actually start using it, you need to have the confidence that that community will stick around and it's able to actually continue to grow and thrive, right? So how do we gain that confidence? Here's a data point. Most recently, OTEL is actually the second most popular project under CNCF. So think about that. That red dot that you see up there next to Kubernetes, that is how active OTEL is today. So we've got over 1,700 authors in OTEL. So just to frame that, you know, other popular projects like Prometheus and Argo are also on this chart, and they are further behind OTEL. And that's just because of the level of interest and activity that's going on in this community today. Another really good indicator of health of an open source project is the variety of organizations that are contributing to it. So I'm happy to say, you know, there's lots of big names that you're seeing in the top 10. But even more than that, what is really awesome is there's 300 plus organizations that have made at least 50 contributions to OTEL. That's super telling. That means this is not just some, you know, a bunch of big players running this project. There is a wide variety of users who are actually contributing to it. All right. So that's a little bit of, you know, credibility and background about OTEL. Now, what role does OTEL play in the telemetry lifecycle? This is sort of the way that we at Google look at the lifecycle of telemetry, starting from generation, collection, ingestion, and then it'll go into routing, storage, and consumption. At the generation level, you've got things like your applications, your infrastructure, and all of those need to actually generate telemetry, right? And how does that happen? It doesn't just happen automatically. This is where OTEL plays a big role, and I would argue is now the industry standard here, which is we have a set of SDKs for the four golden languages, which are Java, Python, JavaScript, Go. Those are stable and well supported by the community as well as, you know, us at Google. And then there's also auto instrumentation libraries as well, which let you get started with generating telemetry from those applications without even really going in and having to change code manually. That's offered by OTEL, and that's the generation site. Now, once your applications, your infrastructure are actually generating this telemetry, you need a way to collect that, possibly enrich that, and then send that to its destination, and that's where the collection part comes in. Typically, folks have used things like a variety of agents to do this. The OTEL collector has grown in popularity here. So I'll share one data point. I'm actually the PM for tracing within Google Cloud, and what's super interesting in the last few years we've seen is the number, the amount of trace data that's coming into our system from customers, you know, over 50% of that is now coming through an OTEL collector, and that's risen enormously in the last few years. So OTEL also offers in-process exporters in addition to the OTEL collector here. In-process exporters allow you to do that directly from code. You can send your telemetry data to an endpoint that can consume that telemetry. And then ingestion side, this is interesting. So you're probably sending your telemetry to some back end, some observability back end, right? And those back ends expose endpoints to which you can send that data to. There's a role that OTEL now plays here as well, which is the OTLP or Open Telemetry Protocol, which is a data exchange format for sending and receiving telemetry. Really proud to say that at GCP, we just announced support for an OTLP endpoint at telemetry.googleapis.com, and you're now able to send trace data natively using OTLP to that endpoint. Now, I won't get into the details on the rest of the lifecycle here, routing, storage, consumption. Especially storage and consumption, I would say for OTEL, those are explicitly stated as off-limits. But the thing is, if you're sending data using the OTEL data model and conventions, there's an opportunity for those storage tools to actually store it using that OTEL data model. Cloud Trace, for example, does this today. And then on the consumption side, if these tools, these observability tools that are out there, know that you're sending the data using OTEL data model as well as conventions, we can leverage that to offer you optimal user experiences, right? Because if we know that the data is coming in using certain conventions, we can fully leverage that and build the most excellent UI that can leverage that and give folks an optimal UX. Now, moving into a little bit of what we've been doing in OpenTelemetry, I mentioned that the collector is the most mature component in OTEL. Now, even given that, it is not yet at a 1.0 release. So we're working towards that. We've done a reliability assessment in support of that. And we're going to get to 1.0 soon, which is really a stamp of stability from OTEL community for that. Many of you probably are using Prometheus, which is a super popular system for metrics and monitoring. And the two communities, Prometheus and OpenTelemetry, are working together to improve interoperability and then converge on some things. So you recall me showing the generation and the collection side. That's sort of where Prometheus and OTEL overlap, not on the storage or consumption side. In that area, we are looking to converge. For example, the Prometheus OTLP exporter was launched in the last year. I'll skip events for now. Go auto instrumentation is super interesting. So Go is one of the languages where we didn't have auto instrumentation because of some technical challenges. But some innovative things around eBPF has allowed the community to actually make progress there. And we have a beta launch of eBPF-based Go auto instrumentation in the community now. So if you have a Go-based application and you don't have telemetry coming from it, it's a good place to get started using this. Finally, in terms of last year, profiling. So we've got logs, metrics, and traces as signals. And lots of folks are using profiling. So that is another new signal that we've announced experimental support for. So watch that space if you're interested in profiling. So next year in OTEL. I don't know. You guys tell me, right? This is an open source project. It is a community made up of numerous vendors, users, everybody. So we need folks like you who are out there using this every day to come tell us what we should work on and start contributing. And there's numerous ways to contribute, right? You know, please check out the contributing site on OTEL. For me personally, I got started by going and looking at a number of SIGs, which are special interest groups in OTEL. And I picked some out that were of interest for me. Now, I also made sure that my employer, Google, was also interested in those same SIGs. But, you know, that aligned and I was able to get involved by looking at some of the GitHub issues, joining their Slack channel. And then eventually I joined some of their SIG meetings. And through that, I got active and started contributing. Now, maybe I lie a little bit. There are some plans in OTEL for the next year and so on. So Gen.AI, how many of you folks are working for a company that is looking at some sort of Gen.AI app being built today? Okay, that's more hands than previously. Observability and telemetry cannot be an afterthought for Gen.AI apps. It needs to be thought of ahead of time. That's what we're doing in OTEL. We have a SIG that's focused on Gen.AI. We're developing conventions. We're building instrumentation libraries. There's lots of folks from a variety of places. So the usual Google's, Microsoft's there. We've got agent framework folks like Pydantic. A lot of AI observability vendors that are new and upcoming are involved there. And we're building conventions. So please look into this. If you need observability for Gen.AI apps, consider using the OTEL conventions and libraries there. We're also coming up with entities, which is, you know, if your telemetry is being generated, it's being generated by something, right? That thing could be a cluster or a VM host and so on. That will now be represented in OTEL as entity. So that's up and coming. Weaver is a new technology being used to generate client SDKs and docs using conventions in OTEL. Well, CICD observability. So there's a lot of heroic work done by folks to get code launches out through the pipeline. Now, what about observability of those pipelines themselves, right? So we're working towards building conventions for CICD pipelines so you can have observability on top of your CICD pipelines. Opamp, which Mike knows a lot more about than I do, Opamp is a new protocol in OTEL that's meant for managing large fleets of collectors or other agents as well. Now, what are we doing with OTEL in Google Cloud? Google Cloud is absolutely, you know, embracing OTEL. We've embraced it. On the generation side, we're doing a couple of things. We've launched libraries for Vertex AI and the Google Gen AI SDK into the Python contrib library. So, again, folks building Gen AI apps use those libraries. We've also launched an OTEL operator that already exists in OTEL. We've, you know, offered some GKE-specific configurations on GitHub and made it easier to use the OTEL operator within GKE. So this offers things like auto instrumentation as well as collection in your GKE clusters more easily. On the collection side, we've launched the Google-built OTEL collector. Now, this is, again, my colleague yesterday, John Breyer, had a slide up there saying forks and a line across it, meaning we do not fork the OTEL collector at all. All we're doing is providing a secure software supply chain package that has gone through some testing on our site. This is really only for, you know, regulated customers who have a difficult time getting these collectors and components directly from OTEL. So we're serving their need there. On the ingestion side, I mentioned this earlier. Telemetry.googleapis.com is now an OTELP native endpoint which you can send traces to. Metrics support is coming soon, and logs are on the horizon as well. This means you do not need to use exporters that are specific to our tooling. You can use the native OpenTelemetry exporter. So this is really GCP standing behind our commitment to be the most open and developer-friendly cloud. We do not want to cause any kind of vendor lock-in. This really lets your entire observability and telemetry architecture be vendor-neutral, vendor-agnostic entirely, and be, you know, open standards following. On the storage and consumption side, CloudTrace uses the OTEL data model natively, and we've optimized our user experience to fully leverage the fact that the data that's coming in is all OTEL. And finally, on the observability analytics UI, this is a SQL-based querying UI for telemetry data. The fact that you're sending the data using OTEL means you can rely on it being in the OTEL data model and conventions, which really lets you craft some powerful and complex queries. So that's kind of what GCP is doing with OTEL. There's a lot more coming between GCP and OTEL. Now, I'm going to hand it over to Mike to talk a little bit more about the collection section that I've highlighted here, the second bullet there. Excellent. Thank you. Just a couple more questions, but as I know folks are using OTEL in production, who is using it at, like, high scale or high volume by whatever definition? Okay. Okay. So I'm with Bindplane. We've been working with Google for several years now, partnering. Also been working on the OpenTelemetry project for almost as long. Most of that time has been focused on the collector and working within the collector. We donated the log component to the collector from an open source project that we had started three, four years ago and ever since have been very involved. And so it's exciting to see everything that's happening within OpenTelemetry. It's been an exciting year on top of exciting year in terms of the progress and what's been happening. But I wanted to take a few minutes to focus specifically on how do we scale and what are the things that we want to look at when we're thinking about scaling to high volume with OpenTelemetry. Because I think it's an area where maybe it's not discussed enough, where we talk about, okay, here, let's get a collector up and running. But now we're dealing with petabytes of data. How do we manage that? So I'm going to start with a little bit on the collector. And I think it looks like most folks are familiar with the collector. But just as a refresher, you know, this is the agent, right? This is designed as a single agent that can collect data with receivers. It can process data with processors and then send it wherever it needs to go with exporters. And within the OpenTelemetry project, there are over 90 official receivers now. These are all available within the OpenTelemetry project maintained by the team. And then there are other third-party receivers that you can pull into a distro if needed. But the key point is you're probably going to be able to get up just about anything that you need, just about any telemetry type into your environment with the receivers that are there. Or there's likely to be one coming soon. So processors, they'll let you transform telemetry. And that could be things like, you know, adding metadata, redacting, filtering, batching, anything that needs to happen while the data is in flight. That's going to be the responsibility of processors. And then exporters are what get the data where it needs to go. That could be going to another collector. It could be going to the destination, whether it's cloud operations, a storage bucket, or another vendor. Exporters, and they're over 50 now. But the great thing about OpenTelemetry and the collector specifically is this is something that has wide adoption from the community, from the industry, and everyone's on board. And so this is something that you can use as a building block. And that's why I'm bringing this up, is the collector is the building block of an observability pipeline. There's a pipeline internal. But then when we look at what it is in a simplified way, once you're deploying it, there's also a pipeline of collectors. It's pipelines all the way down, right? But the key concepts here are we have edge collectors, you have collectors in the middle, and then we're routing the data wherever it needs to go. And when you're thinking about scaling architecture and starting out with the right architecture, moving toward the right architecture is going to get you a long ways toward being able to handle all the telemetry that you have in your environment. And so I'm going to jump ahead and just look at maybe a more realistic, although simplified version of that. We have a concept within OpenTelemetry of the collector as agent. So you can think of these and the collector as gateway. And if you split collector usages into this pattern, it's going to make it a lot easier as you start to deal with a lot of volume. It's the same binary. This is the same thing. We're just calling it an agent in one case. We're calling it a gateway in another. But the agent has certain responsibilities. We put this near the host, near the application, collect the data, collect telemetry, do a little bit of preprocessing, and then we ship it off to a gateway. The gateway does any of the heavy processing on that, any normalization, any caching, or the majority of the caching, and then routes it where it needs to go. And if you follow this pattern, you have gateways. These can be load balanced. They can auto-scale as needed, or you can have them at a fixed size. But you're going to be able to deal with a lot of throughput and deal with it easily and scale up easily. I'll also include one more piece here, which is a key part of scaling or at least adopting OpenTelemetry. I imagine very few people go into OpenTelemetry adoption and don't have anything else running or any other agents in their environment that they have to deal with. And it's a big lift to say, go and replace all of those with OpenTelemetry collectors. It is much more reasonable to say, let's get them into the pipeline. If you have a non-OTEL agent, something proprietary or another OpenSource agent, it's a very reasonable solution to send that data to another gateway, get it into your pipeline, and it's all managed within the same place. And that's what I know a lot of our customers do as we start to migrate from existing solutions to an OpenTelemetry solution. One other key item I wanted to call out is just how do you separate the data streams? I mean, this is maybe more of a business question, but it's a key one. So the same architecture with the gateway, with agents, you have to make decisions on what are those streams going to look like. This is one way to do that. And usually if you choose what's the most critical, if you have an application or team within your organization and you structure it this way, you're going to have a lot of similarities in these gateways. You're going to be able to apply the similar or same rules across the telemetry flowing through, and that architecture is going to make it easier to scale. When you start to mix applications or teams, it can be much more challenging to use a central point to route and standardize or modify data. I will say another common architecture, and I don't have a slide for it, is by telemetry type. So if you're in your org, you have very clearly we want traces to go one location. We want logs to go another location, metrics another. Some folks will do it that way. I think it's less common to see that, but it really just depends on the environment and your needs. So a few best practices for high volume. The agent gateway architecture, this is something that in most cases is going to have a big impact. If you have unpredictable workloads, auto-scaling those gateways as opposed to a fixed size, it's going to let you flex up and down. We always recommend reducing and filtering the data as soon as you can. So if there's data that you don't need eliminated from pipelines, you're not managing every step along the way because that pipeline is likely to expand. So maybe you have one gateway now. As you grow, you're going to have a couple steps in the process and in that stream. Anyway, you can minimize pressing on the agent. That's moving to the gateway. That's key for many reasons, but you don't want to impact workloads. So the less we can do at the agent side, the better. And then when we talk about caching, persistent queues, if we have requirements to say we can't lose any data, much better to do that at the gateway to make sure that we have the storage and capacity to deal with network interruptions, things that may result in lost telemetry. Thank you. Okay. And I think gateways are really key. And so just digging into that a little bit more, most of the operations in the collector are stateless. And I hate hearing most operations because the first thing you think is, well, what are the ones that aren't, right? And there are some tail sampling that's not stateless. If you're using that, you need to consider that and maybe consider the architecture. But in general, if you're not or you're sticking to stateless operations, it's going to be easy to scale that within a gateway group. Scaling on CPU memory is usually fine. However, there are better ways that give you more granularity. And that's what we're showing here. What's showing there? The collector exposes Prometheus metrics. These can all be used. And so it gives you internal information about the collector and tells you things like your queue size, right? And that is if you're looking to really be efficient in your scaling, that's going to give you better information than going off of purely CPU and memory. That said, that becomes important when you're really trying to push the limits. And before then, you know, sometimes you're fine going with a simple solution. Caching requirements, those are key, too. And just something to consider as you decide on what's my instance size, what's the cache size that I need. But OpenTelemetry has built-in persistent queue capabilities. You can maintain a queue in memory. If you need persistent storage over potential crashes or issues, you can do that on disk. That's available. And it really just ends up being a decision of what is your ability to manage an outage in certain areas and how critical is that telemetry as it passes through. So those are some of the considerations. And that's really thinking of it as a pure OpenTelemetry pipeline. And we focused a lot on building BindPlane so it's incredibly simple to use OpenTelemetry. And I've been very involved in the project. BindPlane is a telemetry pipeline that's built to manage OpenTelemetry and do that at scale. You may have heard OpAmp, that's the agent management protocol that's designed to manage collectors and do that at scale. And it was really the community coming together to design this protocol based on what we've all learned before, building proprietary versions of it and implementing it in an open way. But BindPlane is designed to route data, to help you to standardize your data, to simplify, and it simplifies in a lot of ways. You can build those configurations from within BindPlane. It's a low-code version. You can also manage them as raw configurations if that's what you prefer to do. And it lets you reduce and reroute. So when volume becomes an issue or the total volume that you're sending is something that you need to manage more closely, you can do that within BindPlane and we give you tools to make that really easy. Oh, and the most important thing. It's available free to Google Cloud customers. So BindPlane Google Edition is something that you can go out, you can grab it, and you can use it with Google Cloud. And so I would strongly recommend if it's something that you're working with OpenTelemetry, you know, take a look and see if this is a solution that's going to make it easier for you. When we talk about building out an observability pipeline, so everything that I just showed you, BindPlane has native support for OpAm, so we can remotely manage those agents. We maintain a BindPlane distribution for OpenTelemetry. And so this is a collection of the components that we think are most critical for a collector. And it has some of our own that are built in, but it's entirely open source. You can build this yourself. You can make modifications to it yourself. And it's supported, right? So we're supporting this distro. But BindPlane is really designed for visibility. It's designed for scale. When we talk about scale, it's not thousands of agents. It's tens and hundreds of thousands of agents that you're looking to manage across an environment. And BindPlane can support that. We should have time to do a quick little demo, so I won't talk about this too much. But just to give you an idea of how BindPlane operates with OpenTelemetry, that architecture I just showed you, this is a similar structure represented within BindPlane. And it's a set of agents, gateways, and destinations. And any of these you can go into and understand the configuration, make modifications to it, and then manage these agents at high scale. We also provide you with the ability to manage the volume, but in a way that's a visual way, an interactive way. So you can look at any of these nodes or any of these groups and see the telemetry that's coming in, understand it, apply the processors that are going to transform that or modify or reduce, and then get a simulated version of what the output's going to be. So this is before you ever deploy it to your collectors. And that's really, really critical for production. And if you're, you know, I'm sure a lot of you have dev stage production environments, but the only option otherwise is run it through and then test it out. And to be able to simulate and do this from within BindPlane can really speed things up and make it a lot easier to understand your data. So I'm going to hand over to Jose, and with the time, we'll do a demo after. Wonderful. Thank you, Mike. All right. So thank you. Thank you, Mike. I appreciate it. All right. So I'm going to highlight that again. BindPlane for Google is free to Google customers. That is key because you can deploy these without any expense. But, yes, what do you do with all of these open telemetry stuff once you deploy the collectors, you have the gateways and all that stuff? Well, Suje mentioned, you know, that's the hotel side of things. That's where hotel works. On the right, the storage and the consumption, that is where cloud observability comes into play, or one of our partners. There's many partners that can ingest hotel data and give you the usage of that. This is a key quote from one of our customers. I'm not going to read the whole thing, but basically they are saving millions of dollars by implementing open telemetry and then a place to ingest the data and analyze the data, which happens to be cloud observability, of course. So, yes, there's quite a bit of savings by using open source, and open source that has been tested to work quite well in production. I'm not going to spend too much time on this, but let's highlight what happens once you deploy your collectors, your gateways, and you start sending data. So you can send them to cloud observability. Logs, metrics, and traces, and you can organize this data in different scopes, log scopes, metric scopes, trace scopes. And then all of this data can actually be analyzed in one location. Hopefully we have enough time for a quick demo. I'll show you a dashboard with logs, metrics, and traces in one location. But where we're going with this is something like if you use BigQuery, BigQuery is the big data warehousing product that we have. It will allow you to do SQL queries for logs, metrics, and traces in one location. Now, we also, since we have all of the data in there, we have Gemini Cloud Assist integrations. I don't know if you saw the announcement of the blog post yesterday, Gemini Cloud Assist investigations. So Gemini can help you understand what's happening with your environment. You can ask, like, hey, I have this error message. Can you tell me how to solve it? And Gemini will say, well, maybe try this or try that to solve your problems. Or give you a log explainer. I don't understand what this log message means. Can you tell me what it means? Gemini can help you with that. Not only that, but now we have App Hub integration for application monitoring. So if you need something more like an APM type of thing where you can create golden signals on your dashboards, you can do that. You have all your data in the same location. And you can integrate with your own data, too. So if you need customer information in one table so you can correlate to logs, you can do that. And if you want to create really advanced reporting, you can integrate with Looker. So now that you have the data in one location, there's ways of working with all of this. I'm not going to review diagrams in detail. That is the most annoying thing that can happen in a conference. Like, I'm going to show you each box that I am not. I am going to show you really high-level what happens. We ingest all of the data from one side. It comes into cloud observability. You can have separate projects or central projects. In this case, this is a financial services customer that I work with, and they wanted the metrics separate. They wanted the metrics in their own project and centralizing all of the logins. So we centralize in one project, create different log buckets, and then the log buckets were in two separate regions, so they have access to the data in case of the R scenario. And same thing happening if the application is running natively in Google Cloud. They want to centralize all of that data. That is one scenario that you can look at. This is a retail customer that I've been working with, and they say, we also want integration with SecOps. Fantastic. Now the pipeline agent can send directly the data to SecOps, and some of the data can be sent to cloud observability. They have a percentage of logs are security logs, a percentage of logs are operations logs. They can be sent right in there, and they can integrate all of that in BigQuery also. And same thing happening if it's native from Google Cloud Services. This is a little bit more complicated. I'm also not going to review it in detail. Well, if you went to a session yesterday, this was reviewed in detail. But this is a technology customer that they had a specific requirement that they wanted the logs from the sidecar, so the application running in GKE, to be sent to a project where the other services for the application were running, and then send it back to the central observability environment. That was possible because they're using OpenTelemetry Collector, and they're able to route the logs wherever they want to, and then from cloud observability, we can also route those logs. Oh, wonderful. So why don't we take a look at a quick demo? Mike, if you want to come to the stage? Yeah. So everything we were just talking about, let's do a quick two-minute overview. And this is an actual environment, demo environment, and blind plane. And it shows just what we were saying. We were saying, we have our gateways, it's a managed auto-scaling gateway group, we have agents in groups, workstations with 8,000 agents deployed, and then managing it all from a central location. One thing I'll call out is, you know, we're showing one gateway, obviously, in environments you may have hundreds or thousands. But we can drill in and understand the data as it's flowing through. The workstation, we say, we're going to modify this, make some changes, change the telemetry we're collecting at the agent level. This is all using open telemetry configuration and configs behind the scenes. But we add some low-code capabilities. We also provide some options for deployment, right? We know that you typically don't want to just push out a configuration change to 8,000 systems. And so we can do this in stage or rollouts. The draft, we simulated what it's going to look like, we test it in a stage, and we roll it out across all 8,000 of those. Validating that it's configured correctly as we go. And this is, you know, I mean, it's a nice visual cue, right? It tells you the amount of data, but it ends up being really critical when you're understanding your telemetry and the structure within an environment, identifying those sources of, you know, significant data that you may need to consider changing. This is what we call a snapshot view. So you see a snapshot of actual live data on the side. Make changes by adding processors, like filtering, deleting, removing, transforming, adding metadata, and then seeing a simulated result on the right. And this is something that lets you really quickly start to modify, transform, or standardize your telemetry throughout your environment. Similarly, we'll push this out, and then you can see the impact. In this case, we started eliminating some of those items. And there are new components, new processors, new destinations added all the time. This is all based on the BindPlane distro for OpenTelemetry. It also makes it really easy to do things like, let's start sending elsewhere. So it'll be up, but changing it from sending to, say, Cloud Observability to Cloud Observability and also Cloud Storage is a couple of clicks and then a deployment. And that's, you know, that's kind of the power you have of the architecture and also with OpenTelemetry and BindPlane. All right, so what happens once you have all of that data sent to one location? Here is going to be a dashboard. I actually put this together just a few weeks ago for Next. And it's one dashboard that is showing you logs, metrics, and traces in the same location. And that is actually, it could be really tricky to do, but now with Cloud Observability and the backend being BigQuery, it is quite simple. Now, dashboards in Cloud Observability are also just JSON. So you're dealing with JSON, you tell it where to look into, maybe you create some sequels, and then you have all of your data in one location. Together with, of course, you can have documentation and logos for the application and whatnot, or annotations. If you want to integrate with personalized service help that will tell you if there is an issue in Google Cloud, you can have those annotations in the same dashboard. So the single pane of glass now is actually easy to do, and it's possible for all of the environment in Google Cloud. We are done with time. We're getting kicked out, but we can continue the conversation. Please see me right out there, and we continue talking. Thank you so much, folks. We'll see you next time. barg poured first. We'll see you next time, Myself. Bye-bye. Bye-bye. Bye-bye. Have a great day, a time, co-chis breakfast,Ã¼ss, if you love it. Bye-bye. Bye-bye. Bye-bye. Bye-bye. Bye-bye. Bye-bye. Bye-bye. Bye-bye.