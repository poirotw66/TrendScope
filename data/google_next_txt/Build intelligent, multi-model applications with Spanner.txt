 Before I get started, we'll do a trivia question. Why do you think we named Spanner Spanner? And I'll give you a cue. It had nothing to do with this tool. So for the answer of why we named Spanner Spanner, I'll defer to Dave when he presents. At the end of the session, he'll break that mystery. Let's get started. My name is Jagdeep Singh. I lead the product management team for Spanner at Google. I'm joined by Jonathan Ferry from Goldman Sachs. I have Bhavan from Walmart and my colleague from engineering, Dave Weisman. So we have quite an agenda line for you. Over the next 45 minutes, we will talk about challenges customers like you face in building intelligent database applications. And then we'll see how Spanner can help. We'll also hear from Goldman Sachs of how they use Spanner for their global trade ledger. Walmart will talk about their use cases where they use Spanner for payments. We'll share new product announcements. We'll also briefly touch on migrations and the tooling that we have to make migrations easy. And finally, we'll take questions from the audience. All four of us will be around to carry this conversation forward. So please come see us after the session. Let's start by looking at the role of databases in database applications. For over the last many decades, operational databases have been at the heart of business applications. For a long time, the architecture was very simple. You put a relational database behind a middle tier and a front end, and things relatively worked fine for many decades. However, these things got complicated when applications had to scale many, many fold. Application scaling, for the most part, is a solved space. With technologies like containers, caching, even driven architectures, databases, however, are your single source of truth, and they are often the bottleneck. So the traditional approaches to scaling have been you could scale up, but then again, you run into problems where there's increasing cost. There's also a ceiling of how far you can go, and then still your database is your single point of failure. You could replicate, but then with replication comes operational complexity. You have to test for failures, and executing failover is still complicated. And there are multiple points of failure in a replication topology. Your network itself is a point of failure. And finally, on the replication side, you have to account for that replication lag. So you have to build your applications to account for that eventual consistency. Another approach that was taken was sharding. You have to pay a development tax for it. It becomes complicated. Routing, load balancing, those kinds of things have to be accounted for. People also tried active-active architectures. But what happens with active-active... Again, complexity comes into play. Again, you have to account for those conflict resolution scenarios. Traditional on-prem databases, and even cloud databases, do not deliver on all the dimensions that are required for modern applications. Furthermore, with Gen.AI coming into the loop, and intelligent applications, people are building new experiences, things like real-time fraud detection, personalization, dynamic pricing. They all need new ways of storing data and querying data. Now, you have to operationalize these new special bolt-on systems like search, graph, vector, and that increases complexity. Remember, now we are dealing with multiple sources of truth because you have multiple databases in the architecture. Beyond just learning these new technologies, products, and this has led to overheads like managing the ETL, dealing with data duplication, data lag. And from a governance and compliance perspective, your surface area has grown many-fold. Furthermore, with these disparate systems, not all the use cases you thought of are possible. And guess what? The SLA of your application is determined by the SLA of the database with the minimum SLA. So you go to that lowest common denominator for your application SLA. So Spanner has evolved to solve these two main problems. It takes care of data management for high availability, scalability, and consistency. And it also provides you support in the evolution of your application space. So building multimodal application deployments, we have made that seamless. And let's dive in and go through the details here. Spanner is a fresh, new approach, a no-compromise database for modern applications. It offers you the relational database that you're familiar with without the compromises that are historically required. There are no operations, zero operations from your side. We don't have a concept of any downtime. It's always on, five nines availability. It's infinite scale, and it scales linearly. So there's no limit on how far you can go because you're scaling out. And it's elastic. You can start very, very small from one-tenth of a node, and you can go to any levels. So both from a QPS perspective and a deployment topology perspective, you can start from a regional spanner, and then you can have a global footprint. And we provide global consistency. So the database is always consistent. Last year, we took that kernel and we made Spanner a multimodal platform. We took all the goodness or all the superpowers that are associated with Spanner and gave them to all the other data models like graph, vector, full-text search, and they all work seamlessly together right out of the box. Dave will go through much deeper on this multimodal capabilities in a little bit. It's battle-hardened. We have been running it for over a decade. Just the numbers are mind-boggling to me. Today, we process 6 billion requests per second. Let the number just sink in. 6 billion requests per second. 17 exabytes of data under management. And with read and write latencies below 5 milliseconds. At Google, all Google's billion-plus user services, things like ads, YouTube, Gmail, Drive, GPay, workspaces, are all powered by Spanner. All of the GCP services, cloud services, use Spanner as their backbone. And beyond Google, many of the world's most innovative companies run mission-critical workloads on Spanner. Let's look at some of the common use cases, and by no means is this an exhaustive list. We'll hear from Goldman Sachs. Financial services across the spectrum, capital markets, money center banks, retail banks, use Spanner for use cases like payment processing, order processing, consolidating trade ledgers across asset classes. Similarly, retail customers like Walmart, like Macy's, use Spanner to maintain a single view of their products, single view of their inventory, orders across thousands of stores worldwide without having to constantly synchronize data between different databases. Similarly, in gaming, telco and media and entertainment, they use Spanner for metadata management, for user profiles, and even telemetry. Healthcare customers also have seen a lot of use cases in clinical trials, drug discovery, patient 360. And with multimodal capabilities that we have added in the last year or two, we have seen a lot of new use cases. People have reimagined things that they can do. Things like fraud detection, real-time fraud detection in FSI, product recommendations, personalization in retail, in gaming, personalization in gaming, even in telcos, digital twins is a use case that customers are experimenting with. In healthcare, we have seen Spanner being used for drug discovery, for disease control, for medical records. Additionally, each modality within Spanner, be it relational, NoSQL, search, graph, is used by customers in its own right. I'm going to double-click on some of the recent announcements that we have made and capabilities that we have launched. So the first one is elasticity. It's a true hallmark of Spanner. You can start small, you can start as small as $65 a month, and you can get to infinite scale without any changes to your application. I'm excited to share that we launched Managed Autoscaler earlier this year and also asymmetric scaling of read replicas. The second one is price performance. This is something that we constantly keep working on. We also introduced tiered storage recently. It lets you strike the right balance between cost and performance for large data repositories. It lets you configure aging policies, and then it moves data automatically to HDD, which is 80% cheaper than SSD storage. We offer you read and light latencies of less than 5 milliseconds. We are happy to announce today gated preview of many new functionalities that offer you up to 50% reduction in end-to-end latencies for your application. This enables a lot of real-time use cases that you might be considering or working on. Moving along, I see a lot of customers who have requirements to locate data in different geographies for different reasons. For example, some of the global banks have regulatory requirements of where their ledgers can be stored. E-commerce websites have to localize their user profile information for low-latency access where their users are. Traditionally, customers have done this by sharding their data across multiple different geographies, or some of them have a central database, and then they replicate data back and forth. As a result, you never really have a unified view of your database. I'm excited to share that geopartitioning is available in preview. This provides you a unified one database while ensuring that you meet your geolocation requirements. Furthermore, you can scale these partitions independently, so if there's a lot more load in AMIA, you can scale it separately. the next thing I'll talk about is Spanner and BigQuery are two cornerstones of many of our billion-user-plus properties. Customers, also, a lot of them use these two properties together. You want to run detailed analytics on your operational data. Also, you would want to bring those analytics and enrich your operational data. To achieve this, traditionally, what you would do is ETL data back and forth. With Spanner now supporting federated analytics using Data Boost, customers have the ability to execute analytics, many data reporting, AI training workloads, other non-interactive workloads with zero impact on your operational workloads. Second, Spanner tables can be queried from BigQuery right out of the box using external data sets. Finally, the insights obtained from your analytic workloads can immediately be brought to Spanner for low-latency serving as dashboards using reverse ETL and continuous query support. I've been speaking for a while and I hope you are as excited about Spanner as I am. With that, I'll invite Jonathan to talk about Goldman Sachs and their use case. Thank you. So, that's me. I'm a partner in Goldman Sachs. I've been there for like 24 years or something. Crazy like that, anyway. So, what I'm trying to do is in the next like let's say 10-ish minutes I'm going to try and give you a rundown of a section of Goldman Sachs' business and how it actually works, right? So, we call this business Global Markets. The idea of Global Markets is that we take a risk from a customer that they can't deal with themselves and we take on that risk and hand them back some kind of like cash flow which just flattens the risk out for them. So, specifically in this case we're talking about an airline. So, an airline has very big exposure to the price of jet fuel for obvious reasons. They fly, right? But they have no ability to control that risk. So, they call us up and they say please take that risk off our hands and we will pay you like $100 a month and you guys will give us a barrel of jet fuel a month. Something like that, right? So, we agree a contract. That contract, you know, writes down all the specifics and exactly how, you know, how frequently is this going to be paid out and what are the actual terms? Like, where does it fix? Where does the jet fuel get delivered to? All that kind of stuff. And this then ends up being in our world a graph, right? So, if you look on the right-hand side of this picture, you can see that there's a graph that shows you there's a contract down the center which is start at the top, right? You sign your contract with your customer and then you have balances on either side of dollars and sterling because the airline is denominated in sterling. Then you have a rate reset which is basically an observation of the price of jet fuel, right? So, that rate reset says, okay, you now have to pay the customer the floating rate of jet fuel and the customer will pay you $100. So, you move along in your evolution of your contract. Your contract has moved a payment forward. There's a cash flow that's going out plus 10, minus 10 and then there's 10 pounds on one side, $10 on the other side. That's a settlement at February 2nd and then you have another reset so another cash flow. This is all kind of like somewhat interesting, right? So, you've now got your business in Goldman Sachs and you've got like this graph of all the things and at each of these points if you think about it from the Goldman perspective, you have to be able to come in and say, what is my sterling balance as of January 1st? What's my sterling balance as of January 31st? February 2nd? Et cetera, et cetera, right? You're rolling time forward but you're only looking at this one contract. Looks nice and simple, right? You can sort of fit it into like I don't know 10 bytes or something ridiculous, right? Okay, now the customer has grown. They now need two planes. They're really big. So, they go ahead and buy a plane in the US and in order to buy the plane in the US they need help from us to get, you know, a dollar sterling swap that gives them the dollars, right? So, now you've got in your world you've got now two graphs. One of them is kind of complicated going through which is your original contract but the other one's kind of infected that first graph, right? In a weird sort of way because now you've got like balances that's got some stuff from your airline purchase and some stuff from your original contract. So, this is all getting quite squirrelly and complicated, right? So, you can't sort of think of this now as just sort of fitting into one little space. I'm just looking at like along the commodities line or I'm looking only along the FX line or the airline if I did the actual airline deal. Okay, now think bigger, right? the whole of Goldman is involved in all of these transactions across all the jurisdictions in all of the different asset classes and from the Goldman perspective you have tons of different functions each of which need to look at all of this data at certain slices of the business hierarchy, right? So, each of these bubbles in this slide represents sort of some subset of all of the graphs in the Goldman universe that kind of link together, right? So, look at the diverse asset classes for example. All commodities trades, right, will result in risk to let's say oil or jet fuel or some derivative of oil or jet fuel, right? But now I'm not looking just along the cloudy airlines line, I'm not looking just along the UK line, I'm not looking just along the FX, I'm looking at all the commodities. So, all of those need to be self-consistent, right? You have all the other bubbles in here which have similar sort of cross-cutting concerns across these vast disconnected graphs. Some of these graphs then can actually connect themselves. So, you get like these transactions where you've got two totally disjoint graphs. You do what's called a novation which is basically you link together two graphs and then you sell the risk to some other company. And now you've got two disconnected graphs which suddenly became connected. The basic point here is the dataset can't be sharded. So, back to Jagdeep's point, right? You now can't think about like shipping your data between databases because now how are you going to manage those transactions? It's crazy, right? It's going to be ridiculous. Okay. So, now we've got to a ledger which is what I'm actually implementing, right? This is sort of like this is a classic Goldman thing which is we just misname all of the things. So, we've called this a ledger but the underlying dataset is not in fact a ledger. What a ledger is, this is a lot of words, but the basic point here is you take all of those graphs, you look at all of the impacts of those graphs, you order them and then you slice them by whatever like business information you need to know, right? So, like I need to know my commodities exposure. Okay, let me order together all the commodities trades, slice it off, take off that chunk and hey presto, I can now see, okay, I've got this much oil exposure across the whole of Goldman Sachs at this point in time, right? you have to be able to do that globally consistently. So, it doesn't matter where the transaction came from, doesn't matter who's observing the transaction, you have to get the same answer because then you get your controllers talking the same language as your traders, talking the same language as your market risk and all of that, right? There's a whole thing there about by 10 quo query requirements but I'm not going to go into that because that's complicated. So, that gets you to your technical specification. So, now what do we want to do? We want to take all of this complicated stuff and like pay Google because that's why they exist, right? You pay them. Lots and lots of money, I promise, yeah. So, right, so you want to pay them to take off all of that complexity and all you have to do then is make an operationally very simple stateless service, right? You've got a little container that just like constructs its transaction, hands it off to Spanner, go, right? You want to get a single transaction that expresses all of the dependencies of your data so whatever you read, whatever you write, right? You just shovel that into one transaction, push it down, go. The most important thing is correctness because I can always beat speed, I can always build speed on top of correctness but correctness on top of speed, that's their job, like that's hard, right? So, I care that they get it correct even if they're a bit more latent, which they actually aren't that latent but whatever, even if they have high latencies, I still want them to concentrate on correctness. So, if we think about like what Jugdeep was talking about, about the global distribution of the data, right, even across those global distributions, you still want correct transactions. You obviously have to deal with the speed of light, but there you are. Distributing business services allows for flexibility. The point there is if you keep all of your business services super simple, then, for example, I could just kill all the US-based services, all the US-based containers, Kubernetes deployments, right, and everything can root over to the UK, or EMEA, let's say, and my latencies will go through the floor, of course, but my availability will still be fine, and my correctness will still stay, which again, that's the thing I care about, right? So, database requirements, multiple regions, we are a global bank, we're based in New York, but we are a global bank, I, for example, live in London, as you can probably tell from my accent. Intrinsically, partially ordered, so that means, that's that whole thing about being able to slice your graphs and the events on your graphs and then, you know, have the ordering so that you can sum it all up. Total consistency between observers, so that's the thing where you have your controllers and your traders and your market risk and your value at risk, all that sort of stuff agrees with all the things, and then everything, preferably, is independent of scale, so you have to be able to go up to all of the scales and it should still work. That's what we want, so please. So, that's us. Handing back to Dave. There you go. Thanks, Jonathan. I think it's exciting what Goldman Sachs is doing and I'm looking forward to the continued partnership that we have. Switching gears a little bit, I'm going to talk about how Spanner's multi-model capabilities allow developers to easily build intelligent applications, something that Jagdeep referred to earlier. And to do this, I'm going to use an example. Let's imagine that we have Lindsay, a developer, working for a run retailer named Spanmart. Lindsay wants to develop an intelligent application to support product search and product recommendations. Lindsay, like most people commonly would, starts with a relational database that contains products, inventory, user profiles, and past purchases. And Lindsay wants to search over product descriptions with access to advanced functionality like synonymization and decompounding and get the benefits of AI by augmenting her traditional IR-based searches with semantic searches. In addition to that, Lindsay, Lindsay's business intelligence team provided her info on product relationships and per-user recommendations, and she wants to use Graph to be able to combine information across the product catalog, the purchases, the inventory, and this new information. Going back to the slide that Jagdeep presented before, a typical system will require a bunch of complexity for this. It would require Lindsay to introduce multiple purpose-built databases into her deployment and build and operate ETL pipelines to synchronize and transform data among them. As you can see, Lindsay is not too thrilled about this, and she's dreading the conversations with her finance department on cost modeling and new system approvals. Now let's look at how Lindsay would build this operation using Spanner's multi-model capabilities. On Spanner, adding graph, vector, and full-text search is as simple as adding a few DDL statements to your database. First, Lindsay adds a search index on columns already in the relational database, and she gets access to advanced natural language capabilities out of the box with no additional capabilities required. Next, Lindsay's data science team has provided her ML models for advanced product similarity matching, and she uses this to integrate a highly scalable and available vector index, and this is just another index in Spanner. Finally, to model and extract relationships between users, products, and purchase history, data already in the database, Lindsay uses Spanner graph. She builds an overlay representation to represent her data graphically with no additional storage required if the data's already in the database. With a few simple DDL statements, Lindsay is now set up to build and deploy her end-to-end application, including all the core platform benefits of Spanner like availability, elasticity. Now, while the promise of a single system solution is great, it's kind of meaningless if each of the models are not particularly powerful in their own right. So let's dive deeper into what makes each of these models amazing. First, with Spanner graph, we offer a graph native interface using GQL, a standardized graph query language, to give you the full functionality of graph-based access patterns. Spanner graph lets you model data natively as a graph or as an overlay on top of pre-existing relational tables so that you don't have to copy or duplicate storage. Today, we're happy to announce native Spanner Studio Visualization to allow you to visualize and explore your graph structure, native graph rag support for powerful integrations with systems like Langchain and Llama Index from a toolchain perspective, and a slew of query performance optimizations for lightning-fast access to multi-hop traversals. Moving on to full-text search, which is something that Google has a little bit of experience with, we've taken the learnings and power of Google Search and we've exposed it as an integrated offering on top of in-database textual data. So in addition to common functionality you might see in a search system, such as Ngram and numeric indexing support, Spanner Search supports advanced IR tools like synonymy, decompounding, and spell correction, and all of this is offered out of the box with support for over 40 languages. We're also happy to announce today native support for JSON indexing, a powerful tool to support wildcard matches on semi-structured data and native support for the Postgres interface. Finally, Spanner's vector search offering provides a fully integrated semantic search solution to complement traditional information retrieval-based approaches. With native vertex AI integration and KNN support, building scalable Gen AI apps are as simple as modifying your schema and your queries, no additional integrations required. And today, we're happy to bring Spanner's approximate nearest neighbor search to GA. With ANN, Spanner's search supports Spanner's vector search supports searching over tens of billions of vector embeddings, and it's built with Google's state-of-the-art scan technology for fast results and amazing recall. And with Spanner, these models are fully interoperable, allowing you to query all of your data and build amazing applications by simply writing some SQL. As an example, here we have a user that is looking for brown hiking boots. The query starts by finding products whose description matches the term brown hiking boots, searching over the full-text search index. Then, to augment the traditional IR-based approach, we use Spanner's native vertex AI integration to generate embeddings off of descriptions and to feed this embedding into a vector search in order to find semantically similar results. Finally, these results are personalized by limiting the products to those that our input user has some relationship with someone who has already purchased it. And it doesn't stop there. Multi-model Spanner provides powerful toolkit to build Gen AI-first applications. With Spanner's search capabilities, users can combine information retrieval and semantic search with powerful ranking techniques like reciprocal ragfusion to re-rank results. And as we know, LLMs do much better with context. These primitives, along with Spanner's core relational capabilities, allow simple and powerful RAG and GraphRAG applications to be easily developed. Combining all of this with Spanner's native integration with vertex AI for real-time inference and embedding generation and integration with common toolkits like Langchain and Llama Index give you a full end-to-end solution for development. In addition, today we're happy to announce the availability of NLP extensions, which allow users to apply Gen AI reasoning to extract knowledge from your core database. The icing on the cake of all of this is that this interoperable functionality allows you to drastically simplify operations, system complexity, and overall total cost of operations. Complex and operationally expensive ETL pipelines are gone, application inconsistencies caused by multiple systems of record are gone, and complex governance and access management are also things of the past. With Spanner's multi-model capabilities and zero-touch integration with BigQuery, you have access to powerful OLTP and HTAP functionality, allowing you to solve application problems across a wide variety of domains. I'm now happy to bring up Bhavan, who is going to discuss how Walmart has transformed their payments platform on top of Spanner. Thank you. Thanks, Dave. SpanMart and Walmart. I think you stole our example. Somewhat related. Somewhat related. So, folks, I'm going to talk about Walmart payments platform and how we leveraged Spanner and some of the related Google technologies in that space. A little bit introduction about myself. I've been at Walmart for five years. I run all of the databases. Walmart, in these days and times, save money, live better. is their key motto. So, that's what excites me about Walmart overall as a place to work. So, let me talk a little bit about what from a data landscape perspective we deal with. So, Walmart across three clouds. Google, Azure, and private. And around 10,000 plus edges. So, every Walmart store is an edge cloud for us. And each edge has upward of 30 to 40 databases. So, you can quickly calculate we have upwards of 50 to 100,000 databases that we manage, my team manages. Now, a good subset of them need to have BCDR. They need to have data lifecycle management. We need to do upgrades and all of those things for those databases. These databases during holidays, some of them see as much as 10x the traffic. So, a lot of challenges. A lot of challenges and over the last few years, we, like most of you in the industry, have started going towards NoSQL, but then have realized, hey, consistency and reliability of that NoSQL world requires a lot of application level investments. So, immediate consistency is very interesting to us and that's what attracted us to Spanner as an offering. As we looked at Spanner, a few important things that drove our decisioning. Of course, you know, CloudNator was something which was core to all of our decision making. as in, we want to make sure that we use the capabilities which are core to the cloud in the most optimal way. Okay. Now, while we do that, we try to make sure that our data access patterns are somewhat abstracted out. So, when we do, and we'll talk a little bit about it, when we make these database choices, typically our data layer would be agnostic of the database and we actually do test it such that, you know, your data works outside of that particular data store choice. And, of course, while we do that, you know, testing, scaling, elasticity, understanding how data moves between systems, most of our systems will typically have OLAP, OLTP, faces to it. So, all that is super important for us. So, what we started our Spanish journey with was with payments. Now, payments at Walmart is essentially every store register where you check out the payment goes through our ecosystem and around 90 plus percentage of those payments today happen on Spanner. And, of course, with payments, you know, you don't want to wait. So, from the store, getting it all the way to the data store and getting an acknowledgement has to be in sub-seconds. And, that payment has a fraud counterpart where data has to move between the payment system and the fraud system in near real time. So, all these were problems that we needed to solve as we onboarded on Spanner. Now, of course, when we do this, we looked at many, many things and looked at how the deployment topology supported the sub-second side of the world. We tested and tested at significant high workloads. As I shared earlier, our abstraction layer tested the same thing against Postgres, MySQL to make sure that we're not having any leaky abstraction with consistency in play. That's how we went through our payment journey. A little bit about what we learned during the journey. So, first of all, I must say that we deal with multiple cloud vendors and definitely the partnership, joint development, joint work that we did on SDKs and CDC and actually tiered storage which is coming out now. All of those were awesome stories and thanks Google for making those happen. Some of the challenges, while, you know, awesome journey, still latency, still some time hit us. It is one of those things where when there are infra changes happening behind the scene, we'll see blips in our system. When you are in multi-region and you are not reading from the leader, we do see latency challenges. Tiered storage was a challenge but I think it's all good solved today, so thank you. CDC ETL also I think is largely solved. We definitely like to lifecycle our data automatically in the system rather than explicitly, so time to live is an important part. While we started our journey with largely operational, transactional, very critical part of our system, if payment is down, pretty much Walmart is down, the new world is multimodal and graph, vector search, full text search, all of those are POCs going on right now. Very exciting. I do think that the multimodal world that Dave talked about is something which we struggle with today with many, many copies and so on and looking forward to Spanner solving some of these problems. With this, I'll give it back to Dave. Thank you. Thank you, Bhavan. So we've learned how Spanner can be used as a multipurpose database, supporting individual data models and combining data models for intelligent AI first applications. A common challenge we hear is how do we reap these benefits for pre-existing brownfield workloads that are not natively built on Spanner as a first-party citizen? So we're going to go into that in a bit more detail now. Spanner offers an ecosystem of tooling to make application and data migrations a seamless experience. So with Spanner migration tool, we support zero downtime migrations, running data migrations over extended periods of time and supporting both forward and reverse replication for real-time cutover and cutback. In addition, we have native integrated data validation to validate data before cutting over production traffic, something that is critically important to make sure that you are happy with the state of your estate before you actually migrate. We also have native integrated schema conversion tools, which can connect to your source database and do automatic schema conversions to optimize your source database to something that is appropriate both from a type and performance perspective on Spanner. And today we're happy to announce AI-powered assessments to help evaluate and assist in schema and code migrations in order to make migrations to Spanner even simpler than they are today. Oh, right. And Spanner, I forgot about this. Spanner as a scale-out system, as one might expect, we have native integration support for sharded databases. It is a common pattern, a common use case that we see, and all of our migration tooling is supporting that as a first-class citizen. A common migration pattern we see is Spanner from sharded MySQL databases. This makes sense, since a lot of legacy sharded MySQL deployments struggle with re-sharding, over-provisioning, app complexity, some of the problems that Jagdi referred to earlier. In fact, one of the first use cases for Spanner internally in Google was mitering the ads payment system off of a sharded MySQL database into Spanner. Now, Spanner's a relatively good solution for such migrations. Its foundations of scale-out, elasticity, and availability solve common problems for such deployments. And Spanner offers a familiar MySQL dialect, since Google SQL is founded in MySQL, and it has a rich ecosystem of drivers and RMs that should make application complexity simple. Today, we're happy to announce a suite of expanded capabilities and support for making MySQL to Spanner migrations easier. First, expanded SQL capabilities like select for update and auto-incremented keys are common patterns that we see in the MySQL ecosystem and are things that are now natively supported in Spanner requiring less application modification and migration. We also have a host of new types and operators so that even less application migration is necessary. Next, we've expanded support for commonly used ecosystem tools like Hibernate and JDBC as well as database SQL for Go development. And to make supporting high-contention workloads and give a performance profile more similar to MySQL, today we're making available the repeatable read isolation level, which is the default isolation level in MySQL, so that latency and throughput are things that are more similar to a MySQL deployment in doing an application migration to Spanner. And finally, in order to support the migration scale of common large-charted MySQL databases, we're happy to announce that we can now handle 10x the scale in our total migration bulk throughput at a fraction of the cost of prior solutions. Now, as you recall from earlier in the talk, Spanner is more than just a relational database. And as a scale-out database, Spanner continues to see a lot of interest as far as NoSQL database migrations. It's unsurprising since Spanner's platform capabilities of scale-out and low-latency support are the foundations of NoSQL databases. And Spanner combines advanced functionality like multi-row transactions and consistent secondary indexes, with powerful relational capabilities like joins and arbitrary predicate filtering. We're making these capabilities even easier to access today with the launch of a package of tools to make migrations from Cassandra to Spanner seamless, including a fully Cassandra compatible API. With the new offering, users can reap the benefits of a fully managed and elastic solution and put complexities like re-sharding, over- provisioning, and system maintenance behind them. And with our Cassandra compatible API and support for zero downtime migrations, migrating an application is as simple as changing a connection string. Now, back to Jagdeep to wrap up. Thanks to Bhavan and Jonathan to give their stories. I hope you are as excited about Spanner as I am. I invite each and every one of you to try Spanner. I'm sure it's cheaper than the coffee per month that you spend on. It's the most available, scalable database for all your workloads. It's multi-model done right. especially for the Gen AI world and with analytical capabilities and also integration to BQ. This is the one system which is the platform that we run on, that most other companies, innovative companies run on, and I invite you guys to come build on the top of this platform. Questions? Questions? And we are happy to take this conversation. All four of us will be around. So if we can answer any questions, please let us know. Thank you. Thank you. P blink. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. You. Thank you. Thank you. Well, you. Thank you. Thank you.