 Hello, everyone. Thank you so much for coming to one of the last sessions here at Google Next. I hope you've had a fantastic conference so far. Today, I'm just extremely impressed with how many people are still here on this beautiful Friday afternoon. We are going to start off, or actually our session today is going to focus on AI and API security. We're going to specifically be addressing the OWASP top 10 for LLMs and the OWASP top 10 for APIs. Those are two different lists, by the way, just to be very clear about that. Myself, I am Andrew Crabtree. I am a customer engineer here at Google. I specialize in API management and application integration. Joining me today is Shelly. She's one of our product managers. She specializes in Apigee and advanced API security. And coming all the way from France is Murad Abbas. He is the head of API governance for Renault Automotive Group. So just a quick kind of run through of what we're going to be looking at. Murad's going to start us off addressing the API journey at Renault. Shelly's then going to take us through both the LLM to OWASP top 10 list and the API OWASP top 10 list and I'll be joining her with demos as well as we go. After that, we'll do a quick Q&A and wrap up. But right now, please welcome to the stage, Murad Abbas. Hello, Andrew. Hello. So I'm very pleased to be there with you. That's my first time to Google Next. And thank you to my friends from Google to invite me here. So who knows Renault within the room? Oh, impressed. Maybe 50%. So I will remind anyway, you, what is Renault company, Renault Group? So we are an international carmaker operating in about 36 countries. We sold last year about 2.2 million vehicles. And we are almost 100,000 employees over the world. We have four brands, Alpine, the sports one, Renault with a wide range of vehicles from thermal, hybrid and electrical. We have Dacia brand, a more affordable range of vehicles. And finally, a new brand, recent one, Mobilize. I don't know if you know this brand. It has some electrical vehicles. This brand is in charge of charging stations and also the business of the monetization of the data for all Renault Group brands. So the story of Renault Group started around seven to five years ago. We had to face three major issues, three major stakes. As big companies, we had big data silos between our business units. And the idea was to break those silos because we were strongly convinced that the data has a huge value, especially when it is crossed. So we started by setting up a common language between our businesses with data object defined, with their attributes, relationships, etc. On top of this business information model, we identified where or our single point of truth operated by our master data repositories. And it was our first step. The second step was to increase the feasibility and simplify our IS system. We had in the past some point-to-point relation between our systems. And one API was developed for one use case. It was very bad, very few reusability. And we wanted to break the situation by setting up a communication layer with reusable services. The last take was to interact more and more with the ecosystem. Our vehicles become as IoT-connected objects. And we have to interact a lot with startups to deal with new business use cases. And so we had a big challenge on that point. So our answer was to set up what we call today the Horshoe architecture. This architecture shows you two major layers. The first one is the API management layer that is a synchronous layer operated by APGX and hybrid. The second one is the asynchronous layer. We call it internally even backbone or digital backbone. And we use Solace for that. And on top of those two layers, we set up a service platform that shows us the catalog of all available services within the company. We also manage a kind of workflow for subscription of our consumers. And also we go up to the automatic provisioning on APG of all our services or on Solace. But this architecture works only if we are compliant with security guidelines. That's why I would like to show you an API journey. This is how we secured our APIs within Renault Group. From a consumer on the left up to the provider, we have a lot of security controls. And the biggest control is done by our APGX product on the middle because we check the validity of the API key of the consumer. We check that the consumer has the right to consume and has subscribed to this service. Also, we go, we check the access token, its validity. We use also some throttling features as the spike arrest policies where we use this feature to protect our back end, in fact. We set up some maximum rates of solicitations. And we use also quotas to limit the number of calls of each of our consumers. We want to go deeper soon to use some advanced API security features in order to analyze some suspicious behavior in some consumption. Behind that, we will have some LLM analyzing in real time our log well from APG. That's it. So, in synthesis, we done a kind of appraisal of what this strategy brought to our company five years later. And we moved from 10 REST APIs to up to 2,000 high-level APIs on production today. We have a strong increase every year, plus 30%. Also, in terms of consumption and calls, we have up to 150 million calls per day. That is quite huge. And every year, we have plus 50% to 60% of consumption. Also, we moved, as I told you at the beginning, from an average of 1.2% consumer per API to 6.5%. This shows that this strategy brings productivity, because when you have an available service that is used by consumers, it means that you earn time. It's time to market. You have cost reduction on your development. And, by the way, we did also an estimation of the cost avoidance on all our new projects. And we are about 22% of cost avoidance because of existing APIs. And our next big challenges are about the interaction with the ecosystem. I will show you later some monetization topics. We are monetizing the data. And also, as a lot of companies, we are dealing with the Gen AI. So, you can see here some key figures with the important increase of consumption. Last year, we reached about 32 billion calls. And we have an estimation for 2025 of 50 billion calls on our APG platform. Let's move to our monetization. So, I'm very happy to present you our product called Mobilize Data Solutions. As I told you, all the data monetization is done with our Mobilize brand. This is a portal that exposed our data product in an easy and secure mode. So, please, don't hesitate to take pictures. Try to connect to the URL link. And you could see all the products we have. We have some very classical products with the technical definition of the vehicle for repairing. We have also, for example, the location of our dealers available through APIs. We have our real estate, etc. But something very important is related to our connected vehicle. For example, we have in streaming mode, you can access to raw data, very basic data, and also advanced services as road hazard, road health. Recently, we will add the number of passengers for car sharing, etc. So, we have about today 20 products and maybe 10 that are hidden for specific customers. We have 20 companies buying in a daily mode our data. And that's it. And this one is this product. Behind this product, we use the APG monetization model. That's it. And this product brings us also a big amount of increase of traffic on our API platform. Another big challenge we are facing is the Gen.AI, as all of us, I think. We started our journey in 2023 with the arrival of LLMs. And, you know, we have created our own Gen.AI platform called Chat at Renault. And it allows all our businesses to use LLMs in a safe mode by prompting and to simplify, reduce workload, accelerate the productivity in their business. Then, last year, we started the agent AI implementation. In fact, we just added the RAG features that gives us the Renault context of our business. And that brings a lot more value compared to 2023. And today, we are facing with the multi-agent use cases. We are developing through LandGraph using ADK Google platform. And we are delivering our first use cases for our business. But what we can notice that with the multi-agent platform, LLM will speak to other LLM in a total autonomous way. And all those communication are done through APIs. And once again, it will exponentially increase our API traffic. And I will show you an example of AI agent we are developing within my team. This agent is both used by multi-agent use cases and directly by developers, architects in their daily activity. So, this is the API agent. In fact, the idea behind that is to use the powerful of the Gen.AI to improve and automatize all the API lifecycle within the company. And also, to facilitate the data access. First of all, I told you that we have more than 2,000 APIs on production. And when business or end user wants to find a specific API with the relevant data, it becomes very complex. Because if you make a classical search based on semantical word, for example, if you say, I'm looking for an API that deals with ordering parts in our manufacturing plants, you will have hundreds of answers. And the business or the developer will not know exactly which API to use. So, we developed this agent with a smart search feature. You prompt your need. This agent understands perfectly your need because he has the knowledge of the Renault context. He knows the business information model. So, the glossary, the good wording, etc., etc. And it answers you and it gives you the right APIs for your business need. Second, we also want to generate automatically our OpenAPI or AsyncAPI specification based on prompting in the good Renault context. So, we want to be compliant with our design guidelines, security guidelines, business information model guidelines, etc. And we've done it and it works. And we have a lot of gain of time in our projects. Finally, we also want to make some quality audits on our APIs. We implemented very old APIs five years ago. The guidelines were not existing or they moved since this time. And so, we want to have the capability to make an audit on an existing API and to check what's going on to get some recommendation on improvements. And finally, we go up to the code generation with this agent. We give the OpenAPI specification. We specify if we are a provider of API or a consumer. We give also the definition of our technical stacks by prompting. And it generates automatically the code for our developers. So, maybe the code is not 100% compliant, but it is enough to avoid 80% of the workload of our developers. That's it. So, now I will let Shelley to join me. Thank you. And she will show you API and AI security challenges. Thank you, Shelley. Thank you so much, Morad. Oh, my God. I think I just lost $50 on a bet. Because I was sure nobody will show up at the last day and the last session. So, thank you so much for coming. And thank you, Morad, so much for sharing with us the Renault AI journey. Right? It's really exciting to hear about the new user experiences that you're building for your customers. I'm sure that many of you are here today because you're also at some point of the AI journey. And you probably also have security concerns about it. So, let's jump into it. First of all, I wanted to tell you that you're not alone. Many of our customers raised concerns around... It's so nice to see you taking photos. Thank you. Many of our customers raised concerns around security with these AI workloads. So, let's say that you chose your AI platform. You have your AI agent and you are ready to roll it out to production. How do you make sure that the prompts that you're receiving doesn't have any hostile inputs? How do you make sure that the LLMs don't expose sensitive information like PAI? How do you make sure that you're having the right auditing trails for this kind of communication? And how do you make sure that you have the right authentication and authorization controls in place? And lastly, you need to roll out those AI workloads and still keep all your compliance requirements in place. And of course, you need to do it at scale and in a production-level environment. A more formal way to capture all of those risks are listed here on the slide by OSP. So, OSP, for you who are not familiar, is the Open Wide Web Application Security Project. Yes, it's a nonprofit that focuses on cybersecurity. It has a lot of reports, articles, tools, and frameworks. So, they recently went out with OSP top 10 for LLMs, which captures the risks which are associated with rolling out LLM models. And I want to focus on the four red ones. Okay. So, prompt injection involves injecting inputs that might alter the model's behavior. So, think about jailbreak, for example. These are specific prompts that could cause the model to disregard any security or safety protocols that it has. Next, LLMs, especially when embedded into applications, might increase the risk for leakage of sensitive data, PII, health records, financial records, anything like that. Improper output handling refers specifically to insufficient validation and sanitation of the outputs themselves. That might result in other attacks to downstream workloads. So, for example, with web application, it could result in cross-site scripting attacks or CSRF attacks. In other back-end systems, it could result in privileged escalations attacks or remote code execution. And lastly, system prompt leakage. So, system prompts are used to guide the models for better results. Right? They might unintentionally hold credentials and sensitive information with them. So, if they are leaked out, attackers might use them to facilitate other attacks. So, these kind of, the four risks that we just covered kind of map to those two concerns that our customers also raised. What do we have to do about it? So, Google's answer to that is Model Armor, which is a new product that focused on securing LLM prompts and responses. It's model agnostic. It's model agnostic. So, we can use whatever model that you want to use. And it's also cloud agnostic. So, you can host those models on every public cloud that you want. Okay. So, we focus on the first one. Sorry. And the first two ones. What about the rest? The rest of the concerns? The other three. So, for that, we have Apigee. Apigee is Google Cloud API Management Platform. And to those who are not familiar with it, it's really can serve many use cases. Among them are those AI workloads at any scale. And it's also wherever those workloads reside, whether it's on-prem, hybrid, and so forth. And it also has strong governance and security capabilities and analytics as part of it. So, these kind of two products merge together to the defense in-depth approach that we have in Google. Right? So, at the left side, we have Cloud Armor, which is Google Cloud Web Application Firewall. It's on the edge of the network. It's focused on OS top 10 for applications, such as distributed denial of attacks, distributed denial of service attacks, SQL injection attacks, cross-site scripting. So, this is – we're not going to cover in this session, but you can read all about it. So, the second layer is Apigee and Advanced API Security, which focus on protecting from OS top 10 for APIs. And I'll cover it soon. And the last one is Model Armor, which focus on protecting from OS top 10 for LLMs. So, what you can see here is a really high-level, simplified version of the architecture that we recommend using. You can see here that on the left side, you have the agents. Right? In the middle tier, you have Apigee Advanced API Security and Model Armor. And on the right side, you have the different models, the different LLM models. And actually, this is the architecture that we build our demo on, and Andrew is going to show the demo. Thank you, Andrew. Thank you, Shelley. Let me get this off of here first. And let's make sure you guys can see it. Perfect. So, as Shelley mentioned, I'm going to be showing kind of an interaction between an agent. We're going to be protecting the LLM with Apigee. You don't need to know a lot about Apigee to see this, so I'm going to start a debugger here so that we can actually watch this as it – basically as the transactions come through. And then I'm going to send it in various prompts that kind of demonstrate the different abilities of it. We're first going to start with actually the unbounded consumption part of the OWASP, which is basically protecting the LLM to make sure that we're not just letting anybody do whatever they want with it. So, I do have some rate-limiting controls and quota management and that kind of stuff on it. I'm not going to be sending enough traffic to trip that, but the first thing I want to show you is the ability to do semantic caching. So, if you're getting a lot of the same kind of questions, there's no reason to constantly do the same lookup on the LLM. We can just return that directly from cache. So, I'm going to start with a very basic prompt here, just simply asking, why is the sky blue? We're going to send that call through. Obviously, you can see, it takes a couple seconds for it to figure out what you're asking for, go get the information, et cetera. It will then show up. It does do an asynchronous pull on the transaction. So, we see the transactions actually show up here on the left-hand side. It took a little over three seconds to do that. If we take a look through the transaction, this is just Apigee's debugger view kind of showing what was going on during that sequence. Ultimately, the things I want to point out here is that we did check a semantic cache. We did not get a hit, right, because I hadn't asked that yet. And then we do have a model armor check in here. We'll mess more with the model armor check here in just a second. But basically, my prompt was fine. It went to the actual LLM, and then we basically returned the response from that. But let's ask it a very similar question. So, the sky is blue. Why? And when we send this through, notice it started immediately returning. So, basically, what's going on behind the scenes, I'll show you here in just a second, is we hit that semantic cache. It said this is effectively the exact same question. We returned it out of the semantic cache. So, let's go take a look at the transaction that came through. And we can see exactly that. We got to the semantic cache. We didn't need to go any further. We got to basically return it directly from the cache, bypassing the LLM altogether. So, again, making sure that when we don't need to hit it, we're not bothering with it, right? So, one of the ways to help protect from the unbounded consumption, again, couple that with rate limiting, quota management. A great example for quota management is it doesn't necessarily have to be call volume-based. You could do things like token counts. You get so many tokens a day per hour or what have you. It's a great way to do that enforcement. Let's clear this off and try something a little more dangerous. So, I'm going to ask it now, how do I create explosives? Hopefully, it won't tell me that, right? So, prompt comes back, says, this is a dangerous topic. I am not giving you that information. The reason, though, that it did this is because I have a model armor template that actually enforces that. So, if we go back to our transaction log, we'll see in this case, transaction came in. No, it was not cached because we've never answered that question. And then, once we get to the model armor part, we actually get thrown an exception that this is a dangerous prompt. So, stopping that transaction in mid-flight. Let's clear it off. Let's try another one that Shelley mentioned was private information. So, I do have a model armor template that says, do not give out private information. I'm going to ask it then, well, who is andrew at symbol.com? And so, at this point, it's saying you're asking me for personal information. In this case, using an email address. I'm not doing that, right? So, again, we jump back to the translation log. And we can see model armor again rejected it with, in this case, its PII as an email. No go from our template point of view. Now, lastly, I'm going to try doing a dangerous injection here. So, I've fed it an update, basically trying to get it to allow me to access data that I should not have access to. I'll send that through. Again, flag as abusive. Basically, we know we are attempting to do a jailbreak on this. If we go take a look at the transaction that came through as well. Back to the, we didn't cache it because we obviously never answered this before. And then we see where model armor threw a jailbreak attempt. So, that's the first live demo. I'll be back in just a minute. Otherwise, I will now hand it back to Shelly. Thank you, Andrew. This looks great. Thank you, the demo gods, right? Okay. Okay. So, I hope you're convinced that there is no AI without APIs. And because of that, I want to actually talk a little bit about the security which is associated with APIs. Okay. So, for that, let's talk about the OSPOP 10 for APIs. And you can see them listed here on this slide. What I try to do is to kind of group them, cluster them into groups that have some kind of something in common. So, you can see the red group is associated with authentication and authorization risks. The blue group is associated with unrestricted access to your resources or to sensitive data. The green group is associated with how you manage your APIs, security. Do you list all your API? Do you see all your APIs? Do you manage them? Do you manage them? And how well they are configured with regards to security? And the yellow one is around how your APIs are actually being consumed, if there is any malicious activity there. Now, in Apigee, we have our approach for security is build secure and run secure. And also, Moran talked about it in his section about the security policies that they're using with Apigee, whether it's rate limiting, quota, API key validation. And you can also see the longest column here are security policies, right? Like auth policies and schema validation and threat mediation. So, many policies are coming already out of the box with Apigee. And the user can create and apply those policies to the API gateways. Now, in addition to that, we have advanced API security, which is an add-on for Apigee. And what you see here on the slide are the four focus areas for that. So, the first focus area is to make every API visible. And the idea here is really to eliminate any blind spots that might occur in your digital environment. The second one is ensure consistent standards. And the idea here is, you know, we say in security, you're as weak as your weakest link. So, the idea here is really to make sure that all your APIs have the same security standards and policies in place. Next is understand every attack, which means to understand how your APIs are being accessed and if there is any suspicious activity which is happening on your APIs. And lastly, the ability to react on that. So, if you do detect any malicious activity, the ability to take action, deny traffic, redirect traffic, flag it, or do anything like that. Now, what I tried to do here in this slide, but I think graphically it's not the best slide, but I was trying to map those OSP 10 to the features that we have with advanced API security. So, I place those risks that are associated with two features in the middle. So, you can see here that there are many risks that could be handled or addressed by the risk assessment feature and also by the abuse detection. So, let's take an example. Risk number two talks about broken authentication, which means that someone is falsely claiming to be someone else in order to get some access or privileges, right? So, our recommendation for that is first to build the proxies in the right way, right? Use the right authentication and authorization policies on those proxies when you build them, when you roll out them to production. But the other thing is with our abuse detection rules, we also have a brute force rule that can detect if there is an active attack on your APIs, right? If someone is actually using some conditional stuffing attack in order to get access to your APIs. So, that's the reason we're claiming that those two features can address the different risks. Now, that's the reason also that I want to cover and drill down on those two features. So, first of all is the risk assessment. And really, the idea here is to find any misconfigured API proxies that might be in your environment. And the way that we do it is with a profile. So, think of a profile as a set of security policies that you want all your API proxies to adhere to. We have an engine that continuously evaluates your API proxies and scores them according to the profile. And also give the recommendation of what needs to be done in order to improve the security posture. And Andrew will demo it in a second. The second feature is around abuse detection. And really, here what we're doing is we're running different rules on the API traffic in order to detect any suspicious activity, suspicious patterns. And the way that we do it is really we have different rules. Part of them are heuristic rules. Part of them are machine learning, ML, AI rules that we run on the traffic. And we also have in-product close to real-time dashboards in order to show you the attack landscape. And we also connected LLM to explain the security finding by the system. Those LLMs are based on internal LLMs that we have within Google and we share across the security products. We call it SecLLMs. But basically, they're focused on security, right? The share between VirusTotal, Mandiant, Security Command Center. You probably heard all of this. And we're also using them. We're feeding the information in the incident into those LLMs and getting a summary. And the idea here is to help the user quickly understand what's going on around the security findings. So, with that, I'll hand it over to Andrew to go over a demo. Thank you very much, Shelley. All right. We're going to jump right back in. Basically, highlighting the things that Shelley just went over. So, I'm going to start off with the security risk assessment piece, part of the Apigee Advanced API security module. What this is doing, it's evaluating what we call a security profile against the way your APIs are deployed in that environment. You don't necessarily have to be familiar with Apigee. But there is the concept of things that you do with inside of your API itself and then things that as an administrator can then force upon your APIs. So, it looks at the way it's deployed. So, this is not like a static build time analysis. This is a runtime level deployment analysis. It looks at a combination of those pieces to then come up with a risk score for each and every API there. There is a monitoring condition, basically, that says if your score starts dropping, it will start notifying you. You can use that to, like, fail your CICD pipeline build. Whatever makes the most sense in that particular case. Now, we do provide a default profile, which is what we're seeing right here. That covers many of the things that we've already talked about today, but you can build your own. I'll show you a build one here in just a second. But if we take a look at the default one, I've got a bunch of APIs in here. They're all terrible from a security point of view, right, because this is a playground area of mine. But if I look at any particular one, it's actually going to recommend what I should have done in this case. So, you can see that I don't have any authorization policies. I'm not validating the payload that's coming in. I'm not even verifying any kind of traffic shaping or, like, quota management in this particular case. But maybe some of these things I don't care about, right? So, maybe I'm doing an internal particular environment. I don't necessarily need quite as much traffic shaping. But I still want to have things like the actual access control and that kind of stuff in place. So, I can go create a new one. And let's just pick a name here. Just next profile. And let's just assume that all we really care about is it has authorization policies in there. So, I can keep adding all the different ones that I care about, and then I can weight them accordingly. So, let's consider that one a major here. So, I'm going to create that profile. I'm going to go back to the security scoring and say, well, rather than the one that we just did with the default profile, let's look at my new profile. And so, my new profile, since I've only got the one policy, it's pretty binary, right? You're either doing really well or you're doing terrible. And then it's only going to do the recommendation specific for that profile. So, that allows you to customize your own profiles for your organization and for your own environment. So, if you've got different environments, maybe you've got an internal environment, an external environment, you can keep the profiles that make the most sense for your organization. So, let's move to another piece that Shelley mentioned. Let's look at abuse detection here. So, I did run basically an abusive script against my environment here last night. And so, we're going to see that it created this concept of an incident. So, it flagged it as an incident. We can now drill down into, well, what was actually going on. So, when I click on it here, get that error off there or that message. We can actually see a breakdown of what was impacted, what were they trying to do, what regional areas did it come from. So, we see that my attack simulates an attack coming from Ecuador and somewhat of the U.S. We can see that it was a flutter attack. It had a lot of OAuth abuse in it as well. We can see the traffic of how much of this traffic was abusive versus normal traffic. We also get a breakdown of the IP addresses that it came from. So, that's the primary one there. We can see the applications, if these were legitimate applications, but using it in an abusive manner. So, it doesn't necessarily have to be just because their error rates or their traffic was too high. It's looking for longer-term behavioral patterns, even if they're getting 200s being returned and everything kind of seems normal if you're looking at individual ones. If we click on an individual app here, so like my demo app, it'll then break down the overall traffic, what API products was it using, what of those API products, which individual proxies were the ones receiving the traffic, what response codes, what IP addresses. Lots and lots of information here. Now, you may have noticed on the main page, I kind of scrolled by it originally, but I want to go back to it. There's an insights. So, this is basically using Gemini to actually give you a summary of what you're looking at. So, if you're not super familiar with it, this is basically saying, hey, you've got these Python user agents coming in, and especially on that one IP address, you probably want to start blocking that. And then it even suggests your next steps here. So, one of the next steps that it's suggesting is, well, how do I block it? So, that would move us into what we call an action. So, once I know or identify that something's going on, what do I want to do about it? And so, I can create an action here. Let's just say I'm just going to make up a rule name. We can set some expiration dates and such, but I really want to show you this part. So, this gets into the effectively what are my options to do with this traffic as it's coming through. And so, I can allow it. Maybe this is an internal application acting up, but it's not really malicious. I can deny it. If I do that, I can then pick either a pre-configured message. Maybe I want to act like it just disappeared, right? Start returning 404s when this particular client or IP comes in. Or I can flag it. And so, the flag is a very creative way to kind of mess with the client that's doing this. So, you can inject headers into the API, and then the API then can decide what's best for it to actually then take action upon. Maybe you want to start honeypotting it and basically mess with the client and start changing data and stuff like that. Maybe you want to start elevating it through SecOps or your SIEM or wherever makes the most sense from that aspect. Because not a lot of times, though, blocking it, right, they just kind of move to another spot. So, when you're flagging it at that point, the client has no idea that you've detected that they're doing their attack. So, with that, we're almost to the end. I'll hand it back to Shelley to wrap up. Okay. Thank you. Thank you, Andrew. This was great. Okay. So, let's wrap up. We really talked about, we heard about Renault Journey. We talked about API and AI security challenges, OASP top 10 for LLMs and APIs. If you want to get started, you can use the free trial evaluation for Apigee and advanced API security. You can embed their model armor policies like we talked about, or you can use pay-as-you-go, and you can start playing with that. If you want to read more information about OASP top 10 for APIs and its mapping to Apigee, you can find it here in this recent blog and report that we published. And lastly, please share your feedback on the app if you want to see us next year. So, with that, I really want to thank you for coming to Next. I hope you found it valuable, and I hope you didn't lose a lot of money. Thank you.