 Welcome, folks, and a very warm welcome to you next. I hope you're enjoying and learning all about the Google innovations in generative AI. I know it's day three, but we have an exciting topic. We wanted to talk about how you take all the power of generative AI to the edge, where your data is living, and how you take those algorithms that are there and make them run on the data that's there. So that's the topic. And I have with me Ray. Ray, you want to have a quick introduction? Yeah. Hi, everyone. My name's Ray Colleen. I'm a software engineer on distributed cloud, and I'm one of the overall technical leads for the GDC product. And my name is Manu. I'm part of Google product team. I focus on Google distributed cloud infrastructure services. So as you've seen in all the presentations, the power of Gen AI and all the differentiators that Google is bringing to the table, essentially generative AI may be one of the things in our lifetime that will not just change how we do things. I think there is a fundamental shift in how we think and even perceive the challenges that we have faced for years. With that fundamental shift, I think there is a real opportunity that it might create a multi-trillion dollar economy just based on the problems that we get to solve with the generative AI. But we also know that about 50% of the applications and critical data is actually on-prem. With all the innovation that is happening in the cloud and with Gemini and all the AI, generative AI pieces, there is a gap. How do you take those innovations to your data because that data cannot move to the cloud? And it cannot move to the cloud because compliance reasons, data residency reasons. Or it could be something to the order of latency requirements that you need to actually process the data. And it has to be processed on an edge or a remote location or a location which cannot connect to the Internet at a very high bandwidth connectivity. So with all those challenges, we see a gap in the technology and the innovation that we have and the challenge that customers are facing with the locality of the data. With that problem in mind, we have built Google Distributed Cloud. Google Distributed Cloud is a software and a hardware product. And it brings the best of Google AI to the place where your data is next to the data that you have. It includes not just AI services. It includes a full stack of IaaS and PaaS services which is needed to build your applications. It's built, ground up on Kubernetes and open source elements. And it allows you to scale from a really small footprint to a large footprint as your workloads and the requirements grow. That's the vehicle that we are using to bring all that services to you in the locality that you care about. GDC comes in three flavors. The first one is a software only. And it can be deployed on the infrastructure that you already own. It focuses mainly on containerized applications and modern applications. And it's a connected version. So you could be running your GKE clusters in the cloud. You could be running those GKE clusters on-prem. And you will see a unified control plane. And you can manage them all together seamlessly. Then the next flavor of that is where we combine hardware and software to give you a bit more prescriptive approach in terms of a full stack. So this is the connected version of Google Distributed Cloud. And it helps you with a very small deployment with a three node and can help you scale up. On the right, we move to the air gap, which is an offering which is specifically designed for highly secure environments which need to be deployed in air gap from day zero to day one and day two. So given the use cases and constraints you are dealing with the data and where you process, you get to choose between a software only, a connected, or an air gap offering. Now, specifically talking about air gap, and Ray's going to talk more about it in the following slides. When we think of air gap, one of the most important principles that we live by is how do we make sure that customers are expecting a sovereign deployment where they can operate the system, they can scale the system, they can scale the system by themselves with no ability to have a cutoff switch which is remote. Nobody can switch them off remotely. So with those principles in mind, it is built from ground up where starting with day zero, deployment, day one planning, day two operations, all of those can be done in a completely air gap environment with no external cutoff switches in there. So it's just not something that was an afterthought, but the entire product from ground up is built with those principles in mind. Now, with those use cases, it not just brings the richness of and the best of Google AI to you in those use cases, it also brings you a full stack of services. So we currently use our partners for hardware. So we have HPE for servers. We have NetApp for storage. We use GPUs from NVIDIA. We have Cisco for networking. We use the partners to build the underlying infrastructure stack. On top of it, we build the consistent API for consumption of those services as infrastructure as a service. So on top of it, we have VM services, Kubernetes services. How do you do networking services? So it gives you a consistent PaaS layer to build your applications and grow your applications with the code itself. On top of it, you get, because this is a cloud, you get the whole managed PaaS services. And these include how do you manage logging, how do you manage operations, how do you manage KMS systems. The entire set of features are built in at the PaaS layer. And as you then start to deploy and build applications, you need databases, you need analytics solutions. All those come in the data lifecycle layer of the stack. And then you get the goodness of Gemini on top of it to either use what Google is offering or build your own solution with the model gardens that you prefer. So it essentially just gives you that entire spectrum to build and deploy and operate your infrastructure and services in an air gap environment. I'm going to hand it off to Ray to talk more about some of the use cases. Oh, one more thing. I also want to talk about GDC Sandbox. So because the system comes with hardware and customers have asked us, like, hey, how do I get to experience the product? How do I get my developers to develop on the product before I actually deploy it? I want to start building my applications while we work on getting the shipments and getting the stuff deployed. With those specific use cases in mind, we build GDC Sandbox. GDC Sandbox provides the GDC experience on GCP. It provides you that consistent framework that you can build your applications before you start deploying on the GDC infrastructure itself. You can try it out. You can build the apps. It gives you that experience before the hardware gets deployed. And even after the hardware gets deployed, it gives you a developer platform to help you port the applications across the spectrum itself. I'll hand it off to Ray to talk about more use cases in the sovereign spectrum. Cool. All right. Thanks, Manu. I'm going to talk about two use cases that I find really exciting that run on top of GDC. The first I'm going to talk about is that we will be bringing the SAP business technology platform to GDC. SAP BTP is a cloud-native architecture by SAP providing a modern ERP solutions to organizations of significant size. It consists of dozens of individual microservices that run on top of a framework that makes it available to extend so you can actually get more functionality out of your core ERP data. Now, SAP BTP currently runs on GCP as well as other public cloud platforms. And GDC will be their next platform. And because it's on GDC, you'll be able to run this inside the air gap, as Manu mentioned earlier, and on secure networks, bringing the power of all of that platform to data that previously was not accessible. Now, SAP BTP leverages many modern cloud services, including virtual machines as a service, Kubernetes as a service, object storage as a service, core SDN networking concepts such as VPCs, load balancers, managed DNS, right? And it uses pass offerings such as managed SQL. Well, GDC offers these equivalent services in a way that looks and feels the same way as a public cloud platform such as GCP. And we offer VMM, and we offer a GK on GDC, and we offer GDC object storage, and GDC database services, and GDC networking to enable this. Now, how did SAP do this? Well, GDC offers the various hyperscaler concepts. So SAP took their base frameworks, and they ported it over to GDC, as they have done to GCP in the past and their other public cloud offerings, and they're making it work. And SAP uses things like Terraform and Crossplane and RubyFog and a bunch of other type of libraries that enable them to provision infrastructure using an infrastructure as code approach. And this makes their GDC deployments look very similar to their GCP deployments and their other public clouds. Now, for me, as a TL, what's exciting about this workload is it demonstrates that GDC is ready for the most demanding workloads. To be able to run something like BTP, which has 100-plus microservices successfully, to me is a real testament to what we have been able to build with GDC. Now, the next use case is something that's close to my heart, because 20 years ago when I started at Google, I worked on the Google search appliance, which was this yellow box that we sold that people put inside their data center. And then they gave it a list of start URLs, as in start here and start crawling everything that you can find, and do page rank on it. And then you can go ahead and in a Google-type search box, search for information, and you get back a relevant set of links. However, right, back then when you do that, you get the set of links, it's up to you to synthesize that information. So I have to pull from this link and pull from that link and start looking at those things together to get the information that I need. But agent space, in my opinion, takes this an order of magnitude further. So this, what it lets me do, is connect it to my enterprise sources, such as Jira, which is a partner, or ServiceNow, or even a bucket full of documents, or even a custom API that you can push data into. Gets that information in there, and then enables Gemini to look at that data and augment the Gemini results with the data that comes from your sources. So then I can ask it questions such as, hey, give me all the Jira tickets that have been attached to ServiceNow incidents, filed in the last 24 hours by customers, where I have been CC'd. And it will produce me a result just with the tickets that I have access to. And that saves me from having to create either some sort of crazy, complex query that I run, or having to do this manually. So with GDC agent space, I can now get the power of that type of search inside of my air gap network, using the secure data that is there, making sense of it. Now, the next slide here just talks about some of the hardest problems of this enterprise search space that agent space solves. And that is, how do I get a set of results that only I have access to? So if I'm crawling all of Jira, I don't want it to return results for tickets that I am not on or that I don't have access to. And so how this works is that agent space natively understands the ACLs that are provided by these services, and is able to tailor the response to the data based upon only the information that I have access to. And we've worked with several partners to do this, to create these integrations such that there isn't a complicated work to do to get this to be safe and secure. So, with that, now I can go ahead and get access to all this information on secure networks, using secure data, and I don't have to worry about any spillage. So, with that, I'm going to hand it back over to Manu for the next part. Thank you. So, we move to panel discussion, and I really want to invite two of our panelists, Nathan and Praveen. Hello, hello. Thank you very much. Awesome. I appreciate it. Yeah, I'm actually that same guy on the right. I just happened to shave my beard recently and get contact lenses, but I assure you that is me. So, I work for a company called SAIC, one of the large mission integrators for the federal government, state government, etc., and some of the largest cloud services for the federal government. But I want to talk to you about stuff which has to do with this appliance right here. And a little bit about my background. Once upon a time long ago, I grew up on a hydroponic lettuce farm in rural Maryland. So, some pretty advanced agricultural technology at the time. Subsequent to that, prior to coming to SAIC, did a lot of work in education with the World Bank in developing countries, and some of the early blockchain work for conditional cash transfer between foreign governments, and then tracking over to student outcomes in developing areas like Bogota, Colombia. And in working with SAIC, I've led research and development of a team that's done tremendous work solving the problem of getting all the AI goodness, the data processing goodness, available to users in remote areas where they may not have connectivity, or they don't have connectivity. And in those areas, you get all that AI goodness, and that's great. And then people that I worked with, they would say, hey, but you can do that on the cloud. Here's this great thing here. I'm like, yeah, but I can't get to that. So, the team has worked really hard and done a good job solving that problem. And so, I'm excited about what I'm going to show you in a minute from an appliance perspective, because now with the same APIs, those same capabilities, when they say, hey, here's this great thing on the cloud, we can actually bring that to a remote area. So, I want you to imagine for a moment, you know, one of my uncles, he actually was an early volunteer doctor for an organization called International Medical Corps, a volunteer group of people that bring some of the best doctors in the world to help people in remote areas that have just had horrible events occur. Think about Sudan, think about tsunamis, think about things like that. And so, they have people that are ready to be deployed that are some of the leading doctors in the world, and the things that they can bring in as a medical kit, help them help people and do the best work they can, when they don't have the tools that we take for granted that we get from Google, for example. So, now imagine if just like the preposition supplies for the doctors, in the doctors themselves, that then they can bring all that Google goodness into an area, right, and then have all of the benefits that we get from generative AI, from all the different technology, et cetera, with them, without the Internet. And so, that's why I'm excited about this particular appliance, not only for all these kind of scenarios of helping people in rural areas, but also for our customers when they have missions where they need to have all of these capabilities without connectivity. So, that's where this appliance gets really cool. And I'll show you real quick. So, simple description of this. It's Google in a box. And then this was actually wheeled up on the escalator. And so, you can see the rack right there. You guys can talk about the specs a little bit. But basically, big, awesome GPUs, awesome compute, et cetera. So, you can take all that information that you're collecting from, in some missions, sensors, or to have documents that are needed, stuff that's like on the ground, medical support, et cetera, all right here. And that's what I'm really excited about. So, thank you for the opportunity to talk about it. And, yeah. So, you got your cables and wires in here, et cetera. And let me go back. Yeah. Hello, everyone. I'm Praveen. Praveen from Accenture. I lead GDC globally for Accenture. We've been working very closely with Google over the last year in defining the use cases. How do we, and we're going to a lot of the public sectors to understand how we bring this technology. We're very excited to talk to you about what we have been talking to public sectors. What are they looking to do with this? And look at the use cases. Absolutely. Thank you. I want to go back to, for a second, the A-Grid appliance. So, as Nathan explained, this is kind of the GDC appliance. It is designed to be portable. I don't think you need to say that. He walked in with it. So, it's designed to be portable. It is built to withstand very harsh environments. It can run completely isolated. You can connect it to the core. You don't have to connect to the core. It comes with services like data transfer services. You can run containerized workloads, VM workloads on it, and, of course, AI workloads on it. So, it comes with all the capabilities all inside this box itself. It is on our floor downstairs. Please stop by. Take a look. Definitely all the use cases that we can cover with this form factor in a portable form are just tremendous. And besides that, it is IL-5 certified for deployments in different regions, too. So, I'll move back to our panel, and I'll take a stop. Spot over there. So, Nathan, as we can see, you're very passionate about the edge. Yep. Tell me some of the challenges that you see with your customers. So, a big thing is, like, so we can make the AI stuff work, right, on a computer in a disconnected environment. That's something that the team's been able to put together. And we've proven that, you know, in the desert in different areas. So, if you can imagine a small container that, on top, very large sensor arrays, radars, you want to deconflict airspace or sense things that are going on. And in there have computing capability that's networked. No internet, right, but the processing there for AI and large amounts of sensor data that's coming into there, right. So, we can solve the problem of being able to process that information. But where I get excited about these capabilities is we can take all the great things that we can do with the APIs in Google and Google Cloud, right, to then actually be on here, be able to do so much more, right, where somebody else is actually managing those capabilities. And when somebody asks me about, hey, is it secure, hey, this, that, and the other, then the answer is, yeah, it's taken care of by here's the Google stuff. And then for us as engineers, we're solving problems in the field around a specific use case. Like, what is the user needs and then not worrying about some of these other areas. So, as a strategic mission integrator, it allows us to very, very quickly focus on the end user experience, on the mission, on what we want to have happen, and do it quickly, right. Like, do it at the type of speed of you go up to the cloud and you turn on a VM and you've got all this great stuff going on. To have that same capability, but on a device like this, in the desert, et cetera, then we're just able to operate immediately. So, that speed, knowing that we've got the security questions answered, and the ability to just really rapidly achieve outcomes and impact that we want to in the field. Because a lot of the tech is taken care of, and we can integrate the different systems and bring it together. I'll add one quick thing to it. So, in talking to the engineers in the early development of it, we don't want to be locked into only using the Google services. Sorry, guys. On this appliance, we have stuff that's in the field already. We have existing, you know, investments. We have stuff that runs on Windows. We have stuff that runs in Linux, whatever it happens to be. So, the straightforward nature of, yes, we have this. It's air-gapped. It's been in our control the whole time. But somebody comes up and they have stuff on USB. I can plug the USB stick in there if I trust it, right? And I can load that software on there. And even if it's been developed to use the APIs on the cloud, it'll just work and stuff like that. So, the flexibility to adapt and integrate all the different things that we need in the field with the usability and the trust that we get out of Google stuff, that's what's exciting about it. That's awesome. Thank you for sharing that. Yeah. And, yes, we wanted to make sure customers feel that they can port whatever applications, wherever they want to go with it. So, Praveen, you've been working very closely with public sector customers. Yep. And, like, with Gen AI, I'm sure you're getting a lot of queries on how we can enable the power of Gen AI to solve some of the use cases. Tell us about, like, what do you see from an adoption standpoint? Where do you see that market moving and the customers taking Gen AI? Yeah, sure. I think in our work with public sectors, I think if you look back about 12 months ago, and everybody started looking at Gen AI coming, they were looking at where Gen AI is coming, how they can use. There's lots of experiments being done. But in an intrinsic nature, there was always a concern that to get the best of Gen AI, I need my data to leave the boundary. And nobody really wanted to move it beyond an experiment, right? While there is a lot of adoption of AI, because in public sector AI, it means a lot of things. You can do OCR, you can deploy ML models on existing infrastructure. But the scale at which Gen AI was moving, it woke a lot of public sectors. And in every discussion, they were trying to understand, how do I get this at my place? What can I do to get it at my premise and have control of the data that can go in, that the data can go out, as well as making sure that what it is coming out with inferences are real? And that is what was the biggest barrier everybody was watching. But over the last three months, the discussions have rapidly moved because of various things happening in the world today. And the public sector is actually looking to pivot to being the leaders. And they're really making a lot of moves if you look across Europe, if you look across other geographies. They want to quickly adopt AI. They want to be the role setters of how Jai and Gen AI can do two things. One is improve operational efficiency because if you look at the public sector, a lot of work happens at the back end. There is a lot of manual processes. There is tons of documentation. There's tons of things. A lot of the workforce actually works behind the scene. And the ability to influence, to bring them to the field by taking a lot of these tasks to do Gen AI will help them to deploy on the field and do the tasks that are actually required to be done. And that is creating a lot of interest. A lot of markets are actually rolling out their AI principles. UK rolled out recently. They want to be the first. They're investing multi-billions, and everybody wants to get on with it. So I think in the next 12 months, they're saying that the public sector will adopt AI faster than private sector. And they want to be the role models and also set trends on how they want to use it. So it's been an interesting time of discussions for us with all the sectors. And this really is making life very easy. Yeah. So I want to add to that, right? So exactly like understanding where the data is and stuff like that in the world today. But adaptability, right? So the ability to very quickly adapt to changing circumstances. So the portability of it becomes awesome, right? So it has – I do a lot with Gen AI, too. But think about the OCR capabilities, translation capabilities. So the ability to take this into an environment, right, where I have that information that I don't want sending onto the Internet or I don't want to move into that existing space, but then load it up and use it and get those benefits. It allows us to be able to leverage Gen AI that much faster. And if I were to even – please. That's a simple topic again. Regulation is very critical in public sector. So in order for them to adopt AI, everybody's thinking back as to how do I make sure the regulations moves in line with that. So you see a lot of changes around them coming up with being able to adopt it more easily because in the current instance, regulations prevent it. They have a lot of security restrictions, ability to – there's tons of things to be done. A lot of the governments are looking to simplify that in our experience and asking our help to see how we can do that as well. No, that's fair. I think as it's a pretty new frontier for even public sector, the regulations are evolving. But there is a high desire to actually solve the problems in a completely new way. Yeah. And till date, nobody had a technology. I mean, as I mentioned, AI, ML was all there. But being able to get the full power of Gen AI sitting in front of what they can do is something – they're finding it very exciting. So when you were talking about the capabilities and the whole story that led up in your work on it, right? And so here are all the different ways that I can manage the stack that's on there, right? And so what's awesome about that – so working in Edge for a couple of years purposely did not use cloud, right? And it was, hey, let's do everything without touching the cloud. Then I started using public clouds that are out there. And I was like, dude, this is a hell of a lot easier. I wish it was that easy when we were setting up these other things because then we could have, you know, achieved the impact and the outcome that we wanted to that much faster. So the tools that exist and are evolving and improving in all the public clouds, right? And SCIC is one of the leading providers as far as helping with missions across all the clouds. How easy and fast it is to use those things is really fantastic. So going from, like, none of that goodness to, wow, that's really awesome and now being able to hopefully, right, boomerang back is something I'm really excited about. Yeah, that's fair. I mean, it's just not the infrastructure. It's about infrastructure as code. What does it do to my developer velocity? And the whole stack becomes very important in accelerating the entire application development and solving the problem itself. Yeah. Yeah. The theme of the world is unlocking AI for growth. And I think if you look around, I think everybody's trying to do that. Absolutely. To the use cases, Praveen, that you mentioned, like, how do you see GDC AirGap kind of addressing some of the challenges that are kind of either slowing down or blocking your customers from adopting and addressing these challenges? I think two things I said. When you think about the customer use cases specific to some very regulated industries, which are very isolated industries, we have had many discussions on use cases where they want to combine various sources of data. And the data is lying in multiple sparse systems across, which is hidden from a lot of public eyes. And the ability to bring that data together. A, there is a lot of unstructuring that's happening in the data stored in various formats. And the challenge is, again, some of the people working in the public sector, their systems are very legacy today. If you look underneath the hood. And also the people that work on the systems are not up to date with what's happening around GNI. So there's been a lot of discussion as to how to upskill the people behind it, how to make sure that the legacy platforms are coming up to what can be done so that it can get into a phase where you can start using these tools and technologies. And I think we started working with many of these public sectors. And we have now pages and pages of requests of use cases that have said, can I do this? Can I do that? How do I combine? So the moment they're realizing. But then there are barriers. I mean, information cannot move from a department to another department today because they have restrictions on regulatory boundaries. So they cannot feed in multiple sources. They have checks and balances on what things can be done. So as I said, regulation needs to move along with it. They realize. And that's one of the barriers where technology is great. People love it. They can see the appliance. They can see the use cases. Putting it into production will need the whole structure to move along with it, and which many of them are actually realizing and jumping on it. Yeah. So the Yeti cooler nature grab and go of this is pretty great, too, right? So we'll run into customers that are like, hey, cloud's great, but we can't do that for reasons X, Y, Z, right? And they're in a location where they have disaster recovery requirements where they will have all their processing and storage on-prem, but then a hurricane's coming in or whatever, and then they need to move as much as possible to an inland location or things of that nature. So being able to grab and pack this up and go from point A to point B, that allows us then to actually kind of leapfrog the objection, I would say, to some of those cloud capabilities to something that they can bring in and then leverage NAI and whatever's next and next and next, and still have something that's in a grab-and-go type capability. Fantastic. So it's interesting, as I hear Praveen and Nathan talk, it gets to kind of like some of the stuff we thought about four years ago when starting this project and like why it is that we chose to do GDC and why it is that we chose the path that we did. Is that we were observing out there that when you went into kind of the secure networks and you looked at what the regulations would allow to be run, what you found out there is you had a couple of folks doing region-scale deployments. I mean, we're talking about data centers the size of this conference center that are used to deploy, you know, secure networks and secure clouds. And unfortunately, while that works for some customers, right, in some locales, the vast majority of people who need this do not have the ability to deploy at that scale. And so then we're thinking about, okay, so if we're going to start at this problem, we really need to think about it from what can we do that gets to that size, but also gets up to a pretty decent size, currently 30 racks, right, and growing, right, to providing an experience that bests what's out there. In those environments today, which was the majority of which were VM-based platforms. So as folks in that space, they would take a VM-based platform and then try to build their own private clouds from it. And then they would find themselves attempting to create a database service and attempting to create an object storage. And they ended up with a bunch of bespoke individual services that were very difficult to integrate and work because they all had their own way of approaching. And then having been on cloud for 10 years and seeing the development model that Nathan mentioned where it's just, hey, I want a VM, I just make an API call. Hey, I want an object store, I just get a bucket. And I can do that. That's the interface that's being taught in college right now. Like, you know, my buddy who's at UC Irvine, like, their approach is to do AWS, or sorry, for, you know, for public clouds. And then they just go ahead and, you know, set it up so that their students do their assignments on public cloud, right? So that's what's coming into the marketplace as well. So with that notice and the fact that we had these VM-based platforms, we're like, how can we bring that public cloud experience into this scale, this rack scale and this appliance scale? And we took and built the platform with that user in mind. And so GDC provides that experience through a common API platform, a common set of APIs, supporting infrastructure as code, access and identity management that's built into the platform. And one of the exciting things for me was we built this knowing that we had to get our accreditation to make this product go. And building a product with accreditation built in is so much better than taking a product and trying to bolt on accreditation afterwards. And so that's allowed us to do some really neat things and move a lot faster and start to provide these, you know, Gen.AI and other type of capabilities on top of a substrate that looks and feels familiar to the operators and developers that, you know, our customers are trying to hire. And so to me, to see that coming to fruition today and to hear Nathan and Praveen kind of talk about how that's meeting the market where they were, it's pretty cool. It's pretty neat to experience that. So, and on that, so just triggering some thoughts, right? So, like many of you have the good fortune of working with a lot of really talented people. In SAIC, we have an innovation factory and we're able to very rapidly create things that help solve problems and achieve the outcomes and get impact and get stuff in people's hands for a given mission, right? And so this huge group of people, these really brilliant people I work with, what's happening with Gen.AI is amazing, right? And so it's not so much seeing, like, how much can be done with fewer people, but it's, like, how much more each one of those individuals can do that much faster, right? Like, it takes everybody 10x, right? It takes something that's, like, mundane and kind of gets in the way of the engineering creativity, whether it's infrastructure or whatever it happens to be or data science, so on and so forth, and then to just really take everything that much further. So being able to then, okay, cool, extend that to end users that are outside of the cloud on edge, that's part of what gets me really excited, because it's usually been, like, yeah, that's great on the cloud, but can't do it here in that use case. So being able to extend that amplification for everybody and anybody out on the edge, in the field, whoever it happens to be. And just to add to it, it's not just you getting excited. Every customer that we speak to is actually getting excited about it. It's creating a lot of interest and demand. I'm sure you guys have no depth of demand of people asking you, how can I get this online? How can I start innovating? And how can I actually get what was hidden behind the curtains to be able to start doing a lot more but still be behind the curtain is what is driving the market. And I think if things go, and I can't imagine what two years from now or the next 2026, next will introduce, right? So it will probably change the market, and we will see enterprises racing ahead of public sectors and say, oh, wow, they could do this faster, and why are we not being able to do this much faster, right? And you will see a combination of all three, whether it is public to connect it to the edge, being able to connect a number of sensors, ease the supply chain, ease your number of use cases that you can build to all the way on the secure boundary. I think the future is very bright. And that's so interesting to learn from your comments and your experience. Like, as Ray mentioned, when you're building GDC, the intent was from ground up. How do you build a system that is designed to run in air gap outside of GCP? It wasn't an afterthought. It wasn't a bolt-on. So that's where a lot of fundamental security and zero-trust principles that it's built on. You kind of get to experience that without having to worry about those as an afterthought. And being able to accelerate the developer velocity, I think that's kind of the goal. Like, how do we get people to consume and solve problems versus take months, if not years, to build infrastructure, send the tooling to get to there, and then I need to now solve a problem. So, okay, technical question for you, Ray, which is, so this has little, like, Lego nubbins on here so they can stack. What does it take to turn this into a cluster if I get two or five or ten, whatever I put on it? Today, they operate, as you said, completely your app. So we call them a universe, and we think of a universe as, like, what GCP is, right? It's a single cloud instance, right? But over time, right, you know, as we go, the scale, the way we design the product is it can scale from the three servers you see there, right, from all the way up to currently 31 racks and much bigger in the future, right? So that notion of doing that means that you could have a bunch of these and say, okay, I need this much in this location, and then the four together could act like a cluster. That's a roadmap item. I can't, you know, being an engineer, I can't promise you that, right? But today, those are four universes, and you can treat them almost like zones, right, in your design. So you could have them, you know, going back and doing replicating across and stuff, and, you know, yeah, you'd have to deal with some authentication challenges, but, you know, that's what we could do right now today, and then in the near future, we could make them multi-zone. Going back to the, like, you know, the doctors that are ready to go or the person who's ready to go, like, in a box, right? Okay, so if I'm understanding correctly, then, okay, doctor one, doctor two, doctor three, doctor four, taking up the space of, like, one bed, right, because there's some practical constraints in the world, right? So how many beds does one have when you get into Edge? Okay, so backing up, when you get to Edge, some of the challenges are you have some great constraints, like how many people, how many beds do you have, right? How much power is needed? This works on AC power. I was glad to see that on your spec sheet, that it was just, like, regular plug it in, and a number of other really simple, practical things. So, you know, as someone that's looking to bring pieces together and watch other teams bring these pieces together on the Edge, it's cool seeing these available as components and so that you could cluster these. So it's what? How many A100s in there? So that has a single A100 in there with 80 gigabyte of GPU RAM. Okay, so whatever model's out there that's 80 GB or less, we can shove it in there and run. That's awesome, right? And then how much RAM and compute and all that stuff? I'm going to ask the product manager. Ah, next slide, right? But my understanding is it's a lot. So... I think it's 784 gigs, but it could be higher. How much? It's 784. Okay, yeah, we could do something with that. I would suggest, like... Look at the spec sheet. I would really encourage you to go to the floor, touch the system. We'll definitely answer the questions. That looks at the water that I need to think about. I, I think it would be the second set ofvas. No... Oh, yeah. And I can take a break from that.