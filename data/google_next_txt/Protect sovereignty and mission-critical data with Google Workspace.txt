 . Hi, everyone. I'm Olivia Burgess. I'm a Senior Product Marketing Manager here at Google, and I'm really excited to share with you some insights around protecting sovereign AI and mission-critical data with Google Workspace. So as you've heard throughout Next, generative AI is presenting an unrivaled pace of innovation. This is the era getting defined by intuitive interaction between humans and technology through processing and generating language in different modes, such as text, audio, video, or images. Generative AI will have a massive impact on all industries, and the rate at which this technology is diffusing into industries other than software is unprecedented. Organizational leaders are asking how they can get these tools safely into the hands of their users so that their employees can be innovative and productive. But at the same time, we have more regulations over the world's data than ever before, with another 260 on the horizon. So what do you do if you're one of those almost 90% of senior executives who feel that AI is absolutely essential or very important to achieving business success, but concerns about trust and data governance may be giving you pause? Does ramping up AI capabilities always require a risk-receptive approach? I have good news for you. You don't need to go backwards to on-premise legacy tech solutions. You can ramp up your generative AI capabilities while maintaining zero tolerance for risk. We receive feedback from customers that really boils down to two elements. They want to remain competitive through innovation and AI, but they don't want to accept risk. By the end of this recap, the goal is to share a couple of insights around how you don't have to miss out on innovation, and the sovereignty versus innovation dilemma is really only dependent upon the cloud provider you choose. Here at Workspace, we have three unique characteristics that help us deliver on this front. Firstly, we have a born-in-the-cloud, cloud-native, and web-first architecture that ensures your productivity platform is not static. It keeps improving with time. You don't want to be stuck in 2022, a couple of years behind on the latest and greatest in innovation. Secondly, we don't have sprawl of data. Because all of our data is in the cloud, we don't have that level of complexity of managing and securing multiple different versions of the same file in multiple locations. And thirdly, full stack of generative AI within Workspace is proprietary. It belongs to Google across the entire AI lifecycle. So we own every layer of the AI stack, and we can then provide both vectors of sovereignty and innovation. Google Workspace has provided sovereign controls for many years now. It starts with our Zero Trust Secure architecture, the tools that help to prevent data loss risks, and really then further extend to data regionalization capabilities, vendor access controls, and uniquely Google client-side encryption, in which the customer maintains ownership of their encryption keys, and therefore ownership of their data. We're proud to share today that we're now extending those capabilities to Gemini for Google Workspace, and introducing sovereign AI for Workspace. Again, this really starts with the foundation of Zero Trust. We're expanding our Zero Trust capabilities into Gemini to include AI classification, data labeling, and DLP. You can set enforceable rules and help auto-manage those labeling processes so that your data is appropriately classified and treated accordingly by generative AI systems. Secondly, we're pleased to announce that Gemini for Google Workspace is now compliant with data regions. That means that you can choose which region to store and process your generative AI data. So Gemini data can now be processed and stored within the EU, the US, or a mix of both. For those organizations who require either due to regulation or due to wanting to maintain protections in case of a black swan event, local data storage, which means that Gemini for Workspace data can be exported through a GCS bucket into a local data service of your choice. Thirdly, we're providing vendor access controls for Gemini for Workspace because Gemini for Workspace is now compliant with access transparency, access approvals, and access management. So you get to control how and from where Google has accessed your Gemini data for troubleshooting purposes. Thirdly, with context-aware access, you have the ability to set policies around the device location and OU from which you would like certain areas of data to be accessed from. And then finally, client-side encryption is an incredibly powerful tool when it comes to limiting the types of data that should be exposed to either Gemini or any other generative AI assistant. It means that if you have either a client-side encrypted document or capabilities such as an enforceable data loss prevention policy within your data, Gemini will not retrieve that document and it will not use it within the generative AI system. But you don't need to take our word for our best in class compliance and privacy record. We have the most stringent auditors in the world who have evaluated and deeply processed the different capabilities of Gemini and Workspace, as well as some of our competitors. As you'll see, we have the first certified AI assistant in Gemini and Workspace and the Gemini app with certifications in SOC 1 through 3, the ISO series, and most recently FedRAMPi and BSIC5. Even if you're not a regulated customer, you should have great confidence that these regulators have conducted those stringent audits on your behalf and have given true confidence in these systems. If you're ready to learn more, we have a ton of deep information out there. Please feel free as a first step to download the Gemini for Google Workspace security, privacy, and compliance white paper to learn more about how you can innovate whilst keeping your data sovereign and compliant. Thanks so much, everyone.