 Hello, everybody. Thank you for taking the time. I know we are in between your dinners, parties, and also there is a music event. So thank you so much. Today's session is building an AI-ready data foundation with lean teams. And we have a unique, diverse, global panel of customers and speakers to talk to you about their journey with BigQuery and Google Cloud and how they have been able to successfully build their AI-ready data foundation with lean teams. So starting with what's stopping you and others from achieving an AI-driven transformation, especially in the era of AI. We have identified three main pillars. One is around data silos, structured and unstructured data. There are multiple copies of data across clouds and on-premises. The second is around lack of AI-readiness. AI is only as good as the data quality. And bad data quality puts your AI models at risk. We also have lack of unified data and AI governance for your businesses. Third is around increased costs. Current systems cannot scale with the growing data volume. High costs are associated with AI development and deployment as an add-on versus native AI integration. Finally, data movement across different systems, different storage components are not cost-effective. So how do we address these challenges? BigQuery combines the best of data and AI in one platform. It is designed to improve the speed and agility of your business. It helps you derive short-term and long-term value for your organization. It combines everything from data to AI to governance, processing engines, and finally the BI layer. At the foundation of this platform is the multi-model data foundation layer. So users can now operate within a single consistent environment. BigQuery's cross-cloud capabilities extend beyond Google Cloud. Support for other hyperscalers like AWS, Azure, et cetera, ensuring customers do not have a vendor lock-in, and we provide flexibility. Governance is a very critical aspect of our overall strategy. Unified governance across data and AI provides centralized policy enforcement, security, and metadata intelligence, allowing organizations to define, secure, monitor their data and AI assets across clouds seamlessly and formats. The deep AI integration powered by Vertex AI brings AI-native capabilities directly into your queries. And finally, a wide variety of engines support, such as for SQL, Python, Spark, for streaming your data, querying, and actioning on your data. From the technology part, we discuss the ecosystem part. How does it all tie in? We continue to be the most open platform, be it open platforms like Iceberg, engines like Spark, Kafka, or cross-cloud query execution. We have provided and continue to support customers with multitude of Google resources for your migration journey. The first one is obviously the data migration incentives program to offset some of the costs, or majority of the costs, for running two systems in parallel. Secondly, our PSO organization, the professional services organization, it helps you plan and manage your migration journey. Finally, the customer engineering team, the BlackBells, they help offer deep technical expertise throughout your journey. Finally, any migration journey cannot be complete without the partners, the partner ecosystem. We partner closely with technology companies to deliver choice to our customers. It goes on to show our commitment to our partners and in being the most open cloud provider. Looking at what do we provide as Google Cloud in terms of services, BigQuery migration services makes it really easy to help migrate you to BigQuery. 15 plus supported query translation sources are included to help you migrate any of the data warehouses or data leaks. We have multitude of APIs for partners and Gemini enhanced features and capabilities. Overall, we have seen year over year a 3x increase over the utilization as well as adoption of BigQuery migration services with thousands of customers using the services to migrate their workloads to BigQuery. So tying all this together, we would like to discuss this further with a great panel today that we have from across the globe, different industries and also different businesses. So let me get started with the panel here today. Myself, Sajjal Agarwal, I'm a Senior Product Manager with Google Cloud BigQuery, running this for a bit and look forward to the panel today. Next, I have Tom, who is one of the partners from Intelligent. Tom? Hello, everyone. Tom Riker from Intelligent. I lead the Google Partner who focuses on AI, data, and cloud solutions from everyone from startups to the mid-market. Thank you, Tom. Marius. Hello, everyone. I'm Marius. I'm the Data and AI Engineering Manager at YSEA. So we care about all things end-to-end data on the data spectrum from data engineering all the way to data science engineering and AI and actually deriving value of data. And YSEA is a super app operating in North Africa. We're going to talk more about this in a bit. Very happy to be here. Charlie? First, you? Hey, everyone. Charlie Valley, CEO and co-founder of SmarterX. We create regulatory classifications for consumer products, waste, transportation, storage, all the unsexy data that goes into selling consumer products. Work with seven retailers, over 2,000 brands, and we use the full Google Cloud suite, including BigQuery. So happy to be here. And finally, all the way from South Korea, Shin-yung. Hello. I'm Shin-yung-bak. I'm a team leader in reverse data insights team. Before we begin introducing, I'd like to express my gratitude to Google Cloud for giving us the opportunity to share our experiences. Reverse is a global fandom platform that connects artists and fans, offering a diverse range of services. To better illustrate our work and service, I prepared a short video. Let's watch it together. So she is in the fun and the music industry, so it's appropriate to run a quick video. It's ready to go. Leave us. It's going to be a great year. Thank you for sharing with us. So let's get started with the panel discussion. We talked about some of the challenges in the industry, as I highlighted. You can get started with, for example, I think, Yasser, Marius, representing Yasser. What were some of the challenges in your businesses that you were looking to overcome? And you ended up choosing BigQuery. So can you share a little bit about your journey? Sure, absolutely. Hello again. So for us, the name of the game was centralization and simplification without sacrificing any key features and functionality. To give you some context, first of all, we're talking about Yasser, which is a relatively young company, like eight years long, operating in the Maghreb region of northern Africa. And the key, but also with operations in other African countries like Senegal and South Africa as well. So there's Algeria, Morocco, and Tunisia, kind of the main markets. But the workforce is equally global as well. So we've got offices in Cairo, Paris, Dubai. So there's some diversity there. Then at the same time, the business in itself is multi-domain. So we've got mobility services, last mile delivery services, financial services. And ultimately, what we've managed to do is create a marketplace that has participating entities such as drivers and couriers, shoppers and riders, grocery suppliers, restaurant owners, financial services agents. So if you see this reflected on data, that's quite a lot in diverse data sets. At the same time, some more context, the team, the data and AI team is largely centralized and lean in the sense that we're not an army of scientists and engineers and analysts, or we don't have a plethora of roles like the specialized data governance roles and security roles. So with that whole context in place, we had to manage the situation. The key challenge for us is that we had some data in Databricks and also some data in BigQuery and GCP as well. So we actually had an early days partnership with Google Cloud that we were not utilizing full on, at least from a data point of view. And so the decision was to really go all in and migrate, build a single data platform within BigQuery, and likewise, an ML platform based on Vertex AI. So we had, as I was saying, some data sets in Databricks, primarily relating to MLO workflows. And the architecture was such that, or the experience, if you like, that we were taking some BigQuery data sets from GCP, from BigQuery, moving them onto Databricks to train our ML models, try to deploy them. We would create Databricks containers that we would like to host back onto Cloud Run. So that was inefficient, as you can imagine. A very specific challenge, for instance, was that the networking complexities between environments of these different platforms were a pain. They were delaying our model deployments. It was actually one of the areas we were spending more troubleshooting time on, and that's something we didn't like. Also, as you can imagine, from a data governance point of view, you have two different data sets, splits evolving in a different way, which is completely suboptimal. Likewise, the data engineering to maintain these pipelines or even have just coherent, consistent, single data models. We're actually seeing metrics and custom pipelines created on one platform and the other, again, without the harmony that we would like. So that was one. Then another one that we took a very strong stance on from the start was the fact that we wanted our data and AI platform setup to be completely IAC'd. So infrastructure is code. Terraform, therefore, had to work across everything, and we were struggling with the coverage by which Terraform was available with Databricks. So Google Cloud was much better at this. Also, the documentation to do this was much, much better. So that was one that we needed to mitigate because as the company was growing, and actually it was growing, there has been a remarkable growth. In a way, the company is very much like a pioneer landmark company in the area. We knew that it would become a mess to manage environments, their configurations, the communication between services, access control altogether. So these were some of the basic challenges. Why BigQuery altogether? I mean, it ticked all the boxes in terms of our basic requirements and criteria. I can name a few without really saying all the cool things that come with BigQuery. But for us, the integration without the services, of course. Some smaller stuff, perhaps. The fact that you can extract data in various formats, like a Delta format or Parquet, Avro, based on your use cases and your needs. And the fact that you've got these features such as scheduling queries from BigQuery or having Python notebooks nowadays, these things accelerate time to value, like speed to value. And again, with us being a lean, relatively small team, these are things you're going to do quickly. You're going to hack your way quickly to value, and then we'll come back to more formal orchestration efforts to make things more robust. Talking about the ML of flow, the workflows that we had on Databricks, ultimately we knew that we would be migrating to Vertex AI, build a platform there. I think the key premise that used to be in the past with the prior selection of Databricks of democratizing data science was not a feature by now. So our team members get upskilled in all things GCP, and therefore, yeah, it makes sense to centralize and benefit from the elimination of silos. So all the things you talked about earlier, the problems, really these were things we faced. So hopefully that gives some context of where we were and why GCP and BigQuery was a natural choice for us. Really helpful. Thank you so much for sharing our Databricks to BigQuery migration story. Next one, I would say, let's go with Charlie. If we look at the overall AI Ready Data Foundation, everybody wants to work in the space. They have lots and tons and tons of data. But with lean teams, small and medium-sized businesses, what are some of the challenges that the companies, this size, growth, and the constraints, the challenges that they face today, and how do they get the help from BigQuery or Google Cloud? Sure. Sure. So we've been around for nine years, and I feel like we've used every system. And when you do that, I think as Marius was saying, you know, you end up with kind of sprawl, and you're spending a ton of time, you know. You don't realize you're kind of migrating between systems daily. So for us, it was really important, you know, we do regulatory. I just realized I can talk into my mic. So we do regulatory classification, and we needed the data, the LLMs, and the compute in the same place. Like, just get it in one experience. Stop moving it around. Because you don't understand how much time you're wasting until you do have it in that one spot. That leads into kind of the second point for me, which is flow. So, you know, when we have folks who are building those regulatory classifications and building AI models to support that, to navigate between BigQuery and Vertex, it really needs to all be in that kind of same spot so that they can do their most productive work. You know, we've taught a lot of people to code over the last couple years, and they're using Gemini to be able to code more, to be in BigQuery and just have that at their fingertips where, you know, the people who have known SQL the whole time can do it better, faster. Those who didn't can adjust to that. For us, having it all in one spot is what allows for that flow state where they can just work faster, better, stronger. And then the final one, and I'm kind of stepping on, well, saying one of the same points, is we get to say yes to customers a lot on data formatting stuff where, like, back in the day, you used to spend a bunch of time bickering about that, and it slows it down. So just being able to say yes to customers, send your crappy CSVs, send your JSON, whatever file format using BigQuery can just kind of ingest it on the fly and not spend time on that and spend more time computing. So, yeah, that's kind of, for us, with a lean team, not so many folks migrating to, you know, BigQuery has kind of given us all that power with none of the wasted effort. That's awesome. And what was the size of the teams you mentioned? Like five? Small? We're 35 people, but kind of, you know, half of that is developers. Yeah. And, but within that, it's also, you know, we're trying to make our entire team computational, you know, so smaller core dev team to do the traditional dev work, but it kind of makes everyone something of a data analyst, something of a developer. It's really cool. Yeah. Thank you. Coming to one of the partners here on the panel, Tom, you are with Intelligent and you worked with one of the customers for Google Cloud BigQuery, MarketMind. So tell us a little bit about your journey, your partnership with them, and how you helped them in their migration journey. Sure. So as a partner, we deal with startups to enterprises. We were contacted by MarketMind, who's a fintech who was, they're based in Toronto, startup, and they were building out, they needed a POC built around a next-gen investor relations platform to really, you know, help investors, both institutional and retail investors, try to get control over and manage the messaging that, you know, is really going out there, you know, to them. There were kind of two things we were trying to solve for them. First, they need to engage these retail investors. So I don't know if you know, in the public companies and the markets, there are now more retail investors than institutional investors. And institutional investors always have had the luxury of picking up the phone, directly going to the CEO, or getting a very timely message back from the C-suite in a public company. Retail investors really, to do some research, they would go out to the Internet, you know, they would go on, you know, meme boards and chat forums, et cetera, and they really didn't know. They were subject to kind of misinformation, inaccurate information. So that, obviously, as we all know about meme stocks, can drive a public company's valuation up and down, which could be a nightmare for the C-suite. So MarketMine, actually the founder, lived through that. So when he founded MarketMine, he really wanted to address that to give a SaaS platform, you know, that really investor-relation departments can use from these public companies to get that kind of on-point messaging that, you know, the CFO, the CEO would want an investor. So it's almost the retail investors getting that investor, you know, institutional investor type of service and messaging. What BigQuery and really the overall data foundation, this was an agentic, gen AI platform, and we really needed to go to, you know, roll out the data foundation. That was a base that could handle all of this sentiment data from all sources, structured data, unstructured data, semi-structured data, from the Internet, scraped data. We needed these companies, we needed the platform to be listening in the market. And that's pretty complicated. And the ingestion amount of information that you end up, we needed BigQuery, we chose BigQuery to ultimately serve, to store, and then do advanced analytics on it. But also, we knew this was going to be an agentic platform. So what we wanted to do was leverage Vertex AI, and that was the easy choice. And our ultimate recommendation to them, when we were proposing a tech stack and AI data layer, that they could ultimately go with. And just the amazing scale and that integration that the whole stack, as you showed on that slide before, serves up, it really made a lean team. We were five people, a pot of five that was building this, that could ultimately just leverage the power of the stack, do more with less. Five people, wow. So it does work. Yes, it does. You need a good balance of some senior people, but also some of the mid-level engineers had tooling to assist them and bring them up. But the platform was always just, you know, kind of, it's built-in governance. So if there was any kind of log error in a log that fired up, it also had a recommendation. So it was very, it was kind of the platform that allowed them to build very quickly. That's good. Thank you for sharing that. Coming to Shenyang, question for, I was, wanted to ask today was when you decided to migrate to BigQuery, obviously there are multiple options and choices of, you know, the hyperscalers in the industry. What were some of the reasons as well as points of discussion that you had and finally decided to go with BigQuery? Let me break this down into three main areas. First, we faced a significant challenge with separate data stories and analytics environments. Before implementing BigQuery, this existed as separate two services. Consequently, managing two different services requires dedicated resources leading to increased overhead. We expect the fully integrated platform BigQuery to streamline our data operations and lead to significantly boosted efficiency. Second, we are dealing with dramatic and unexpected traffic spikes. Imagine this, a super-duper popular artist goes live. We get over the best numbers of fans from all over the world jumping online at once. This means sudden huge spikes in traffic. We get over the best numbers of people. We need to get over the best numbers of people. So, we need the performance that was both fast and flexible. Keeping a ton of high-powered servers running all the time would have cost to opportunity. So, it was key for our data platform to be able to flexibly and effectively control how many resources it uses. Third, build a complexity of building AI and my infrastructure. For a small engineering team, integrating machine learning platform into our services wasn't realistic. E-QORI provides a solution to this problem. We are very impressed with capability of BQML. We are utilizing LLMs for various purposes. We use them to analyze and summarize user survey responses and purchase-related feedback in multiple languages. Second, we are building an internal data catalog by automated generating data descriptions and example sample queries. In the past, this task would have demanded complex data pipeline, individual API contract, extensive key and cost management, and separate security reviews for each API. However, by integrating Vertex AI, Gemini models through Google Cloud, BQML, we have significantly simplified these processes. This is really helpful. You said work efficiency increased by 10 times. That is huge. Thank you so much for sharing. Coming to, so we talked about the challenges, the implementation. We talked about how BigQuery is actually the app solution and a partner in the journey of some of the small and medium businesses as customers as well as with partners. Moving on to the benefits part, you know, in this question, Marius, maybe for you, you based your data platform in BigQuery. So integration, you touched base on the Vertex AI and other Google Cloud AI services for AI model development as well as deployment. What were some of the benefits that you can say for your business as well as for the audience here that they can achieve with this? Yeah, I think they would relate. So more or less take all the challenges that I mentioned before and flip it into areas where we saw positive impact and benefits. So a single data platform, so better data management and data discovery as well as having to search for data in two areas. You know, what comes with this, better data governance altogether. Simpler, more efficient data and ML workflows and deployment. That was a big area we saw benefits on. Networking simplification. So what I talked about before in terms of interconnectivity between different services and environments. And then just more BI, more analytics. Like previously we were having analytics dashboards in Lucas Studio linked to BigQuery data. Likewise, Databricks has similar capabilities, but just not being able to marry up data or join them as easily at least from the two platforms. And then just the management, the governance of this whole analytics workspace for us was a problem. So, yeah, let's take the integration part. So BigQuery with a few examples only. I'm not going to talk about all the BigQuery integrations that we've benefited from. But BigQuery and one that is not quoted as frequently, but workspace, BigQuery and workspace. So we have new team members coming in and we are assigned to a Google group, as you would imagine, for team management purposes. But then these Google groups we are using for our role-based access control. And this, by the way, is all completely terraformed. So, you know, voila, by assigning somebody to a Google group for business use cases, we've got them to the right action, to the right permissions to do data sets across our data platform. So that was a big benefit. Then also what comes with governance is our increasing use of Dataplex. And, again, talking about a small lean team, we don't have to worry about other tools like perhaps Atlan or Alation, like in that space, because one of the things you want to do as a small team is you don't want to have multiple accounts management together. You want a single account, a single pilling view, and, you know, benefiting from the benefits that come with that. So, you know, BigQuery and Looker Studio, so now all of our analytics dashboards are on a single tool. We are struggling a bit with, you know, Looker Studio doesn't have the governance of Looker, but we are actually, you know, moving on to Looker to get the benefits there. So that's a big plus. And also I think the fact that we're not splitting the team between dashboards from one platform, dashboards from another means more collaboration. But also, you know, from a management point of view, better utilization of your resources. Yeah, there's more collaboration between the team members. And obviously the biggest one, BigQuery and Vertex AI. So we've built our data, our ML platform on top of Vertex AI. We've created sandbox environments, production environments, so the teams, the data scientists can very easily actually fire up instances with minimal support from our ML ops engineers and do their training all the way to API setup. We've actually seen these soft benefit of talent upskilling more. And like the analysts want to move more into the data ops space, the data scientists more into the ML ops space, which is great for us. And also there's an element of talent attraction as well. Like, you know, it can be a more appealing argument to actually say we're, you know, working a lot with the GCP. And then when it comes to our ML platform altogether, completely terraformed, completely CICDed. So it's not even a topic of conversation nowadays, the connectivity element that I mentioned, but the ML deployment part. Like we know it's part of the ML lifecycle and the project delivery, but it's not something we're actively discussing on how much is this going to take and all that, which used to be the case in the past. More integrations, BigQuery and data form. So kind of our DBT equivalent. Again, we don't need to worry about other tools. And we're benefiting from a single data models there to be used for all data in our single data platform without, again, the data being split. What else? Then the smaller parts that I mentioned earlier, like BigQuery and BigQuery ML or the Python notebooks that you can run on BigQuery and the fact that you can schedule them. And all the way to recently what was announced last month of the BigQuery repos and the Git integration. So these things allow us, again, to move fast, get to value faster, and obviously with the Git integration, benefiting from all the cool stuff that Git has to bring around code versioning and the good engineering maturity elements there. Finally, I cannot not mention BigQuery and Gemini. So our analysts are benefiting from faster SQL code generation, debugging, which is exactly the stuff you want to see. I mean, we're not only using Gemini for the BigQuery ecosystem, but Vertex AI ecosystem and across actually workspace. So we've really taken that on. So, again, on the people side of things, just two more things to say. We really appreciate the impact this is having on talent and talent upskilling. And, you know, this is something we're going to reinforce actually, you know, make sure we've got the learning opportunities there for our data scientists and our data analysts and data engineers to learn more of the BigQuery ecosystem and benefit for all of these integrations and solutions available. So, but also in this migration, the Google support team in the region has been so very helpful and prompt and technical responses that this whole migration for us would have been a much more slower and troublesome journey if it wasn't for them. So I have to say this out there. Thank you, guys. We're still on a journey. So for me, this panel is very interesting because there's learnings we're taking because, again, we're still on a journey, but it's going on a good place, and I don't see anything kind of challenging our decision coming forward. Thank you so much for sharing your journey as well as the entire suite of products that you mentioned, not just BigQuery, but integration as well as with customer support. So the entire journey, the entire migration journey with Google Cloud and BigQuery. So thank you. Coming on to from benefits to advice, you know, we see the benefits to organizations. Advice to companies that are getting started in this space. Charlie, maybe a question for you. How can they get started in their journey if they are starting now, if it's too late against their competition, et cetera? But advice for companies in similar space? Yeah, absolutely. So the first thing I would say is it's never been easier to start over. You know, it used to the idea of doing a migration kind of relatively overnight used to not be able to do that. So it's kind of a strange and empowering thing that you really can make the migration and kind of get all your tools into one house. My first piece of advice is really just to start using it. I think in past times where we've done a migration or considered one, you spend a lot of time talking about it. And then once you actually start using the tools, it's kind of a different game. So for us, making that choice, you know, getting fully on BigQuery and fully adopting all of the tools, as soon as you start using it, actually get in there, use it yourself, understand how it all interacts. I think for us, that kind of creates the roadmap. You know, if your team is truly invested in it and understanding it, you know, these tools have come so far. I think the doing is kind of the learning is kind of the road mapping. I may be a little bit looser on that than other folks are, but it worked far better for us. And then the second one I have is once you're kind of in that process of doing is just imagining what the ideal data UX is for your users, whether that's internal or the customers themselves. Because while, you know, what Sajal presented in that diagram, there's a lot of moving parts here, you know, Google kind of makes the lines go away. You know, it actually turns into kind of one system if you commit to using the full stack. So I would recommend, imagine the ideal user experience, not thinking about the stack, not thinking about all the things that underpin it, but truly what is that experience of searching and analyzing and creating new data and adding it to your system? Because that's possible now and you don't need to be held back on that. So, yeah, I guess for me, it's just a matter of touching the data, using the tools, using BigQuery, Gemini inside of it, and having that kind of define your path forward. Thank you for sharing the advice. And we have migration incentives as well to support in the journey to get started today. So coming to Tom, maybe, we talk about your journey as a partner. And your ability to scale with other customers and help them take to market the industry trends that you see. And do you see patterns, you know, across regions? And we talk about, can you talk about those from an industry perspective a little bit? Sure. So, you know, plus one of what Charlie was saying about the tools and really getting that acumen and learning and always be learning, do the Kaizen mode on the tools. Things are changing so rapidly. So we are seeing a trend for a lot of these kind of lean teams, knowing they were living in the world of do more with less. Really be open, not resistant to, you know, learning a lot from these tools. You may discover them, join, you know, be active on Stackflow, join your community. So we are kind of seeing this behavior with, you know, with these teams to really just embrace and knowledge share across. And also, you know, give them a forum to also kind of share what they've learned with this tool. So at the Dev Keynote, there are now agents, data engineering agent now available in console. There's Cloud Assist. There's just so many tools in console, for example. You can just, you cannot get stuck. You have Assist co-pilots. If you're a Git shop, you know, using Git co-pilot, you can, there's just, you have to embrace these tools. So we are seeing that trend. So, you know, on companies, that means you need to build that supportive environment, you know, to really encourage that and scent that. And also, you know, enable the tools, which sometimes means buying, you know, some subscriptions. We are seeing a very kind of hyper approach out there, hyper acceleration about attacking, stack ranking the complexity and attacking the low-hanging fruit first in terms of when you're looking at a project. So we build, so we build, we're builders. So we tend to kind of get the quick first wins, iterate, and, you know, go back and forth with our clients. We are seeing kind of an avoidance from that kind of waterfall-like, you know, let's go attack massive parallel teams to go and just, you know, address the big project. We do see, you know, those iterations. And then, again, the tooling is also enabling that, and especially with its, again, also plus one, Charlie, just start building. You can just get a culture of rapid prototyping, get playgrounds going up. We are seeing that. A lot of devs and engineers are asking, you know, asking us for that. And, you know, really there is in the industry, especially with the Google data and AI stack that's out there, a lean team can really be bold and accomplish, you know, the most sophisticated idea, you know, and not need hundreds or tens of, you know, hundreds of people. You could just be, you know, a three- to five-person team and lean on the scalability and the power of that integrated. Yeah, to your point before, you have to buy into the stack. It does work with the stack. So I would end on that. Also, just, you know, getting out of, from a cost-effective perspective, you know, and that pay-as-you-go model, it's for lean teams that's very helpful to just, you know, start building as well. It's not cost-prohibitive. And you get yourself out of the DBA, the infrastructure management, the network management, the server management world. You know, just lean on that scalable serverless platform. Big query and, you know, there's nothing you can't accomplish. That's a great story. And thank you for sharing the industry trends here. So just get started and follow the steps. So coming back to you, Shin-Yang, we talked a lot of goodness, a lot of good things. But in terms of your journey, some things, the results in the journey you wish were different or things that could have been better. And, you know, the learnings that you would like to share with us, good and bad both. Reverse Company provides many services through Reverse. We offer services like live video stream, paid DM chat, and online shopping. Given the diversity of our services, our data team handle a wide variety of data, and we manage a substantial number of data mart. Migrating over 1,000 data sets inquiries required us to streamline our process for efficiency. To address this, we developed a tool for the automated conversion of Spark SQL to BigQuery SQL. Initially, the dry run success rate was not satisfactory. However, by fine-tuning the conditions and rearranging the command sequence, we significantly improved the success rate. We recommend going beyond just creating an automated conversion tool. It's crucial to experiment with several representative data sets to identify and address common pain points. Moreover, it's vital to keep in mind the SQL dialects in each system. Also, be cautious with data and time-related data types and regular expression engine's differences. In particular, regular expression engines, more often manual intervention due to their inherent complexities. Furthermore, we advise prioritizing the migration user based on data criticality and batch flow. To finalize, we recommend carefully testing with a selection of complex and very query sample to further develop the migration of capabilities. As I mentioned earlier, our services are quite diverse. To add one more point, they are also rapidly with frequent feature changes and additions. Furthermore, the entertainment industry is unique and characterized by many unexpected events. Therefore, we must respond quickly and effectively to this situation. Therefore, we must respond quickly. These industry dynamics and combined with the rapid revolution of our services make the implementation of AI in our data strategy increasingly crucial. To overcome many challenges we faced and achieve our goals, our data team have chosen Google. And now in the middle of migration. Since the migration is still in progress, I think it's still early to discuss final results and detailed improvement. However, we are hoping for great results and we will do our best. Thank you very much. With that, we have some time maybe for one question. The audience, if there are any questions here. Top of the hour. We don't want to keep holding you back between... Looks like most of the questions were answered with the great panel here. So, finally, a quick reminder. Scan the QR code for learning more about the BigQuery migration services and all the latest and greatest announcements. The tooling, the connectors, and everything that comes along. And the incentives program as well. So, these are the two QR codes for taking the next step in the journey. Your feedback is greatly appreciated. Thank you very much, everybody, for taking the time. And a great thank you to the panel. Thank you, Sarah. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you.