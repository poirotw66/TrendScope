 Hello and welcome. My name is Tim McQuinney. I'm joined here by my colleague, Jim Casey. We are both product managers on the Google Workspace team focused on security. In today's session, we're really excited to talk to you about how organizations are able to take advantage of Gemini and Google Workspace without compromising on security. So really the inspiration for this came, I would say, many months ago. Gemini talked to Workspace customers almost daily, and the theme of this last year has been very consistent around organizations that want to take advantage of Gen.AI. They want to take advantage of Gemini, but they have questions, questions about the privacy safeguards in place for their users and their data, questions about can I use Gemini safely with my most sensitive intellectual property, and what actions should I think about and take as I get ready to embark on this journey. So today, we want to sort of have that conversation that we usually have locally one-on-one with customers, with all of you kind of at scale. And to support today's conversation, we actually just published a white paper on Monday, and we'll share the link afterwards that sort of unpacks some of these topics in more detail. Now, this wouldn't be Cloud Next if you didn't also have the opportunity to hear from both a Google Workspace partner and a customer on sort of their lived experience, as well as a little insight into our product roadmap and recent innovations. So let's dive into it. Chances are, those in this room kind of fall into one of two buckets. You're either well along the way with your AI enablement journey, or you're starting to consider it. And maybe you're feeling the executive pressure, or your employees are eager to start using these tools, or perhaps even starting to find their own solutions, something we kind of call shadow AI or shadow IT. And that can get scary very quickly, especially if users are reaching for unbedded, ungoverned solutions, and they have access to very sensitive information. So as security practitioners, you really have to think about, how do I provide that well-paid path? Google Workspace provides that well-paid path. We were really architected for the AI era when you look at how Workspace was developed from the origins. With a cloud-native delivery model, with zero-trust principles baked in, and then, of course, the built-in data protection capabilities you can take advantage of, the sovereign controls you can take advantage of, and the advanced threat protections. And that extends to you, as a Google Workspace customer, to the Google Cloud security ecosystem. The data protections in Workspace can be leveraged in the browser with Chrome Enterprise. You can pass the telemetry to Google Cloud SecOps and take advantage of that robust tooling. And then there's even the domain expertise of the Mandiant team that you can integrate with. So now I'll hand it to Jim to talk through some of how we apply these same principles to Gemini in Google Workspace. Yeah, thanks, Jim. And, you know, I think one of the things that you can see from the data, and maybe you've experienced this in your own organization, is we have an exploding use of Gen AI, but the maturity of a lot of these deployments isn't necessarily where we might want it to be. And so we asked ourselves at Google, you know, how can we make this easier for organizations to use generative AI in a secure way and at the same time preserving all the productivity benefits that your users are getting? Sometimes those things can be a little bit at odds, right? And so how can we give you the best of both worlds? And so the first part of our answer to that is what you can see here, right? So what we've done is we've created a system here where you can have the confidence that Gemini is going to be secure and that it's going to be compliant in the way that you need it to be. But more importantly, we've also given you the ability to have configurable governance around this. So the way that your policies and how you want to protect data, what you define as data in one organization, might be very different from, you know, the person sitting next to you or across from you here in this presentation today. So how do you make it where those pieces can all fit together in a way that's meaningful for your organization? So let's break this down a little bit more. Let's look at some of these in more detail. So private by design. What do we mean by that? Well, there's really two points you can think about with this. The first one, we will not share your content outside your organization without your permission, right? Second thing, your content is not used for any other customers. Your content is not human-reviewed. It's not used for generative AI model training outside of your domain without your permission, right? So private by design. Let's talk about compliance. Now, the usual way we might say this is if you are in a highly regulated industry, right? But I think everybody's in a highly regulated industry these days, right? There's some, one of these acronyms is probably affecting your life at work in one or more ways, right? And what we want to do is, and what we've done, is we have invested heavily with Google Workspace to give you a comprehensive set of compliance certifications that we've done for you, and including, this is really kind of cool, we're one of the first generative AI assistants to achieve FedRAMP high authorization, which is, that's pretty great. But let's talk about another important aspect about how Gemini uses security first principles, and I'm going to ask Tim to walk you through some of that. So one of the things I've really come to appreciate about how we develop the product is the fact that Google manages the full lifecycle. And what that means is we can sort of break down secure models under two pillars. One is the actual development of the foundational model, and then the second is the secure operation of that model. That is how I'm interacting with this as a feature, as an end user. But when it comes to the secure development of a model, you have to think of things like source data tampering, adversarial testing, and red teaming. How do I make sure that my training data is not compromised or poisoned? Because that then manifests into a compromised user experience. Gemini is a Google-built model. The foundational model is developed by the same principles that all the Google products must adhere to when it comes to secure development practices. And then Gemini Workspace is then layered on with the operational security benefits of advanced threat monitoring for kind of new emerging threat vectors such as prompt injection attacks. The last piece of this sort of framework is around data governance. So there's things built in into Gemini for Google Workspace for you as a customer that you sort of get out of the box. But then there's the questions around data governance. When we look at Gemini, Gemini fundamentally does not change the access characteristics of your data in Google Workspace. If I have access to data, I can interact with that data through Gemini. If I don't have access to that data, Gemini is not going to somehow circumvent the access controls that are in place. So then the question becomes really not a question of AI. It's do I, as an organization, have the appropriate data access and sharing boundaries? Have I achieved the data security posture that's appropriate for the risk that my organization faces, the productivity needs, and the collaboration needs of my employees? Rather than prescribing a rigid or one-size-fits-all approach to data governance, what we've built is effectively a workbench. We provide the tools and you as a customer are able to configure the data security posture that's right for you. And then with that, Gemini respects your access boundaries. It doesn't change that definition. So this is a really interesting concept and where we see a lot of the conversations with our customers heading. So what I'd like to do is invite Mr. Tyler Prudel of Flashpoint, a cybersecurity organization and a Google Workspace customer, and Andrew Livingstone, the chief technology officer for Strata Prime, a Google Workspace customer, onto the stage and we can have a conversation with them about their Gemini experience. Welcome. Thank you. Thanks. Thanks. Thanks, Tom. Thanks, Tom. All right. Well, thank you both for being here today. Jim and I have had the pleasure of getting to know you kind of over your Gemini journeys and I think those are both some very interesting stories from both of you for everyone to hear today. But I'd like to start with some intros to understand who you are, your role, what your organization does. So Tyler, you want to kick us off? Yeah, sure, Tim. My name's Tyler Prudel. I am the director of IT at Flashpoint. For those unfamiliar with Flashpoint, Flashpoint's the industry leader in threat data and intelligence, we help mission-critical organizations and governments globally, proactively, and decisively tackle their most pressing security challenges. Excellent. Thank you. And Andrew? Hey, everybody. So I'm Andrew Livingstone. I'm CTO of a Google Cloud partner called Strataprime. We're a highly specialized Google Workspace partner and we actually help companies move to Google from Microsoft-based productivity solutions. And then once they're there, we do a lot of deep advisory and security work around data security and privacy. Great. Well, welcome and thank you both for being here. So, Tyler, my understanding is that Flashpoint is using Gemini with their employees today, but, you know, that's obviously a newer thing with the advent of AI over the last few years. Could you talk to us a little bit about the organizational goals when it came to Gen AI? What use cases were you looking to enable? What were you really hoping to get in terms of an organizational benefit? But also, like, what was the trepidation? What were the risks with this? Yeah, of course. So I would say, like many companies, Flashpoint, when maybe in late 2023, Gen AI really was coming onto the scene and Flashpoint saw the huge benefits that Gen AI could bring to the organization in terms of productivity, augmenting the workforce in terms of their skills. And while it seemed like this amazing tool, it also posed a lot of questions around security and data governance. And so we took a really cautious approach by looking at many different options. And when Gemini came around, we noticed that Gemini was built into Google Workspace. It was in the environment that we knew and that we trusted already, just like we trust Google Workspace for Gmail and Google Drive. Gemini didn't change that in terms of how we trusted it with our data. And the really big thing for us is that Gemini doesn't train the model on our data. And that was a really important factor as a lot of other companies that we looked at, that wasn't always the case. And I think another big point for us is that the features that Gemini would release, that Google would release through Gemini, were enterprise-ready when they were released. And I think from an admin perspective, that gave a lot of confidence that, hey, we're putting this out into our workforce. We know that the features are enterprise-ready. We know that we have the granular controls, the auditability, and the ability to really just deploy Gemini in a secure fashion. And, you know, not really, we're not sacrificing anything on that end. Yeah, and, you know, Tim had mentioned shadow AI a little earlier. I'm interested in your perspective on that. What's that been like at Flashpoint? Have you experienced this? And what advice might you give to folks here today about dealing with that? Yeah, great question, Jim. So I would say shadow AI is a really big concern. And when looking to provide a tool, a Gen.AI tool to our workforce, one of our driving motivators was, hey, there's this really powerful new technology out on the forefront. And if our users don't have a secure and compliant way to use it, that introduces the possibility of shadow AI. And shadow AI is very dangerous because you don't know what your employees are putting in, what are the, you know, data governance strategies of the companies, what is, you know, are they training on your most secretive data? So, you know, you have to lock down your environment, but you also have to provide your employees with an alternative because if they don't have an alternative, people are very good at finding ways around it. You know, we have phones in our pockets 24-7. And so I think Gemini really provided that solution for us. So I guess maybe the good news is it's not so different from shadow IT just in general. It's the same kind of principles. Yeah, exactly. Same principle and I think the biggest difference that we found with shadow AI is because AI is so powerful, people are more likely to go and look for an alternative. So, yeah. So, Andrew, I'm curious. How indicative is Tyler's experience with the organizations you work with? Because you sort of transcend industries and sectors. Is this kind of what you're seeing in the wild? Yeah, let's talk about it. So I think the concerns that Tyler raised underneath his questions are questions that a lot of companies have that we hear about. And I think the biggest one that you were talking about with shadow AI and some of these technologies is if I install a Gen AI tool into my environment, will my users have access to data that they shouldn't have? Right? That's like question number one. And the reality is that the way that you've designed Gemini is that it only operates as the user. And that is massively simplifying as an admin because now I don't have to worry about, you know, is this tool going to impersonate other users and summarizing data or indexing it? I know that a user is only going to have access to content that they have explicitly have access to. And where this comes in with shadow AI is when I'm talking to companies about third-party tools, they don't play by those rules. If you're a workspace admin and you install a third-party AI, you're installing it as a delegated administrator. It can impersonate any user. It doesn't have to respect Google Drive sharing boundaries or group policies. And that's where the risk comes from. So with highly regulated companies that are talking about shadow AI, they're saying, no, we're not going to allow third-party AI and we're going to lean in with Gemini because it respects user privacy and is a massively simplifying proposition. And so we've talked a lot about how users might be interacting with Gen AI in their day-to-day jobs. I'm interested in your perspective on maybe the other end of that equation of how Gemini and Gen AI learns about the different things that are happening in your organization, what's important, what isn't. And one of the common things that we hear on this is oversharing. Okay. Right? And it's kind of related in a way and I'm interested in your thoughts too about how that ties into your overall data governance that you might have in an organization. Yeah, great question. So with oversharing, the risk that we're talking about is I have documents in my company that are shared too permissively. So in the workspace environment, that's either we have the worst of all of them which is anonymous links which can be accessed by anybody that has the link or domain-wide sharing links, right, where anybody at the domain can access the files. When we talk about oversharing, that's what we're talking about. So the risk here, Jim, where it kind of intersects with AI because that's a concern in and of itself is when I install a Gen AI tool, is it going to surface content to my user more easily that they shouldn't have access to but they do, right? So this is the problem and this is probably concern number two of IT leaders, right? So first one is can they access stuff they shouldn't? Okay, great. Now what about the stuff that they already have access to? So here, what's sensitive is specific to each organization as you said, right? So step one is I've got to understand what's sensitive for my company and then as workspace admins, as Tyler knows, we have controls that you guys have provided for us to be able to put up those boundaries. So one of those boundaries is with information rights management where I can say, Gemini, you cannot access documents that have PHI or personal financial data, right? Because that's a policy or an acceptable use that we've chosen. It's not because we don't trust the tools but it's more of that's the posture that's right for our company. And as an admin, you can extend that to say, maybe go after specific shared drives and deem that as a location where you're not going to allow Gemini to access content because it's board of directors minutes or meetings from product roadmap and super confidential data. So the controls are there for us as administrators to prevent the risks of oversharing being surfaced through AI because Gemini allows us to do that. But calling back to my previous point, how the heck are you going to do that with a third party tool? Yeah. Like, good luck with that, right? It's just not going to happen. And I think your point is we can take a lot of the same principles that we've learned over the years about how to manage this for users and the metaphor applies here with Gen.AI. Absolutely. So, Tyler, I mean, fast forward. You guys are several months if not a year or so into a successful Gemini deployment. Tell us a little bit about, like, your lens and how you approach the data governance question. Is that a question that you kind of grapple with prior to the advent of AI? Did Gemini or just kind of the shadow AI concerns change the perspective? What was the experience? Yeah, so I would say a lot of what Andrew said is very valid and true to the experience that I lived at Flashpoint is that, you know, we came into the Gemini era, per se, with a really strong data governance posture. But I think the value that Google brought to us was that we had those controls. We had granular controls. We could limit what Gemini had access to if we wanted to. We had access to AI data classification. So, you know, by being able to classifying your data is a great thing to do, but it takes a while. But with AI data classification, it makes your life so much easier. It can do it very quickly. And then, I would just say that in general, we just felt that, you know, having the auditability and all these tools at our disposal really just made it easy for us. But at the same time, we didn't, you know, we could still deploy Gemini and it would respect the permissions that the users had to access the data versus some of the other tools we looked at. Like Andrew mentioned, if I, as the workspace admin, connected that tool to our Google Drive, it would have all the access I have to my Google Drive. And that's a very scary proposition as Gemini is respecting the individual users' roles, which I think just makes a deployment very simple. And, you know, and then you have all these features where you can fine-tune. You can add in the AI data for classification. You can, you know, restrict data with IRM. And there's just a lot of tools at your disposal so that you can grow with Gemini and into this kind of Gen AI era. Excellent. Yeah. So I want to kind of try to make that more specific for the admins in the room. And I think that if you're struggling with, like, an oversharing problem and you think you have that now, like a playbook on how to resolve that would be to the first thing you want to do when you realize that you're in a hole is stop digging. So stop creating domain-wide sharing files. And you can do that in your Drive access settings by going to an area called Target Audiences and removing the domain-wide option and giving your users group-based options to share files. And by removing the ability to create anonymous files. You do those two things and you've now stopped creating, you know, files that are overshared in the worst possible way. And then the second thing I would say to do is the product provides to us the ability to export all of our Drive data with the Drive export. And you can put that into a free tool which is Looker Studio which is included in Workspace. And now you have a data governance dashboard that costs you $0 that shows you where files are shared across your company and where they're shared domain-wide and where they're shared outside of the company. Now step three is if you're an Enterprise customer, Enterprise Standard or Enterprise Plus, you can use DLP rules to then classify those files where they contain sensitive data. If you're an Enterprise Plus customer, use AI classification. It's like a thousand times easier. So now your dashboard that you built in probably your lunch hour shows you across the company all your files that are shared externally and now those that are shared externally with sensitive data. And that costs you nothing to do just with the tools that you have. So what you're saying in not so many words is this is a tractable problem. A hundred percent. The tools are there for admins. And if only we had demos of those things. Oh yeah. Maybe you could put something together. We might have time. All right. Well, parting thought for the two of you. For the audience, for those who are maybe at the early stages of embarking this journey, maybe an insight, a lesson learned, something you wish you knew sort of at the onset. of that. I would just say I wish I knew how easy it was with the Gemini that it's already built in and you just have to show the users the magic of the tools that they have where Gemini's in Drive and email. It's already, it follows, it meets them where they are. And I think knowing that it's easy on the admin side to deploy and manage and then also super simple for the end user just makes my life as a workspace admin so much easier. Andrew? And I think my parting thought would be enablement is key. Get your users some support from your partner or from Google on how to use this technology. What we see is that there's vastly greater return on time savings and acceptable use when you, you know, you do some training and enablement up front. So I would highly recommend that. Excellent. Well, thank you both. Really appreciate you kind of sharing your perspective and being with us today. Thanks for having us. Thanks for having us. Appreciate it. Thanks. Thank you. All right. That was a great discussion. And, you know, it's discussions like these that got us thinking about how might we define a repeatable and simple process that you can follow so that you can confidently roll out, you know, what might seem those two competing goals that I talked about. getting the productivity gains and all those benefits you want for your employees and your users while at the same time doing that in a secure way so that you don't compromise on, you don't have to make compromises on security to adopt these kinds of technologies with Workspace. And so in our conversations, as Tim mentioned earlier, you know, we leveraged a lot of smart folks like, you know, these two gentlemen that we just had up on the stage and we came up with, I think, a pretty straightforward process for going from, you know, zero to productive or wherever you are in your journey on this and to be able to do that quickly and easily. And so there's three pieces of this and the first one, let's talk about the first one here in a little bit more detail. So identify and report. Well, you cannot protect what you're not tracking. And so that's why the first step that we think you need to take is you've got to identify and catalog the sensitive data that you do have. And you might be surprised how much you actually have when you start on this journey. And you might ask, well, sensitive data, what kind of data are we really talking about here, Jim? Well, it's, one way I like to think about it is any data that if your competitor got their hands on would benefit them. That's one way to think about it, right? There's a lot of other ways to think about it, but that's one that's kind of an acid test. All of that is sensitive data. It's critical to your business. And, you know, it could also be everything from financial records to, you know, product specs, you know, kind of the what you do or even your own internal processes and operations, kind of the how you do things. All of that is really, really valuable to your organization and we need to be able to protect that. So, to make this real for you all, bear with me. I want you all to just imagine your closet back home, right? You've already got that mental image of what that is, right? And if we had to identify the most important items of clothing in your closet right now, what would we do? Right? You know, we might have a special shelf we might move things to or a special part of the closet, you know, and we might put some, you know, categorization around that. Like, you know, these are my fancy occasion clothes. You know, I'm going to cloud next. You know, we got to look nice, right? You know, but that way you can find it quickly and you don't lose it when you need it. And, you know, if we, coming back to what we're talking about today, you can, you know, you can reorganize your closet when you get back home. But if we were to start this on our data, right, are we going to just like bust out a bunch of label makers and start labeling everything like crazy, you know, and figuring out what sparks joy for us? You know? Probably not. You know, that's not what we want to do. What we actually need to do, a couple things we need to do before we do that. The first thing we need to do is we need to be able to define our taxonomy. Now, our taxonomy could be something as simple as we might say for sensitivity, we might say, you know, public, confidential, need to know. Could be even more complex than that, right? But that's a general way to think about it, right? And then the next thing that we need to be able to do, it's great if you manually can apply things, and we've been able to do that for a while, and we'll show you some new things we're doing with labeling for other kinds of data, but it's great if you can manually apply it, but the problem with that is a lot of times people forget, or they don't know all the intricate policies of something that's need to know versus confidential. It's hard for people to remember all that and keep that in their head, and then it's hard for them to remember to click on the thing and apply the label. Now, if you have really, really motivated users, that's great, right? But for most of us, we get busy, we forget, so wouldn't it be great if we could automate if the system was smart enough to know how to label these things for us, right? And one of the things we'll show you is AI classification and data loss prevention or DLP to do that. And then the last thing you've got to be able to do is we've got to be able to report on all of these things, right? So that we can see, okay, where is our sensitive data, right? And we heard earlier about, you know, the ability for us to get that kind of dashboard of where all my data is at any one time. And so, Tim, you want to talk about some of the features? Yeah. I get the fun part. I get to share everything that's new. So as you've heard, you know, how do I've done this classification program? I want to understand the state of my corpus. How do I do that? Last year, last fall, we GA Drive Inventory Reporting. That's a snapshot of the metadata of your drive items. You can understand what items I have, who owns them, are they shared externally? How are they classified with Drive labels? Over the course of this year, you're going to notice some semantic improvements expanding that table to answer more questions. And we're also going to start doing some experiments with different snapshot cadences. Currently, it's a weekly snapshot. And then, it's in beta. I know some of you in the room have already started using it. Classification labels for Gmail. So that same functionality that's been in Drive for many years integrated with DLP. So now you can identify, hey, this is a need-to-know email message. And maybe you have a DLP rule that with content detectors and pre-chain detectors and string matches and regex and things of that nature, oh, you're talking about something our organization thinks is sensitive. Let's label that. And let's also make sure we put a sharing boundary on that so we prevent egress. And then, with AI classification, we GA'd it at this conference last year. Today, we are going to show you a brief demo in just a second of a major release coming later on this summer, which is the ability to train multiple AI classification models and do that on demand. So let's actually take a quick look at this live. So what multi-model support is, is today it's a single model. So you may pick a label for a specific use case and train an AI model for it. With multi-model support, there's a couple use cases this unlocks. The first may be, hey, I have a model and a label that's specific for my HR team. I want to train a custom model just for the HR team and use that to classify their files and audience target it. So you can build these audience-specific models. You can build models for different use cases. With this, we've simplified the UI and made it just much cleaner and simpler to operate. And we also introduced what we refer to as on-demand training. So when you go and you identify, I want the model to focus on these files, to have that be the basis of its understanding. It's an iterative process. When the product first launched, we, on a regular cadence, would retrain the models. Now you will have a button. So when you get to the point where you say, hey, I've collected my training data. I'm ready to give this a go. I want to test it and QA it. You hit a button. It kicks off the jobs on demand. You get a clear status. And shortly thereafter, you're able to test it. So what does this look like? Here we have a Google Doc. Thank you, by the way. Our demo is live. Wonderful. This is the risk of live demos during sessions. And you can actually see multiple labels were applied to this file. So not just a single. We actually have two models evaluating the same file when it was created. You can see the need to know badge. But let's actually take a look at this and see, oh, we have a label for sensitivity. It's need to know. We have a separate label for a record retention policy identifying the business record type of financial data. So behind the scenes, I have data loss prevention policies. You can see that share icon. We're not going to share this sensitive data out of the domain. Let's have a bolt custom drive retention policy that's saying, hey, financial data, let's make sure we retain this for three years from the date of creation to ensure that we have compliance for the retention schedules. Both labels applied automatically with AI. And here's a quick look of what that UI looks like. So you can see a list. I have a couple models. Actually, I have one. I haven't even trained yet. I'm calling it my stealth label. I want to put some metadata in my inventory report to understand some data governance questions I have before I'm ready to roll that out as a label that my end users can see. You can see I have my trained labels and both of those jobs were initiated this morning. One completed at, let's see here, 10.22, the other at 10.23. That's the on-demand training. The morning of the live demo, I trained a model against every demo, best practice, and piece of advice you can imagine. And it worked successfully. And I'll just show you quickly, we won't step through all this and we'll cut back to the presentation in a second. But this is the new UI. It's a point and click flow to build that model. You simply select the label that you want to train the model for. Then it says, do you want to create a training label or use an existing one? You select it. You put a name. And that's it. Three steps, three clicks of the mouse. You have configured an AI classification model grounded and trained specifically on the data that you identify without writing a line of code. It's very clean. That will be coming out later this summer. Now let's take a look at the next step of the playbook. And Tim, before I get to that, just to put a finer point on this, when you're creating that training data, you just apply a label to that document, right? Like it's not like you have to code or do anything like that. Easy as that. So with labels, labels have permissions. You can say who in the organization can see it, who in the organization can interact with it. When we create a training label, we set it to what we refer to as restricted access. And that simply means only specific users that you as the admin say should have this label, have the ability to access it. So say, hey, for my finance team, I want to train a label, or train a model specifically for them. We go in, we identify who in the finance organization can put eyes on content, understands their data policies, and says, this is a good example for the model to base its understanding off of. And we train them all exclusively on that content. So you have full control over what the model bases its understanding on. And with multi-model support, you can be very targeted and precise, and you can create many models for many use cases. Cool. Perfect. All right. Well, let's switch back to the slides. And we've got a few more things that we're excited to show you, too. So we've got all of our data has been labeled. And now we get to, for me anyway, what I think is the cool part. So once we've got that label on the message, we can start to define policies that can control how users can share, interact with, or otherwise just use that piece of information according to the organizational policies you define. Now you might say, well, what is a policy? Well, so in Workspace, we make that happen through just rules is a simple way to think about it, right? So we can define things like, you know, and these rules are all defined inside of a no-code environment. So you can define things that are things like, anything that is labeled as need-to-know cannot be shared externally. You could also start to add combinations to things as well, right? So you can create rules that can interact with each other, like, you know, we showed you earlier how to, you know, automatically label things. You could say, anything that mentions this particular project that we're doing, that's going to be need-to-know. Oh, and anything that's need-to-know can't be shared externally. And the system is smart enough to know how to sequence those as well so that you get the outcome that you'd like. And so when we think about them, you know, the other thing that we talked about here is around information rights management or IRM. And we talked about that a little bit earlier, right? And we built that in to Gemini. So basically, what that does is it gives you the power to control what Gemini can or cannot access. And the great thing about this, all these things come together, give you the capabilities that you need to make this work the way you need it for your own unique organizational needs that you've got. So Tim, want to talk a little bit about some of this stuff? Absolutely. All right. So a couple really recent GA launches are ready this year in this space. The first is Gmail DLP. So this is the same DLP engine that powers Google Drive, Google Chat, the Chrome browser with Chrome Enterprise, and now that's GA in Gmail, which means you can express a data loss prevention policy scoped to many applications. It's really simple to configure, and now you can get that. What's really cool, and we'll show you this in just a second, is Gmail DLP has what we refer to as synchronous processing. So we ensure a verdict is rendered before there's data egress, but we do it very quickly so there's real-time feedback to the user to educate them with customizable policy messages. So you as a user, it might very well and often is in inadvertent violations of policy. You don't know what you're doing is necessarily at odds with a company policy, and you get a stylized modal that's presented to you, and your admin can give you a message in their words for the specific rule that was triggered to say, hey, Tim, by the way, this looks like financial data. You shouldn't share it externally. Please modify the message accordingly. And you can do that today. That is GA, and with the labels that we talked about before, integrated with that, labels are going GA very shortly here this month for Gmail. The other major announcement we made, it was actually at the beginning of January, is Drive IRM. As Andrew mentioned, IRM actually is a way to put a governance layer on a file that restricts Gemini's ability to interact with it. IRM traditionally was only for viewers and commenters on Drive files. Now we have IRM for all, we refer to it. So you could scope a rule that says, if a file contains this type of sensitive information, I want to prevent download, copy, print, email, and even Gemini access for viewers, commenters, but also editors and owners. And they made a nice little change with the enforcement of IRM when they did this. They allow you to copy within the file. So it doesn't kind of hinder that editing experience. I can still rearrange content within the file, but the content is bound to the file. So I can't take that sensitive data, copy it from a Drive item, and go paste it in a Gmail message or somewhere else. And then, really for the admins of the room, last year we announced the GA of a policy API. That allows you to audit your admin configuration in your settings. One of the pieces of feedback we got from customers is the desire to programmatically manage DLP rules in particular, which is I want to script the actual configuration and the modification of my rules. So that's going to a beta very shortly and a GA later on this summer. So it's an extension of the policy API, but for the programmatic administration of DLP policies. So now let's take actually another live look at the demo and see what that Gmail DLP looks like. Yeah, and to kind of set some context for this, you know, a lot of the times when we're, you know, trying to protect sensitive information, we can think about the bad guys trying to get your data, right? But up to a third or sometimes even more of the time, it's just accidental. Somebody just made a mistake, right? And so what we're going to show you is how the system can actually catch these kinds of mistakes. And I know that none of you have ever done this before, all right, where you had a big, long list of people on an email, right? And there's one person on that list that probably should not have gotten that information. Wouldn't it be great if the system could catch that and tell you before you sent that out, right? Well, that's what we're doing here. And now nobody judged him. You know, everybody makes this mistake, right? But what you see happen here is we got feedback right in the moment. There are two things that happened here. The first one, and we'll restart on the bottom. The first one is that the system recognized that we needed to apply a sensitivity label to this message based on the content in that message. And we also knew that it's need to know. The next thing that happened, we have a policy in this organization here, in this fictional one we're showing, that anything need to know cannot be shared externally. And so that's what you see on the top. Now, he's going to go in and remove that external recipient. Actually, let's do an audible here. Okay. Let's remove that label. Okay, yeah. Try this again. Say, I don't want to do that. Oh, sorry. And it blocks it again. You can also set permissions about you could even remove it or not if you want. Now we'll remove the external party. Okay, so now he's actually going to fix this. Removes the external recipient. We'll leave it as need to know. Yep. All right. We'll need to know. And you hit send. And it worked. Message gone. Pretty cool, huh? And again. We haven't rehearsed this. Yeah. All right. What's the fourth pillar, Jim? Or the third pillar, rather. Let's cut back to the slides, please. Yeah. Okay. So, the last piece of the puzzle here. You know, what we want to be able to do is monitor and track all the sensitive information that we've got in our organization. What does this really mean? Well, you've got to have the ability at any moment in time to know where your sensitive data is, who accessed it, who got it, what workspace app has touched it, right, and when it was accessed. And all of this information we can make available in a couple of different ways to you depending on what you're trying to do. One of the ways, the foundation of all this is we've put a lot of work to enhance the audit logging that we do in workspace. We've normalized it across both Drive and Gmail, and we've also now recording all these events. So, like, what we just saw there before where that label got applied, right, that's logged. So, you can go back and play this back in time and look at the life cycle of that email message or the life cycle of that doc that you might have in Drive. We also have, you know, some built-in reporting that's based off of those audit logs that you can use to find out where your information is. The nice thing, too, we also have enhanced the way that you export that to other tools, so, like, Looker Studio or other BI tool. But also, our SecOps integration can consume this as well, right? We also make this data available to Vault, right? So, there's a lot of different ways that you can leverage and use this kind of data and your information, and we want to make sure that you can use all these different approaches to be able to help manage how you track and monitor your data. So, Tim. So, audit announcements and audit enhancements aren't always the most flashy thing that gets a lot of PR buzz, but for admins, it's absolutely critical. So, the first area of heavy investment for us over the last year or so, and you're going to continue to see announcements over the course of this year, is making the auditability journey of labeling much cleaner and easier to interact with. Audit logs can be a needle in the haystack. There's appropriate sharing, appropriate downloading of content at scale, especially when we have hundreds or thousands of users. I, as an admin, want to understand, hey, show me all the download events for data that's classified as need-to-know, because if it's classified as need-to-know, that is actually peculiar that's leaving the ecosystem, especially at scale. So, some of the things we are doing in this space, we are passing the applied labels on the Gmail and Drive events down to the security investigation tool, and that will come out later this year, so you'll be able to actually filter in your investigations based on applied labels. For the drive logs that are available on the reports API, the applied labels will be there as well, and then the applied labels on the Gmail and Drive logs will be passed to SecOps for customers to take advantage of that tool. We're extending the auditability of Gemini in a couple ways. So, the raw user interactions with the Gemini applications that power the usage reports are going to be made available as a data set, and we are also, which we launched last year, Gemini data access. So, when Gemini accesses a drive item that is logged today, we're going to be extending that to Gmail shortly here. So, let's recap quickly. Kind of three key points to take away. Workspace was architected really for the Gemini era with the built-in security foundations that we extended to the implementation of Gemini. Those security-first and principles include privacy by design, broad compliance support, secure by default from the model development to the model operation, and then extends to how you operate your governance strategy with respect for user access and the tools you need to figure out that right data posture. And you can do that with our classification capabilities, our data loss prevention capabilities, and our auditing capabilities. So, with that, I think we'd like to thank you for coming today. As we mentioned, the concepts we discussed got published in a white paper just on Monday. That is that first QR code. There's a couple other resources. And if anybody has questions, Jim and I will be at the top of the stage for a little bit. We'd love to talk with you. And there's demos, demos of all this stuff that you can see all this stuff in action if you want to dive more deeply over here. Yeah, we will be on the expo for all week. Thank you, everybody. Appreciate it. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you.