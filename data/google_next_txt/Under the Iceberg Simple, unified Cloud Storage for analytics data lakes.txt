 VIVIK SZARSAITH- VIVIK SZARSAITH- Hello and welcome to the recap for Under the Iceberg, simple unified cloud storage for analytics data lakes. My name is Vivek SZARSAITH. I'm a group product manager at Google Cloud. In our session, we had three key takeaways. Customers are really taking advantage of OpenTable formats, especially Apache Iceberg, in order to unify their analytics data lakes. And they're making use of cloud storage as the common data platform for their data lakes, whether they're using first party solutions like BigQuery tables for Apache Iceberg, third party solutions like Snowflake or Databricks, or do it yourself using OpenSource. And cloud storage provides key innovations in simplicity, performance, and intelligence for facilitating these analytics data lakes. We talked about customers like Spotify, who are trying to manage data lakes at scale. They have exabyte or petabyte scale data, thousands or tens of thousands of buckets across multiple continents, and many different workloads, including data intensive workloads like analytics and AIML. These customers are really trying to analyze and better understand their data for cost optimization and efficiency purposes. And they want to co-locate storage and compute better for better performance with minimal downtime. So we talked about key cloud storage innovations to solve these problems, like Storage Intelligence Insight datasets, which helps customers ask the right questions of their data with tools like BigQuery or Looker templates, or Gemini-assisted natural language queries. Insight datasets helps customers take daily snapshots of object and bucket metadata to answer these key questions with no impact to reads and writes. We also talked about Anywhere Cache, which is an SSD-based readcast attached to Google Cloud Storage buckets, which helps customers to easily co-locate storage and compute in their existing buckets. Anywhere Cache accelerates reads with up to 2.5 terabytes per second of throughput per zone, and a 70% reduction in time-to-first byte latency. It's also a great solution to leverage with multi-region buckets to provide compute optionality, and geo-redundancy, without sacrificing either performance or cost effectiveness. We also talked about customers like Uber, who are trying to do analytics migrations and refactors. Some of these customers are trying to migrate their do-it-yourself data lakes to Google Cloud. And their apps, like Hadoop and Spark, expect file-like performance and governance. Other customers are trying to refactor their analytics workloads to work on object storage for better cost-effectiveness, scalability, and ease of use. But they need 10x improvements in performance, and things like throughput, latency, and transactions per second. And they also often need file-like write semantics, such as appendability. So we talked about key cloud storage innovations like hierarchical namespace, which helps customers to enable at bucket creation for file system-like data structure and APIs. Hierarchical namespace accelerates analytics and AI workloads with up to 8x initial QPS for better ramping of workloads and atomic folder renames, which is often key for things like Hadoop Spark task processing, as well as ML checkpointing. And we also talked about providing fine-grained IAM grants at folder level using managed folders. Next, we talked about rapid storage, which is in private preview, which provides really high-performance object storage in a dedicated zonal bucket. Rapid storage gives up to 6 terabytes per second throughput and 20 million requests per second, and sub-millisecond latency for random reads and appendable writes with a new gRPC-based streaming protocol. We also had our customer Two Sigma present on their single data platform using cloud storage and Anywhere Cache for their high-performance analytics workloads. Two Sigma was able to build upon key cloud storage innovations such as AutoClass, Hierarchical Namespace, and especially Anywhere Cache, which helped them improve the scale and performance of their analytics workload without requiring any major code changes and significantly reducing their operational complexity. So, in short, cloud storage is the foundation for a unified data lake architecture, whether you're using a first party, third party, or do-it-yourself solutions. It helps you unify your analytics data lake with a common data platform built on cloud storage and key innovations in simplicity, performance, and management. Here are a couple of links to help you get started. Thank you for watching, and we hope you join us on your cloud storage journey.