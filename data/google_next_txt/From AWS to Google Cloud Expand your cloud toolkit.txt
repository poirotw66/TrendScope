 . My name is Megan O'Keefe. I'm a developer advocate here at Google Cloud. I lead the team focused on industry compete and improving Google Cloud's developer experience. I'm joined here with Marco Ferrari, a cloud solutions architect, also at Google Cloud, focusing on migration. So what will we be covering today? Okay, so this is a very large topic, and so we've tried to fit as much as we can. We'll start with sort of a tour of AWS versus Google Cloud, similarities, differences, some key things to know. And then Marco is going to be covering some info on migration, migrating workloads from AWS into Google Cloud. We will then show a live demo of a migration using GKE and Cloud SQL and database migration service. And we'll close out with some thoughts on things we weren't able to cover, things like multi-cloud, zero downtime, things like that. All right. So let's start with just a show of hands. So who is a current AWS user? Okay. You found the right room. Okay. Raise your hand if you have less than one year of experience on Google Cloud. Okay. You're all in the right spot. I'm so excited. Okay. So this section is for you. It's some info on kind of the key stuff you need to know. So thankfully, both AWS and Google Cloud, they're both cloud platforms. You know, both are global scale platforms with hundreds of products that work in kind of the same way. You know, you pay as you go in most cases, with the exception of things like reserved instances. You can run workloads and databases and generative AI models and analytics and data warehouse and all of that. Both have identity and access management. You can set up your organization and all of the various identities and then you can grant them access to various resources and organizations. And then across all of those products at global scale, both of these platforms have many services, surfaces rather, through which you interact with those products. Things like web console UIs, like you're seeing here and here. Through APIs on top of those products through which there are client libraries in various languages, Python, Java, Node, Go, what have you. As well as command line interfaces. So on AWS, you might use the AWS CLI. On Google Cloud, you have the G Cloud CLI. And then you have infrastructure as code. Things like Terraform providers. You might know Terraform works across platforms. So you can have Terraform modules for both AWS and GCP. And then you might also have things like CloudFormation on AWS. All right. So those were the similarities. Let's get into some differences. Resource hierarchy. So I work with AWS and Google Cloud pretty much every day. And these are some things that can trip me up. The first is the resource hierarchy differences. So as you can see here on the left, in AWS, you have organizations and accounts. And so at the top level, you have that organization root. So when you first sign up for AWS, right, you get that root organization under which you can set up OUs or organizational units. This is where you can set things like policies for certain sub organizations within your team. And then under that, resources in AWS are organized into accounts. And this might be ultimate review, so I'll speed through that part. One OU can have multiple sub accounts. In Google Cloud, the sort of analog to that is organizations, folders, and projects. So at the top level of Google Cloud, you have that organization. This is where all of your teams live. And under that, you have folders. Folders are really useful in subdividing things like sub teams or even sub environments. So like dev, test, prod. And then under those folders, you have projects. The benefit of organizing your projects in Google Cloud into folders is that you can set things like IAM policies and policy constraints. Things like our dev environments can't have public IPs, right? And then, again, resources are organized into projects. All right, networking. So this is another thing that always trips me up as I'm switching back and forth. So AWS, as you may well know, is pretty isolated regionally. And what I mean by that, not just from a resource isolation standpoint, but just from a dev experience. When you sign into the AWS console, you're usually sticking into one region, US East 1 or something like that. With the exception of things like EC2, where you often get that global view. And then from a networking perspective, AWS VPC subnets are tied to availability zones, or AZs for short. And then if you're doing traffic control or things like firewall rule, you might be very familiar with the security groups. These are the bane of my existence, at least. These manage inbound and outbound traffic. And then for doing public access, so connecting public internet into an AWS VPC, you'll be using an internet gateway. So let's talk Google Cloud networking. So unlike AWS, Google Cloud VPCs are global by default. It's less regional. And this also reflects in things like the Google Cloud console. You're often seeing a global view by default, not regional. And then within the VPC, Google Cloud subnets are usually tied to regions by default. And then the firewall whole process is managed through firewall rules as well as firewall policies. So similar, but with some differences. All right. Raise your hand if you struggle with IAM. I'm going to raise my hand now. This is the thing that I get most tripped up on when I'm switching through these platforms, right? And I'll tell you some reasons why. So while conceptually, AWS and Google Cloud IAM are somewhat similar, at kind of the day-to-day level, they're really not. And so in AWS, on the left-hand side, you have identity. So you have IAM groups. You have IAM users. You might also be using third-party identity management tools, SSO, things like IAM Identity Center. So this doesn't even capture the whole part of identity. And then you have IAM roles, which are essentially, think of it like a role in a play. It's something that any person or machine can assume. And then in terms of access management, you attach, through IAM policies, those identities to certain resource permissions. Those permissions can be grouped into IAM policies. In Google Cloud, identity is managed through Google accounts that you can group together through Google groups and also through third-party identity management tools. And then you have something called a service account. This tends to not be something a human typically assumes. Service accounts in Google Cloud tend to be things that resources assume. Cloud Build assumes the Cloud Build service account in order to deploy to Cloud Run, for example. And then you use an IAM policy binding to bind those identities to, this is where it gets confusing, IAM roles. So note here, unlike in AWS where an IAM role is a bit of identity in Google Cloud, an IAM role is a form of access management. This is the thing I get the most tripped up on. And so if you're switching through these platforms, know that a role in AWS is not the same as a role in Google Cloud. Now, we don't have time today to go through all of the sort of mappings between the various products. You might be asking, I use Redshift on AWS. How do I get started on, let's say, BigQuery? This QR code links to a super handy guide that maps AWS products to Google Cloud. There's also an Azure column. So if you are working, God forbid, with three providers in one day, know that all three platforms are covered there. So with that, I'll hand it off to Marco to cover some migration framework info. Hi, folks. My name is Marco Ferrari. And I was told that you gesture too much in the traditional Italian fashion because it doesn't play well with the microphone. So I'll try to give that to a minimum. So let me talk to you about how you migrate workloads from AWS to Google Cloud. So first of all, Google Cloud provides services, tools, solutions, and products to migrate from AWS and other hyperscalers such as Azure to Google Cloud. So let's have a look at the migration tools first. So we can start grouping these tools by area if we want. So we have tools and products that focus on migrating compute resources. So we have migration center to do the automated assessment of your VM portfolio. Then we have migrate to VMs to actually do the migration in a managed way. So you don't need to script anything. You don't need to manage anything. It's a managed service to do VM migration. Then we have migrate to containers, which is a product that you can use to migrate VMs to containers. So let's say that you have a VM for which you don't have any appetite for kind of refactoring. It's a legacy workload. You can lift and shift that to a container running on Google Kubernetes Engine. This is helpful, for example, if you have, I don't know, low touch development environment that you want to move, but you don't exactly know and you don't have an appetite for modernizing them. You don't want to refactor them. So you just lift them and shift to a containerized environment if your entire, if the rest of your workload's portfolio is containerized already. So for object storage, we have storage transfer service, which is a managed service to move data from, for example, Amazon S3 or Azure Blob Storage or even a file system to Google Cloud Storage. Again, this is a managed service. So to configure a migration, you don't need to script anything or play with the Google Cloud APIs. It's just a managed service that does the migration for you, even on an ongoing basis. So it's not a, let's say, a schedule or a batch transfer and that's it. It also replicates changes until you tell it to stop, basically. So it can be used for an ongoing migration. Some teams also use this as a way to replicate data across clouds. So let's say that you have a mandate for a multi-cloud environment in such as in a regulated environment. You can use that to replicate storage across clouds in a managed way without needing to manage anything, any VM or any, any workload that does that. For databases, we have a comprehensive tool that does database, database assessments. So you point it to a database. It produces a report telling you, okay, here are your database instances. Here are the tables that you have here. And here are possible issues that you might have in migrating from one cloud provider to another. Because as Megan mentioned, those features and those products might be similarly named, but under the hood that might behave differently. And finally, a database migration service, which is another managed service to do database migrations. Again, you don't need to, if you don't want to script anything, you don't need to use, if you don't want database, so the native tools tooling to do database migrations, to do, I don't know, a database dump on the source and then restore it. So you can use this managed service that does the migration for you. So, looks easy, right? But it's not just about the tools. It's about having a structured approach to a migration. This is just an example. So the flow chart that you see there, and you can find plenty of those in the migration guides. So, in a migration project, let me give you an example. In a migration project a couple of years ago, we, a couple of years ago, we were asked, okay, can you please design a zero done time migration for this application? So, the customer wanted that because it was a business critical application portfolio. So, we are engineers. So, we got back to the drawing board, said, okay, here is the plan. It's going to cost you X millions to do this with zero done time. So, they said, okay, you know what? Maybe we can go ahead and just consider a fraction of the application portfolio to migrate with zero done time, and the rest with another approach. So, this is because this example tells us that we don't need to pick a single migration strategy for the whole migration exercise, migration project. We can be flexible. We can have a hybrid approach. So, different strategies for different workloads. So, as long as you have a structure, a structured approach, a structured migration plan, you do risk the migration. To do this, we established a migration framework composed by four phases. And this is to, so a framework is there to establish common terminology. So, a phase approach. So, you don't, for each migration, you don't need to sit down and think about, okay, how am I going to structure this migration? You already know because you apply the framework. For each phase of the framework, we also established a set of tasks that you need to go through to complete that particular phase. For example, when you do the assessment, okay, I want to know what is my application inventory like. I want to know information about each application. What are their dependencies? What are their business criticality requirements? What are their disaster recovery procedures like, et cetera? For the plan phase is where, after doing the assessment, you start planning and building a landing zone and a foundation on Google Cloud. Setting up AAM networking and all that foundational stuff that you need to deploy in your applications. Then you have the deploy phase where you actually take those workloads from the source environment and deploy them in the target environment. So, this is where, for example, tools like Migrate to VMs or Database Migration Service or Storage Transfer Service come into play. And finally, you have the optimize phase where you run through an optimization loop that tells you, okay, let's establish optimization requirements and then let's think about how we can reach those requirements, how we can meet those requirements. Finally, having a framework also lets you generalize some of the experience that you gather while doing migration to accelerate future migrations. So, you basically gain momentum as the migration goes and then doing the next migration is going to be easier. Google Cloud also offers the RAM program. It's a partner-led program that builds on top of decades of experience in doing migrations. Again, a structured approach applying the migration framework that you just saw. And you have scheduled L checks to see if the migration is going towards the right place. And also, you have access not only to the partner but to also Google Cloud engineers and experts to help you with the migration. So, how did we fit all this together? So, we wrote, we authored a set of migration guides that we are constantly maintaining and extending to collate all this information in a single place. So, those migration guides, and you'll see the link in the last slide, tell you how to do the migration, how to go through the migration framework in a particular migration cases. So, you can start thinking how a migration might look like. So, let's have a look at some common migration journeys. So, the first one is a relatively straightforward one from Amazon S3 to Cloud Storage. As you can see, we have toolings to do the assessment, to do the migration. So, again, this looks easy in principle, but the complexity lies in the details of the migration strategy that you want to follow. So, we can see another example of this, but again, if you need to do, if your workloads can afford a downtime, it's easy to migrate, right? Because you can just do the transfer and then restart your workloads. Because you can easily go through a break, it's easy toDoesTown to continue whether it will Italy soon or not change any final migration there. Amazon EC2 to Compute Engine. Again, this is a relatively straightforward migration journey because we have the migration center to do the assessment. Then we have migrate to VMs and migrate to containers to do the actual VM migration. So, again, relatively straightforward migration project, migration methodology, but the complexity lies in the details. One thing is to migrate a set of VMs that can afford downtime. Another thing is migrating VMs with zero downtime. So, the migration becomes way more complex. We will see a couple of ways about how to handle this later. The next migration journey that we have a look is from Amazon EKS to GKE, so Google Kubernetes Engine. This one is a bit trickier to reason about because it focuses mostly on your continuous integration and continuous deployment pipelines. So, refactoring those rather than migrating workloads from your EKS clusters to your GKE clusters. So, you likely already have a containerized runtime environment if you are on EKS. So, you can start by refactoring your CI CD pipelines to push artifacts to repositories that are on Google Cloud artifact registry. And then you refactor your deployment pipelines to target the GKE cluster instead of targeting the EKS cluster. And you can do this in a gradual way, shifting traffic from your source environment to your destination environment. The last migration journey that we have a look is from Amazon RDS to Cloud SQL and AlloyDB. Again, this is a relatively straightforward migration journey until you go into the details. So, we have tools to do the assessment. We have tools to do the migration. But these database engines don't work the same across cloud providers. So, you might be relying on a configuration parameter or on a feature that is only available in your source environment on AWS. So, you would need to refactor it, the workload that uses that to work on Cloud SQL. This is true also on the other way around, by the way. And with this, I'll leave the stage to Megan for the demo. Thank you. Okay. Thank you so much, Marco, for covering really a comprehensive framework for migration into Google Cloud. This is a relatively short talk, so we don't have time to sit down with all of our various teams in our sample application and do the entire framework. And so, what this demo will be showing is kind of a really compressed and, yeah, a tightly compressed migration journey of a financial services application moving from AWS into Google Cloud. The sample that we're going to be using today is called Symbol Bank. It's just a retail banking application. It lets you log in and do transactions in a bank. This app is built in Python and Java. And it currently runs on EKS. So, Elastic Kubernetes Service in AWS. And it relies on two Postgres databases, both running in RDS, relational database service. One for the accounts. So, this is like my account info and my various contacts. And then Ledger, which handles all of the financial transactions. All of our container images are stored in Elastic Container Registry, ECR for short. And our CI, CD into ECR and EKS is managed through GitHub Actions. So, let's cover sort of the planning phase of this migration. And so, let's just talk databases. So, as I said, we've got an accounts database and a transactions database called Ledger. In this case, we're working with a relatively small amount of data. In real life, you might have a huge amount of data that you need to inventory. Different SQL schemas that you need to keep track of. And in this case, we're going to be using DMS, database migration service, to automate the migration of both of the those RDS databases into Google Cloud SQL. As Marco said, we also have AlloyDB, which is a really great sort of scalable option for SQL databases. In this case, we're doing Cloud SQL. And then for our Kubernetes services, we're going to move them from EKS into GKE, Google Kubernetes Engine. As I sort of showed in that arc diagram, we're working with six different services in different languages, each with a container image that needs to be built. It needs to be built through CICD and deployed into that Kubernetes cluster. And so, what we'll have to do is refactor our GitHub Actions workflow to handle that migration into GCP. And then to sort of optimize for scaling, we're going to be using GKE Autopilot, which helps you with automated node scale up and many, many other features. And we'll have to worry about things like our RBAC and our IM as well. And so, we won't be covering that in a ton of detail here, but know that that's in play. So is networking. So, as Marco kind of said, Kubernetes is so portable, but there's a lot of gotchas when you're moving from different hosted iterations of Kubernetes, like EKS into GKE. Ingress is a really good example. So, what you see on the right is our ingress class and our ingress resource that we had on AWS. Well, this is going to look totally different in GKE because there's no ALB or application load balancer in GCP. We're going to be using a service of type load balancer to simply punch a port to get to our front end. And then again, we'll need to migrate that CICD. So, this is the full picture of what we'll be migrating. You can see DMS there at the bottom handling a continuous migration of both of those databases. So, in this case, we're doing a little bit of downtime. But if we were doing a full zero downtime migration, the benefit of using a DMS continuous job is that as you are moving over, let's say some folks are still hitting that AWS side of things. Let's say they make a transaction. DMS will take care of getting that transaction automatically moved into the Cloud SQL database over in GCP. So, it can be hugely beneficial for that. So, this is what we want to end up with. So, let's try to switch over to the live demo here and try to make it happen. All right. So, what you see here is the AWS console. It might be a familiar view for many of you. And what you see here is our RDS database, Symbol Bank. It's available. It's active. It's ready to go. Here are our various Elastic Container Registry repositories for each of our six financial services. We've got the front end. We've got a transaction history service and a load gen just generating traffic there. And here's our EKS cluster with our various workloads and pods. And here it is running live. I just refresh it. I sign in. And here is our. It's telling me not to use a demo password. Don't use demo passwords. And you can see here at the bottom, if I zoom in, here it is running on AWS. Okay. So, when it comes to migration, one thing that we recommend doing in sort of the migrate phase is trying to keep close track of the resources you're creating in Google Cloud. The way that we're doing it here is through Terraform. You might be asking, do I need to go through all of the work to set up everything in infrastructure as code as I'm doing this just initial first migration? Doing this has a lot of benefits. If you're clicking around the console and just setting up those prototype resources, it can be really hard to keep track of, like, what the heck you just deployed. Let's say something goes wrong and you want to undo it. Infrastructure as code and declarative things, things that go through a review are a really good option here. What you see here is our database migration service job defined in infrastructure as code with all of its various configuration fields. And we also have infrastructure as code for artifact registry. We have it for our GKE cluster. Now, Terraform, as you might know, takes kind of a long time to deploy. And so what we have here is just a kind of a sped-up version of a fresh Google Cloud project, the project that I'm about to show, and me kind of going through the Terraform plan and the Terraform apply for those base-level resources. So in this case, that is the GKE cluster. That is the database migration job. Various IM resources as things like VPC. And if I fast-forward here through to the end, you can see the resources were successfully created. Now, let's take a tour of what those resources are. So I'm going to start here in the DMS console. So here is our job. And you can see, because it's of migration type continuous, it's still actively running. I started this a couple of days ago. It's still going. We can see some nice metrics of, okay, what's the destination storage? And DMS takes care of creating that Cloud SQL instance for you. So that's, in this case, what we've got going on. And our subtables. And so what we can do is go into Cloud SQL Studio, which is just a nice SQL view within the console, and just run some sample queries and see that all of this data, in this case, accounts info, was successfully migrated from RDS into Cloud SQL. Okay, so that's a really, really fast version of the database stuff. Let's talk the EKS bit. So in this case, what I'm showing here is our GitHub Actions workflow. So before this was running for EKS and ECR, we did a refactor of this so that we are authenticating into Google Cloud. We are authenticating into artifact registry. And we are building and pushing all of our financial services using Docker. And so, and then we're using a tool called Customize. If you're a Kubernetes user, you might have heard of this before. It allows you to really easily manage that YAML configuration. So in this case, we're updating the image in our deployment YAML from an ECR image to an artifact registry image. And what you see here, again, these things can take a bit of time to run in CICD land. So this is just a sped up version of what that GitHub Actions workflow looks like in action. Here it is running. It's authenticating. It's building those images and pushing them to artifact registry. And at the end, it is doing an actual deploy into our GKE cluster. Now, again, this is not a zero downtime migration. As Marco said, you'll want to look into things like blue, green, canary, and making sure that if you want to do a progressive moveover of traffic, there are some ways to do that. There's also service mesh in the mix. And happy to answer any questions there. So once that GitHub Actions workflow is all done, what you see here is our GKE Autopilot cluster with all of those deployments successfully running. And if we go over into our networking resources, we can see our front end has that public IP through a Google Cloud load balancer. We sign in. And here is our banking application running in GKE. You can see it running at the bottom for no cheating here. And we can, you know, just send payments and we can see that traffic getting in and out of our database really well. And so that was a very fast, very compressed version of what that migration could look like. You might be working with a completely different set of services. You might be running on VMs. You might be running on Lambda and trying to get into Cloud Run. So know that every migration journey is different using the framework that Marco sort of outlined, you know, making sure that you are planning for what you want to achieve and you're addressing any special considerations. Things like, you know, the size of the data you're working with, things like security, networking, IM. There's so much to cover here. But hopefully this gave you a little taste. If we could go back to the slides here. Thank you. So with that, I'll hand it off to Marco to give some closing thoughts. Really appreciate you all being here so early in the morning. There you go. So let's make this quick. We know that we are the only thing that stands to have breakfast. So closing thoughts. Okay. As we mentioned many times, the migrations can be complex. So we just saw an example of a relatively simple application. Still, there are challenges like how do I migrate database data in a reliable way? How to actually do the refactoring of those CI, CD processes to deploy on GKE? So even in a simple example like that, there are a few challenges. Here, we go through kind of the same exercise in a more complex migration scenarios. So here are typical requirements that you might want to realize for a given migration. So I have a set of workloads, for example, that are quite business critical. So how do I handle those in a zero-run-time migration way? You can do that in a few ways. For example, depending on the runtime environment that you are migrating. So if you are migrating to a containerized runtime environment, such as from EKS to GKE, then you have a wide range of options like having a multi-cluster service mesh, and you gradually shift traffic towards the new environment using the service mesh. If you don't have anything like that, plain VM-based environment, you can sort of achieve the same way by doing some traffic engineering, by steering traffic at the load balancing level towards the target environment on Google Cloud. And the second thing I want to mention is that a migration is also an opportunity to extend your environment to a multi-cloud environment. So as I mentioned, some customers have a mandate in highly regulated environments to depend on multiple cloud providers, and this is a way for doing that. So once you have all the cross-cloud connectivity set up for the migration, you can reuse that to build a multi-cloud environment. For example, you might think, okay, now that I migrated to Google Cloud, I might use the source environment on AWS as a way to build my disaster recovery environment. So this is an option. So these things happen for real. The third thing is kind of a peculiar case. We had some cases of migrations where the workloads to migrate are actually quite legacy. So the people that work on those are not in the company anymore. So how do we handle that? How do we advise that? So basically you can lift and shift those VMs even without knowing what's inside those machines using migrate to VMs and hybrid subnets. Even if the workloads that run on these VMs use hard-coded IPs, you don't care. You just lift those VMs on Google Cloud. And then with a proxy ARP, you can redirect traffic from the source environment to the target environment on Google Cloud. So this is an example of how migrations can get complex pretty fast. And you cannot do much about that because you cannot refactor. Even wanting to do that, you cannot refactor those workloads because you don't know where the source code is. You don't know who built those workloads in the first place. So they are not available anymore. So, and this is it. So we have time for questions. Thank you so much. Thank you.