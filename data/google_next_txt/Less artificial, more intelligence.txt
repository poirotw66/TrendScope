 Music Please welcome Managing Director, APAC, Customer Growth Engine, Architecture, Solutions and Technology, Matesh Agarwal. Hi, good morning. Good morning everyone. Slightly louder, no one had coffee today? One more for APAC, please. Asia Pacific. Welcome everyone and thank you for taking time this morning. Really appreciate it. And I hope the conference has been exciting and productive so far. I can tell you I lost $480 yesterday at the slots. I went to Gemini. I asked it for strategies. Tell me what else I can do. Gemini gave me a very, very simple answer. Stick to the conference. All right. So, as they say, what happens in Vegas stays in Vegas, except for what happens in APAC goes global. So, you're going to hear a lot about things as you move forward. So, you've heard a lot about AI this week at Google Cloud Next. And I hope all of you are having fun. And I hope all of you are having fun. Particularly, how AI is at the center of how we all collectively help our customers to accelerate their transformation journeys. Today, we will hear from these wonderful four APAC executives who are here to really share their stories. They've traveled all the way to share with us amazing, amazing stories, team, about how Google's AI-powered cloud technology has helped them to achieve meaningful business outcomes. However, before we get into that, I also wanted to provide my own perspective on how artificial intelligence, Gen AI, is becoming less about the artificial and more about the intelligence. I hope you're ready for the next few minutes. Now, we all know we've got this whole diktat around the world for return to work. Right? Some of you, there's been a lot of debate around this. While return to work is a very, very persistent theme, there is a lot of debate between virtual, physical, or hybrid teams. And teams, how are they the most effective? Right? All of you here at the conference, including me, I don't know how many hours you worked, how many hours you were at the slots. Right? I've been doing APAC calls in the night, the conference during the day, and clocked over 20,000 steps, thanks to this wonderful limp that I have now. You can see hybrid work is real, and when you all go back, there's going to be so much that's piled in. You can see articles published every single day in nearly every market, every market, including every market in Asia Pacific, on this. But we think there is another type of hybrid team that I really want to share with all of you. This is the hybrid human at work, each of you here at work, with AI agents in the cloud. So think about it. Hybrid humans at work with AI agents on the cloud, and hopefully on Google Cloud. The power of this paradigm is that it gives us a new way of thinking about the potential value we can get from artificial intelligence. leveraging AI agents together with humans at work allows us to move from SaaS to what I call RAS. Let me explain what that means. SaaS, or software as a service, as we're all familiar with, is simply, in a very simple way, you rent a tool that's useful as software to do everyday work, whether it's for your internal employees or whether it's for external employees. You get access to all the software capabilities without needing to install, manage, or maintain the underlying infrastructure or the software itself. You heard many, many of our partners provide this functionality to the users on-premise and then over the cloud. Then, I believe there are two new paradigms. One, which I call RAS, which is work as a service, which perhaps all of you are a little less familiar with. Now, what exactly is RAS? And we believe that this is going to really revolutionize how things work all over the world, especially in a human density populated part like Asia-Pacific. Work as a service really focuses on the specific work output or tasks executed by an AI agent now, and as the agentic era becomes big. And instead of just providing the tool, work as a service represents the delivery of the actions or processes that the AI agent performs. Think about every single day what you do. And think about, I think there are roughly about 400 or 500 people in this room, each of you having a minimum 20 to 30 agents. And think about now your own organizations and how that execution of workflow will happen. Think about the everyday interaction that you will do at work, and every day how the software environment needs to work with each other. And this is why we believe that agentic AI is going to really become big. And therefore, intercommunication is going to be so important, just like the new language of the world. And we believe A2A, which Sundar and Thomas announced earlier in the keynote, is going to really take over the world in terms of interoperability between these various agents, irrespective of whether these agents were deployed by you, came out of the box from Google, or from third-party partners. Then there is the final part, which we believe most customers care about, which I call RAS, or results as a service. Think about it. At the end of the day, how many meetings have each of you been in where all your boss cared about was the result? And you will see four of our wonderful customers speak about the results that they actually got. Not experimentation. Experimentation is great. But what people really care about, what did I move to production? What were the results I got of what I did? And we believe the results as a service is going to really start to become possible with agentic AI. With RAS, payments, or as we all get paid every day, is directly going to be tied to achieving predefined business outcomes, such as processing a number of documents with high confidence, or the number of calls avoided from escalating to a human agent. When was the last time any of you loved to talk to a call center agent? Anyone want to raise their hands? Harshanah, our marketing leader, is apparently giving away $1,000 of slots, along with some Gemini free, if any of you felt you loved talking to a call center agent. Harshanah, keep your $1,000, right? Think about how a human agent today works and interacts with you. Think of agentic AI as something that can simply replace any complex human agent requirement. We think that digital ad campaigns will get massively disrupted, and the way you create impressions today, internally, or with your customers, or with your partners, is going to absolutely be different. Finally, you will pay for the value delivered by the AI agent, and not the execution of the work itself. I'll repeat that. It's important for you to remember. Think about the paradigm where you will pay for the actual delivery of the work, and not for the steps taken to get there. And we believe that agentic AI, therefore, is going to completely change software as a service, work as a service, and results as a service. In the APAC context, where many of you belong, in the coming moments, we will really hear from four of our distinguished customer executives speak to the value that they've generated in their business with Google Cloud and Google Cloud AI. Before that, I wanted to share with those less familiar just what it means to operate in the APAC context. What we've seen, and you might have seen this in your own languages there, as we know we have many, many languages, APAC customers have the same enterprise requirements as many other markets, whether it's North America, EMEA, Japan, LATAM. But there are dramatic differences as well. These differences are in the pace of adoption, and you'll hear from our distinguished guests and speakers, the pace of adoption is completely different. The scale is completely different. The way you push boundaries in Asia-Pacific, completely different. And, as Karan, if he was here, would tell you, pricing is completely different. We want everything at the lowest cost possible, but at the highest scale, with the highest performance, and absolutely magic to happen overnight. And let me tell you, as a technologist, you folks push the boundary in Asia-Pacific every single day on technology. For Google Cloud, Asia-Pacific comprises 13 countries with rich and vibrant cultures, more than 2,000 distinctive dialects and languages that are spoken, diverse regulatory requirements, and you all, all want a customized, tailored approach to AI, which means our revered partners come into play a lot more often. Language is such a big consideration. Our professional teams, our professional services teams really come to the fore. Now, to address this, we are investing in a simple three-pronged strategy. We are investing in data center expansion with two new regions that we announced in 2024, in Malaysia and Thailand. And we are very, very proud to have really had a huge spray of all of this across Asia-Pacific. We are also investing in huge amount of hardware accelerators in APAC. We are investing in regionalizing services. Many, many of you have asked for data residency. You have asked for end-to-end ML processing. You have asked for local language requirements when it comes to AI. You have asked for specific voice requirements, video requirements, and vernacular requirements. The three Vs, voice, video, and vernacular, are super important to Asia-Pacific. And that is where our models like VO2, CHIRP3 HD voices, are across today 34 APAC languages. And you'll hear from a couple of our customers speak about how they're using voice, video, and vernacular. I hope it is clear that Google Cloud is investing in Asia-Pacific and taking an APAC-first strategy, not just in data center expansion, but also our models and accelerators, the products and the language and the dialect and the nuances that are there. Google Cloud would continue to be the most enterprise-ready, cloud-tailored for AI in Asia-Pacific. With that, let me ask for two things. Number one, can I ask all Google Cloud employees from Asia-Pacific to just stand up for a moment? Just for one moment. Can we all please give a huge round of applause to all our customers, all our partners? I think we can do better Asia-Pacific. Thank you so much, everyone, for really supporting us. Thank you. With that, let's turn over to our first of the four speakers, Luis Ujina from Macquarie Bank. Please welcome Luis on stage. Please give him a big round of applause, please. Thank you. Hi, everyone. I hope that you have really enjoyed the last couple of days at Google Next and you don't have a lot of AI overload by now. Let me share a couple of seconds on what's Macquarie Bank. Macquarie Banking and Financial Services, it's an Australian bank. We are the fifth largest bank in Australia. We deliver all our capabilities through digital channels, and we have two million customers in the Australian market. What I'm going to share today is mostly some of the good decisions that we made in the last few years in order to unlock the power of AI. And I will speak a little bit about how we can use AI to really improve the customer experience, because usually it's one of the areas that are not very touched when we are discussing about AI. A strategy is how to gain and maintain control of your destiny. And this is exactly what we did in 2020 when we decided to move all the digital workloads and our customer data into Google Cloud. In 2025, 97% of our workloads and all the customer data are running on public cloud. And only in 2025, we are going to deliver more than 30 different products and services that have some kind of AI capabilities embedded. Having all the data into the cloud and having all the capabilities and workloads is giving us a massive advantage in terms of really unlocking the power of AI. Because at some point, it's one of the biggest issues that you have when you are trying to really scale in that particular point. Some people, some of my colleagues, are asking me, hey, Luis, what's the difference between being an AI-first company or just using AI? And usually my answer is, well, the big difference is how intertwined is the world of AI in everything that we are doing in the company, in the culture of the company. Usually, AI is a private club for the IT guys. AI is something that is running on IT, and IT is unlocking and making decisions on how AI is going to work. At Macquarie, we have AI embedded in every single team. And this is a big, big difference. I'm speaking about putting AI on not only IT, but also on the support teams, on the business teams, on the marketing team, in some of the areas that you will never think that AI needs to be present. And this is a big, big difference. It's how you really make AI available to everyone. Because today, you will never, ever hire anyone that is telling you in the interviews, I have no idea what is internet. I have no idea how to use internet. Very, very soon, if you are an AI-first company, you will never, ever hire someone that says, I have no idea what is prompt engineering. I have no idea what is AI. I don't know how to use AI on a daily basis. Or I don't know what is Gemini or something similar. And this is the big, big change that is making an AI-first company, AI-first. Otherwise, you will have a lot of projects, a lot of models, and a lot of capabilities, but the company will never, ever be thinking on an AI approach. The second thing that is important is most of the companies, and today, you know, in the last couple of days, you have seen in many, many speakers, most of the people are thinking on AI in terms of efficiency. How do we automate the company? How do we create more efficiency? How we are moving faster? And it's amazing. It's great. But there is something that is usually forgotten. That is, what is the customer? At some point, the customer is the most important asset that you have in the company. You can drive amazing AI capabilities if you don't have happy customers. If the people are not using your products, basically, you are not going to be in the business for a long, long time. That's why I think that it is really, really important to be discussing about AI-driven customer experience. Because in the same way that AI, when you are working in terms of efficiency, is driving efficiency for the company and reducing the cost, AI also can be used to drive the revenue, to have more customers, happier, and using your systems more and more often. And this is where I like to speak a little bit today. today. Many, many companies are very good delivering data. What I mean is, is something that happened in the past. When something happened in the past, putting that on a screen is easy, right? And we have many, many services and many, many capabilities where we are just basically delivering what happened in the past. Some companies are getting better on insights. Insights is about reducing the cognitive load of the customer, especially in the financial industry, in the utilities industry, in insurance. We usually send billions of data points to the customer. And what we said is good luck. You know, good luck with understanding what's happening. With insights, basically what we are doing is reducing the cognitive load and reducing the amount of time that the customer needs to spend understanding what's happening in the system. Just a few companies are good doing recommendations. And this is probably the best things that you can do if you are not using AI. You can start doing some recommendations based on the data that I have, the insights that I gave you, this is what you should be doing next. What we strongly believe is AI is the only technology and the only capability that we'll be able to unlock two things. The first one is automation. Automation not at the backend system, not in the backend system, not in the, you know, below the glass of the company. I'm speaking about customer automation. I'm speaking on things like in a bank is because I know who you are. I know your behavior. And I know what you are doing on a daily basis. I will be able to help you. Because how many of you love to be spending every single Sunday morning paying bills? Well, no one in the audience, right? Makes sense. No one wants to spend time doing something that, look, in 2025, we are able to create a movie using AI. We are able to have conversations with AI. As we saw in the keynote, we are able to have, you know, a full customer journey driven by AI. But still, in 2025, we need to spend a couple of hours every couple of weeks paying bills and doing things that should be fully automated. And the last frontier, where we think that is the nirvana of delivering services to the customer, is moving into the world of autopiloting. So at some point, every single company should be able to use the customer data, the customer behaviors, and the information that we have from the customer in order to really drive the business in autopilot. This is the highest level that you can achieve in terms of efficiency and revenue. You will have millions of customers that will love to use your company, that will love to use your product, because basically, you are not putting the cognitive load on themselves. You are putting all the load, you are putting all the capacity in your company, and you will be able to deliver an amazing product. We strongly believe that this is the last frontier in terms of using AI to deliver and delight the customer. And those are the two areas that in seven minutes I'd like to share with you. I'd like to share with you how important it is to start thinking on moving all your workloads, and especially all the information into the cloud. because all the tools that you are going to be using, Vertex or Document AI, et cetera, et cetera, they rely on data, data that needs to be accessible, and you need to have as much data as possible always in the cloud. So I would like to finish with a particular, a little bit of a words of wisdom based on what we have suffered in the past, and it's hope is not a strategy. Right? So I have heard so many times in the last few years, oh, I hope that someone will come and tell me. I hope that this is going to be solved with the technology. It's not going to happen. Hope is not a strategy, and believe it or not, it's rarely a good plan either. So no one has a plan that says, no one has a strategy that says, my AI strategy is hope, hoping that someone is going to solve my problem. You need to start investing now. You need to start, if you are not doing yet, you need to start thinking, how you are going to put the whole company in an AI mode. Just to give you an example, at Macquarie, we have every month more than 15,000 employees that are using the Macquarie AI chat. And we have more than 5,000 employees that has been trained by my colleague, Mattelis, that is here in prompt engineering. So we have every single one being able to understand what's happening here. So hope is not a strategy. My expectation is if you want to be AI driven or AI first, you really need to start thinking how you are going to transform the company, not only IT. Thank you so much. And now I'll pass the time to Luis Cruz to share about DBS's AI journey. Thank you. Hi, good morning. It's been a very exciting week and I'm very happy to be able to share with you what's been a journey of my life and a journey in DBS on how we've evolved AI in the bank in a highly regulated industry. So anyway, today, let's go ahead and get started. So the task wasn't easy. It was about how do we industrialize AI, not just people doing statistical models back then and just, you know, evolving the landscape of the different possibilities that AI started. And we started very early. So the year 2017, we didn't have what we have today. so how we had to think about it was about how do we scale without closing the doors on the possibilities of what's going to happen in the future. And for us, we've been able to industrialize AI today at a capacity where the thought process in 2017 was centralized data. and then as markets evolve, countries evolve, then geopolitical landscapes hit and then data now is actually, you know, has to be in the country. So then the whole concept of centralization, you know, was all broken down. So we had to move to hybrid models and, you know, with partnerships that we have like Google, we've been able to stretch the same principles and concepts we had on our on-prem data platform and scale those to India and Indonesia where building data centers was actually not really the mission of the purpose of what we wanted to do. So leveraging capabilities that they provided has actually allowed us to run more than 1,500 models that we have today operationally, compute daily, and touch the lives of every single customer of ours and we have about 370 use cases that run today. Just to give you a size of the scale, we run 38,000 to 39,000 computational jobs on the data platform today and we manage the platform through metadata predominantly and, you know, that's actually stretched to Indonesia and India running on Google native capabilities and that was part of the journey, right? So the journey that I'm describing right now is about traditional AI and ML putting jobs, computational jobs over capacity before we hit, you know, the borders of generative AI. So when generative AI came into the door, the real question was, okay, how is this going to change? How is this going to change all the work that we've done and invested over the last, you know, six to seven years? And to that matter, we said, well, because we've been building the platform in an open ecosystem, for us, generative AI was about adding one additional domain on how we had the perspective of artificial intelligence as a whole. So Gen AI became one more subdomain in the entire domain of AI. And we accepted the fact that it might not be treated as the same way that a traditional AI model works. So what I mean by that is that you're going to have now a convergence of developer and data scientist which are basically careers that are converging today. They're building more and more AI-driven applications, right? And, you know, data scientist jobs are also changing because they're becoming more and more part of a developer journey, right? So that's some of the things that we looked at as a subset and we said, okay, this is going to transform the way we work. It's not only going to transform the way our tellers work, our banking operators, our relationship managers work, it's going to change the work, IT works, SDLC works, developers work, data scientists basically touching everything in the organization. So, the question was, how do we think about this in a way that we can materialize the business value and the outcomes? We've heard a lot, we've listened a lot, and we came up with two basic concepts, verticals and horizontals. So, when we moved to verticals and horizontals, we said, what is a vertical? Well, vertical is a very unique, specific use case tailored for a particular purpose, such as a relationship manager trying to put a credit memo report. So, you can put a Gen AI application for that, absolutely, right? But it only touches a subset of users within the organization, right? Horizontal use cases were a bigger problem to solve, because the question from our CEO was, if Gen AI is so good, it needs to touch the life and soul of every single employee in the bank. So, how do we go about that? Horizontal use cases was a combination of what we define as enterprise knowledge, and how do we make sense of unstructured data and proliferation of unstructured data as a whole, and give that through a conversational chat interface that is secure and our regulators feel that is within the boundaries of risk that they can accept. The vertical use cases for co-pilot roles were a little bit simpler, because they were literally assistants and subsets of their day-to-day activity of what they do today. So, it's very tailored and very specific, but you can't have a framework that allows people just to build vertical use cases as a whole, because what will happen is then there's actually no business value. You might have a lot of verticals that will cost more than actually the work itself, and we've seen that too. So, how you evaluate what those use cases are is part of a key critical journey that I can express today. So, what are the enablers identification of use cases? What are the data tech capabilities that we have today that can empower this? Because I helped build the data platform. I knew we got control of the structured data. Now, how do we get control of the unstructured data? It was a key question. Doing the responsibility, the guardrails, the people engagement, is not an easy task. And when you work in a region like mine, typically the regulation in Singapore is very different from Indonesia, from Hong Kong, from India, and regulators treat the domains very, very differently. so the system has to be open enough that you don't need to reshape and re-architect everything every single time you take or import any of these capabilities to the countries. So for us, that openness of being able to lift our on-prem data platform into Google Cloud was very seamless. Just to give you a sense of the transformation, we started our journey of moving the DBS data platform to Google Cloud in India in October 2024, and we went live on March 31st. So that's a five-month journey, and you had an entire data platform built, right? All data migrations, all jobs, everything. So the extension of Gen AI capabilities happen at the same pace. So manage centrally, extend capabilities to the countries with the regulation and the risks that we needed to cover. So with that, I'm going to leave this message to you. Think about verticals, horizontal use cases, how to think about company-wide, specific role-based co-pilots versus touching the lives and souls of everybody, and I hope you actually enjoyed the nine minutes I have to share with you the message, and now I would like to welcome Jason layout from Ops to share his AI story. Good morning, everyone. I'm Jason from OPPO. I hope you're all familiar with OPPO. We make very nice smartphones. So there has been a lot of excitement about agentic AI. Today, I'm honored to share how OPPO is partnering with Google Cloud to deliver human-centered AI solutions that creates real value. I'll also talk a little bit about our view and our research into agentic AI experience. Now, before we dive in, let me take you on a quick journey from the tech hubs of Shenzhen to the bright nights of Las Vegas. You might be curious. My journey here actually involved two flights. Let me demonstrate how OPPO AI Search streamlined my entire trip from Shenzhen to San Francisco and then to Las Vegas. AI Search is a powerful system-naval AI tool jointly created by OPPO and Google Cloud. AI Search is powered by Google Gemini models, allowing you to search on-device documents and even device settings, just like asking a friend. For instance, when I inquired about my flight departure time from Hong Kong to San Francisco, AI Search looked into the PDF files that contained my flight information and returned the answer to me. Then, asking about my Las Vegas hotel room type, AI Search accurately retrieved attraction view room from my reservation document. Notice that AI Search doesn't just give me the answer. It automatically flags the source document on my phone. With just one tap, I can check all the details. AI Search was one of the many incredible tools I used during my trip. After arriving in San Francisco, I strolled around the city and took several photos. Let me show you some of the photos. The first photo was taken inside a cafe. The cinema rolls look tasty, but the window glares got in the way. I can improve it using the OPPO AI reflection remover on my phone. Look how easily I can remove that glare. Beside the AI reflection remover, there are other powerful photo editing tools within our OPPO AI editor, such as AI Unblur, AI clarity enhancer, and AI eraser. They can help you recreate your masterpieces by restoring the details of blurry photos, converting low-quality images into high-resolution visuals, and removing unwanted subjects very easily. Puff. It's gone. Check out the amazing differences before and after the OPPO AI editor. So making photo improvements has never been easier with OPPO AI. OPPO AI can do more than that. Let me show you how AI helps me to prepare for this talk. I wrote out the draft, and then I used the AI assistant for notes to check and rewrite the draft for me. See? It instantly elevates my speech. And I'm very happy to share that all these AI productivity tools, including AI assistant for notes, AI writer, and AI recording summary are powered by Google Gemini. So with all these powerful AI tools, I know you may have questions about data security. For OPPO, AI security is our responsibility, not just a feature. That's why OPPO and Google ensure every AI interaction is secure, private, and protected. OPPO is taking the need in launching the first AI private computing cloud, which leverages confidential computing from Google cloud. It is a dedicated environment, ensuring that AI data processing happens within a secure, isolated system with end-to-end encryption to keep all AI interactions private. With this breakthrough, OPPO is redefining what it means to make AI both intelligent and secure. As AI takes the spotlight, at OPPO, our focus remains on what truly matters to users. We are putting AI experience at the heart of everything we do. And our goal is clear. Leading innovation in AI experience, delivering the very best. So in summary, OPPO is redefining the future of AI by bringing efficient, personalized, intuitive, and secure AI to our global users. By combining our in-house development with strategic collaborations with Google, OPPO is introducing a system-level AI approach that provides users with deeply customized and highly efficient AI experience. As we enter the agentic AI era, our future AI should advance to better observe, reason, and execute tasks for us. We believe that creating a personal agentic experience requires active participation from our users. Our mobile device is already our daily personal companion. We have it every day in our pockets. We believe it's a natural progression for mobile devices to provide more agentic experience. Personalization is a key component to achieve this vision. Users should be able to co-create this exclusive agentic AI experience based on their own interests, actions, data, memories, and even more. To bring this personal agentic experience to life, we are introducing a new user knowledge system in our future devices. In collaboration with Google Cloud, this system will serve as a centralized memory hub for user data, solving data fragmentation problems, and enabling the users to efficiently retrieve and manage their personal data. With this new user knowledge system empowering all the AI features, we are making significant progress towards developing an agentic operating system. At the OPPO Research Institute, we focus on advancing agentic AI to address diverse and complex user intents through adaptable task decomposition and flexible tool uses. We emphasize on two key aspects for agentic AI experience. One is on the lightweight agentic model with strong reasoning, planning, and tool use capabilities. The second is about AI agents with autonomous perception, reasoning, planning, and decision-making abilities. So let me introduce two of the open source projects we have been trying to contribute to the society. Last year, we launched Hammer, a family of lightweight agentic models specifically engineered for on-device deployment. Hammer has been enhanced to improve generalization capabilities of tool use and supports plug-and-play functionality for new tools. The latest version of Hammer maintains top performance among models of comparable sizes on a series of benchmarks, such as the Berkeley function calling leaderboard. The API-based agents like Hammer rely on well-defined and reliable infrastructure, specifically the APIs, which are not always available. So this year, we introduced Project Mobile Use, which is a GUI agent that allows the users to input task instructions and then autonomously plans and executes on mobile devices. So it supports multi-agent framework, is equipped with planning, reflection, memorization, and progress mechanisms. It achieves a top three ranking on the Android world leaderboard among similar sized models. So our research projects ensures that the user intents are accurately understood and executed, delivering human-centered benefits. As you've seen, with OPPO and Google Cloud's partnership, we are not just advancing technology. We are redefining how AI transforms everyday experiences. The innovative AI features are significantly changing the way we work and play. OPPO is dedicated to making AI more accessible with a leading AI experience, including AI-powered tools, agentic AI interactions, and AI security. By the end of 2025, we aim to have nearly 100 million global users benefiting from OPPO AI. So we are ushering in the AI phone era, where AI is no longer just an exclusive privilege, but an essential part of everyday life. Just like today's session topic, less artificial, more intelligence. It is the dawn of human-centered intelligence. Thank you. And now, let me pass the time to Binwen from GovTech to share more about their AI journey. Hi. Good morning, everyone. Amazing sharing by Jason. I feel like buying an OPPO phone myself right after this session. All right. So, here we go. All right. I'm honored to be here this morning to share Singapore government's journey towards cloud migration in partnership with Google, and how the recent integration and revolution of AI is really transforming our strategy and accelerating our innovation, efficiency, and overall competitiveness across the whole of government of Singapore. Now, before I start, perhaps a quick introduction of who we are or where I came from. So, GovTech is a technology agency within the Singapore government, and one of our charter is really to drive Singapore's smart nation initiative and public sector digital transformation. And one of our primary mission is to harness the power of technology to improve public services and to make them more efficient, accessible, and more citizen-centric. And one of our key focus is really to build a secure and seamless digital services across more than 100 government agencies and departments across Singapore and the general public to centralised platform strategy. So, what is our centralised platform strategy? Now, Singapore government centralised platform strategy has started quite a few years ago, and it has evolved over time. And the most recent iteration, as you can see from the diagram, is in the form of offering what we call a Singapore government technology stack, or we call it SGTS. It consists of three layers. So, the service layer, that is what our target users, citizens, and government employees interact with. So, it is a face of Singapore government digital presence, and it has a strong focus on user experience, accessibility, and delivery of seamless services. And supporting that, we have a base layer. And base layer is the layer that provides foundational capabilities that enable service layer to function effectively. So, it provides core digital infrastructure platforms such as data, CICD, API gateway, observability, so on and so forth. And underneath all of this is the hosting layer, and that is where our base infrastructure layer, supporting the entire stack, tech stack, right? So, we focus a lot more on scalability, security, optimised cost, and efficient resource management. And that's where the focus of my sharing is today, on the hosting layer. So, in the hosting layer, we have this platform of what we call a government non-commercial cloud, or GCC in short. So, what is GCC? So, GCC is an infrastructure platform. It is built in partnership with major hyperscale cloud providers, obviously including Google. And we have created and accelerated a cloud adoption strategy, launched in 2018. That's when we started building GCC, and we had a goal that in about five years from 2018, we target to migrate more than 70% of Singapore government systems, I'm talking about thousands of systems, to the commercial cloud. And we believe then that the design of GCC, using the construct that you can see in the diagram, it will help us standardise our hosting environment, hosting platform. It can increase agility, resiliency, security, and help us reduce operating costs as well. And the good news was, by 2023, more than 72% of our systems has been successfully migrated to cloud. I've just checked the data last month. We have achieved like 80 over percent, 83, 84% of systems, 1,000 over systems. And they are now on commercial cloud. And thus, we have achieved the phase one of our cloud adoption vision. So, you must be wondering, where is the AI in all of this sharing, right? All right, that will be coming up. So, in 2023, I think we are driven really by a shifting landscape and the revolution of AI. And hence, we partner with Google to launch what we call AI-powered cloud, AGCC. It's an abstraction of GCC and it sits on top of a GCC platform. And the goal then was really to tap on Google Cloud's generative AI capabilities and the partner ecosystem to help us accelerate the development of next-generation citizen-centric services. So, our original goal of migrating to cloud was to just modernize our systems on cloud, lowering costs, increasing time to market, efficiency, security, so on and so forth. But with AGCC, we realized that we need to adapt to a new strategy to fully leverage on the power of AI to further enhance performance, drive innovation, and deliver even greater value to our citizens. So, the future is all about transforming our capabilities and not just moving to cloud, but to reimagine what's possible with the tools AI has to offer. Hence, in partnership with Google, one of the earliest initiatives that we did under AGCC was a series of what we call AI Trailblazers program. And what is Trailblazer? So, Trailblazer is an AI accelerator program or a series of programs that we provide the whole of government of Singapore so that they can tap on engineering talent and infrastructure support to help them start building AI use cases. So, we ran up to maybe more than four rounds of Trailblazer. And in the initial Trailblazers, we have generated, just for the first one or two runs, there are more than 70 over use cases that we have generated across the whole of government. And beyond Trailblazers, many of these use cases get productionalized and turned into real systems. I'm just going to share three examples today. Now, the first one comes from the agencies that I'm from, right? Government Technology Agency or GAVTEC. So, we use a hybrid AI approach, combines natural language processing and generative AI capabilities and to build a virtual intelligent chat assistant. So, we support over 60 government agencies and departments, facilitating over 800,000 monthly queries. And that helps us provide a 24-7 efficient customer service. Well, we can also enable quick updates and maintenance. Now, the second example that I want to share is from an agency in Singapore that focuses a lot more on defense. It's from Center of Strategic Infocom Technologies or CSIT. So, they use secure on-site solution enabled by GDCH or Google Distributed, cloud-hosted, right? So, they ensure that their defense data is stored locally, complying with strict data sovereignty regulations. So, they ensure sensitive data remains under Singapore's control with the goal that those defense infrastructure can harness advanced AI technology while they can still ensure robust data sovereignty and security. And it's a defense agency after all. So, the third quick example that I want to share is from our home team, Science and Technology, or we call it HDX. So, HDX collaborates with Google Cloud to ensure security systems are scalable, secure, and able to handle vast amounts of data, and making the platform flexible enough to adapt to future technological advancement. So, HDX actually worked with Singapore Police Force and Immigration and Checkpoint Authority of Singapore. And they embedded AI into its frontline operations, thus boosting their homeland or our homeland and border security. And they also did partner with a Singapore prison service, for example. So, they did a human behavior detection system, and it enhances the safety and operational efficiency across Singapore prisons. So, after all these examples, what's next after GCC? So, we believe we should continue to expand our AI capabilities and probably focus a little bit more on responsible and scalable AI solutions to the whole of government of Singapore. So, our focus really is to deliver explainable AI, makes it transparent and accountable, edge AI, bring it closer to the users for real-time intelligence. And most importantly, I think, since we are of the government domain and government business, security and AI safety is rather important to us. So, we have to be responsible, privacy conscious, so that we can build resilient systems that prioritize fairness and compliance with our own internal strict data security regulations. So, this is not new. This is a regular, you know, diagram on a user journey. But what I really want to share is that when we thought about the need to realize our vision, we actually work towards providing a secured golden path for our AGCC users so that they can onboard and accelerate their AI adoption easier. So, we started from enabling our users to access a landing page and to finally creating an automated billing capabilities on our own cloud management portal in partnership with Google, right? So, we draw into the process of integrating AI capabilities into our cloud infrastructure platform. Right? Via a structured, iterative approach so as to ensure that our platform continues to deliver value in both short and long term. Now, one more example. So, more recently, we started a proof of concept, a POC in partnership with Google. So, we intend to develop an AI infrastructure as a service and we are in the midst of completing it. So, I think we should be able to do it towards the end of April 2025. So, what is our goal in this? So, we try to validate a cost-effective, scalable, safe and secure and fast time-to-market platform for our government agencies and department to tap on cutting-edge AI tools and capabilities. So, from this diagram, I just want to highlight two key components or capabilities that Google has to offer. So, FPG AI proxies, I think it is great. It will help us abstract our backend services. It can add layers of security, rate limiting, traffic management and such, right? And I think we are more excited about Google model Armour as well. So, as a fully managed service, I think it's designed to enhance the security and safety of our AI applications. So, we want to validate that function. So, for screening of both inputs and outputs prompts and responses. So, there's a lot of security risk and we hope that we are able to screen that before they interact with our AI models. So, I've reached the end of my presentation. So, I just want to share. Here you go. All right. A quote from Henry Ford. So, I think he once said that, right? If I asked people what they wanted, they would have said faster horses. So, I think the true innovation is not just about making our existing system slightly better, faster horses. So, it's about envisioning new possibilities. Why are something that we haven't even fully rationalized and we are still testing, right? We are still validating. So, AI to us is indeed not a buzzword. So, it's a continuation of a journey since we started migrating to cloud in a big way back in 2018. So, we'll continue to experiment, iterate and we'll embrace the transformative potentials of AI. And we hope that we will be creating a government that's not just keeping pace with the latest technology, but we want to really champion digital transformation and lead the way across the public service. So, with that, thank you. Please enjoy the rest of the Google Max event. So, I hand it over to Mitesh, who is supposed to wrap up the whole session. Thank you. Thank you. Thank you. Awesome. Wasn't that incredible? Thank you for staying back. Thank you to our four speakers from McQuarrie Bank, DBS, Guftak, of course, and OPPO. Two financial services customers, one mobile phone company, and one amazing public sector partner for us. Great stories. These are not just the only stories, as all of you know, right? We have stories across the board. And if you want to be part of that journey, right, please talk to us. We are here for you. And remember, AI apparently is the new electricity, but cloud is the grid that powers it, and data is the fuel that powers that grid. Right? So, incredibly honored to have all of you here today with us. I want to thank all of our speakers, all four of them, for really having supported us. Come here, spend their time today. And I want to thank everybody here in the audience for spending time with us. Have a great conference. And if you're headed back home later today, safe trip back. Thank you. See you again. My name is Batesh. Thank you. Thank you. Thank you. Thank you. Thank you.