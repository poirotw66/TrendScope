 Welcome, everyone, to this session on BigQuery ML. So we are going to be talking a lot about all the generative AI and predictive ML capabilities in BigQuery and all the useful applications that you can build with it. So I'll kick the session off. I'm Weber Sethi. I'm a product manager on BigQuery ML. And later in the session, you will be joined by Omid, who's going to do a demo. For BigQuery ML capabilities and money from Home Depot is going to talk about how they have been leveraging BigQuery ML in their business. So let's start by understanding what is BigQuery ML. So very simply, BigQuery ML is a collection of capabilities which let you do end-to-end AI and ML in BigQuery with just a few lines of SQL statement. So let's try to understand with a very typical ML example. So I want to predict body mass of penguins. How can I do this in BigQuery? So I can do it with a simple SQL statement like this. I can ask BigQuery to create a model. And I choose linear regression as the algorithm that I want to train. And I just tell what the input label is that I want to predict. And then provide the input data. So it's that simple. So this statement is going to kick off a training job. And you get a model at the end of it. Now you have a trained model. And you want to get predictions from it. I can write an equally simple SQL statement to provide that model as an input and the new data that I want to do the predictions on. So through this entire journey, I never had to choose any VMs or choose how to do distributed training or write complicated featurization code, do test train split. All of that is taken care of for you in BigQuery. And you get a seamless experience. So moving on, as in this was a very simple example to give you a flavor of what BigQuery ML is. But it's actually a full suite of AI ML capabilities. And we have a deep set of features for every step in your AI ML journey. So you would typically start with data in a BigQuery table. And you would want to do things like featurization on that data. So what we have done in BigQuery ML is we have implemented these common feature transformations natively in BigQuery. So we have things like ability to bucketize your data, encode it, normalize it, even work with unstructured data like images and resize it. So this is all natively implemented in BigQuery, available via SQL, and it's very, very scalable. And you can do more advanced featurizations, like, for example, generate embeddings on your data. And then the featurizations you do in BigQuery are very well integrated into the GCP ecosystem. So they are integrated with the Vertex feature store. Once you're done with featurization, there's a bunch of options for you to train models in BigQuery. So we have implemented all the common ML modalities, like all the common use cases. You will find algorithms for that in BigQuery. And you can do advanced things like hyperparameter optimizations using that familiar SQL syntax I showed to you. So now you have trained a model and you want to evaluate it. We have support for that as well. So you can evaluate predictive machine learning models and LLMs right inside BigQuery. And now you've found a model that you like. You can register this model to Vertex CI model registry so that you have a common repository of your trained models. Now, coming to inference, it's as simple as writing that simple SQL to do that batch inference. But this is actually a very flexible capability in BigQuery. So you can choose to use this platform piecemeal. So say for some reason you didn't actually train your model in BigQuery, you can still import the model artifact into BigQuery and use that SQL interface I showed to you to run the inference at scale. You can also run streaming inference. So if you have new data coming in and you want to, say, use an LLM to process something on that data, you can do that with continuous queries. And you can connect to remote endpoints to again get a SQL interface for inference. And tying this all together, once you have developed your pipeline, we have monitoring capabilities so that you can do things like detecting when your training and inference data is drifting apart. So what does putting all this AI ML capabilities inside BigQuery give you? Well, firstly, it dramatically expands ML access for users in your organization. So BigQuery ML has been around for a while, and we have so many customers who come back to us with feedback that data analysts and engineers who would previously not be able to touch ML problems are now able to solve them very effectively with BigQuery ML. It really reduces complexity. So as you were seeing, there was no info to manage when using BigQuery ML. And even if you are a data scientist and a Python expert, you will still love BigQuery ML for this part, right? So I've been focusing on the SQL interface, and that's what we are also going to show you in the demo. But BigQuery also has an equivalent Python interface. So even for data scientists and experts users, it's a very good platform. And BigQuery ML is very easy to secure. So because the data is staying in BigQuery, you define permissions for data access once. And then ML is just another workload against that data. And it's very scalable. So we take care of distributed training and distributed inference for you. Now let's double-click a bit into the generative AI and predictive ML capabilities in BigQuery, starting with generative AI. So I'll start with how we think of generative AI in BigQuery. So BigQuery is integrated with Vertex AI and GCP Cloud AI services. And this gives you a way to consume LLMs and other models directly from BigQuery with SQL. So what all does this include? This includes LLMs like Gemini, but also third-party models like Cloud. It includes embedding models, so you can generate embeddings on your text or image data. It includes things like Doc AI, so you can parse PDFs with BigQuery ML and semantically chunk them for RAG applications. And we also integrate with other cloud services for specialized workloads like transcription and translation. And this is how you can use Gemini models in BigQuery. Again, the SQL syntax is very familiar. So you are not actually training a model here. You are telling us to connect to a remote endpoint, and Vertex provides us these models as a service, right? So I'm just indicating that I want to use a Gemini Flash model, and there's many other options available to you. And once I have done that, I'm in the inference business, right? And we have many inference functions available, and they work very simply. So you provide us what do you want the model to do so that this becomes the prompt, and what data should this model work on. In this case, I want to generate country for the data which is in the city column in my example table. And this prompt can be arbitrarily complex, so this is a very simple example, but you can ask the model to do pretty complicated stuff, and this is not limited to text. So BigQuery is multimodal, and Gemini models are multimodal, so you can mix this information and ask it to work over multimodal data as well. So I'll go over a few key features in BigQuery, a few generative features in BigQuery. So the first one I want to touch upon is the choice of LLMs you have in BigQuery. So we love Gemini models. We think they're great, but you also have the ability to consume Claude models, Lama, and Mistral models as a service from BigQuery. And if you're feeling adventurous, you can actually host any hugging face model on a Vertex AI model endpoint, and then use it with BigQuery. So this is like more than 200,000 models available at your fingertips, right? With the same easy SQL interface that I was talking about. As I was mentioning, BigQuery is multimodal. So we give you a table abstraction on your structured and unstructured data. So you can have a column with structured data and another column pointing to your data in GCS, which is unstructured data. And you can mix the two together. And very importantly, the data does not move. It stays in GCS. And then you can pass this mixed data to Gemini for multimodal inference or something like DocAI for PDF parsing. And we're very excited to announce a new feature in BigQuery ML, which is structured data output. So in most enterprise scenarios, you would want to constrain the output that you are receiving from your LLM to a certain schema. So BigQuery ML now allows you to do that. You can pass in an output schema right here. And you can use this AIG to generate table function, which will give the output as new columns to you. So it really, really, really simplifies how you write code against LLM and use it to generate information. We are adding new row-wise functions in BigQuery ML. So sometimes you might want an LLM inference to be a part of your select statement or a where statement. So now you can easily do that as well with BigQuery ML. And finally, all of this is packaged in a very scalable product and which is market-leading in pricing. So if you're hosting your own endpoints, running your own models, you can scale those up and BigQuery ML scales with it. If you're using our models as a service, you can buy provision throughput and that BigQuery ML will scale according to it. And very importantly, when you're using Gemini models from BigQuery, you are doing batch workloads. So you get a 50% discount on them, right? It's super cost-effective. So what all can you do with these capabilities? Let's just go through a few examples. So in BigQuery ML, we see a lot of NLP kind of use cases that our customers use these models for. So things like entity extraction, you can have unstructured text like, say, reports from some consumers or reviews or logs, and you can extract structured text out of it with LLMs. You can do this with images as well. So say you're running a car rental business and you want to detect which parts of the car were damaged and generate structured data out of it. You can do that with Gemini models. You can enrich the data using this country and city example I was talking about. You can do sentiment analysis, a super popular use case. More generally, you can do any kind of classification with Gemini models. You can do content generation and summarization. So you might have things like user information in your warehouse, and you might want to use that user information to generate a personalized email. So you can do that with BigQuery. You can also do things like you have a corpus of videos and you want to get summarization of those videos to use in some analytics. That's possible. And finally, BigQuery ML also lets you go beyond these prompt-like use cases to building more complex Gen A applications. So we have capability to generate embeddings and to do vector search. So this allows you to do things like build multimodal search applications. So you can embed images and do semantic search on those images with text. Or you can do RAG applications with build RAG applications with SQL. So you can parse PDFs, chunk them, embed them, use a vector search service to search for the right artifacts and then feed the model to ground the results in. So that's generative AI. But BigQuery ML also has a wide range of offerings in predictive ML. So I'll hit upon a few things that you can do with BigQuery ML for predictive ML. Firstly, BigQuery ML is really good at, we are very good at our forecasting offering. So we offer Arima-based models for forecasting, but over the years, we have added a lot of features which help actual businesses do this well. So for example, you can do multivariate forecasting with BigQuery ML. You can forecast thousands of time series simultaneously with BigQuery ML. So if you're a retailer and you have a global business with hundreds of thousands of SKUs, you can create projections for all of those with a single SQL statement in BigQuery. And we handle a lot of real-world issues with forecasting, right? So irregular time series, missing data, we handle all of that for you automatically. Anomaly detection is a close cousin of this problem. So we support time series anomaly detection and we support anomaly detection on IID data. So you can ask for things like is a particular transaction anomalous or not. Then we have a range of algorithms to support regression and classification problems, starting with XGBoost. So you can do things like, for example, score my sales leads. In fact, Money is going to be talking about a very similar use case in Home Depot that they're working with. You can do things like classification, again with XGBoost and other models. So you can do things like classify my credit application into a certain risk category. You can do clustering dimensionality reduction with BigQuery ML. So with KMEs, you can do segmentation of your users and optimize the marketing strategies for them. You can do dimensionality reduction for very complex data and feed these features to a downstream model. And finally, you can do recommendations with matrix factorization and widened deep models. So standard movie example here, but you can actually apply to very complex real business problems. Okay. Now I'm going to be switching gears and talking about a few recent launches in BigQuery. This one we are very excited about because this combines the advances which have been happening in the Gen AI world and applies it to the predictive ML domain. So we are launching the integration of Times FM foundation model into BigQuery. So this is a state-of-the-art foundation model that we have trained on more than 100 billion real-world data points and it generalizes really well to real business domains. It's also very flexible so you can forecast across different frequencies of the data. So you can, for example, do a daily forecast and hourly forecast from the same model and you can specify how far in the future you want to forecast and what kind of confidence interval you want to set. So with the integration in BigQuery, you can use it with a simple function like this, just providing the input data and essentially what time series you want to forecast on and how far in the future you want to forecast on. So super scalable, super fast, you can forecast millions of time series in a matter of minutes and it's quite accurate. Even in many scenarios, more accurate than models you train custom on your data sets. The next feature really gives superpower to your analysts. So we have always, like all of us have been in this situation where we care about some business metric and it has moved and we're trying to understand what caused the change in this business metric. So if you have small amounts of data or simple data, you can maybe do it with manually slicing and dicing the data, but it quickly gets very tricky. So we are launching NGA, contribution analysis model in BigQuery, which allows you to specify what are the parts of the data that you really care about, like these dimensions and what metric do we use to see for the change and that's really it. And you basically get the top contributors which led to the change in the data between the test and the control set. So that's a very quick primer on BigQuery ML. I'm actually going to hand it over to Omin now who is going to demo a lot of these features I talked about. Thank you. Thank you. Thank you. Thank you. All right. Thank you, Vaibhav. So I lead the engineering teams focused on AI, ML, text search, and vector search in BigQuery. And I'm going to do a quick demo, a live demo in production of some of the recent launches that Vaibhav talked about. So just to set the stage, so we're going to be using for this demo a BigQuery table on this, essentially a table that covers the outpatient procedures and charges in the U.S. And this is a mix of public Medicare data with some synthetic augmentation with it to make it demo friendly. So we're going to cover three scenarios. So number one, we're going to show structured data generation. This is a new feature we launched last week which lets you extract entities, numbers, and facts, you know, such as, you know, procedure type, procedure code, and whether it's a surgical procedure from unstructured data. And this is going to use the new AI.generate table function. You know, it basically gives you the output according to that schema you specify. Then we're going to use contribution analysis to try to identify some factors leading to some unexpected changes in charges, you know, between the 23 and 24 in that data. That's going to use the create model as well as the get insights function. And then at the end, I'll close with a demo on forecasting based on the times FM state-of-the-art model that Weiboff talked about. And that's going to use the AI.forecast model function. So with that, I'm going to switch over to the other machine to do the demo. All right. Okay. So I have this notebook in BigQuery. As I said, this is a live demo, so hopefully it all goes well. So first, let's just take a quick peek at the data. So the data is organized hourly. And, you know, to show some of the columns, you know, we run this simple query. So for example, you know, this one row, it says, okay, in this hour in the Manhattan hospital area, this procedure was performed on two patients and led to this amount of submitted charges from the healthcare provider. and these were the insurance payments for that, right? And then the second row, something else, you know, done in the state of Texas. Okay? Now, the total number of rows, you know, it's 141 million rows, so it's not a toy data set. And let's dig a bit deeper, you know, get a better feel for the data, right? So let's kind of aggregate the daily patient counts per hospital region, okay? And ordering by, you know, the highest, right? So for example, this one shows, okay, on this day, you know, April 19th, in the Cleveland hospital area, there were 527 patients with these total charges and total payments, and so on. Another way to look at it, you know, I'm going to aggregate total charges and payments per day across the board, and let's see what we get. So the query is run, I'm going to plot it. Okay, so this one's interesting, right? So we see, you know, of course, there is, you know, patterns, you know, spikes and drops, you know, on a daily or weekly basis throughout 23, but overall, the trend is flat. But once we head into 24, there's quite a bit of increase, you know, which seems a little bit worrisome, right? So what we're going to do is, you know, we're going to use some of these tools and functions we talked about to dig a bit deeper and, you know, get more insights. All right, so now I'm going to go to step two. So here, I'm going to use this new AI generate table function. And what it does is, in this case, you know, it's going to use Gemini 2.0 Flash behind the scenes and it's going to tap into the constraint decoding capabilities of this model so that basically, you know, with this prompt, it's going to try to produce output based on this pre-specified schema. So, yes, we have the procedure description as you saw. You know, it's, you know, semi-cryptic, you know, medical terms, you know, sometimes obvious what it is, sometimes not, but it's, you know, mostly complex to analyze, right? So, I'm going to add three extra columns. Like, one, whether it is a surgical procedure. The second one, like, what body system, you know, this was done on, right? And some of the examples I give the model to, you know, categorize to is, like, a circulatory, respiratory, and so on. And third, just, you know, extract the procedure code. And, you know, we're going to put that, you know, we're going to get the distinct list of procedure descriptions and put that in one table. So, the query is running now. In this case, there's about 560 or so distinct procedures. And for each one, you can see, you know, it takes this semi-cryptic text and gives us these new columns. You know, in this case, okay, this is surgical, circulatory, with this code, and so on. So, in some ways, you know, you saw how easy it was to go from cryptic unstructured data to something that's a lot easier to work with for analytics. All right. So, now what I'm going to do is just kind of quickly join it back to the original table I had with 144 million rows. This is just a simple join query, nothing complicated. So, the join is done. Now, with these additional columns, let's try to see what we can do in terms of doing more analysis. Okay? So, here, this is a query. This is going to take about a minute, so I'm going to start running it, and then I'll talk over it, right? So, what we do first is, you know, we're going to take the data from the last few months of 2023, and we call that control data, and then we take the first few months of 2024, and we call that, you know, test data, or, you know, what you're trying to analyze and see what happened. So, that's the first statement. The second statement, we go ahead and create what we call a contribution analysis model. So, in this case, focusing on the total charge, you know, as the metric we are curious about and we want to see what happened with it, what contributed to it, you know, growing so much in 2024, and we list five columns of interest to really look for the contributors to that growth, right? So, in this case, I'm still including that opaque procedure description column, but also, it's surgical, the new one I created, the body system, the procedure code, and also the state, the state where the operation happened. And a few other, you know, parameters, and so, we call this, you know, create model, so the model gets created and once it's there, the third step is to just perform a, you know, the actual analysis using ml.get insights, so that's the one that invokes that model we created. So, the execution finished and the results are in, so, you can see, you know, it identified some categories, some segments as being contributors to some of the outsized growth, you know, surgical operations, it looks like, you know, they contributed a lot, but, you know, if you kind of zoom in a little bit more, an interesting combination, so for example, surgical operations in the circulatory system, you know, had quite a bit of contribution, same with surgicals in the respiratory system. And also, City of California seems to be a top culprit. So, let's visualize this, it's kind of hard to see in a table, so we have this plotly visualization to see it a little bit better, so, all right. So, if you see here, you know, this is kind of 23 and then the 24 data we analyzed, and as you can see, you know, actually the diagnosis was right. I mean, you know, basically, you know, we see substantial contribution from surgical operations in the circulatory system as well as respiratory and the state of California. So, you know, this is basically just one starting point to dig deeper. You know, we could look at the other dimensions or do more, but, you know, you see how easy it is to kind of quickly, you know, zoom into the contributors and go from there. All right. So, with that, let me go to the last part of this demo where I'm shifting gears a little bit and focus more on the forecasting domain. Again, this is going to be based on this AI forecast function we launched actually a couple days ago in preview based on the state-of-the-art Times FM foundation model-based forecasting model from Google. So, in this case, you know, I'm going to do a little bit of extra pre-processing. So, I'm going to store the hourly number of patients per state. So, we're going to do a per-state analysis. And, you know, in this case, you know, I, you know, the BigQuery is, actually was, has started and is primarily based in the Seattle area state of Washington. So, I'm going to pretend I'm in charge of all the insurance payments and also medical staffing and resourcing in the state of Washington. So, I want to get a sense about, okay, what has been the recent trends and also do projections for the next couple of months making sure we are good on resources and staffing and so on. So, and also to just to cross-reference, make sure I'm looking at good data, you know, there's no anomalies and no problems. I also want to show the California data and make sure, you know, it all checks out. So, first, before doing any forecast, I'm going to just forecast, I'm just going to just show what it's been in the last few weeks of April between the two states of California and Washington. So, you see the patterns, you know, there is, you know, some spikes, you know, some daily, early day, late in the day, also some weekly patterns, you know, less traffic on the weekends, but things okay, you know, and lines up with California so it should be right and also lower so again, matches up with the population or expected numbers. So, once we have that, I'm going to actually go ahead and do the forecast. So, for the forecast step, you see, all there is is just one function call to AI.forecast. No training, nothing. And, I'm going to identify the total patients as the value I'm actually trying to do a forecast prediction on. And, as Vaibov mentioned, you know, we have the ability to do multiple time series, forecasting multiple time series at once in one call. So, by providing the provider state as the ID column, this is actually going to do forecast per state. So, it's going to look in that column, you know, for every state value it sees and it's going to give us, like, a separate prediction series. And, so, this one, I'm going to run it, it's going to take less than a minute. But, basically, once it comes back, we expect to see projections for the next 500 data points, in this case, 500 hours, for all the states, actually, in the data. But, I'm going to show Washington and California once it's done. So, let's just give it a few more seconds to finish. All right, it should be almost there. Okay. So, the data is in. I'm just going to plot it with plotly. And, yes. So, this is what we got, right? So, before this state, this was the data that was, you know, in the, in essentially the training set, that's what it used to do the forecast on. And, the points after that is actually the forecast. So, maybe let's zoom in to Washington. So, it looks like it got the patterns right. You know, you got, you see the weekly patterns, daily patterns, the confidence interval. And, it seems to also line up and, you know, corroborate with what we see in the state of California as a, as a double checking point. All right. That's, that's all I had for this demo. And, I'm going to switch back, do one more slide, and then we'll have Mani from Home Depot come over and, you know, tell us how they use BigQuery and BigQuery ML in Home Depot. So, this is about an upcoming feature we're going to have later this year. So, essentially, a lot of the work you saw in terms of doing data science work within BigQuery ML, it's going to be a lot more easier and automated to do. So, we're going to have agents that do automatic planning and code generation for pretty much the entire data science journey. So, this is going to include data loading, data exploration, cleaning, feature engineering, model training, hyperparameter optimizations, evaluation, and inference. And, it's going to be guideable, and it's actually going to perform actions like across the notebook, you know, at once. So, please stay tuned. If you have questions or you want to talk more about it, please talk to us, find any of us, and we'd be happy to discuss more, get feedback, or sign you up for the preview evaluations. All right, with that, I'm going to hand it over to Mani from Home Depot. Yeah. All right. I'm here to talk about the journey of BigQuery within Home Depot, and I've been with the company for over nine years. All through the career, I was in analytics and data science field, supporting various operations of the customer, marketing, and sales. When you just double click into that, all that I'm doing is just playing with the data from the customer, and how can we help all our customers succeed in what they're doing. So, a little bit about Home Depot. I don't want to drain through all the numbers here, but I want to point to some interesting facts here. When you look at this average store size here, 128K square feet, and we have around 2,347 stores. When you get those numbers together, our total retail selling square footage is somewhere around 300 million square feet, which, when you translate that, it's roughly around, or a little lower, 50 times the city of the Vatican. This one, what it means is, just within the last year, we had 160 billion in annual sales. With 160 billion, we had around 1.6 billion-ish transactions. All these transactions are touching multiple areas of Home Depot ecosystem. Maybe supply chain, inventory, merchandising, e-commerce, and many more. From all this, we get tons of data, and we use that data to make sure we help our customers succeed in what they are doing. So when you actually double-click into the customer persona, as you are playing into the data and looking into what's happening within the data, you'll see two key customer personas. One, it's basically a consumer or a DIYer, and the next one is a professional contractor, who we call as pros. So pros, they are basically working with the consumers to help finish their projects. With the pros, as they're working with the consumers, they have lots of complex needs. As the complex needs grow, Home Depot has to evolve. Over the years, we are building lots and lots of capabilities to support all our pro customers. Capabilities like you'll see that in the key customer needs, there are several capabilities that we are offering. Flatbed delivery is one of those things that I really am excited about, and it has been helping a lot of our pros get their material delivered to the location of their projects. One key area that my team closely supports is sales representative relationship. Sales representative relationship is basically, how do you have your customers, professional contractors, supported by Home Depot associates, to get their jobs done. From data science point of view, my team basically helps in getting the right data about the customer into the hands of sales associates so that our associates can better understand the needs of customers and serve them the better. That's the background of where I'm heading now. Now it's all about the data. We have been heavy users of BigQuery for maybe over six years or beyond that. But when you look at the BigQuery ML usage, we have been struggling a lot when we want to put this data into the production, into the hand of associates. So we started our journey in 2020. How do we build our models and how do we deploy that to the production-facing applications? The challenge we had back in the day was we built, the data scientists built the models on their own ecosystem and we let the ML engineers build the same model on their ecosystem to deploy into the production. But over the time, we learned the patterns. What are the things that are basically stopping us to accelerate? In 2023 and 2024, we were able to crack open the secret there and we realized that we are really very strong with the technology. We are really very strong with the people. All that's missing there is just the process. People, process, and technology. All that put together had helped us accelerate deploying the models to production 10x faster. Today, as a matter of fact, we are deploying the models as soon as the data scientist wraps up their best version of the model. So it's probably an hour. They just go through a couple of rounds of approval process. So now double clicking into what is that integrated framework. What you see here is just three streams of work here. The first one on the top is a development project. That is where my team basically plays a lot with the data. In the Jupyter notebook interface, or you can do it in the BQUI, we will leverage the BigQuery ML, which is what bonding all of us together there. And then along with that, you'll also notice that there is a tabloid icon here. Sorry. I'll go back. So there is a tabloid icon here. So basically, BigQuery has a lot of rich features. In order for us to better understand the models and better translate this to our business partners, we need to be able to weave this BigQuery ML into a story that our business partners can understand. So that is where we use the tabloid. Next one is the CICD handshake. We are using GitHub there, and Data Science team works on Data Science Sandbox, and ML team has their MLGit repository. But you'll see that there is a bidirectional arrow here. ML team creates templates for us in order for us to make these models deployed into production faster. We use those templates, we put our model, our code, into third format, and the models are ready to deploy in a matter of an hour. Finally, in the production project, our ML engineers, they focus on how do we accept the model that we got from the data science team, is all the data in the production server, and how do we deploy that in production. So just this one helped us accelerate deploying our models to production. With that, I want to use this framework to show you two use cases today. We have used this framework for predictive ML application and also generative AI application. So we'll go with the predictive ML here. So again, it's all data science, so you need lots of data. And before I jump into the slide, I have a question for all the data scientists here. What is the equation that you see on this slide here? You don't have to answer that, by the way. I'll talk about that equation in the next slide, too. But yeah, so the objective is simple. We have a lot of customer data. How do we make a better customer experience through our sales associates? That's our job. For that, we're just using BigQuery and BigQuery ML. And BigQuery ML has lots of features that can help us make our model more digestible for business partners. And finally, the outcome is, with the XAI features that we have in the BigQuery ML, we are able to convince our business teams why we have to lean towards an ML model rather than a heuristic model. A heuristic model may be a linear equation, but with the ML, BigQuery ML, when you go with the complex algorithms, you should be able to digest all of that information. And the key result there is the top 20 customers that are prioritized by ML model, they're outperforming the rest of the cohort. Now, jumping a little bit into the next one, this is where you'll have an answer to the previous question. And this is my code here, and I've tried anonymizing as much as I can, so you might wonder how this code would run here when I anonymize this one. So within the BigQuery, we're using three different areas here. One is a model development, and then the model evaluation, and weekly batch inferencing. We have more of a batch inferencing here, and we run this model weekly on the production data. So within the model development, the last time I checked with one of the algorithm, the question that I asked you previously, which is an XGBoost algorithm, and you'll see that I have selected the booster tree class for here. That was an XGBoost algorithm, and there were around 35 options, and there are several hyper parameters as well. Now, if you do a math of 35, 30 plus options into all the parameters that you have, you have lots of ways to customize your model. But then I have bucketed all of this into simpler sections here to help me understand how to succeed in convincing my business partners. First, you'll see that algorithm selection. So I'm basically telling that this is the algorithm that I want, this is how many trees that I want. And then there are hyper parameters, and then enable explain AI. This is the one that I love the most. This basically helps me translate the complex model into a simple digestible information here. Finally, we are also doing a little bit more of model monitoring. ML model, when it generates, there's a lot of metadata left out. We take that metadata back and translate that into more of a dashboards, show that to our business partners, or for our data science team, what's going on with your model. What was the prediction last month? What was the prediction last week? And how are the predictions drifting? So all of that information. Now, jumping into the most curious aspect here, the XAI feature, I want to show you how we translate that into more of a digestible information for our business. So in the XAI, in the parameters that I showed you earlier, when you enable explain global, global explain equals true, it gives you this option. It gives you this option of ML global explain. What it does is, the data that you have trained on, it gives you what is the feature importance. So the thing that you see here, it's all the Shapley values that you get from your ML global explain. We later take that and translate that into a tableau dashboard so that everyone can see what's going on. But really important thing is, explain predict. So when you are predicting, we have a few customer examples here, why would your model say the likelihood of this customer converting is one, and what is the probability score of that customer conversion? 0.87. And why is that model saying 87 here? So this basically shows that there is this feature one that's contributing really high. And in the global, if you see, feature one is the highest. So there is something happening here. So this is the story that we are telling our business partners. When you speak to this customer, you need to have this information in your back pocket. What's going on with this customer life cycle? And how can we help this customer grow further more with the company? How can we make sure that this customer succeeds? The same thing with the second customer as well. The model said, predicted variable is zero, which is basically the likely chance that this customer would convert and grow with us is zero. And the probability of that is 60. So maybe now our business teams are going to put more emphasis on the customers that are going to convert and give us more revenue. So this is one example where we have deployed this model and we have seen great outcome from this. Now switching gears here, the next example, generative AI. And we use the same framework, the one that I showed you earlier. So in the generative AI, the way we are using Gen AI here is going back to Viable's use cases, entity extraction. So we are basically taking customer reviews about a professional contractor. It's on your Elp or Google. You know that the businesses get reviews there. We take that review and then we classify that data. What is the profession that this customer was doing? So basically, I'm not looking for sentiment here. I'm just trying to understand what is the profession that this customer does there. We know that our customers are buying things from us, but we really don't know what their profession is. So this data is going to help us argument a little bit more understanding about the customer. So all that we are doing is just run an LLM on the data and see what is that customer profession is. And in the methodology, we're using BigQuery, BigQuery ML, and Gemini there. And when we are evaluating the model, we have tried different various evaluations, and one thing that really stood out, easily explainable, was the out-of-box, zero-shot, and few-shot prompting. Out-of-box is basically whatever it is that Gemini says, that is what we say it does out-of-box. Zero-shot is basically your class. I'll show you an example there. With that, we'll go to the next one here. Again, you'll see the anonymized code here. So we are using BigQuery and Gemini here. The model development, we're using Gemini LLM. And then to help Gemini understand a little bit more context about the Home Depot, we give few-shot examples. So basically, if you see this kind of comment, the job that customer is doing is so-and-so. That is what's exactly happening in the few-shot prompting here. So the prompt basic that you see is basically coming from this table that I have. That has examples of what is the customer review, what is that I'm calling out as a label for that job. I'll show you that example later. Then, there are a lot of options for you to customize your output. Again, temperature setting it to zero, making sure that no hallucinations as much as possible, ground yourself to this expected outcome that I was showing there. And then the key thing that we wanted to evaluate model was look at the accuracy and false positive rates. Because this is a multi-class classification problem, we want to look at the accuracy and false positive rates. Now, with this code, when it ran, we got an output from Gemini. Again, this was, I want to call out that this one is a Gemini 1.0, and the column that you see here is an LLM classification. That is what Gemini's output was. So Gemini output, it's basically, it's giving your right answer, but it's also giving me a lot more context why it classified this customer as so-and-so. Yeah, that is really important for me, but when I have this data going into the production-facing applications, I don't want the production-facing applications to fail because there is a lot more data than what it was expecting. So that's the reason why I have a little bit more post-processing as well, and if you go back to my previous slide, you'll see that I have a post-processing here. The simple post-processing that I have here is basically regular expressions. So with all of that, I'm not able to get this data production ready. All that I would pass to my leaders or my business teams are basically, hey, I have this customer based on the reviews, I see that they're working on the concrete job, and then there is a customer that's working on the kitchen remodel job. So this has really helped us augment our customer data. And the next one is basically talking about the accuracy metrics and false post-treat. When we tried the out-of-box, basically asked Gemini, what do you see in this data? Gemini basically said, bunch of things. It did not take any input from me. It did not say concrete or kitchen remodel. Basically said, probably they're working on something related to slab, probably they're something related to appliance or something. But the moment I started showing a little bit about these two labels here, it started improving in the accuracy, which is really very good. But then, there is still room for growth there. So that's when I started giving more examples there. That is where few-shot prompting is. As I give more examples, the model started getting better. Where did I get that examples from? There is no one who is going to sit there and write for me. We leveraged the out-of-box. We asked Gemini, what do you see here in this data? And based on that out-of-box, we manually created 100 samples and said, when you see this type of data, classified as concrete. That way, we are able to get to what we want. I think that's my last slide. And that's all. Thank you. And. opportunity for new business Couste avant think can do it on the proposedWhat happened owner papers in the project. That file with großart, but also clicking on your account performance, reading on嗨, and whispering on hoping to GOT