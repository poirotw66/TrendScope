 Today I'm going to show you how you can leverage AlliDB AI and your applications data to build Gen AI applications. Here we have a simple search application, Symbol Shops. Symbol Shops is an online skincare and cosmetics company that carries products from a series of different brands. Here you'll see I'm looking for products related to preventative aging, so stuff that's going to help me delay aging. You'll see that I get a bunch of relevant search results but they don't contain the words preventative nor aging. They're still relevant. The reason we're able to get these results is because we're not doing a keyword search. Instead we're doing a vector search and we're capturing the semantic meaning of my search term and comparing it against the semantic meaning of the products below. So you'll see that we get SPF. SPF is great for preventative aging but it's not going to contain any of our keywords. You'll also see that I have a personalized toggle. This toggle essentially is applying my profile preferences. So in this case let's say I like products that are vegan friendly and that are meant for people with oily skin. I'm able to just toggle this and still get high quality results. So let's take a look at the vector search we're doing. We're essentially computing and embedding on my question which is preventative aging and we've computed embeddings on the data inside of the database and we're just measuring the distance between the query I have and all of the embeddings we have inside of our database to pull relevant results. Now the awesome thing about doing vector search and PostgreSQL is that we're able to leverage SQL's rich querying capabilities in vector search. So you saw I had a personalized toggle right? The way we were able to do that is by just applying a where clause. So essentially we were able to apply a where clause where we're filtering for items that are vegan and meant for oily skin. We can all do this from a SQL interface which is awesome. Now on Allodb AI we've added further enhancements to vector search on Postgres with the scan index. The scan index is essentially Google searches algorithm for YouTube and Google search and we've put it into a vector index to help you get high quality results with optimal performance. It's about 10 times faster index creation, 4 times faster vector search queries, and 10 times faster filtered vector search which is what you saw before. It also typically uses about three times less memory than the HNSW index on standard postgres SQL. Now at next we've announced three key enhancements to the scan index. Index auto maintenance which ensures that the index adapts to your changing data. Query recall evaluator which will allow you to measure the quality of your vector search easily through this convenience function. And adaptive filtration which essentially ensures that the Postgres planner applies the filters in the correct order with the vector search resulting in optimal performance. Now this is how you do vector search but how about generating the embeddings. For that we have a feature called model endpoint management. With model endpoint management you're able to generate embeddings directly inside of the database leveraging vertex AI's text embedding models, Google DeepMind's Gemini embedding model, and multimodal model embeddings. You're also able to use embedding models from a variety of providers such as OpenAI and HuggingFace. We also have integrations for LLMs and re-ranking APIs through this feature. So now that we've talked about search let's look at another one of value to BEI's capabilities, natural language. Here you'll see that I have a chatbot in the same application and I want to find out more about the symbol prim line. Well you'll see that I'm able to just ask a question in natural language and this chatbot is able to find the answers in the database itself. Now from an application standpoint all you had to do is write a simple SQL query and it's able to handle any question that the user might ask. And it handles generating the same SQL behind the scenes etc. So that you're able to streamline the process of building chat applications in the most secure manner. So with our API natural language we provide built-in security so that we ensure that users are only able to access data they should be seeing. We use data beyond the schema. We use data from data logs from the database itself and other locations. We also have intent clarification and disambiguation which helps resolve the nuances of natural language. So if we just take a look at the architecture it's pretty simple. We're mainly using the data to power the application with AlloyDB AI on top. AlloyDB AI handles the vector search and natural language so that you can focus on building the application itself and the database will handle most of the work itself. This means that you're able to build these rich experiences without needing to use up many resources.