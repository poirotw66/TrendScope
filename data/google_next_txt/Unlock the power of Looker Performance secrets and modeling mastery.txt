 That was pretty weak. Hi everybody! That's much better. My name is Miles. I'm a senior product manager on Looker. Thank you very much for joining us today. We're going to be talking about how you can unlock the power of Looker through performance secrets and modeling mastery. I'm joined today by three of my colleagues. Hamza, who is director of engineering for Looker. Myself, I look after the Looker platform from a product perspective. We're also joined by Josh Temple, who's a senior software engineer here at Google Cloud, as well as the co-founder of Spectacles, and a special guest speaker, director of data strategy from HubSpot, Andrew Martin. So I'm going to, we're going to go through four sections today. First, talking about the Looker platform at a very high level, what kind of scale capabilities it can reach, and how we kind of think about performance and scale across the Looker platform. Then we're going to go into what administrators roles for managing instance performance and other workload performance powered by Looker, what they need to do. Go through kind of how HubSpot has applied Looker internally and how they've grown up and have scaled out their Looker usage, and wrap it all up with some discussions on specific developer considerations, tools, and also do a demo of Spectacles or our continuous integration functionality that's been recently embedded within Looker itself. So I'm going to hand it off to Hamza now. Thank you very much. All right. Thank you, everyone, for attending. So first, I'll be covering just a general sort of brief overview of the Looker platform. You know, the key goal here is to introduce the core concepts and terminology that we'll be using throughout the rest of the presentation. We won't be getting very in-depth here, but just want to set the right framing. One thing that we want you to take away from the presentation today, Looker scales to the most demanding workloads. One of the key aspects behind that is Looker's in-database architecture, which allows Looker to leverage the full scale of your database. But we'll also talk about performance being a shared responsibility. It is something that Looker admins, users, and model developers all influence. And we'll talk about the different actions that those different user groups can take to influence performance. So first, just setting some high-level concepts, Looker as a part of your overall data ecosystem. So on the diagram here, you can see, you know, a key aspect of Looker is unifying data from your various data sources into a single governed modeling layer. In that way, we think of our sort of semantic layer as a Rosetta Stone, transforming, you know, your various data sources, your tables, your various schemas into a, you know, organizational level semantic layer that can be consumed further upstream. And that can obviously be consumed within the Looker application itself, but we'll go into some depth later in the presentation about how that can also be consumed by other parts of your BI ecosystem through Looker, as well as, you know, consumed by some of our newer AI capabilities and so forth. The real vision here is, you know, Looker as a single source of truth for model data and metrics that can be consumed throughout your BI ecosystem. We also want to talk a little bit about the various use cases that Looker can be used for and highlight some of our, some of our, you know, customers that have been successful with those use cases at scale. So I think first and foremost, the use case that many of you will be familiar with, you know, modern BI analytics, first and foremost, Looker is a BI tool. And we believe Looker is a world-class BI experience that puts trusted, actionable insights in the hands of decision makers and can do this for organizations at scale with, you know, thousands of business analysts, you know, all utilizing the product concurrently. Another aspect of Looker is our integrated insights. So I alluded to this in the earlier slide. Looker provides data, governed data, not just in its own sort of application layer, but makes that available to other parts of your data ecosystem. So the ability to export it to Sheets, Excel, the ability for other BI tools like Tableau and Power BI to query Looker, for example. This is something that, for example, MercadoLibre leverages heavily. Another major use case for Looker is what we call data-driven workloads, which are basically sort of non-analytic workloads. We look at Looker here as scaling and operationalizing business workflows at scale, right? So Looker being used by, you know, hundreds of operators, each, you know, understanding what work is on cue for them and so forth. AudioMob is a great example of this at scale with Looker. And then finally, another use case that folks are probably familiar with, embedded, right? So we have the ability for you to fully control how you expose this governed data, including essentially through custom web apps or even full applications. Wix is a great example of a customer that does this at significant scale. So this will be a slide we pause on for a few minutes. We're not going to focus on the actual architecture here, but we want to introduce some of the layers of the architecture that will help guide the conversation throughout the presentation. So just looking at, you know, looking at this slide, probably the best place to begin is in the bottom left here. Those three boxes or three yellow boxes, these are the different ways that load can be generated on your Looker stack, right? User requests, scheduled queries, and just direct API activity. You'll notice that this is in a green box that we've kind of shaded as shared responsibility. This is something that affects the performance and scale of your application that is not fully within control of the application, which is kind of, in summary, a way of saying that, you know, the load and the type of load, the nature of load that's placed on it, that's part of what affects the performance of Looker. Another key part above that is the models themselves. So the way the LookML is written, and, you know, we'll spend some time on that towards the later half of the presentation, but the way that the models are written will dictate the types of queries that are made to the underlying data sources, and those have a strong effect on performance. The middle layer here, the main takeaway, I think, for the conversation today is this is all stuff that Looker manages behind the scenes. This is fully Looker's responsibility. These are the internal plumbing aspects of the application. There are some key parts there. For example, for models, these are pre-compiled and cached. For query processing, we do have, for example, queuing and other mechanisms in play to manage that performance, and then, of course, the scaling of the actual infrastructure that Looker is running on. These are all things that are managed for you. But there's another side of Looker that's, there's a third portion of the architecture, which is, again, something that's influenced by you as our customers, which is the scale of the underlying data sources, which, you know, in many cases, you know, have their own scaling characteristics and have their own limits and bottlenecks. And we'll talk about each of these kind of major areas and the best practices around them, what we have in the application today to allow you to monitor and be aware of them, controls and levers, as well as what we have coming down the pipeline. So maybe some last takeaways. We'll talk today about three different sets of users. We just want to make sure that that terminology is clear. So one is the administrators, the folks who, you know, manage the Looker instance within the customer organization. So this includes setting some of our administrator-facing capabilities and controls, and overall just deciding, for example, what the internal policies of the organization are and so forth. The middle category are developers and modelers, right? Basically, the people responsible for writing and authoring the Look ML. We'll spend a significant portion of the presentation talking about best practices for those folks. And then the final category are the end users, the analysts and viewers. And for these folks, the main contribution towards performance concerns is their usage, right? But they're an important actor in the overall picture. All right. Last slide before we get into the juicy stuff. I wanted to introduce the three areas that we'll focus on in terms of defining best practices and exploring the capabilities and controls that we have in the application. One is going to be Look ML architecture, right? How do we author the best Look ML? And how do we do things like avoiding unnecessary joins, minimizing merged queries, and overly expensive dashboards? Another category is going to be instance-level configuration. So as administrators, we have the ability to restrict certain actions to make it available by exception only. And there are other things to consider, for example, not clustering scheduled queries. And the last category that we'll explore today is external database capacity. Both the controls that we have in Looker to help it respect your external database capacity, as well as what can be done within those data sources in general at a high level to best facilitate the workloads that Looker will send them. All right. With that, I'll turn it over to Miles to get into the deeper content for that first category. What can administrators do to influence performance? Great. Thanks so much, Hamza. Okay. We're going to start looking through admins and how they can manage Looker kind of from a macro level and what they need to consider to create a performant environment and make sure all of your users are as happy as possible. So what do administrators actually need to worry about? Well, they need to worry about the instance or the Looker instance lifecycle, when it's created, how it's running, whether it needs to be deleted. This also includes provisioning users, making sure that it gets hooked up to the right external connections as well. So defining and maintaining those external connections and external data warehouse connections is critical importance. This is also where, like Hamza was just alluding to, you can match the capacity of your external data warehouse with the complexion of the workload that you then need to run through Looker. Admins also need to manage users, define their access, and there is a lot of sophisticated user permissioning and roles that we can enable within Looker, though these things aren't free. The more roles, the more custom roles that you can, that you introduce into a Looker instance, the more that it can basically weigh down various types of activity that depends on that access check. Also, think about overall instance performance and governance. Oftentimes, like Hamza alluded to in the opening section, the throughput of a given query is dependent on how well the query is written, not just how many people are using that query, and also what types of content is allowed to be published, and at what scale. So these governance capabilities or rules that you can set for your users within your BI ecosystem can have profound implications on latency that will result in real life. And diagnosing performance problems can be really, really hard. Oftentimes, a user will complain about general slowness. So, for example, one that we have here that I know some developers have dealt with is the IDE is slow. Okay. Well, that could include model validation compilation and content validation times. Takes too long. But that doesn't give you too many breadcrumbs to follow and gives you absolutely no context on the root cause. So what we're going to hopefully arm you with today are some tools for you to look through to diagnose these kinds of problems. For example, the IDE being slow could be due to a high use of Git concurrently. A lot of developers using the same repo at the same time can cause the IDE to basically come to a crawl because the caches are all being refreshed dynamically as the users are loading them. Query compilation performance can degrade when commits are pushed frequently because of that cache eviction that I just mentioned. Validation times could be very slow because the scope is inappropriate. You're trying to validate against too much content. Or there could be a lot of stale content. Stuff that's sitting on disk that no one's accessing costs the system just as much as things that are sitting there and used every day. And maybe it's because of a bug. And that's more on Looker's side. But you need to go through this sort of checklist to understand, okay, where is the actual bottleneck? What's causing the degraded performance and how can I go about fixing it? So one of the places that you can try to do this diagnosis is in system activity in the admin section of Looker. System activity has a few key areas. This is something that we're actually doing some active development on this year and we're going to be expanding some of the capabilities. But right now, I'd recommend you focus on these four key areas in system activity today. One is looking at database performance. You need to identify where there are hot spots on your connected DBs. Because of Looker's in database architecture, we scale as well as your database. So if your database is overloaded, Looker is too, or the experience will be. Second, instance performance. This is where admins can make governance come to life. Identify pileups and scheduled content is one of the most common root causes of intermittent slowness in a Looker instance, mainly because no one's there to monitor the schedules. For example, I was working with a customer a few months ago and they didn't realize that they had 5,000 scheduled sends all firing exactly at 9 a.m. took them four hours to clear that queue out. And what we were able to do is identify those schedules that were critical business performance, put them at the start of the day and segment the rest of the scheduled sends over the rest of the calendar day to reduce that system load and voila, a lot of performance problems just disappeared overnight. Query performance is also hugely important. This is where the actual definition of the query matters quite a bit and we'll have a couple guides on how we can navigate that. And lastly, performance recommendations. This is where we will offer to you proactive recommendations. Warning, you have a ton of scheduled sends right now. Warning, you have way too many tiles on this dashboard. It could single-handedly exhaust your slots on BigQuery, for example. So this is one of the really important areas that you as an admin can understand what's going on. Let's look at the query. Because Looker is connected to your external database, there are sections of the query that are in Looker and then others then sent out to the database and then we'll retrieve the results and present them to users. These are all of the actual steps, each of these blue, orange, red, and green boxes that you'll see in the system activity logs. If you want to kind of group them up conceptually, the first four are all about pre-processing. We're looking at the model, we're looking at the data, and we're making sure that we're ready to semantically define all of this. Then we're queued. Ideally, we're queued inside Looker and not inside your database's queue. We'll talk about why that's important in just a couple minutes. Next, SQL running. This by far takes the longest amount of time. This is the time in the database, actually executing the query and retrieving those results. Lastly, we have post-processing. This is where it comes back to Looker and we actually visualize and render those results. So what we did was we looked across several billion queries in Looker and we identified the 70th percentile time for each of these stages across those billions of queries. This is a good rough indicator of what you should expect in each of these stages, especially from a relative basis. What you'll notice here is that SQL running by far takes the most amount of time, usually more than all of the rest of the steps put together. And that's where optimizing your query, optimizing your LookML will have the greatest impact because this will improve the efficiency of how the query is being executed in that external DB. There are things you can do within Looker, of course, to reduce some of the times in the other areas as well. But a lot of it comes down to the database and people really, really, really want their database to scale. So pardon me for going into a little bit of a lecture mode for just a second. We're going to talk about a few very high-level computer science concepts when it comes to databases. Ideally, everyone wants A. Perfect scaling. What each of these charts is showing, by the way, is on the vertical axis we have time. Horizontal axis is number of queries. So the line itself is queries per unit of time. This is all sort of illustrative. So everyone really wants A. As you have more queries, you want to get more data. And people are mostly okay with B, the idea of diminishing rates of return. Whereas query volumes go up, yeah, the per query latency will degrade a little bit, but you'll still get more data per unit of time. Everyone hates C. C is when there's diminishing returns with a bottleneck. This is usually in real life the capacity of your external database. Or it could be some of the capacity of other critical parts of the workload. For example, size of the cache and cache eviction. Everyone thinks D doesn't happen. And D is something called retrograde throughput. This is what happens when the database itself is at or near its max capacity. And what this chart is showing you, the green line, is that total database throughput actually degrades absolutely as you get higher and higher towards that limit. Most of that is for resource contention within the database. the database needs to spend more time managing its own queue and has to spend fewer resources on executing those queries. And so this is called Gunther's universal scalability law. It exists for all BI tools that are speaking to an external DB. So it's universally useful across all database types. All databases have some concept quota, slots, or capacity. So this is where managing database scale considerations can have sneaky powerful implications. So this is looking at that retrograde throughput chart again, but just that one. What we're seeing in the green is the throughput per second and the blue line is showing total latency for the database. So what this is showing is as you have more concurrent queries, your total throughput declines and your system-wide latency will increase as a general rule. Now a lot of databases natively try to avoid retrograde throughput and that's one of the reasons that they'll give you an overcap of slots or concurrent queries. But we have a mechanism for you to kind of normalize how you're treating these external DBs. And that is that Looker itself has a pretty powerful queue. And if you're queuing the query inside Looker, it's not weighing down your external instance. So it's actually a positive thing to have queries retained and queued within Looker because you can see the status of them. We've just recently added a capability within the connections tool in admin that allows you to explicitly set this. There are two key values that were added. One is the total maximum number of concurrent connections allowed for that specific database. So you can set this on as many databases as you have per DB. And the second is the per user connection concurrency limit. This ensures that you won't have an individual user or an individual dashboard soak all of the capacity for your data warehouse. Setting these on a per DB level can have great impact in user experience because you'll have fewer lost queries or failed queries. The queries will be retained within Looker's queue. We also have some new guardrails and controls that help manage instance-wide behavior. So for example, you can set a new minimum refresh interval on all auto-refreshing dashboards. This is a feature we've added in the last few months. What this will do is it collars the amount of auto-refreshing content. I think my hypothesis is a lot of Looker users don't understand what we mean when we do auto-refresh dashboards. Auto-refresh dashboards will be firing at that interval under the hood whether anyone is looking at that dashboard or not. And anytime a user loads the dashboard it will also refresh it. So usually auto-refresh are not necessary for dashboards unless it's kind of like in a kiosk-like mode where no user is going to be interacting with it. So this allows you to kind of collar the amount of load that you can have from auto-refresh content. Merged queries are another kind of third rail of scalability. It is a powerful feature within Looker but it needs to be used carefully. Merging queries from two external DBs into one inherently makes that a little bit less scalable. So mitigating or making sure that merged queries are used only when absolutely necessary and hopefully you can have like an ETL pipeline merging some of the data sets upstream that can help clear up a lot of bottlenecks within the Looker instance as well. So before I hand it over to Andrew to talk about how HubSpot has used Looker I wanted to just mention a few things that's important for all admins to consider. One is stale and unused content. It's very important to clean that stuff up over time especially in a regular cadence. If you have individuals leave the company they might have a lot of content sitting in their personal folder that could be taking up this space and causing some of the overhead. Also be careful with your many roles and permissions. In general you know there's a lot of fine grain control for roles and access that you can set within Looker but it's not free. Dynamic content checks and dynamic permission checks can weigh down users experience so think about the number of types of custom roles that you might need at scale and back fill from there rather than trying to just create a new role on every marginal request that you might have. Try to avoid many nested folders. This is again sort of like a ubiquitous content but the further down a folder structure we need to navigate to iterate across stuff the more costly it can be. Watch out for auto refreshes. Make sure they're not too frequent and look out for schedule pileups. And then lastly always think about the capacity of your link system. Think about the performance of Looker itself. Okay. I wanted to hand it over to Andrew who's going to talk a little bit about his real life journey through some of the growing up of Looker at HubSpot over time. How's everybody doing? Good. Good. I know it's the middle of the afternoon bear with me. I'm excited to be here. My name's Andrew Martin. I'm the director of data strategy and operations at HubSpot. I will get to my slide here. So I'm really excited to talk to you today about how HubSpot has grown up with Looker and how we approach usability and scalability within the platform. So a little bit about HubSpot. We are a $2 billion plus company headquartered in Cambridge, Massachusetts. Our mission is to help millions of organizations grow better and our aspiration is to be the number one AI-powered customer platform for scaling companies. So a little bit of history. We've been Looker customers for about 11 years now. We have over 8,000 employees and we have over 8,000 users of Looker at HubSpot across all facets of the organization and it is our source of truth for the majority of our reporting across business performance and everything over to People Analytics too. So Environment at a glance, we run what's called a hub and spoke model. So center that spoke is governed by our centralized data team. Each hub is a project that's usually owned by a functionally aligned ops and or analytics team. So like I said, a little over 8,000 users, almost 5,000 weekly querying users, so a lot of heavy usage on the platform, 17,000 looks and about 3,700 scheduled plans or scheduled sends. So some opportunities we recognize that led us to our 2025 Looker strategy. First off was governance. All of these functionally aligned teams that own our projects today none of them were responsible for governance or at least it wasn't a top priority. So we wanted it to be a top priority for a team to implement some structure and a governance strategy across all of our projects. Second, we did a lot of interviews with our user base internally last year as part of a data strategy project. Out of that came a lot of feedback that, hey, I love Looker, I use it on a regular basis, is there anything we can do to speed up the front end. Third was duplicative explorers. We have over 1,500 explorers today. And so you can imagine as somebody new joining the company, whether you're a business user or an analyst, it's hard to get up to speed quickly when there are so many different data sources that are owned by so many different teams. Last but not least, at a point last year we had 20,000 public dashboards across all of our projects. We used to because we have under 10,000 now, we auto archived half of them due to activity or lack thereof. So we're under 10,000 now. Our goal is to be under 2,000 by the end of this year. I'll get to how we're going to do that a little bit later. So part of what has enabled us to make standardization of our looker environment a priority or some more changes that we did last year. So I guess in the first half of last year we still had distributed analytics engineering teams and members of our functionally aligned operations teams in different parts of the organization. And so we brought those teams together under one roof and we now have a centralized data team underneath the hood of a centralized operations team. Again, at the time last year, looker standardization was not a priority. Now it is a strategic objective for 2025. Our data warehouse infrastructure team used to be much more reactive to our stakeholders needs. They've now been empowered through executive leadership and they've been given a mandate essentially to introduce friction where needed. So we like to say internally good friction. I'll give you an example of that in a little bit. So in the second half of last year, we engaged Google Professional Services to do a health check on our environment, which was really helpful. It was a top-down review of our implementation, our strategy, and at the end we got some recommendations that we can action on. So a few of those included implement content management. We didn't have any ongoing content management or asset retention policies across our projects. Two, remove inactive users, reallocate users across license types where appropriate. Three was work with dashboard owners to split up and pare down dashboards over recommended limits. So Miles was just talking about merge queries. I think the best practice is 25 tiles or less on each dashboard and no more than four merge queries. we have a report internally that kind of identifies all of those offenders let's say that are on that list that are high usage that we aim to work with our business users who own those dashboards to pare them down. One feature that's been really helpful for that is when you're working with a dashboard owner who is a little bit nervous about taking content away from a dashboard is breaking that up into multiple dashboards and using boards. Put it all on the same board. From a user experience standpoint it's actually better it's more organized and more digestible too. We like I said had 3,700 scheduled sends. We had the assumption that there was a lot of resource contention that was being introduced by those schedules. We worked with Google team to move those to a separate scheduler node and therefore kind of remove that from the list of possible things that could be slowing down our front end performance. And like I mentioned previously reduction overall number explorers we want to get down to under a thousand by the end of this year. We have a centralized data warehouse project that is going to help with that. Also around the same time we did the health check last year we started evaluating spectacles on the recommendation from the Google product management team and we were particularly interested in SQL validator lookML validator and content management. Those were huge draws. In the two week POC we did we focused on our sales project and our sales AE team was able to eliminate 487 SQL errors out of our project which was immense and really showed us what spectacles could do. We ended up launching spectacles in January early this year. It's in the process of being rolled out to all of our analytics engineering teams right now and we're already using some of the content management features. So what is our 2025 strategy? So building blocks here. first off standardization. We are in the process of implementing a standard folder structure. We also want to communicate dashboard development guidelines to our analyst community to help them roll out content in a more uniform way to our stakeholders. We also want to purge unused content and manage that a little bit better, put asset retention policies in place and run them on a regular basis and deploy spectacles throughout our organization to help keep it uncluttered. Governance. So if we're going to do the work to implement that folder structure for example, we want to do some things like turn off sharing from personal folders, not let everybody create new folders and undo some of that work that we did. And we also want to work on grouping those high usage dashboards into boards for greater visibility. Lastly, we want to make sure that we train our user base, both analysts and business users alike, so that they know how to use Looker best and what should it should not be used for. Before I hand it over to Josh, I just want to say thank you to all of my colleagues at HubSpot, central data team. They all do fantastic work. I'm honored to be here to represent them. So thank you all. Josh, come on up. Thanks. Hi, everyone. Thanks, Andrew. My name is Josh Temple. I am one of the founders of Spectacles, now a part of the Looker team, bringing delightful developer experiences to Looker users and admins like you. And I'm going to talk just briefly about developers' responsibility for performance. And so when we talk about developer responsibility for performance, there's two aspects that I'd like to focus on here. One is the choices that a Looker developer makes and the impact they have on the performance of the instance itself, the LookML that we architect, the queries we write, et cetera. But I also want to talk about the performance of the LookML developer team because it's not just about the computers, it's also about the people and how we can quickly iterate over changes and when we think about the full life cycle of a change to LookML, how do we make sure that that's done efficiently and quickly? So for a single LookML developer in one Looker instance, it's maybe quite straightforward to make these decisions, but at the enterprise scale when you're contributing to a large Looker instance with many projects and models, being a good steward of that instance and making good choices about how it's structured can be more challenging. But luckily we've got a couple decades of experience within software engineering, we can draw on a lot of these best practices and help us have efficient teams and efficient workflows. So there's a few quick hits on this slide of tips and tricks for good choices you can make as a Looker developer in the area of performance. And I want to summarize these really in two areas. One is thinking about the way that you write the LookML model itself. Because the LookML model is what's ultimately parsed and used to compile SQL, being thoughtful about the structure and organization of that model and ensuring that it aligns with the functional area, resisting the human urge to put everything into the same model and put everything into the same view and table. Looker has a lot of great tools for organization and hierarchy. And so making sure that you make the full use of those will go a long ways in the performance of the instance. The other thing I want to double click on here is the idea of being proactive about fixing performance problems. I think as developers, when we're faced with a choice between tracking down a thorny performance issue and making a straightforward new change to add something to the model, it's very easy to go after the quick and easy and straightforward one. But being disciplined as a team and through the policies that we set of really tracking down these performance issues and heading them off early on will make a big impact for our users. So I've got a few woes here that Looker developers often run into. Will you raise your hand if you've ever deployed a code change to Looker that broke a dashboard? Shame on you. Raise your hand if you ever had to deal with a firefighting issue where a database column changed and the corresponding update was not made to the LookML model and it broke a dashboard or some explorer or something like that, right? Not our fault. That's not our fault. And then raise your hand if you have this problem where it's hard to find a dashboard or it's hard to know where to look within your Looker instance because there's just too much content. Yeah. So these are common problems, right? And I'm going to talk about two tools today that can help out with these problems. The first is the content validator. So raise your hand if you've used the content validator within Looker. This is a great tool. If you haven't used it, go check it out. It's a way to basically see at a high level what content in Looker doesn't work. What looks or dashboards are depending on references to LookML that are now invalid. And so the content validator has recently undergone some great improvements to make it faster and more performant where you can now scope content validation to a specific project, specific folder. And this is a really great way just to go in and see like what kind of broken content exists and how can I clean it up. What I'm very excited to show you today is a live demo of a new feature that we've been working on called Looker CI, continuous integration. And if you haven't heard the term continuous integration before, essentially what it is is a way to run a battery of automated tests on every code change before it goes to production, helping you catch breaking changes before your users find them. And so I'm going to do a live demo here of this CI feature. And the CI feature is broken up into what we call validators. So there's four different things that it will check. The first is does the LookML that you've written actually compile into valid SQL that runs in the database? And then it also runs the content validator to check for changes that might break a dashboard or a look. It can run LookML data tests if you have those assertions already defined to catch business logic assumptions like my conversion rate should never be negative or something like that. And then lastly, if you're creating LookML from outside of the Looker IDE, you can run LookML syntax validation as well to catch changes in code gen pipelines or developers working in their own text editors and that sort of thing. Okay, I'm going to hop over to a quick demo of the CI feature which is rolling out to public preview at the end of this month. All right, so here we are in Looker. I'm in a view called orders and I'm going to make a change with a couple breaking, a couple errors and we're going to see if we can catch those before they hit our users in production. So the first thing I'm going to do is I'm going to go add a dimension, a new dimension called Traffic Source. So let's say we've been asked to attribute these orders by marketing channel or something like that. And I'm in a hurry and I don't catch the typo. And let's also imagine I've got this dimension status here. And I know that I'm going to be joining this view in other places and I'm a little worried that status isn't going to be too generic and I want to make sure my users can understand which kind of status we're talking about here. And I don't know about labels. I don't know about aliases. I don't know about really the right way to do this in Looker. But I think it's probably safe enough just to change the name of this dimension. Wrong. What I've actually done here is introduce a dimension that doesn't run in the database because of the typo and a change to this dimension status here will break every piece of content that depends on a dimension named status. So this is not great. But let's commit it. I've just committed with the commit message J. So very, very helpful there for the rest of my team. We'll go ahead and commit that and open up a pull request in GitHub. So when I do this, because I have the continuous integration feature turned on, Looker is going to kick off these validators that I talked about earlier. And we'll actually see the status of those validators start to roll in here. In theory. What's that? It won't come in through the actions. I'm actually going to switch to it. We have a pre-recorded version here. I don't know why we're not seeing that status come through. So let me switch to that and then I'll show you what we'd expect to happen here. My mouse is not working on this. Is there any way on slide 43 to kick off that video? There we go. Okay, now we're back. All right. Okay, so let me skip ahead here a little bit. Okay. So we'll create this pull request. When this pull request gets created then the CI run kicks off automatically and it's going to write statuses right here. So we can see in GitHub we've got the content validator running. We've got the SQL validator running. We can click back into Looker now to see what's happening here. And we see this new tab on the left, continuous integration, and we've got an active run here that's running against our pull request. We can see it's running on that specific commit and it's running two validators to check for SQL errors and breaking content errors. It's running an incremental mode which means it's actually going to make an intelligent comparison against Looker production and it'll only show me the errors that are relevant to my specific change. So if I already have a lot of content errors in the content validator or I already have broken SQL dimensions, things like that, I only see the things that I'm responsible for. And so skipped ahead to a previous run here just in the interest of time. But you can see the CI tool returns that there was an error with the SQL statement, an unknown column, and also a breaking change to a piece of content. And so I can go back into Looker now and I can link directly to the problematic dimension and make that change. So back in Looker, we'll make the fix. We'll correct our typo. And instead of renaming the dimension here, we will add a label. So it's clear to our users this is an order status. And we can save that change, make a new commit. And when that new commit lands in GitHub, Looker will automatically kick off a new continuous integration run. And we should eventually get a passing status. So back in the CI tab here, and now I can see that second run has been queued. But in the interest of time, I'll show you the past run here. And we can see that we've passed validation now. And so we can very confidently merge this change knowing that it shouldn't break any of the important content. It should work from a SQL perspective and will maintain the trust that we've spent so much time earning with our business users. Thank you. Thank you. Thank you. Thank you. Okay. Thanks, everybody. Really appreciate the time today. All of the speakers are going to be available at the front of the room if anyone has any questions. We don't have time for Q&A, unfortunately. But feel free to reach out to any of us, either on LinkedIn or here up front. We'd be happy to engage with you. So thanks very much for your time. Really appreciate it. Thank you. Thanks Father. Thanks for joining us. Thank you. Thank you for joining us. Thank you. Thank you. Thank you so much for asking. Thanks. I'll just have to do this thing. Thank you.