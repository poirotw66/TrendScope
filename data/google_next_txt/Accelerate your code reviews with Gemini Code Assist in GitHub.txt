 All right, welcome everybody and thanks for joining our session on how to accelerate your code reviews with Gemini Code Assist and GitHub. Let me just advance here. So my name is Marcus Grapeggia, Product Manager within Google Cloud. I'll also be joined today by Eddie Santos, our Staff Software Engineer, as well as Rajesh Gajula, Senior Director of Engineering for Tailored Brands. As for today, the agenda, I'll start by covering a bit more about what is Gemini Code Assist, what are the kind of the core problems it solves and the key use cases it supports. Then I'll talk a bit more about how specifically can AI help with the code review process. I'll then hand it over to Rajesh to talk a bit more about Tailored Brands' experience and journey with Gemini Code Assist. And we'll close it up with a live demo. Eddie will be showing you live how can use Gemini Code Assist on both GitHub as well as on GitLab, right? So let's start. So what is Gemini Code Assist, right? So for folks who may not be familiar with, Gemini Code Assist is Google's AI powered assistance to help make developers more productive, more effective, and more satisfied. So it essentially provides capabilities such as code completion, code generation, multi-turn chat, or code transformations directly on your IDE. So imagine VS Code, IntelliJ, PyCharm, Android Studio. Here is bringing the assistance of AI directly on your IDE. Within Gemini Code Assist, one thing which is very important for us is a focus on being enterprise-ready and enterprise-focused. That essentially means two core things. The first one is having the right enterprise context, which is tailored to the needs of enterprise development teams. So what that means is typically enterprise development teams have a large collection of private libraries, private best practices, and private conventions. The idea here is you can customize Gemini Code Assist to take all those conventions that you can use your account and provide both code completion, code generation, and chat assistance, taking into account your knowledge and having AI systems, which is not generic, but tailored to your private code and your best practices. That also means providing tools for teams to understand the impact of Gen AI. So essentially imagine statistics and logging and monitoring data around usage, acceptance rate, and so on and so forth. It also means having tools to allow you to meet your compliance, security, and privacy needs. For example, Gemini Code Assist does not train on the customer data, on the customer events. We don't even store your data as per our governance, as per data governance policy. Essentially, it behaves equivalent to a stateless service in that sense. We also have support for VPC service controls, data residency. Essentially, all the controls typically makes it easier for our customers to meet their compliance needs. So that's one. Now I want to quickly show you folks this chart. So this is essentially the result of an analysis which Google internally run on our engineering team. So how did you get this data? So we instrumented our developer workstations and measured how much time were across tens of thousands of engineers, how much time were they spending on different tasks, different services of the development lifecycle. So what this gives us is quantitative evidence of something that we kind of know qualitatively, that software engineering, developer productivity is much more than just about writing code, right? So you can see here, developers do multiple things across the day. So they, yes, they write code, they have meetings, they report on Jira tickets, GitHub issues, they troubleshoot, they have more meetings and all those different tasks. The core idea here is if you want to get the most code out of an AI assistant solution, you need to think broader than just code. The key idea here is you want to think about, okay, how can I make my code review process more effective? How can I help with testing? How can I help with investigation? How can I make reproducing issues more easy and so on and so forth? The idea here is if you approach that holistically, you can get a bigger combined impact on across developer assistants. Going deeper, one thing we did here was we spoke with multiple of our customers to try to better understand, okay, what are the things which are holding your development teams back from achieving peak velocity and peak satisfaction? There are many, many challenges teams has. Those are the four biggest categories we heard again and again from our customers. The first one is slow developer onboarding. Imagine the time it takes from engineer, which is new trade team, new trade project or new trade code base to be able to effectively read, understand, review and contribute to a code base. That's one thing which you see sometimes taking days, sometimes taking weeks. That's kind of part of that ramp up curve. It's one of the key areas where AI can help with helping you better understand code bases and conventions. A second big area is excessive repetitive tasks. There are many, many tasks which are very critical. You may essentially imagine documenting code, writing comments, writing unit tests, following the right naming conventions, but which often are very repetitive and kind of may get in the way of the more complex tests of the development lifecycle and could be a good fit for AI automation and AI assistance. A third very interesting task is high maintenance costs and tech debt. That's a very interesting one because the idea here is AI can help accelerate that, such as helping you better test a code base, have better test coverage, or help you generate comments for a code base, or help you understand a code base. But interestingly, one thing we saw is you also want to make sure you have the proper guardrails around AI to avoid the downwards pressure on quality. One of the things which is very critical is to ensure that your developers, particularly the more junior ones, are carefully reviewing all the AI-generated code to ensure it is not introducing potential security or performance issues on your code base, or making your code base maintenance harder in the long term. A fourth big one is difficulty enforcing best practices. The key idea here is there's a typical challenge where typically you see developers, let's say, with six months or one year having much less of understanding of, okay, what are the conventions? What is the right way of writing code for maximal efficiency on my code base? That's a core area we'll be focusing on today among those four here, which is, okay, how can we help our customers bring some of those best practices and the tools to make that easier at scale? Right, so that's one. And the second big thing is how do we address those issues, right? So one of the key things we're doing with Gemini Code Assist is rethink the full software development life cycle on its entirety, right? So you can see here on the left-hand side, you have the traditional areas where AI assistance has been focusing on over the last years, which is the developer inner loop, right? So, and Gemini Code Assist helps with these areas. So, for example, as you are designing your tool, we can help you brainstorm a new application. We can help you understand code with a chatbot and code generation. We can also help you generate code or modify code or generate unit tests. That's all which happens within the IDE. But it's also very important, if you think about the chart before, to also think about the developer outer loop. And that's a core area of focusing more and more within Code Assist. For example, code reveals. How can you ensure that you are catching divergence from best practices? How can you ensure that you are catching potential regressions after the code was submitted for pull request review? Fix and maintenance. How can you ensure that you are detecting issues and minimize the time to resolving those issues? One example of an area where Code Assist helps here is Gemini in Firebase Crashlytics, where if you have crashes or ANRs, you can use Gemini to help you understand these tech traces, understand those memory issues, and also get suggestions on how to mitigate your code. As well as operation, how can you better understand your deployment model, your architecture, to effectively manage the code base? The key idea here is, if you want to tackle that full chart I showed before, you want to have a solution, which is thinking about all those different areas of the development lifecycle. And how do we do this? Essentially, the key principle we follow within Gemini Code Assist is meeting developers where they are. A big thing we see is development teams have a very varied, heterogeneous collection of DevOps tools. You may have different tools on the IDE. You may have different CI tools. You may have different Azure tracking tools. And those choices, they're often very thought out about and they're often very ingrained on the development process. It's a very big cost to modify those. The idea here is, okay, we then bring Gemini Code Assist to where you are, but you also bring those tools to Gemini. Essentially, by having, you may have seen our talk today about tools. You can have essentially Atlassian, Snyk, Sentry, all those integrated within Gemini, within your ID. You can essentially retrieve this data. And today, specifically, we'll be talking about how we are helping bring code reviews powered by Gemini to GitLab as well as GitHub. Right? And next one, in addition to code reviews, I also want to share some of the capabilities. You can hear more about the sessions at Cloud Next that are making this possible for Gemini Code Assist. So one is we're bringing now Gemini 2.5 in private preview. As I mentioned before, we now have SDLC agents helping implement more and more complex tasks. I mentioned tools and Gemini Code Assist for GitHub, both bringing data from SDLC to Gemini, as well as bringing Gemini to GitHub or to GitLab, as well as code customization and login and monitoring to give all those customization needs, to meet all those customization needs, and bring all the data needed to help development teams on the enterprise better understand the impact of their tools. Right? So that's it for the overview of Code Assist. Let me now jump deeper on how can AI help with code reviews specifically. So now you can use Gemini Code Assist for GitHub. What it does is it brings AI assistants directly to GitHub and GitLab. What you can do here is you can install an application available in the marketplace. The way this works is it brings Gemini as a third entity on the code review process. So every time a pull request is created, you see Gemini, you can actually see there on the top right-hand corner, automatically getting assigned as a code reviewer. And it does provide both a summary of the changes to be done and changes which were done on the pull request, as well as suggestions on how to improve the pull request. It also provides a detailed breakdown on potential code changes. That's one idea. The second way you can also interact with Gemini is at any point, you can type slash Gemini or at Gemini Code Assist to trigger a specific assistance based on a prompt provided by the user. The core idea here is both creating more effective code reviews. Imagine you're a code reviewer. One thing we see is code reviewers spend a fair amount of time reviewing repetitive basic patterns like stylistic issues, reminding people to comment their code, reminding people the right naming conventions. The idea here is take all those well-defined patterns, delegate them to an AI assistant so that those code reviewers can focus on more complex code logic, making sure code is performant or detecting more complex bugs or patterns to improve there. That's one area. The second thing is the idea here is also making the code review process go more smoothly. Because we know here that the time it takes from the point a pull request is written to the time it takes for you to get an actual code review may be hours, in some cases days. The idea here is immediately you get some first line of assistance from Gemini about patterns you can focus on for improving your AI assistance. Sorry, for improving your code. And more importantly, all of this is tailored, can be tailored to your style guide. As you'll be seeing a few, you can create both custom style guides as well as customize the behavior. So having Gemini code assist review code for the patterns which are of most interest for your specific organization. So as I saw before, those are the two main ways to interact with Gemini within GitHub. The first one you can see is I created a pull request. Gemini is being automatically added. The second one, you can see the developer adding a comment. So anywhere you can write a comment, you can just type at Gemini. For example, at Gemini, is this the right pattern for that? Or at Gemini, am I following best practices? Or at Gemini, implement more tests and get a response back here. In this case, you're seeing someone using Gemini in Japanese. Just to show how you can seamlessly have multilingual support here as well. That's one. The second big part here is customization of behavior. The way code assist works is the customization is done on the repository level. So you can create a .gemini folder and add a styleguide.md file. That styleguide is just essentially a markdown file, like the ones you use for typically writing your own regular styleguide. And you can essentially specify the rules. Okay, what are the patterns to look for? You can say, hey, Gemini, look for camel case conventions for variables, but lower camel case for function handlers. And you can specify how Gemini should handle the use cases, as well as providing some few short examples for how to address those. That's one way. You can create this file and for each different repository. So you can have one for a Python repository, one for Java. You can customize that on the repository level. You can also customize the behavior. By default, Gemini tries to be more on the concise side. So Gemini is limited to five suggestions per pull request. But one thing you see is some development teams say, hey, you know what? I want to be very comprehensive. So you can create a config.yaml where you can say how many suggestions you want. Do you want just low severity or do you want just high severity or do you want medium and low severity? So you can actually customize and tailor the triggering and the characteristics of Code Assist to your specific need via a second file within your .gemini folder. Right? So, folks, that's it for the overview here. I'll now pass it over to Rajesh, who will be giving an overview of the story and experience of Taylor Brands with Gemini Code Assist. Thanks, folks. Thank you, Marcus. Thank you, Marcus. Good afternoon, everyone. I'm thrilled to be here. Thank you, Marcus. Thank you, Marcus. So, let me just say, hey, I have a piece of software which writes your code, creates a documentation, creates a unit test cases, and also it does a code reviews. Yeah, probably a great use case for a sci-fi movie. But now, today, because of the tanks to generate AI and Gemini Code Assist, the future is in front of us. My name is Rajesh. I'm the senior director and working for Taylor Brands. How many of you know what Taylor Brands is or what we do? All right? We help people love the way they look and feel for their most important moments. And some of our brands include Men's Wearhouse, Joseph Bank, Moore's Floating, which is up north in Canada, which is similar to Men's Wearhouse, and K&G Fashion Shores. We are the number one position in the Taylor Floating and number one position in dress shirts and number one position in the rental market. So how many of you know either Men's Wearhouse or Joseph Bank? Probably a few. Thank you. We have Men's Wearhouse with 636 stores nationwide across the United States, and Joseph Bank with about 200 stores. And Moore's Floating is similar to Men's Wearhouse, but up in Canada. And K&G is our one-stop affordable shop for men's, women's, and kids with about 100 stores. Our overall Gen AI journey. So ever since ChatGPT was out in 2022, so just like everybody else, we started doing personal exploration. But also some of our employees are also doing some exploration. So we said, like, okay, we need to take this enterprise engagement. So we actually hosted our own private LLM. So we hosted our private ChatGPT, so that way we don't want to be up in the news that ChatGPT is hallucinating or our code is up in the Internet. So we created our private LLM. So we encouraged our developers to go try it, use it, up to your imagination. So we did that, and we quickly realized we needed a governance. So we created a AI governance code. So within our company, so we created some guard rules and what to do, what not to do, and what are people allowed to do, and which data goes out and which doesn't. Then we partnered with Google. So we did various POCs, just like any of you guys. But we started working on this Gemini Core Assist ever since it was in a preview. So we have a lot of our group of very interested and talented developers, so we encourage them to use it for the past year and a half. We did a ton of workshops and trainings, and thanks to our Google partners, so they came to our office. We did lunch and lunch and brown bags and whatnot. And transformation. So we are seeing across about 20% to 30% more productive, which are mentioned by our developers. So we did an occasional service probably every quarter or for the past year and a half. So initially, ah, okay, it's working or not working, or a little bit of extra time they invested in, but our recent service is it's great. Then there are some challenges on issues we need to solve, right? So everyone have issues. So number one is like a time-consuming reviews. You write a code. Obviously, you wanted your peer to review it, but obviously that code review is not up in his priority list, so he got a lot of things to do. And then inconsistent code quality. So every developer is not the same, and everyone has a different lens. So we've seen that. And lack of immediate feedback. But obviously you wanted the code review to be done today, but it might not happen. It will go to tomorrow or the day after. And then they focus on low-value work. So developers handle repetitive, low-impact issues, so we wanted to take away that from the developers. So then code assist solution is one thing. I'm not going to cover all of it. Marcos did a great job in what code review code assist does, writing a new code, understanding an existing code if there is a new joiner in the group, writing a documentation. So obviously we won't normally invest a ton of time in creating a documentation for the code we write, but thanks to code assist, so it's helping us create a lot of documentation and then creating test cases and enhancing the code review process. Obviously there are a lot of challenges along the way, so it's not a cakewalk, and there are a ton of issues, one with the tool compatibility. Most of our developers using code, Visual Studio code, but there are a lot of our developers using the Eclipse. They love Eclipse. They don't want to make a switch. And some of our portions of our IT, they were using a RAD, Rational Application Developer, if you guys know. And code assist does not directly work well with it. So it works great with a Visual Studio code and Google's code build, but we had to solve those challenges, so we worked with them, so there are some not-a-day straightforward plugins, so that's one challenge we had to mitigate. And the language support. We are a 55, 57-year-old company, and we do have some of the legacy workloads. We do use some of the applications run with the basic. So code assist does not provide the same level of code quality with the basic languages or some of the legacy languages. So there are some challenges we've seen with those teams. And then the customizations. So we do have tele-advents have certain packages and modules built in-house, and Gemini code assist might not be aware of all of our internal standards or internal modules which are guys developed. So we had to train that a little bit. And then the training. Some of the developers are really, really good with their prompt. So all the key is the prompt engineering. And some of the developers might take, like, five or six different prompts to get to the answer what you want, but some of them will get with the one prompt. So we had to do a lot of training for our developers to make sure, okay, you need to make sure your prompt is good. And it follows that conversation. It follows that context. You don't need to provide the context every time. But if your prompt is good, you get a great quality of the code. But your prompt is poor. Some of them, we gather that feedback, so some of them are not happy with it, but the root cause was that, okay, let's educate everybody and provide some training on the prompt in it. And then the ROI management. There are some challenges. So we wanted to not just throw away tools to the developer hands and have them use it and have fun, right? So I want to gather ROI. So what is ROI we're getting? So there's no straightforward way to calculate it. We did a lot of surveys and a lot of analysis and also figured out how many lines of code they're accepting and how many of them are there not. And what if can we share the same license with our contractors? So we onboard a lot of contractors working for a project. Okay, so if a contractor, if I'm paying for a license to Google and my contractor is using it, so what's ROI? How should I calculate it? And then the governance. So obviously we wanted to make sure so everybody authenticates to our code assist hosted in our cloud. So I don't want them to use with their private own login ID with connecting to the Google ID and data leaving our company. So we wanted to make sure we have a proper governance and clear policies defined. And then the impact. With all of that, we've seen a huge, huge results. Number one, fast code reviews. It reduces the review cycles and detects bugs early. And the regular users. So we have seen 72% of our developers use it frequently. When I say frequently, almost every day. And then improved developer experience. So less cognitive load with the intelligent suggestions. And high adoption rate. 92% of our team members adopted the code assist. And then the productivity base. And as I mentioned earlier, we did a service every quarter for the last year and a half. Almost like a seven or eight of them. And 90% of them feel more productive by using a code assist. And the knowledge sharing. So automated document creation and test case generation. That's a huge. Our QA team was stoked. They're happy. So there is literally, there is a tool which could write a documentation for this entire 20 pages of the code and then the unit test cases. With that, I will invite Eddie. Eddie. All right. Thank you, Rajesh. That was great to see how Tailored Brands is using Gemini Code Assist and the impact it's had. So I'd actually like to backtrack a little bit to this slide that Rajesh has. Right? So we all know that code reviews are a really important part of a software developer's job. But let's face it, it could be very challenging, right? Time-consuming reviews, the time that it takes for an engineer to go through your pull request and give you valuable feedback. Inconsistent code quality, right? Even if that engineer is really talented, it might just be that they are super busy with something and they miss something important. Lack of immediate feedback. It takes days sometimes to be able to get that review from your reviewer. And, you know, with Gemini Code Assist, you can actually reduce those friendly pings that you have to do to get that feedback. And then also focus on low-value work, right? Code reviews, you know, oftentimes there might be a lot of nitty things, right? And those things are important, but that's not the real value, right? So Gemini Code Assist can help by getting that pull request really clean by the time it gets to your human reviewer. Cool. All right, so with that said, I'd love to take you through a demo so we can see Gemini Code Assist in action. All right, so I have a simple web app here, and I won't get too much into this repository, but I've gone ahead and made some changes. So if I go here to this branch and I click compare, you can see that I've made some changes to the back-end code written in Go. And so we'll get into these details in a second, but, you know, these look good to me, so let's go ahead and create a pull request. So let's give it a title, and, you know, I'm a software developer. I've been pressed for time, so I'm gonna assume that my reviewer knows what this pull request is gonna be about, so let's just name it changes to back-end Go code, right? And what the heck? I'll just leave the description blank because, once again, they should be able to figure that out. And so with that, let's click create pull request. And what happens at this point, right? At this point, typically, you wait. You wait a while, and, you know, it could be hours, it could be days, but that wait can be quite painful. But look at this. Within 10 seconds, Gemini Code Assist posts an initial summary for your reviewers to quickly get up to speed, and it does this by analyzing the diff that you've created to provide that context relative to your code base. So really cool. And so looking through, we get a high-level overview of what those changes were. We get a bullet point list of what all those changes were by theme, so you know what's been happening. You get a profile change log, and so you can see here for every file that was changed, here's the changes that were made in those files. And then lastly, for all you artistic folks out there, if you just prefer to digest the summary in terms of a poem, you've got you covered there, too. So this is great, right? This is a really big benefit for reviewers because you can quickly get up to speed on what's happening in this pull request. But actually, something magical has happened next. Gemini Code Review, Gemini has provided a code review nearly instantly, within 30 seconds, right? And this is really where Gemini shines because it can use its one to two million token context window to extract really relevant files from your entire code base to include as part of its code review. And so it gives high-level feedback, it gives a bullet point list of findings that it has, and it also gives a merge readiness assessment. And so we can't approve your PRs. We want to leave that valuable and, you know, really important task to the actual human reviewers, but we can tell you that, hey, you might want to take care of these things before you merge this pull request because there might be critical or high-severity issues that you need to address. So really cool. This is not just a linter. This is giving you really valuable feedback using the breadth and depth of Gemini as an expert software engineer. And so furthermore, Gemini will actually go through all of the files and leave individual comments. And here, for example, is a low-priority comment. It says that I should complete the readme. Whoops. We've all been there, right? We left the to-do to revisit this later, and we forget about it, and it can lead to a dirty code base. And so Gemini has this covered here to remind us that we need to do this. Cool. So let's scroll down. Greta gives us some feedback. Hey, we did something good, right? This is a good step. I'm sure that this value is properly used throughout the application where database access is needed. Great. Great. And so I want to show you how you can interact with Gemini Codesys directly. So I have this block of code here, and it's a big if-al statement. And, you know, I was writing this. I wasn't actually sure, right? What is the best way to write this? So I can select it like so. One more line. And I can type slash Gemini. I wrote this as in if-else block, but is there a more idiomatic go-way of writing this? Click add single comment, and we'll refresh in a second to see the response. But this is amazing, right? I can interact with Gemini directly in the comments. Instead of having to copy-paste code into the Gemini app to ask these questions, I can ask directly here in these comments to get that feedback in the context of this pull request. And so I'll click refresh to see that response. And voila, look at this. Yes, a switch statement would be more idiomatic and readable in Go for this type of comparison. And so not only does it give that feedback, but look at this. It gave an actual block of code that I can commit directly with that switch statement. And so that's amazing because, you know, that would save me a lot of time to have to go back to the IDE to write this myself. And let's not stop there, right? Let's just say we're curious. What is the best practice, right, for using a switch statement versus if-else? So let's ask again. Slash Gemini. What is a good rule of thumb in deciding whether to use an if-else statement versus a case or a switch statement? Click add single comment. And once again, I can learn here, right? I can actually see, you know, a really insightful answer from Gemini without having to go elsewhere. And so this is great because I'm learning, right? And as software developers, it's always a really important aspect of our job. So let's click refresh. And look at that. Almost instantly, right? We get this feedback. And it says, a good rule of thumb is to use if-else statements when you have a series of Boolean conditions that are not directly related or you need to evaluate different expressions in each condition. Great. I just learned something. Awesome. Now I can do my job better. That's amazing. All right. So this is the code review. Really cool. I can iterate quickly, right? And all of these issues can be addressed rapidly. And when I'm ready and I've pushed my updates, I can go down here and type slash Gemini review. And this will create another review based on the latest commits that I've pushed. So that's awesome, right? Because now I can make rapid iterations with Gemini. And then when I'm ready and it's been cleaned up, I can send it to my colleague who can then invest that time to review the code on a much cleaner PR. And so say I'm that colleague and those changes have been made and, you know, you saw the initial summary, but there's been changes, right? And I want to know what are those changes. So I can actually type slash Gemini summary and click comment. And very similarly, we'll see that we'll get a summary with all those latest changes highlighted so that I can get up to speed quickly once again. So really cool. So you see, it's the same structure. We have the overview, we have the highlights and the change log. And then we also have this activity on the bottom. So I know who's commented so far, what feedback's been given, so I don't make redundant comments. So thinking about the reviewer experience again, how many times have people been asked to review a PR, but they don't know the code base that well, right? And I've been in positions where somebody asks me for a PR and say, hey, can you give me a quick stamp? And you say, uh, okay, I assume that they know what they're talking about, right? And you give it a stamp, but it doesn't feel good because obviously that can have dire consequences in who's on the hook, you as the reviewer are. So I want to share with you a little Easter egg that we have. If you type slash Gemini walkthrough and you type comment, Gemini will actually go through your full code base, go through this repository and understand how it works. It starts at the entry points and it goes through to see how the code flows and it will report that back to you so that you can understand and therefore have that, perform that review with confidence, right? That you know what you're doing and you can give it the proper attention. You don't have to bug that senior engineer on your team to spend time with you, you know, to walk you through. You have Gemini here to help with that. And so taking a look at what we have here, you see this extensive walkthrough, right? And so it tells you what's the overall structure, right? Here's the top level directories. Here is the catalog service walkthrough. Here's the key components. Here's the data flow, right? The front end service walkthrough. And so you can really learn a lot here directly, which is fantastic, right? I could do this all on my own and I give a much more competent review instead of just giving that quick stamp. Awesome. And, you know, just to reiterate, this really heavily leverages Gemini's ability to ingest a lot of your code base, right? One to two million tokens that it's scanning through to pull together the most relevant parts of the code to perform whatever tasks that it's doing. Great. And so as Marco's mentioned, this is for GitHub. You can go to the GitHub marketplace and download this today. It's available in public preview, free tier. But we also have GitLab support. In private preview. So if you'd like to sign up, we'll provide a QR code shortly. But you can see here it's the same exact experience. So everything that I just showed you is also available in GitLab. The initial summary, the code review, all of the individual comments, the walkthrough. So no matter where you are, we can meet you there and we can bring the power of Gemini Codisys there. So that said, back to the deck. All right. So with that, thank you. We look forward to using Gemini Codisys. You can use this QR code here to get started. Thank you. And we do have Enterprise coming soon, so please do fill out this form and we'd love to reach out when it's available. Thanks. Thank you. Please. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you.