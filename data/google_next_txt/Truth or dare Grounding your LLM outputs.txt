 GREG BROSMANNICKI- Hey, everyone. This is Truth or Dare, grounding your LLM outputs. I'm Greg Brosman. I'm an outbound PM on the Google Cloud team. So why grounding? Grounding connects a model to additional sources of information needed to deliver accurate, fresh responses to your users. Grounding is a powerful tool to mitigate the risk of hallucinations, provide up-to-date content, and leverage the power of an enterprise's own data. And we can think about a few different buckets of data that we can ground our models in. Let's start with your private enterprise data, which is a key way for enterprises to differentiate themselves. Taking a look at an example query, if your enterprise user asks a question specific to that company's own policies, an ungrounded model won't be able to answer it correctly, as a model doesn't have access to the right information. But a grounded response will be able to retrieve the right information for the model to base its answer on. Retrieval augmented generation, or RAG, is the common method of doing this. And at a high level, it consists of a few steps that index an enterprise's data to make it searchable, a retrieval step that collects information relevant to a user's query, and a generation step, where the model leverages that context. Search is actually a key part of RAG. It's where we connect a user's query with the most relevant information. And at Google, we're pretty familiar with search. Vertex offers multiple ways of doing RAG on your enterprise data to meet your use case and requirements. Vertex AI Search is our out of the box solution that makes it easy to deploy and manage a high quality RAG solution. RAG Engine offers an easy to get started solution for developers that makes it fast to experiment and start building. And finally, our search platform offers state-of-the-art components for developers who want to fully customize their own RAG solution. Now, let's consider another major type of information we want to connect to models, real-time world information, providing up-to-date answers about events and places around us. As an example, if you ask an ungrounded model about recent events, you won't get a helpful answer. In contrast, a model grounded in real-time world information can tell you about the latest sports, music, and events. Grounding with Google Search leverages the power of Google Search to provide relevant, up-to-date information about the world to the model. And now, with grounding with enterprise web search, highly regulated industries can leverage trusted public web content for their grounding solutions. We're also excited to announce the experimental launch of grounding with Google Maps, which is expanding the breadth of fresh content that we can bring to Gemini. With the power of Google Maps, users can get access to local, fresh places information to help them discover new places to eat, neighborhoods to live in, and much more. Finally, let's consider connecting models to third-party sources of data. As an example, if you want to understand specific trends in finance, adding expert information from a trusted source can provide a richer, more helpful experience. We're continuing to make it easier to leverage those third-party data sources and have partnered with well-known data providers across industries. We know that knowledge workers often rely on third-party data for their day-to-day work. And so with this combination of grounding sources, we have a powerful solution combining a company's own data, the web, and specialized third-party data sets to cover these enterprise use cases. Now let's take a look at a demo. Here we've got an example of a grounding integration, in this case using a healthcare insurance agent. I'll start by sending a query to the agent, let's say, about a specific healthcare concern. In this case, we'll call it my daughter, Emma. With this query, it's first going to invoke the authentication subagent. It'll request my phone number, and I'll provide it. It'll use this phone number to authenticate, and soon enough, it'll be able to retrieve my relevant policy details. Now that I'm authenticated, I'm prompted to ask for something specific. In this case, I'll ask it my insurance question. Here I want to know who are the best allergists in Sunnyvale, California. It'll execute Google Maps grounding and begin to retrieve this information, again, leveraging Google Maps. Here I can actually dive in and start exploring the Google Maps widget, which provides a list of results, locations, phone, and even address. With that done, I can also ask questions about my insurance policy, executing vertex search-based grounding to answer my questions based on my policy docs and retrieve the exact chunk it gets my answer from. Here you can see the steps it's taking, the sources it's pulling, and how it's generating an answer. Here's the specific search query it ran. And that's it. Thanks for joining for this discussion of grounding across data sources to deliver fresh, accurate answers.