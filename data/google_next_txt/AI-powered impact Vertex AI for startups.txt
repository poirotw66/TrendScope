 Well, thank you everyone. Welcome. How's everybody doing? Are we in that moment before or actually after launch now and we're like, okay, we launched. Now we see it and we're going to relax. We're going to try to keep the energy up, guys. So this is a great session. So first of all, welcome to Next. Hope you're having a great time here. My name is Ileana Quiñones and I lead the customer engineering team for North America startups at Google Cloud. So we have a startup hub downstairs in the expo floor. If you have any questions about the startups, please come talk to us and meet us there. We'll be thrilled to have you there. But today, this session and these amazing founders are going to help us understand some very specific applications, use cases, and innovation that they are building using Vertex AI. So for those of you in the audience that know the product or are interested in learning more about the product, this is a great session for you. We're going to have strategies, lessons learned, and some specific capabilities that these founders have used. So with that said, let me set the stage and welcome our founders. So I'm very happy and very grateful that you are all here. I'm going to start with Tete, Tete Xiao. He is the CEO and founder of a company called Prompt AI, and they provide a visual intelligence platform. So Tete has been in this space for many, many years, and what they do is take all information that they capture through visual devices and then act upon them and the information that they can gather. So thank you, Tete, for being here with us today. Thanks for having me here. Of course. And then Achil Gupta, and I should say, Achil, welcome and thank you so much for such a big flight. He comes from India, so great founder from India, market-leading application there. His company is called NoBroker.com, and what they do is they disrupt the real estate industry, basically providing a way to think about removing the middleman from the real estate transactions and do automated property matching and detect fraud as well. So we'll hear more about that in a second. Thank you so much for making the trip and being here today. Wonderful being here. Thank you. Thank you. And then, last but not least, so hi, Ahmed. Welcome here. CEO and founder as well of a company called Resemble AI. So many of you may be familiar with them. They do fantastic innovation in generating voices and automating voices with different models. So think about all the fantastic spaces about cloning your voice. Anyone have tried that? Well, please, do come to this company. Congratulations also on your launch of Rapid Voice Cloning 2.0 just in February, I think, of this year. Yeah. Thank you. Appreciate it. Happy to be here. Great. Thank you so much. Well, with that said, let's deep dive on these things. So why don't we start with you, Suheide, on that one. So I think a lot of people in the audience may be thinking, okay, you're in a different industry, it's all of you. So what dropped your decision to use, for instance, Vertex AI to build your applications, to build your solutions? Because I'm sure there were things that were out there that you were looking at. So what dropped your decision to use Vertex? So we started Resemble five and a half years ago at this point. So five and a half years ago, there weren't many things actually out there. So actually, Vertex didn't exist at all at that point. But we were developing our own models for generating voices. And we tried a lot of things to really get scale in terms of the number of amount of compute we need. Because we had this interesting problem where every customer, every user would come in, and they would be building their own voice model. Right. So we had this weird, like, one user has many model relationship. And what we really needed to do is find a way to scale up compute really quickly. You know, we tried other services as well for this solution. But what we landed on at that time was ML Engine, what was called ML Engine at that time, which is now called Vertex AI. But effectively, we found it to be super scalable in terms of us having the ability to train models very quickly. And there were layers that we actually ended up building on top of, at that time, ML Engine, which is now Vertex, which are now just incorporated right into Vertex. So, you know, we've kind of seen the evolution, the growth of the product. And obviously, compute has become a huge concern. Scalability and availability of the compute has become a concern as well. So for us, just having that compute available and having horizontal scalability for training purposes is what really got us into the product in the first place. That is great to hear. And I know scalability is a big thing just across the board for all the founders here. So let me ask Ahil or Tete, do you find that being a similar point of decision point for you to use Vertex AI? Yes, that's one of the considerations which has really helped even no broker and the converse in what the product, what we have, because it makes it easier. Earlier, if you go back five, ten years back, and we are an 11-year-old company, so he says that he didn't know about Vertex five and a half years back. Eleven years back, there was nothing. So if you had to do something in terms of whether you want to leverage AI, ML to build models or create something, it used to take a lot of time. And that time has drastically come down. It's like you can now do it in a few minutes to a few hours. And there are a lot of foundation models, a lot of models which are available with Vertex, which can easily, seamlessly do the basic tasks for you. So that has definitely improved. And that's a great point, right? Because we have scalability and we have different models as well that you're coming into the picture and then you can decide among them. So that's great. And Tete, do you have a similar experience too on the models or the scalability side? Absolutely. I mean, we are in the visual, physical AI space. So in there, like, there's no, like, uniform model like, you know, Gemini for voice or for text, for example. So we have to train and deploy a lot of different models for different purposes. And I think that's why Vertex AI is really, really helpful because, you know, every couple of weeks we might have to address, you know, a new application, a new use case that might mean, like, we have to tweak the existing models or, you know, train a new one just specifically for that. So we find Vertex AI to be really, really useful for scalability. Nice. So I love this fact and I love the fact that all these are good points for us to know about Vertex AI. Let me try to see also the other side, for instance, when you weren't going through your journeys on Vertex and learning what you could do, going from, like, nothing before to this to ML and then Vertex AI, any specific lessons learned that yourself or your teams actually went through that may have been a little bit hard at the beginning, that were much easier, or just things that were pivotal moments in that journey? No. Sure. Yeah. So basically, if you see No Brokers, we are a world's largest broker-free real estate platform. So we save close to a billion dollar of brokerage in India every year, and it's been 11 years. So we close more than 70,000, 80,000 properties every month. So I am talking about 2,000 properties being closed on the platform, or 200, 300 properties being closed as we speak. So now that needs a lot of smartness onto the platform, and we don't have any field force on the ground. So identifying brokers. So that happens basis, and brokers are called agents here or the property consultants. So there's a very, very different phenomena with which these people behave and they work, identifying their insights, their signals, to when people are uploading pictures. So what we do, we tell owners, okay, you please upload your pictures via WhatsApp. And when somebody sends you the photograph for silly reason, they'll just select 10, 15 photographs together, and one of the photograph can be a good morning or a happy birthday image. And you really don't want those images to be available on your platform, correct? So there has to be a scrutiny which happens. So I am talking about 16, 17. We had built and model with Google, and that time, obviously, Vertex was not there with the object identification where we started identifying what all objects are there in the images. With that, we used to classify whether this image is for a house, dining hall, kitchen, bedroom, and then we used to accept or reject the images. So multiple use cases. And to do this particular use case, it took us a few months at that point of time. And rebuilding the model, training it, tuning it, and there was no AI. It was machine learning at that point of time. The beauty about our industry is that with every two years or three years, you will have a new buzzword and people start using that particular thing. But we were building machine learning models. But now with Gemini and with Vertex, the models which are available, that thing has become so seamless for us. We had built our own model. We had deployed it. We were incurring a cost on that particular thing. Now it's a SaaS model. We just pass on the image, and we ask the model whether this is an image of a property or not. And not only it tells me whether the image of the property can also beautify the image and give it back to me. So those are the seamless things which have definitely helped us with Vertex AI. Me too. I think the lessons that we've learned over time for Vertex have been how well it fits into the other ecosystem of solutions that exist on Google Cloud. So I think Vertex itself has broadened quite significantly over time. Obviously, we were using trained models initially. So being able to train a model, evaluate the model on how successful it is. If it's like, for example, like you mentioned, for object detection, if you were training models right now, having the ability to evaluate and figure out how accurate your model is. And combining with other tools to kind of make that work, whether they're Google-related or whether they're not. Like, you know, we use a product called Weights and Biases to kind of make sure that the product that we're or the model that we're creating is, you know, evaluating correctly. It's actually performing correctly. There's no regressions. But also in terms of, like, you know, we have this continuous stream of foundation models that we're creating. And then being able to scale on Vertex AI from there has been phenomenal. And in terms of data storage, you have, you know, a bunch array of options. Anything from, like, HyperDisk to just plain Google Cloud Storage. And how that all kind of integrates together into this one product where I think a lot of the development team is very happy to kind of work with a bunch of Google tools. But everything kind of exists in one product or another. Which is actually a great thing, I guess, for the audience to know, right? So part of the power of Vertex AI is that integration, integrated vertical stack and solutioning for you to make it easier for your teams and your developers to actually go from prototyping, experimentation on new things, and then actually deploy into production for your customers. So Tete, how has these particular functionalities from Vertex helped in your case, right? Using the models that are provided, using the APIs, using all the integration capabilities? Absolutely. So Prompt AI is still in its early days. We've been operating for about 18 months. And that's kind of an interesting experience. So I want to share that from that perspective. So when you're an early stage company, many times you have to do a lot of trials and errors and iterating a lot through these use cases and processes. So, and I was at my PhD at UC Berkeley before, and that was very different from doing academic research where you want to get everything right. And many times in startup, you really need to get a direction right first, do these iterations, and try to be as efficient and fast as possible. So sometimes we make engineering compromise, and sometimes we look for off-the-shelf solutions first before we decide to delve into that. And I think Vertex AI has been tremendously helpful in that sense because, you know, we can put together a solution very quickly. And this was not unimaginable a couple years back then. And now we can just put them together and be very fast in, like, actually go to the market and deploy it to either a group of test users or our entire user base and sort of iterate from there. And if we realize, okay, we've got to do model training, we'll do that afterwards. But then we can still deploy them on Vertex AI, for example. And Gemini, for example, has been really, really transformative. Because now it's sort of you have this general, almost like a computer, where, like, it understands instructions, it understands natural languages. So we are able to build very high-level applications very quickly using these APIs. Which is great. And I think you all pointed out to one thing, which is your teams like Vertex. They like developing with the platform. Let's get a little more specific on that. So how long, if you can give us a sense, right, for the audience especially, does it take your teams to go from, let's say, an experimentation phase or, like, a trial phase for new parts of your product, your solutions, to then having the model trained and everything ready to go and then deploying? So can you give us a sense of, like, what that journey looks like? How long does it take? Oh, I can share, actually, an interesting story. So we were building up this pet feature. So it's, you know, visual AI helps you with anything. Kids, pets, of course. So we were... I'd love to see my dog. Absolutely. Yeah, we've got to recognize them. I understand, like, this is your dog. This is your neighbor's dog. And if your dog is doing anything, any sort of anything it's not supposed to do, right? Or anything just that's interesting and fun. So we were sort of, like, you know, implementing this feature. And our design product officer, he moved pretty fast. But he was taking his time. He was like, oh, the engineering team was going to, you know, take a while to implement this thing, especially, you know, we're implementing this as a full-scale feature that's going to be pushed out to everybody. And he estimated it was going to take us six weeks to get it done. And we got it done within three. Three weeks. Three weeks. Oh. So that's 50% kind of the original time frame that you guys expected. Absolutely. And he usually, you know, says, like, I tend to bend space time in a company. Because whenever they say it's going to take eight weeks, I'm like, how about four? Let's work it out. How about four? And this time, it was genuinely surprising. Like, we got it done within such a short period of time. That is pretty amazing. So it's great productivity gains for you as your development team. Absolutely. And meet this deadline. So that's fine. You just need to be careful, right? Next time, he will tell you two weeks expecting it to be ready one week. I'm always greedy. There you go. All right. So, well, actually, Ahil and Soheib, any similar experiences? Hopefully. Yeah, I can go first. So we have a model that we deployed into production that can detect deep fakes. So it can detect images, audio, and video if they're AI-generated or not. Whether that's from Google, OpenAI. It doesn't matter who's producing this. If it's open source models, et cetera. A key part of that is actually, like, a curation of synthetic data. So we actually use – we're continuously, like, upgrading these models. And this is almost an automated functionality now. So the idea is that we have this crawler that goes out and that is observing different GitHub repositories and a hugging face, et cetera, and trying to figure out if there are new commits or new models that are being published. It scrapes data, puts them into a cloud storage bucket, puts them into an Excel sheet or Google sheet at this point. This is probably the most un-technical part of this entire process. We'll remove that except for the recording. And effectively what ends up happening is as soon as some QA person says, like, oh, this is actually valid. Here's a data set or here's a model that our model has not seen before. And the regression test shows that the current model has low coverage of this. It will immediately trigger a model training on Vertex to a training platform, a custom job. That's what they call it. And effectively train a model immediately to get that coverage. So, for example, in the last week or so, there have been – week and a half. There have been three models that have come out. Like, Gemini 2.5 now supports image generation. OpenAI supports image generation through ChatGPT. And MidJourney came out with V7. And all of those models, even though MidJourney came out on Monday or Tuesday, if you go upload a picture from that product today, it'll tell you that's fake. And the reason for that is because it quickly gathers data, does a regression test, and then immediately kind of fires off a custom training job to kind of train that model and get that coverage. So it's kind of built in a way that kind of puts all the pieces together. Well, it's saving you but also saving all your users a lot of time, right? Yeah. Yeah. Yeah. The users expect, like, you know, if there's a new model that comes out, an image generator, video, et cetera, our users expect coverage almost immediately, right? Otherwise, if you have, like, a firewall or a spam filter that can only catch spam, like, a month ago, then it's not very useful because your attacks are enhancing almost every day or every week. Yeah, true. So we help people find houses or buy houses. We work in the all facades of the property, which is like you may want to get moving services. You may want to get your rental agreements, sale deed, property deeds. You want your house cleaned. You want your house painting done. And if you see all these services, they have a touchpoint. and they need somebody to go visit your house, maybe to see how much of the area has to be painted so that I can give you the quotation for that particular thing. When you are moving, how much is the coat? How big is your house? Because typically, and I'm sure this happens across the globe, whenever somebody asks you how much stuff you have to move, you will always say, I have little. But when the truck comes, which is supposed to take the luggage and with the people who are married, you will suddenly find so many lofts which have sudden stuff coming out and typically it overflows. So for that, we used Gemini and some beautiful applications what we have done. Now what we tell our customers is that take the Nobroker app and if you are moving, just roam around the house with the video on. And when you are roaming around, just open your wardrobes. If you have the beds which has the storage, just show us how much of the stuff is there. Let us know if that fridge has to be moved, the sofa has to be moved, TV has to be moved. And then we calculate what is the cubic capacity, what is needed to move this particular house and what will be the cost of moving that particular house. Imagine earlier, we were doing a guesstimate, which 60% of the time was not working well because of the hidden stuff which is there in form of toys of your kids or maybe the old clothes what you have. All those things we are able to do now. So that's one and this is phenomenal. Then second one is when you do your lease agreements again. Typically in India, it happens after 11, 12 months. You had to ask all the details on the form. Now what we do, we just tell them whatever lease agreement you have in whatever format, whatever language it has been written, just upload it. We just scrape it, we use OCR, we get all the details, and we ask three, four information like what's a new rent, what's a new deposit. Just fill in those details, click confirm, boom, your rental agreement is ready. So all those things which were taking like days and which was earlier needed, human intervention to do this stuff, all of it we are able to do with A&O. Which is great. So not just eliminating the middleman, but all those potential services of someone going to check on what's the space required and the service and how much we're going to cost and all that. So that's pretty impressive. Thank you, Agil, for sharing that. And actually, I could use some of those services too. Not in the U.S. yet. Not yet. Not yet. All right. So now let's think about you've been working obviously with Vertex already for a while. And the product has evolved, right? It was non-existent, then it was ML, then it's Vertex AI today. And there have been a lot of announcements. At Next this week, right about Vertex. And some of them are related to agents and agent building, and some of them are related to new models. So what I would like to take the conversation now is how are you looking at the future for your companies and how some of these announcements, some of these new developments, advancements, actually can help you power that next layer of innovation that you are thinking about for your companies. So if you can let us know a little bit about that, and that will give us a glimpse also of where your industries are going too. Teddy? Yeah, I can go first. So imagine the future where these spaces are watched by AI so that we don't have to spend hours watching these videos. And also this information coming back to a centralized place, and we're just able to ask questions about what had happened and the insights of what had happened. And that means, for example, well, that means the first step is to understand environment, like visual understanding. And after that, it has to be agentic because it needs to connect the things that have happened to intentions, to what we as operators or users, homeowners, business owners, what they'd like to see. And these things are all different. Sometimes they're personal. What I want for my home might be very different from what you want for your home. And a retail shop owner, what they are trying to get might be very different from a hotel owner, for example. And these models will have to, and systems, I would say, have to be able to understand intentions and work in a way that different people might want very differently. And I think, for example, Vertex AI can be a very important role in that. For example, reasoning capacity for these models. And now they have to think and step by step laying out what they have to do. And now they have to go to the prospective parts of the system, whether it's storage, they might have to check some data in their storage, or they might have to go into the database and come up with a SQL query, some keyword to search for some information. And on top of it, they need to synthesize this information and then decide what to do next. Or stop and present that information to people. And sometimes it's even a voice interface. So we're really getting into the stage where computers are getting really sophisticated. And also, like, we just have AI to automate a bunch of other boring tasks, or sometimes it's just very heavy for human beings to do. Yeah, and I love the fact that you mentioned. I think all these things that you mentioned started with saying it's agentic, right? It's a lot of these process flows that are going to be built on top of that. And Vertex can give you capabilities, right? Agent SDK and the agent builder and all those parts of the product. So how is that helping you or potentially helping you? And let me go with Akhil or Zaheem. So how are you planning on using those? Are you already in that journey of the agent building? How agentic those solutions will be for you? Any specific things that you can share with us? So at the scale of no broker, where we have, like, close to 5,000 employees working for us, and most of them, a big chunk of them, or a majority of them, work in our customer service department, where they have to touch base with the customer, answer their queries, understand what they need. Like, I was talking about packers and movers. I was talking about cleaning, painting, and all those things. So then, but for a customer-facing company, the SOP is that you should have a consistent, great quality service, which is unbiased by the mood of your agent, correct? It should not happen that I had a fight with my wife tonight, or early in the morning, and I'm disgruntled on my customer, and I'm not happy to help that particular customer. And that had always been in my mind that as we grow big, how are we going to solve that particular thing? So we started building models very early. So now what we do, we have built a platform called ConverseIn.ai, which is like Zen out of customer conversations. Customers can be conversing with you on a chat, chatbot, emails, SMS, WhatsApp, and on your call center. We take all those conversations. And India, the beauty is we talk in multiple languages. So we have like 14, 15 languages which are actively used. Otherwise, we have hundreds of languages. And people switch languages. So they'll be speaking in English, and suddenly Hindi me baat ka nileng. That's what I did. And it comes very, very naturally to us. So none of the models were able to solve that particular problem. So we created our own STT models. And now once we had that particular thing, we were able to create agents like Agent Assist, where there is a virtual agent who is sitting on top of our platform. And one of my call center executive, when he or she is talking to the customers, it can tell you what exactly is the history of that customer. That, okay, Eliana, she came to NoBroker platform three months back. This is what she had. Or maybe she has an active service going on. She had sent you an email. She is not happy about something which is going on. This is what you need to tell. So basically, the things like, okay, sir, can I put you on hold? And then I'm going back. I'm going to search with my manager. All those things immediately goes off. Now when you talk to the customer, you say, okay, hi, Eliana, this is what is happening. I see that you have a packer remover movement, and our partner has not reached. I have already put a touch with my partner, and he or she may be reaching in another 30 minutes. So that levels of your experience to a different level. Then after we did that, we realized that there are a lot of tasks which don't even need human. Because I feel as a human, we should do something which is non-mundane. We should be thinking. We should be creating new stuff. We should be doing something smart. So then we created our own virtual agents. You can say humanoids, which can talk in Indian languages. And that's what I was talking about. So it can make a call to you. It will feel as if a human is speaking to you. And if, let's say, you have a property visit schedule, it will just call you and say, hi, I see you have a property visit schedule. And are you coming or not? And then somebody says, oh, no, I see there is a traffic. Oh, I also see that there is a traffic. Okay, so that means that you will be delayed by 45 minutes. That is what Google Map is showing. Let me just reschedule the appointment for you. And I'll also inform the person on the field who was supposed to be with you on that particular visit. So things like that, we have started automating. And that's where the agentic theme has started coming into our platform. And because it was so beautiful, we have started selling it out as a product to other companies also. There you go. So another business revenue stream there. So that's good. Congratulations on that, Ahil. And thank you for sharing it. So what I'm hearing also is that it's not just the internal experience that gets better with all these new advancements, but it's also the experience for your customers, of course, right? So not just for the internal developers that are using the platform, but also the end result. So no company can be successful until your customer is happy. Absolutely. And I love hearing that it's actually good for you to use our technology on both sides. So thank you for that. But so, hey, so let me ask you, because in your space specifically, right, there's a lot of innovation going on with models out there from you, from other companies. There's a lot of competition. There's a lot of innovation that we're bringing to the table. So how are you navigating through that, and how do you see really the future for Resemble.ai is going to look like with your technology, with the help of Google, but also with things that are going on out there that are coming out? Yeah. So I'll answer this in two ways. So we're kind of lucky that we develop models, and our customers go use those models and applications. So we have a lot of insight and oversight as to what applications are very useful and where they're creating an impact. All right. So we see everything from, like, call automation, and I think these two gentlemen have talked a lot about different automations, different agents that are really applicable. And everyone here is probably tired of hearing voice AI for the last two days. So one of the things that's probably the most impactful in Resemble, and, you know, I've actually, like, worked with a circle of other founders to kind of implement this inside of companies, and we're really bullish on this, actually, is I'm a firm believer that every company should have one dedicated person, ideally a team, but if you're a startup, one dedicated person, in just exploring different agents and how they could be applicable as employees in your company. And that has, like, tremendous benefits to the company, and it's now way easier than ever, right? So you can actually get employees that could do programming. You know, there are literally software out there. If you want to get something off the shelf, there's Devin. You know, there's plenty of others. There's customer success products out there. But the real power here is every company, like every human, is also slightly different from one another. But the building blocks of, you know, using Gemini, using OpenAI, using different models to achieve different tasks is a matter of plumbing work together, and then the core really becomes how it works in your workflow, right? So a lot of us, and I'm really bullish on this, is the most valuable AI company, the most valuable agent AI company is probably Slack right now. And the reason is because every AI, like, agent that your company will interact with, it's like an employee within Slack. So why would that be any different? So having these agents being deployable, it's like having staff that has 10-second SLAs. No human staff member can give you a 10-second SLA. But an AI agent can. And there's a lot of great stuff happening within these companies, including Resemble. You know, we're deploying bots that are effectively helping customer success, internal, external. There's different ones. We're hooking them up to different products. We have a bot that typically sits on our document page, which helps people make integrations. Because at a certain point, we're not going to write and maintain SDKs for every single language. It's too much work for us. But what we can do is we can effectively have a, you know, a chat bot that's geared, solely geared to understand our SDK and our documentation. And then the user can go in and say, oh, I need to plug this into Genesis, or I need to plug this into Unity. How do I do that? Right? And, of course, we're not going to write a guide for every single integration, but this thing can. This thing can do it on the spot, on the fly. So creating these, like, agents, particularly internally, which is kind of where I have the focus right now, is it can pay a lot of dividends, and it helps your company learn extremely quickly. So I'm not sure what the audience makeup is. If you own companies, you'll probably be doing this. If you don't, then you should probably go to your boss or manager and say, like, there should be a team or a group of people dedicated to just experimenting with agents, just internally making those workflows better. I love that idea. And let's actually quiz the audience. So just by show of hands, how many of you are maybe already doing that, creating agents internally, going to your managers and saying, hey, we need to do this for some of those employee tasks and functions that are very repetitive or that are intelligent but could be better done with AI right now? Show of hands? Are you on? We're, like, 30% of the room? Yeah. 40? Yeah. Just about. It's a while to go. It's a while to go. Yeah, exactly. But we're just starting in that journey, so I think it's coming. It's coming, actually. Yeah. All right. That sounds great, and thank you for sharing that. All right. So since we have also, of course, founders in the room, one of the things that I'm sure they are probably thinking about also is with your companies, you are in different stages, right? So Tetes' companies earlier on, you guys have been for a few years already. So what's next for your company? What are you excited about for your company for your next milestone? Let me go first. So if you talk about NoBroker, we are an 11-year-old company, the only PropTech unicorn in India. But at this stage also, we are just present in six cities in India. So we have a lot and a lot of ground to cover. And with AI and with kind of automations, what we are able to do at the rate at which technology is changing, I think companies will become global. So it will be the solutions which you'll be able to create from one country and it will work across the globe. And that is something which people keep asking me that when exactly are you going to come to different countries? Because in US also, you see that the amount of interpretation cost is extremely high and with a lot of things happening on the law side. So there's opportunity for us there also. But right now, we are focusing on India, a very big opportunity. With NoBroker, NoBroker services, what we have, and the ConvoZen, which is our customer intelligence AI product, what we have built. So we'll focus on that. Great. So hopefully, we'll see you soon too in the US. And then we'll be happy to move you. There you go. All right. Thank you. Tete, what's next for you? Absolutely. So Prompt.ai was founded by a group of PhD students and professor from Berkeley. So all of us have been working on ComperVision for myself. Personally, it's been a decade. And for one of my colleagues, he's been working on it for more than three decades since early days like when he was at MIT. So we just had this frustration back in the days of like, well, we've been developing so many different algorithms and research works and how come these cameras are still dumb cameras? Like how come they are just recording and I have to go back to it and I have to use a tiny little slider and to look for what I'm trying to get and they can't really talk to each other. They can't not really, they don't really understand any sort of information. And how come that we've been doing so many years, so many years of work in ComperVision and they still can't tell you whether your cat has jumped onto the couch or not? It's not supposed to be that hard. Okay. So that's why we started. And now we're getting closer and closer. I think we're at the down of visual, physical AI. I mean, like you heard the word physical AI all the time, right? Robots and drones and autonomous agents everywhere. But then you think about it, like who's going to watch them, right? And you've got to deploy these cameras everywhere and so that you make sure that they're not functioning or doing bad things. And I think our goal is to sort of have computer to be able to do anything that only requires a pair of eyes. If we just need a human being to sit there and watch, please do that with a computer. Because, you know, we humans can do much more interesting things. Yep. And we can spend our time more efficiently. We can spend our time with family, with friends, and focus on the work that actually requires our attention rather than just like these tiny little things. So that's why I'm really excited about the future. I think these technologies can transform how people interact with the home, with their pets, and their environment. Also, like how businesses function. It's going to make us more secure, feel more safe, and more connected. Great. Thank you. And I guess what I'm hearing from you also is that there's, of course, software solutions that you provide today, and maybe the hardware pieces are coming up at some point, too. Yeah, absolutely. And I think a lot of these hardwares have been really commoditized. Like 20 years ago, I remember like a camera, a nice camera would cost at least hundreds of dollars, if not like thousands of dollars. And now they cost 20 bucks. You can buy them from like anywhere almost. And it's not hard to manufacture. And so the reason that many people are still not buying them is that they really don't find the use case for that. It's like buy a camera, put it there, so I forget about it, and I pay like cloud storage for that. And now finally, people are able to get some usage out of it. And I think it's just going to drive this very positive cycle where people keep buying more cameras, and as a result, we discover more use cases. We try to automate them, and they become happier and buy more cameras. That's true. And at that point, they will need your visual intelligence platform too. Absolutely. Which is great. All right, thank you for that. So let me close this section with you in terms of what's next for the company, and what are you excited about? Yeah, there's a lot to be excited about. Just to give you context, four years ago now, 2021. We're in 2025? Yeah, it was four years ago. Yeah, time is a blur. Four years ago, one of the things that we, one of our customers actually published a show on Netflix called the Andy Warhol Diaries. The entire narration in the Andy Warhol Diaries, Andy Warhol, of course, passed away in the 70s or early 80s. And every narration from him in that documentary was completely AI generated. I call this the pre-ChatGPT era. And that gave us an idea of mainstream use of generative AI. That was nominated for four Emmys, that show, or that documentary series. And that got us thinking, or got me thinking a lot about, okay, this piece of technology that, you know, in 2021, four years ago, is able to reproduce something that a normal consumer that's watching TV cannot tell if it's AI or not anymore. And if you fast forward today, you have this in pretty much all the modalities. You can go and obviously create gorgeous videos with OpenAI or Google, with VO2 now, et cetera. But you can also go on open source and do them. And I don't think open source is slowing down. I think open source is keeping ahead with the pace of where the frontier models are. So the thought really comes in when we're creating these platforms, especially as Resemble is creating these models and allowing, you know, millions of users to use and create models themselves, is how do we do it in a safe manner? How do we get people to not be able to scrape a video off of YouTube of Akhil and effectively just, you know, clone his voice, take his face, create a version of him, you know, and that could be extremely dangerous. Nobody will do that. Somebody might do that. You know, we've had people on YouTube that have said, like, I found my voice being used by a different channel. We've had people, you know, complain about, I never was on this ad. I never promoted this, et cetera. You have politicians, obviously. And the thing that we are really bullish on now and that we really want to have impact on, to be honest, we hope that the company plays some part in this, is the deployment of responsible and safe AI. And those are not just meant by guardrails, but, you know, I'm in the Bay Area, Tete's in the Bay Area. The way we think in the Bay Area, to be honest, is technology is the answer to problems as well, right? Technology can be solved by technology and not necessarily policies, right? And so we've been, you know, building models around watermarking. We've been building models around detecting defects. We open source models around, like, speaker identification and person identification. But all of those are kind of coming together and we're trying to really wrangle around this foreseeable problem where, you know, early in January this year, 55% of the internet, according to a lot of researchers, was being created with generative AI, right? And the projection was by the end of 2026 that 90% of it would be created by generative AI. I think by the end of 2025, with the image and video models that are coming out that are widely accessible on your phones at this point, 90% is a pretty conservative amount or percentage of generative AI being used in content being produced. So that really opens the door for malicious users on the other end that can also use that content. And what we want to do is actually give tools and give models to people and companies that are deploying these models to also offer ways to kind of prevent kind of the responsible or encourage the responsible use and prevent malicious use of those models. So I think that's where a lot of my attention and focus is going because I think generative AI is out of the box. These models are going to improve. I have no doubt by the end of the year it'll get faster, better, higher fidelity. That's a given at this point. So the response is, well, what's the counter to what we're about to see here happen in the world? It's true. And I'm so glad that you mentioned that because the general concept really when we think about guardrails is like regulations and policies and what can we do. But you mentioned something very specific which is, well, technology can also regulate technology. So that's an interesting concept and I think a lot of companies are actually looking into that because policies, regulations will not be able to advance as fast as we need them to catch up with what's happening in technology. So that's an interesting concept of what you brought today. So thank you for that. And actually, we're getting close to closing the session so I'm going to say kind of like a rapid fire, one-liner, what would be your advice for founders in the room who would like to use Vertex AI in their solutions today and what advice can you give them? Just one-liner, very quick. Let's start with Tete, please. Yeah. So speed is really important for all these startups. You've got to try your best for that. Thank you. Yeah, I think the same. So basically, the rate at which you can innovate with Vertex and anything else is extremely fast. So things, as I was mentioning, 10 years back, things which were taking months, few years back, which was taking days, now it's taking hours. So if you think about a problem which you want to solve, you should be able to do a POC of that particular thing extremely fast to know whether it's going to work or not. And that can define how fast you want to work on a problem. Thank you for that, I hear. Is that right? Just go to Aistudio.Google.com and click all the buttons. And you'll learn everything really quickly. That's a good one, too. Well, thank you so much for that. I hear that hopefully this session has been useful for you. I have to say thank you to all the founders, obviously, everybody else in the room. And if you are not, this is my commercial, if you are not familiar with our Google for Startup Cloud program, please come talk to us, Startup Hub, in the Expo Hall. And thank you for being here today. Thank you for investing your time with us today. And thank you for evaluating or using our technology already. Thank you. Have a great rest of your day at the place. Thank you. Thank you. Thank you.