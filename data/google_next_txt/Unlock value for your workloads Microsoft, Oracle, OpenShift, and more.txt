 The session is called Unlocking the Value for Your Enterprise Workloads, especially Microsoft, Oracle, OpenShift, and many more enterprise workloads. My name is Venkat Gattamneny, a lead product management in computing. And my team is responsible for many of these enterprise solutions that you guys run on the platform and power your mission-critical workloads on the platform. With me is my team here as well, many of the faces that several of you may have interacted, if not highly encouraged, you know, for a conversation after the session. But the real rock stars of the show are actually Justin and David, our customers, both Blackline and Kinaxis, who will be up here on stage and talking to you about their unique journeys when it comes to bringing their workloads over to our platform, powering them, optimizing them, and then modernizing them. So what I really hope to accomplish in this session is the following. I'll briefly give you an overview of the value that our customers are seeing, that you guys are seeing by powering your workloads on Google Cloud. Some of the ways in which you can take advantages of the features that we have built on the platform. So it is meant to be a bit of an introductory tour for many of the differentiated value that we provide. But also I have some very exciting new product announcements to make, so which is what I will do. The majority of the focus in the session, we will focus on Microsoft workloads. We'll also cover some AI-powered solutions to help you with your modernization efforts. Of course, no show is a good show without AI these days, so I hope you guys are excited about that. And last, but of course not the least, we'll cover a little bit on new announcements that we're making with Oracle workloads being powered on Google Cloud, as well as how you can bring and run your OpenShift workloads onto our platform. Of course, this OpenShift effort has been a great collaboration with Red Hat for a number of years now, and we have a lot of customers running OpenShift on the platform, and there's a lot of goodness that you can get by bringing your OpenShift workloads and running on Google Cloud. So let me actually start with a little bit of a high-level overview of the mission that we are on as a team. We as a team really believe in creating workload-optimized infrastructure and set of services in Google Cloud to power all of these workloads. I mentioned, of course, Microsoft, Oracle, OpenShift. It's just not that, right? There's SAP, there's mainframe, and many, many more what you would consider traditional workloads that you guys have been running on-premises or elsewhere for a very long time, sometimes decades, right? And a lot of the work that you guys are focused on is how do you really take those workloads, run them properly in a cost-optimized fashion on Google Cloud, and then take unique advantage of Google Cloud as you modernize these applications. And that's really, you know, that mission is at our forefront of the team, and we are in the business of creating optimized infrastructure and services in service of that mission. I have one slide on, and this hopefully tees up a little bit of what we are seeing and what you guys are seeing as you bring your enterprise class workloads onto the platform. Oftentimes, and I've talked about two dozen customers in the last two days, these are the three things I keep hearing often in terms of the value that they are seeing on the platform. But fundamentally, at the bottom here, as you see, the infrastructure that Google Cloud provides has really been built using decades of our own experience in terms of our global infrastructure, networking, bringing SRE, Kubernetes, and technologies like these out to the market. And with billions of dollars of investment that we put on this infrastructure, that also powers some of our first-party offers from Alphabet and Google perspective. It is really the same infrastructure and all the goodness that we've built into that infrastructure that powers your workloads. In terms of unique value, though, how this uniquely sort of addresses your workloads and provides you value, there are really three things. Number one is all of this investment allows us to provide a world-class infrastructure optimized for your applications, whether it's reliability or security or performance that you require to power your mission-critical workloads is what this provides for you. In fact, if you look at us versus some of the other hyperscalers, you'll see numbers, our SLAs, the amount of uptime, amount of security, sort of vulnerabilities that we see, which we track. Across all of these vectors, we actually come out ahead of the other hyperscalers. So that's the first pillar, best world-class IaaS to power your workloads. Number two is lower TCO for your workloads. And we have been on a journey for several years now in creating specific features, innovations, to make sure that we provide the lowest TCO to power your workloads. Some examples here are things like custom VMs that our customers will talk about. Licensing-related costs, because everyone knows licensing is an expensive sort of spend item for you, whether it's Oracle license or VMware license or Microsoft license, et cetera, et cetera. So we've been on a journey to optimize your infrastructure in a lot of ways managed for you by Google so that you can drive down your spend when it comes to licenses. And, of course, AI ops. A lot of our ops these days are powered by our own learnings when it comes to ML and AI. And a lot of that is in place when you are bringing your workloads over to our platform. The last thing, and this is something that is new for this next, probably some of it I started to see last year as well. But, boy, the number of customers that we're talking to that are bringing their workloads on to us to take advantage of the AI features that we offer and the AI capabilities that we offer. Among the hyperscalers, we are the only ones who have the full stack. Of course, our own chips in addition to NVIDIA chips. We have our models. And on top of that, we have APIs for you to easily bring your applications and integrate your traditional workloads, by the way, and integrate with AI services so you can take quick advantage of these AI services and build those into your workflows. So that's something very, very sort of like, you know, new that I'm seeing from our customers. And you'll hear some of what our customers are doing as well here in a short bit. So going into a little bit of a deeper dive into Microsoft workloads, let me start by saying that, you know, we for Microsoft workloads have built a robust platform, and I'll cover some of the technical features and services that we offer to power your Windows and SQL workloads. At this time, we have tens of thousands of customers depending on our platform, Google Cloud, to power their Windows and SQL workloads. You'll see big names like Schlumberger, Cardinal Health, Wayfair, of course, CanAxis, BlackLine, and many others who are bringing these workloads. Most of the time, it's in a lift-and-shift fashion initially, and then, of course, they take advantage of additional services that we bring to bear for those applications. Now, if you ask me what are the unique differentiated value propositions that we offer to customers for Windows and SQL workloads, I think it really boils down to these three things that I mentioned already before, you know, falling into the bucket of infrastructure capabilities, lower TCO, and, you know, taking advantage of modernization when it comes to modernizing these applications. A few things, you know, from each of these, if I were to call out that are rock stars from a platform capabilities perspective that if you haven't yet used, I would highly encourage you to start using are custom machine types. Because custom machine types, unique to us, you can configure your CPUs and RAM in a specific way that can help you tailor the underlying infrastructure and the VMs to your specific workloads. And for SQL Server, this is a big win because this allows you to save licensing on SQL, which is a very expensive item for you because every SQL license depends on the number of cores in the VM. And a lot of your SQL workloads are going to be memory-bound. They're not CPU-bound. So you can really customize those CPUs and get the right amount of RAM and power your workloads and save money. Big TCO savings for customers. Another feature we have is SMTO, which allows you to turn off hyper-threading. And each of those cores that you see are going to be a lot more powerful, but you can half your license costs by doing that. Big feature also in use by a lot of our customers. You don't get these, by the way, elsewhere. Only Google Cloud. And last but not the least, a lot of customers, and we'll talk a little bit about what we are doing to power some of these solutions to help you modernize your applications, and I have an awesome demo for you to watch in a little bit. But those are things that we are noticing customers starting to do. You bring your application, for example, a .NET application, and over time you convert into Kubernetes so you can containerize the application, perhaps a .NET core application running on Linux containers into GKE. We're seeing patterns where customers are bringing SQL Server, and they're on their journey to perhaps look at Postgres as an alternative and look at some of our managed services to modernize. And we are developing technologies, products, to ensure that we help you in that transition. And that's the demo I'll show in a little bit. Going forward, in terms of the platform that I talked about briefly earlier, we have a robust platform to power your Microsoft workloads. Of course, like I said before, a lot of managed services for you to leverage as you look at your Windows and SQL services. Some of these are mentioned here. All of these have out-of-the-box support for Windows and SQL and other Microsoft workloads you may run. For example, GKE supports Windows containers if that's the route you want to take. Cloud SQL for SQL uses the same underlying SQL Server bits but provides you a managed database of service. And the list goes on and on and on. One thing I'm very excited to announce is a new service that we have launched called License Manager on the platform that allows you to actually procure some of the licenses that you will need to run some of your workloads like Office, et cetera. And we have a robust roadmap to add more and more Microsoft products to that so you can start to procure those as you need for your workloads. Especially, of course, Office is going to be required for a lot of your VDI workloads. So we're very excited about starting to offer this to you. Under the managed services umbrella, we also have, of course, which majority of you folks are probably using today, are virtual machines, IaaS. We have performance-tuned, fine-tuned Windows images, SQL images that we keep up with all the patching, et cetera, and those are ready to deploy as and when you choose for your infrastructure for your actual workloads. From a pure compute perspective, of course, there's shared infrastructure, GC multi-tenant VMs. I talked about custom VMs and all the families that are tested out of the box, out of gate, as we launch them for Windows versions. But we also have sole-tenant infrastructure. If you have BYOL-eligible licenses for your Windows, of course, you guys know that sole-tenancy is a requirement. So we have two offerings there. One is GCE sole-tenancy, and the second is GCVE, which is our VMware as a service. And GCE sole-tenancy offers, you know, up to 2x over-subscription, which is, again, unique among all hyperscalers, so you can get more mileage out of your licenses as you bring to the platform. And, of course, VMware engine, if you are running VMware on-premises and you want to continue to use that, that's a great solution for you as well. So, again, you know, to sum it up, robust platform for all of your needs when it comes to Windows and SQL workloads. So, of course, bring them over and talk to us about optimizing them. Let me now, you know, do a bit of a detour on SQL Server and some of the unique solutions that we have on the platform and some new announcements that we're making as well. We know that for your Windows workloads, SQL Server tends to be the center point of those workloads. It is the database that many of you sort of rely on and for your majority of your applications. So we've been hard at work to help you on the SQL Server for a while now. Last year, we launched what we call Workload Manager for SQL Server. So if you have SQL Server deployments and you're worried about, boy, is it configured the right way? Am I getting the best TCO? Am I using all the best practices for Google? All of that is automated in the service we call Workload Manager. What this basically does is it allows you to do a best practice check against your SQL Server deployments and you can do this periodically over whatever cadence that you choose. So if there is drift happening in your SQL Server deployments, you will get alerts, right? And then you can, of course, take proactive action to kind of fix those. That's what Workload Manager evaluations does, right? Now, on the right side, this is something new that we are very excited to announce. We're actually making your deployments a lot more easier because if you can cache those errors at the time of deployment, then your life becomes a lot more easier. So what we are launching is a very simple point-and-click wizard. What do you see? What do you get sort of a wizard for deploying, configuring, and deploying your SQL Server deployments on the platform? Of course, it supports both pay-as-you-go, BYOL, if that's what you want to do for your SQL licensing. And from a high-availability perspective, it supports always-on availability groups. If you want FCI, that's also supported all through a simple wizard look and feel so you can get on with deploying your SQL Server workloads with assurance that you're taking all the right steps, right? So it's a guided tour, if you will, for your SQL Server deployments. And by the way, all of this is Terraform-based. It results in a Terraform template. So if you are into Terraform, you can, of course, make those tweaks to your templates right before deployment as well. So going ahead, of course, HA and DR are super important for your SQL Server workloads. And, of course, SQL Server, the two prominent sort of ways to develop or deploy HA is AOAG, as you know, and FCI as well. Those two have been supported on the platform for a long time now, right? But, of course, as you know, AOAG is expensive because you need SQL Enterprise Edition for it. So we see a lot of customers, you know, go to failover clusters, right, FCI, because you can then save on your SQL Server licensing, and you may not need the full-blown capabilities of an AOAG sort of deployment. But, of course, everyone knows doing FCI using, you know, S2D is super complex. You have to manage the storage yourself. You have to configure all the way from setting up your monitoring to resizing disks, et cetera. Super complex. The management does increase, although you do save a lot on your costs, right, about 30% cost between AOAG and FCI. So we've taken this challenge as Google, and we have developed a native solution. Using HyperDisk Multi-Writer for HA, you can actually get rid of all of the complexity of managing your storage yourself and rely on HyperDisk for that. And that's sort of what we are very excited to announce. In fact, Justin, in a short bit, will talk about how they are putting this into action. Same cost, by the way, with FCI, 30%, you know, down from AOAG. But, boy, your management becomes a lot, lot simpler with this setup. On the DR front, we've had for a while our first-party out-of-the-box DR solution, Google Cloud GCBDR, as we call it. This is actually a very, you know, comprehensive suite for BCDR, and SQL Server, of course, is very well supported by this solution. You get centralized management for it. All the monitoring is set up the right way. You get a lot of reporting insights, et cetera, with that solution, and all of your disaster recovery happens for the entire instance, all of your VMs, right, with the knowledge that it's running SQL, by the way. And that's the solution we've had. Now, if you want a cost-effective solution, even more cost-effective, and you don't want a full-blown, you know, backup and recovery solution, we are announcing this new solution called HyperDisk Cross-Region Async Replication. Essentially, what you're doing is you are replicating the disks that hold your database across regions with the solution. It's very straightforward to set up. You can set up a secondary disk in a different region, reference that disk to a primary disk where your database is running, and all of this, you know, copy replication happens asynchronously so that in case, you know, a DR scenario hits you, you can use, of course, the secondary disk to repopulate. Now, for the orchestration piece of it, we actually, optionally, you can add a partner solution. We just announced our partnership with Jetstream in Marketplace. You can attach that solution with Async PD and have a cost-effective way of doing DR for your SQL server as well. So we got a few options for you to choose for when it comes to DR for SQL. Let me now pass it over to Justin, who's going to talk about their unique journey when it comes to powering Windows workloads and SQL workloads, and who also benefited from some of the solutions that I talked about. Justin? Thank you. Well, we have been definitely on a journey with Microsoft Windows on top of GCP. I joined the company a few years ago inheriting our GCP program, coming from a background of 20 years in SaaS operations, really driving our cloud journey, our cloud story, how we want to move to GCP, SQL server optimization, et cetera. I also host a pretty active cloud podcast around the cloud, and definitely check that out. So a little bit about Blackline. We are the leading financial close management platform in the market, powering the transformation for the office of the CFO. We're in over 50% of the Fortune 500 companies, and we're trusted by over 4,400 companies globally to make sure that their financial books are closed on time, compliantly, and securely. And our journey started about five years ago. We were running in primarily co-location facilities in Europe and in the U.S. We needed to move into a more scalable platform. At that time, very focused on Kubernetes, big data through BigQuery, et cetera. And we ultimately picked Google because of the power they had not only in modernizing our future workloads on Kubernetes and containerization, but also the fact that they had the ability to support our Microsoft workloads in a highly reliable and secure way. And we've been in the process of lift and shifting for the last few years. We're finally completing that process. And then we'll be moving into a more heavy refactoring and modernization phase. But we've still been able to take advantage of all of the great technologies from Google to launch our products, new products on top of Kubernetes, on top of big data, and on top of AI now, which is really starting to excite us about what we can do for our customers in the future with things like Agentec AI and our other AI capabilities. As well as we're now expanding into additional regions, including Kingdom of Saudi Arabia is on our radar, Canada, and other parts of Asia. It wasn't always easy, though. We, three years ago, chose always-on availability groups. It was a great technology. It allows you to replicate data. But in our application, we have a large number of schemas. And so we manage over 25,000 schemas in production today. And that resulted in a large sprawl of SQL servers in our environment. So last year, or almost two years ago, I told Google, I need a better solution. So we partnered very closely with the team here. And that's really where a lot of the FCI architecture they just talked about came from. How do we provide more redundancy, more density in our environment and really start driving an optimized cost story? And that's where FCI really drove our story and really allowed us to scale up our workloads to finish our migration this year. We were able to save over 35% by moving to FCI from AOAG. And we'll see an additional savings as we start looking at the multi-rider HA technology that we're currently in POC on right now. We're also in the process of moving into the full GCPDR suite and making advantage effect for all of our DR. So we're able to reduce the number of nodes that we actually have to manage as we now don't have to maintain an AOAG failover node. We're also looking at latest versions of SQL. And we're very closely partnering with the Google team to make sure that we deliver on that part of our story. Our journey's not done. We have a lot of work to do still. We're adopting AI, transforming our AI workloads. We're looking at AI automation to start driving things like moving out-of-store procedures into more Knative patterns into containers and really driving that transition into how do we provide event-driven, AI-driven close for our customers at the end of the day. It's been an exciting journey. We're looking forward to continuing down this path. And we thank the GCP team for that. Thanks so much, Justin, for the awesome partnership we've had for a long time now. All right, so I'm going to shift a little bit of gears now and talk about modernization and innovation and the work that we're doing to help you transition and bring some of the best of what Google has to offer when it comes to your Windows and SQL workloads. Now, the common patterns, like I mentioned before, when we talk about modernization for Windows workloads is the following. Of course, you're running Windows Server VMs, you're running SQL Server databases, et cetera. But the true benefit of coming to cloud is at the end of the day all the way going to managed services and many times that means going to open source as well. Now, of course, as we all know, there are a lot of challenges to modernizing. Many of you have legacy database that's probably written 10, 20 years ago. I often talk to customers who are like, you know, it's not uncommon for some of this .NET code to have been written, you know, even 20, 25 years ago. And since then, of course, the developers may have even left the company, right? So it is a challenge. A lot of it is monolithic applications that were developed back in the day, so decomposing them is not easy as well. And of course, the entire, you know, refactoring exercise that it takes for these applications is also super challenging because you have to, you know, take your code and then rewrite a lot of that code into the new frameworks that Microsoft has like .NET Core or if you are completely going to open source databases to go to Postgres, et cetera, from SQL Server, which tends to be a favorite choice for customers, you know, running SQL Server. So what we have done is we've taken this challenge up as Google and we've put AI to some good use here. And essentially, we have three solutions here right now that we are very excited about announcing to you guys so that you can take them for a spin. The first one is Gemini-powered assessment report. This essentially takes a look at your code base, your .NET code base, and gives you a very good assessment report of what exactly needs to be done in order for you to modernize. You know, it also gives you some strategies on how you can decompose your monolithic applications. Number two is a Gemini-powered agentic .NET modernization solution, which essentially takes your code, gets into your Git repository, and then starts to do the transformation based on the Gemini models that we have. So a lot of this, we're hoping, will reduce the amount of development effort that will be required to refactor your applications. And I have an awesome demo that I'll play that takes you through all of these journeys in a little bit. And of course, the third one is for your databases. If you are wanting to go from SQL Server to Postgres, the solution we have is database migration service again takes a look at your SQL Server and helps you convert those pesky stored procedures that painstakingly have been written for a lot of years, right, in SQL onto Postgres. And it lands you, of course, in Cloud SQL Postgres. That's the journey that these tools and solutions help you do. Right, so enough of talking. I'm going to actually play a demo to show all of this in action. In this demo, we will see how we can modernize Microsoft applications from legacy to open platforms. Let's pick a classic three-tier sales reporting application with web service endpoints using SQL Server backend database. This B2B application is used by sales reps to get historical sales reports. As a first step to better understand your application, we run the code modernization assessment tool. It scans the application code and uses Gemini to generate the assessment report. The report will help make informed decisions on the transformation project. Assessment includes architecture overview, user journeys, technology stack breakdown, API endpoints, and suggested modernization strategies. We will now start by migrating the code from the legacy.net framework to .net. Then we will containerize and run the application in Google Cloud using open platforms. Finally, we will modernize SQL Server database to Cloud SQL for PostgresQL. The application is written in .net framework 4.8. Let me use my Gemini extension to help me modernize my code. I'll select source control and choose Google Cloud modernize. Behind the scenes, it integrates with the remote Git repository and Google Cloud project. The agent has created a pull request for my review. It is like working with another engineer and the final decision of merging is up to me after reviewing it. The agent comes back with a plan on how it's going to tackle the conversion with detailed steps. It describes the options along with pros and cons. In the diff view, I see that the old CS project file format in .net framework has completely changed to the clean .net core format with far fewer lines of code. Now, let's use Gemini Code Assist to manually fix some minor issues to fully migrate the application. Now that we migrated our application code to .net, let's move to the second step to containerize and deploy the application. In Google Cloud, we can use either Google Kubernetes Engine or run it as serverless container on Cloud Run. For this demo, I will choose Cloud Run. Let's use Gemini Code Assist to generate a Docker file to containerize the application. I will now deploy the application to Cloud Run. The final step is to use DMS to modernize the SQL Server database to Cloud SQL for PostgreSQL. Now, let's look at how migrating the SQL Server database to PostgreSQL can be made simpler. There are two significant challenges associated with database modernization projects. One, converting the database schema and resident code. Two, load downtime continuous data migration. The main challenge is converting the database resident code from SQL Server dialect to PostgreSQL dialect. First, DMS uses its specialized deterministic conversion engine which perfectly converts most common code patterns. Then, Gemini is invoked to complete any leftovers as well as assist in post-conversion activities such as code optimization and code commenting. We've just shown you how to transform legacy Microsoft applications to modern architecture using open platforms unlocking scalability, security, and cost-effectiveness. Today, on Google Cloud, let's discuss how we can bring this transformation to your organization. All right. Thank you so much, Gemini. So, hopefully, that was an exciting demo. You know, you guys should, you know, go back and talk to your teams about potentially using this. I have Alex here in the audience from my team who is happy to take questions about, you know, enrolling in this program and, you know, starting to use this technology. Perhaps, you know, grab a chat with him right after this session. So, I'm going to now invite David onto the stage. They've been, you know, he's from Kinexus and they've been on a journey to use some of these AI capabilities and modernize some of their applications. Let's hear it from David. Thank you, Venkat. Okay. Did I take this picture today? I'll let you guess. Consistency is key. One thing that I will say just about Kinexus, about myself, I'm not going to read the slides to you. You can read them yourselves, but essentially, we are a supply chain technology company we work with customers all around the world. We've been in business for 40 years and, you know, we have been modernizing for 40 years. So, whether it was a hardware-based solution, software-based solution and now AI innovative solutions, we're at the front line with our customers. And so, for me, as the VP of cloud services, I run teams that support all of our external customers, all the environments that they run in, all of the environments that our internal customers, our developers, run on. As well as a data analytics team and a cloud platform engineering team that works on features across all of our stacks. So, if you think of it in terms of our customers, Kinexus is a watchtower that lets them engage with all of their supply chain needs, plan their businesses, make sure that they can execute on all of that, and internal to Kinexus, my team is a watchtower where we see all of the data needs, all of the product features coming through, all of the needs of our customers emerging into product features because a lot of time that development comes from our customers' needs, and we can see things coming a little bit further away just like any watchtower. So, our business looks forward to the future to see things coming and plan for them, and my team does that for the business as well. So, similarly to how Justin at Blackline saw, you know, the need for cloud migration, Kinexus saw that as well. We had a couple of issues that came up during the pandemic. You know, everybody recognized supply chain is difficult. The boat in the Suez Canal was terrible news for anyone who ordered exercise equipment, but great PR for Kinexus. Everyone recognized that boats are still, you know, bringing things around the world. But, you know, the difficulties in procuring hardware, getting them into private cloud data centers that we had located around the world was increasingly difficult. So, these challenges led to us deciding, okay, are we going to continue and move up the value chain and become more of a data center company, or are we going to continue as a SaaS company? So, SaaS is where we're going. It's where we are, and where we can offload some of that work for hard work procurement, we give it to the experts who are running data centers in many, many, many more regions than we are. The interesting part of this is that, you know, even if you are deciding to, you know, reach out and deploy into different areas of the world, the hardware that you want to get is in high demand too. So, getting a TPU into the Kingdom of Saudi Arabia, which is one of the opportunities we were looking at early this morning even, is not possible. We are not going to open data centers in every country, but we can when we are working with a partner who has them. So, scalability on another side, we're talking about, I mentioned this morning, we're, you know, dealing with customers that are in Saudi Arabia, they don't want data leaving the country, we need to be using data centers and hardware and software that are located in region. We can roll that out very quickly. So, speed of scale, the depth of the scale that we can have has allowed us to scale our business. And so, being able to reach customers means our total addressable market is bigger, our company has doubled in size in the recent past and we're going to double size very quickly. Again, so this is how we're getting there. GCP in particular, I like to say, and this is my short clip where I said, you know, we work with software engineers and it's engineers building software. So, our focus on people has been part of our success and focusing on the people inside our organization and also focusing on partners that can work with us and align a roadmap is very, very important. Having access to technical experts that can supplement your technical experts in your organization, help you scale up before you hire 50 more people in another country or in the existing offices allows you to try before you buy but also plan before you take a step. So, we have platforms that are rolling out. We are decomposing a monolithic application and the way that we're doing that is with technical experts who help us have a mix of both an incremental approach and also big bang changes that will make a huge difference. So, managing our short-term and medium-term robots is really important and we have partners that help ease that integration with some of the modern toolkits. So, the way that we actually did it, I think, is very similar to a lot of other organizations and I know I've been doing cloud migrations for the last 10 years. You decide that you want to do a cloud migration, you do it and then you get the bill and you say, oh no, we have a lot more work to do. So, what we did was start with lift and shift, do a big bang in certain regions to, you know, minimize our footprint for our on-premises data centers, recognize where we were efficient, where we weren't efficient and where we are at, you know, I would say phase two right now, we are not in the crawl stage, we're more in the walking where we have specific customers who have needs that are products that we can only offer in cloud. Things that are specifically AI related, maybe they have data residency requirements in an area that we don't have a data center and so those products and those requirements to make those customers perfect for cloud are what are driving them directly to cloud. While we do that, we are refactoring in other ways. So, obviously new features are the easiest ones to build cloud native but as I mentioned, if we are decomposing a monolithic application, it does take a little bit more time. So, we have a combination of we have long-term work that is going on with the huge program that is a multi-year refactor roadmap and then we have other teams that are working on new great features that plug into the current solution and the future solution as well. The combination there is that we have teams that are able to use GCP in ways that they haven't used our data center. They have access to technology really quickly and refactor as you go works really well when you have experts ready to help you all along the way. So, examples of our modernization. So, .NET framework to .NET. We did try this ourselves at first, had some success, but we had a discussion yesterday, I think it was, where we were saying that, you know, Codacys is not an option. It's similar to how everybody has an inbox right now, but, you know, it used to be a physical inbox on someone's desk and the switch to email was you don't have someone who brings your mail down the hallway and puts it into your inbox and takes stuff from your inbox, you use an application. So, for us, these migrations are eased with technology and made more streamlined in ways that allow us to increase productivity at our organization without increasing too much overhead as we do it. The second and third points when we're talking about visible cores, that's SMT that Bencat was mentioning earlier. So, we do have a heavy Windows licensing cost associated with our applications. Definitely one aspect that was very attractive in our GCP migrations was being able to tune our Windows licenses. In data center, you leave everything on all the time, most of the time, I would say, and then the option to turn things off where 24-7 our customers are not, and so when they are not using certain areas, we're able to tune that, and also when they are using it, we can specify how many cores are visible to them. The custom machine types is the super interesting part. Similarly to SQL workloads, we have a very memory-constrained deployment. Cores are not as important as the large in-memory activities that are happening in our planning solution, so the fact that we were able to work with the GCP team to get custom machine types is really, really important, both in cost optimization and just not wasting resources. So, because we were able to work closely with that, we now have a footprint that looks exactly as we need it in the areas that we need it, and we give the solutions exactly as our customers need it. I will pass it on back to Bencat. We're available for Q&A after, but thank you for your attention. Ben. Thanks so much, David, for the ongoing partnership between our teams, and one thing I should have mentioned earlier, but I failed to mention, it's really engagements like we have with, you know, Justin's team, David's team, and many of your teams that allow us to actually bake our roadmaps and prioritize the right features, so they're solving real problems and challenges for you guys. So, please do reach out to us after the session, and happy to have a conversation about how we can help you, right, with any of the stuff that you see today. I'm going to make a little bit of a detour here, and we're going to talk about Oracle and OpenShift on the platform. Like I said before, I want to give you some new announcements that we're making in both of these areas. If you have Oracle workloads on-prem or elsewhere, what we have to offer to you, as well as for your OpenShift workloads. So, first, you know, from an Oracle perspective, many of you may have already seen, we have a partnership with Oracle now. We're super proud of the partnership with Oracle. And because of this partnership, across your applications, if they are, you know, relying on Oracle stack, Oracle databases, as well as at the operating system level, all of them have support in GCP, right? At the OS level, we have, of course, Oracle Linux support. We've had Oracle Linux support, and I have an exciting announcement on that in a bit. On the databases side, there are options available to you. Of course, there's Oracle database, right? If you are into Exadata or autonomous databases, that is available from Google Cloud now. But if you have Oracle databases and you want to run inside of GC VMs, that's also possible. So, there are options for you for Oracle database portion of the stack. And then beyond that, the applications that you have, you know, you're probably using, right? Whether it's PeopleSoft, EBS, et cetera, et cetera, all of those have support in Google Cloud now. And we already have a set of customers, many customers, using many of these solutions. In fact, one of the customers is a bank based in Mexico that you see a quote from them here, Actonver. They have brought their Oracle databases onto the platform, and they are using our AI and analytical, you know, services to get into the data and to derive insights and to build more modern workflows. So, super cool example of how you can use Oracle databases and workloads to modernize them and, you know, without too much of a transformative sort of work that is required. So, announcements-wise, Oracle Linux has been supported on the platform for several months now in a BYOL fashion, BYOI fashion, actually, I should say, bring your own image. We're excited to announce that you have now ready-to-use Oracle Linux images available in GCP. These are for Oracle 8 and 9 versions. So, these are images that Google engineers have worked with Oracle to test and fine-tune, et cetera, and so they're ready for you to immediately spin up, you know, instances, VMs with Oracle Linux all built in and fully supported out of the box. Second thing is we've launched and released a lot of, you know, documentation reference architecture for you to, you know, deploy some of these Oracle applications and databases very easily on the platform. So, if this is of interest to you, please do take a look and we're hoping that we'll add more and more to this, you know, knowledge base over time so that, you know, best practices, et cetera, all are readily available to you on the platform. Now, when it comes to OpenShift workloads, you know, like I said before, this has been an ongoing, longstanding strategic partnership with Red Hat through which we are offering OpenShift to you, both managed OpenShift as well as self-managed OpenShift, OSD, as well as OCP if that's, you know, depending on what you actually want to use on the platform. Here at the conference, I talk to many customers who have, you know, basically bet on OpenShift, right, to be the platform that you want to standardize across hybrid environments or even multi-cloud environments. We absolutely welcome that on the platform and we have been building features and capabilities into OpenShift directly so that you can get the best of what Google Cloud has to offer in OpenShift, specifically across, you know, these three categories. By the way, Kubernetes, right, which is, of course, what OpenShift is based on, if you look at the number one and number two contributors to Kubernetes, open source, it's really Google and Red Hat. So that's why this partnership is something we're very excited about and all of the goodness, all of the expertise that exists in between both the companies is what we are putting to good use so that you have a great experience with OpenShift on the platform. Of course, like I mentioned before, nothing goes, you know, without saying, right, TCO is super important for us to make sure that you don't break the bank as you move workloads to the cloud. OpenShift, of course, also benefits from a lot of the features that we've already built on the platform and more, of course, are coming. In fact, the one that I would call out, we talked about custom VMs already, of course, helps with OpenShift bin packing your containers, but the big other thing is shared pools with HyperDisk, right, also can help you save quite a bit and together, all of these sort of features on the platform, anywhere between 25%, 40% TCO reduction is what we are hearing from customers, right? So, do talk to us about this and AXion with the ARM support, you know, that's something that we are very excited about, you know, bringing to OpenShift as well. Last but not the least, a lot of, like, you know, CRDs is what OpenShift uses to expose APIs over to, of course, applications. So, all of that work is happening to make sure that all of the AI capabilities and APIs that we're building onto the platform are readily accessible for applications that are containerized and running in OpenShift. So, you can take advantage of the, you know, the AI services to power your applications as well, right? So, this is a little bit about, you know, what we have on OpenShift. A lot of exciting work happening from the product teams, both Red Hat and us here. And I'm also very happy that a lot of customers are taking advantage of all these. Some of the logos that you see are very big names, you know, Kohl's, Amadeus, you know, Deutsche Börse Group and so on and so forth. So, if you have OpenShift dependencies or work that you're doing, do talk to us and we're more than excited to kind of help you onboard and take advantage of Google Cloud. OpenShiftights.com to open up your Así..