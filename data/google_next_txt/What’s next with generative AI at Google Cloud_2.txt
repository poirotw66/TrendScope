 . Please welcome Google Cloud AI Senior Director, Product Management, Warren Barkley. Hey. Welcome. Thanks so much for coming, spending a little time with us today. So we're really excited to have you here in Las Vegas with us. Can't believe it's been 12 months since we last talked. Cutting edge AI deployments, we really went from this place a couple years ago where we had these chat bots creating text. And we moved from that to these sophisticated agentic systems that use tools, find information, and really do tasks in human-like ways. Now more than ever, the future is really about agent, employee, and agent, agent workflows as it's quickly emerging to be a mandate for every leader. And so when we kind of think about this new enterprise and what this future looks like, agents will play an important role working alongside your employees to drive efficiencies, decision-making, and innovation. You know, that's why at Google we're really focused on empowering organizations to bring Gen.AI and real-world agents quickly, efficiently, and responsibly. Now let's kind of break down the components within the stack. We recently announced AgentSpace. You might have seen some of that in the keynote, just an awesome demo in the keynote. We're going to show you more about that here. You know, AgentSpace is our platform that helps employees transform data into insights. And of course, we have Vertex.AI. Vertex.AI is the tools and infrastructure so you can build, deploy, and manage your AI agents. Underneath it, we have the brains, the models, Gemini, open models, third-party models. And finally, the rock-solid foundation of our AI hypercomputer. And I still love that AI hypercomputer word. It's just fun. That should be a T-shirt somewhere if it isn't. Customers are creating amazing stuff today. And I'm super excited to have Citi and Pearson here to come talk to us about what they're doing in their organizations with agents and AI right now. You know, with Google Cloud, we're delivering the most comprehensive platform for building and adopting agents. You know, first is accelerating the development of these agents in the deployment. So you can use different things today and pull them together. You can manage and build multi-agent systems with Vertex.AI and our new open-source agent development kit, which we're going to talk about in detail later on. You can scale the adoption of these agents across your enterprise within the data security and privacy that you need. You know, in this spotlight, we're going to talk about these two pieces. So AgentSpace and Vertex.AI. Let's start with Vertex. And let's just break that down. So there's really three kind of big layers within Vertex. First of all, we start at Model Garden, which is the bottom layer. Model Garden is effectively this curated set of models. Now, this is a really important thing. I'm not trying to have 20,000, 50,000, 100,000 models here. We're just trying to have the best models, the most efficient, and surround them with the tools. And that's why this is about having a platform, not just having a bunch of models that you could use. And of course, when you think about all those models and what comes next, Gemini. We're really excited about Gemini and what's happening with Gemini right now. And so if you look, it's incredible, the growth. The growth has been phenomenal. And so since we released Gemini about a year ago, we've seen 40x growth within Vertex.AI. And let me tell you another secret, and this just blows my mind. Gemini 1.5, the time it took to get to a billion tokens. Gemini 2.0, the time it took to get to a billion tokens. It took less than half the time to get to the first billion tokens on 2.0. That's how much this is accelerating. It's just unbelievably quick. And we have customers billing just cool stuff. Moody's Palo Alto Box. Moody's is leveraging Gemini's advanced reasoning to create really cool reports with high efficiency and high accuracy. You know, pulling stuff from complex PDFs and pulling them into reports. The folks at Palo Alto are using Gemini for advanced threat detection and customer support and using that reasoning in cool ways. And Ben and his team over at Box are using this to pull unstructured data and really understand the insights from millions and millions of people. And so we see people doing super cool things with Gemini today. And just a couple weeks ago, we gave you a preview and announced we're going to have Gemini 2.5 Pro. You know, Gemini 2.5 Pro is all about advanced reasoning and thinking. And let's geek out a little bit for a second here on it. One of the things that it does is really cool is that you can have a thinking budget. So based on query complexity, you can actually decide how much you're going to spend on the way of cost versus quality. And you as a developer have control over that thinking budget. And so it's really just awesome. And of course, we have Flash, 2.5 Flash, which is coming soon. You know, Flash is really the workhorse model. It's optimized for low latency, reduced costs, and it gives you impressive balance of these things when you're looking at high volume scenarios. And, Co, let's talk about one of my favorite things today. Today we're announcing the preview of Live API for the Gemini models. OK, what is Live API? Well, Live API allows you to talk to the model. You can stream in streaming audio, video, text, and you can have low latency conversations with the model about stuff. And I think that you're going to see a demo in a second with this. But people, when they see this, I don't think they get it. It looks like magic and it looks like we glued stuff together, but we didn't. It's actually, you should go and play with this today. It's just an unbelievable thing and it really just blows your mind about how we're breaking the walls down between analog and digital. And so I'd like to invite Katie to the stage and she's going to show that killer demo in this stuff. Katie, you want to come out? Hello, everybody. You've heard a lot about features and model improvements, but the best way to understand all of these announcements is to experience them for ourselves. So let's check out the Live API. This API responds to information in a similar way to humans by processing what it sees and hears. So I'm going to open up an app that calls a Live API, but also gives it to some unique Vertex AI functionality like Google search and creating Google Docs. In this next scenario, I'm a brand manager at a beauty company. I have some trend reports and product data I'm looking at. I would like to quickly find new and innovative marketing angles for my products. Looking through all these documents would normally take a lot of time, but let's see what Gemini can do in real time. I'm going to share my screen with Gemini as visual input data. Gemini is going to see and process all of the information on my screen and reason across these sources with me. Gemini, I'm looking at a trends report for back to school beauty from Group M Denmark. Do you mind reading these pages and summarizing what it's saying? You can tell this is a live demo, so let's unmute the mic and give it another try. Gemini, do you mind reading this back to school report and giving me a brief summary of what it's saying? Certainly. This report focuses on the back to school beauty trends, noting the increasing influence of General Z. It mentions the shift towards investing in new beauty tech and products. There is also an emphasis on quick and on-the-go essentials, like mini deodorants and hair products. Great. And do you mind giving me some examples about how this trend is really resonating with a Gen Z audience? I can help with that. Gen Z resonates with the trend through platforms like TikTok and Pinterest, which capture their value of personalization. As students seek products that express their individuality and enhance routines, these platforms shape the back to school beauty landscape for the future. Okay, awesome. Now we have some ideas about these new trends. Let's see how it can apply to our actual products. Gemini, I have a bunch of product data here with reviews, ratings, and customer ages. Based on the back to school beauty trend and the products in my portfolio, which ones would you recommend I can bundle for a back to school beauty kit? I recommend bundling mini deodorants, hydrating lip tint, and skincare items that help prevent breakouts. Awesome. And why'd you pick these products? These products align with the need for quick, on-the-go use and maintaining healthy skin and preventing breakouts. I'm seeing these are must-haves for the back to school season. Okay, sounds good. And do you mind giving me a marketing campaign that I could use for this back to school beauty bundle? Sure. Focus your marketing on TikTok and Pinterest, showcasing the ease and personalization of the bundle for quick routines, and targeted towards Gen Z's interest in expressing individuality. Great. Do you maybe have a slogan I could use? Here's one. Your express pass to personalized beauty. Okay, that sounds great. Now that we have this, let's see if we can look at another trends report and maybe add social into the mix. Hey Gemini, I'm looking at another future shopper report from group M Denmark on what influences which age groups. Between this and what we know about the back to school beauty trend, what kind of social campaign would you recommend I use for this kit? I can assist with that. Consider focusing on social media influencers and bloggers who resonate most with the 16 to 24 age group, since that is a source of influence. Great. And maybe can you give me an idea of a campaign that these influencers could contribute to? I sure can. You can launch a hashtag challenge on TikTok to demonstrate the back to school beauty routine using your beauty bundle products and encourage Gen Z's participation. Okay, I like that. Do you mind summarizing everything we said from this conversation and putting it into a Google Doc? I can definitely create a Google Doc with that info and we'll name it Beauty Bundle Campaign. Thanks Gemini. So now we can see Gemini is going to take everything from our last conversation, including the social media marketing, the tips and everything that we did, summarize it into a Google Doc so we're able to reference this later. And while it's still doing that on the backend, I hope this gives you some wonderful inspiration for the many ways that you can use Gemini to process, understand and derive insights from multimodal data in real time. Thank you to WPP, GroupM and L'Oreal for the content used in this demo. Thank you so much and back to you, Warren. Great. Thanks very much, Katie. That was awesome. I was talking to a customer about three weeks ago and they built this application with LiveAPI that allows their technicians to look at a board and use the video to understand what is on that board. And the technician can ask questions about why is this here and is that there. You know, it's really breaking down and finding new things that you can do. And that's all about this innovation. I think that there are scenarios and use cases that we don't even know about yet that LiveAPI is going to open up. When it comes to about models and choice, you know, we have, of course, Gemini, but we also have a whole bunch of staff specific models. So if you kind of look at these like Imagine, Vio, Chirp, Lyra, with the addition of these models, Vertix AI and Google is the only company that offers generative models across all modalities available today. And with Lyra, it's the music model. And so you can create your own sick beats. I know you're excited about that. Right. So additionally, we're going to continue to bring bleeding edge research from Google DeepMind, like Weather Next. It's a weather forecasting model that leads in accuracy and efficiency. And we'll continue to do that over and over again. Specifically on these task specific models, let's talk a little bit about Vio, too. So last year, we showed this video model that effectively allowed you to create videos. Now we're transforming Vio with this new generation into a comprehensive video creation and editing platform. Within painting, you can remove things out of the background that you want to. And out painting, you can extend the frame of the existing video. This really makes it easy to adapt content for various screen sizes. We also have camera presets, which allows you to decide shot composition, camera angles, and create sophisticated, cineramic techniques. With ease. It's pretty cool. This word, I always grew up. Interpol interpretation. Yeah, I've tried it a bunch of times. I still don't get it right. Okay, what is it really? What is it? Is I take two images, the starting image and the ending image. And I just say, hey, Vio, use the starting and the image and bridge and build a video in between it. You know, we're super excited what you can do with Vio, too. You know, beyond just our models, we have an open partner model ecosystem. And so you can have customers, we want them to have the right model for the right job. AI21, Anthropic, Meta, DeepSeek, Gemma. We have new models from AI2 and others. It's just awesome to see all the models in the model garden. And it's really about giving you choice. But again, as I talked about earlier, it's about having the tools to use these models, not just deploy these models and have to figure out and find the tools around them. And in Winline, we're also excited to announce, as you saw, Mark dropped LLAMA4 on Saturday. It is now available on Vertex just a couple days later. And so you can use LLAMA4 right now. With these additions and choices, you can really concentrate on building groundbreaking applications. It's about the tools. It's about having the platform. It's more than about just the model, and it's all about choice. I'd like to bring David Griffins on stage to talk a little bit about Citi and what they're doing with AI. David? David Griffins on stage to talk a little bit about Citi's AI journey and our partnership with Google. So first of all, let's start with a bit about Citi and why AI matters to us. And it's all about Citi's scale. We have an on-the-ground presence in over 90 countries. We have over 100 million customers, tens of thousands of institutional customers. And we move around $4 trillion a day in financial flows and support of the global economy. And today, finance at its heart is a digital business. So anywhere we work with digital information, AI can help. So we are embracing AI as a universal enabler given the value it can bring us. Whether it's cost-effective products, improving life for our employees, or getting products to our customers faster. And we've been guided by a couple of simple principles with taking a very deliberate approach. So first and foremost, we built a simple, scalable, secure, multi-model platform. This has many benefits, one of which is centralized controls and observability. So we can keep everyone safe and we can learn and observe across the breadth of all of our AI interactions. And very importantly, we think about the impact of AI in two dimensions. One, simple, general, horizontal, assistive AI tools that make life just a little bit easier for everyone. These have very wide applicability. They may only give you 1%, 2%, 3% of productivity back. But if you scale that across the company, this really adds up. And of course, you have to complement that with deeper AI verticals, specialized capabilities for the specialists within your workforce, whether they're developers or customer service operatives. And finally, we really believe in the necessity to scale quickly. A scaled footprint allows you to maximize the impact as this technology advances. Google is at the frontier of AI development. And we want to have a minimal lag between AI innovation and AI impact. So where are we now? So back in 2024, we were working on around 1,000 or so use cases at varying stages of analysis, development, productionization. But we very quickly realized that a few of them had universal applicability. We were working on tools for our markets business that would help them digest thousands of pages of market intelligence, complex regulatory documents in minutes and not hours. We were working on a virtual assistant with our HR team that knew our policies and could speak to our HR systems. It did simple things, but it did them in seconds and not minutes. And we built some developer tools to complement our AI systems that have now created tens of thousands of code reviews, thousands of technical artifacts and saved hundreds of thousands of hours of work. And these became our AI horizontals. We quickly scaled them across the company. We've rolled them out to over 150,000 colleagues across 11 markets in close partnership with our legal risk and compliance teams. And so in 2025, we're in a good spot. And now we're really progressing to scale breadth and depth. We're involving the AI horizontals. We started super simple to build the muscle, but now we're iterating. We're making them more capable. We were giving them access to search, to more internal tools, to more structured data, more automation. They had deeper reach and they are going to be naturally wired in to the workflows. So they're at your fingertips when you need them. And we're industrializing our AI verticals. We've already gone deep with our technology teams and our customer servicing teams. And we're partnering with Google to expand this. We're going into our institutional operations, fraud, KYC, sales and marketing, finance. And then what's next? Well, for us, and I'm sure for everybody in this room, the rubber needs to hit the road. We need real world impact. And to do that, you need two things. You need a great capability and then you need people to use it. And from a capability perspective, the frontier is advancing. The models are getting better. They can process more data with less errors. They can use tools, structured data more reliably. This unlocks useful automation. So we're definitely going to see a Gentic AI move from POC to real world production impact this year. And we're already seeing that start to happen with our developers. And then from an adoption perspective, we've certainly learned it is not enough just to put a great tool in front of somebody. You have to educate and inspire so that they know how to apply this technology productively. So we've created a network of employees across the company, our AI accelerators, to help us spread this message. And there you have it. The capability will continue to evolve. We are going to get deeper adoption and this is going to yield even more impact. We've definitely only just started on this journey, but we're so excited by the road ahead. And it's wonderful to have Google as a partner with us on this journey. And I'll hand back to Warren now. Thank you. Thanks very much. Thanks very much, David. It's awesome to see how Citi's innovating and move forward. So let's move up the stack a little bit into Model Builder. You know, Model Builder brings the best models together with the best platform to effectively unlock those models with aspects like tuning, evaluation and monitoring. Really, you're going to see this is a bit of a theme here. We have kind of four verbs when you're looking at building and adapting models. You have discovery. We talked a little bit about that. You have tuning, customize, evaluation, and of course, monitoring and deploying. So let's kind of dig into that. Well, first, let's talk about discovery. How do we do that? Well, today we're announcing the Vertex AI Model Optimizer. What is that? Well, basically what it allows is a fully managed service that allows you to get a high quality response to whatever prompt you send it to. And so think of it this way. As we actually take a look at the prompt and then route it to the right Gemini model for it to use. So I have a bunch of customers who have been asking for this because they may have a thousand queries that are relatively simplistic and then one complex one. And they want the same kind of high quality level response to that one complex query. And so Vertex Model Optimizer does that for you. So we're very excited to see how that's used by you. And so when you're looking at customizing these pre-trained LLMs, you kind of start on that left side with in context learning. Oh, right side with that in context learning. RAG. And then supervised fine tuning and full fine tuning. And so we're adding a whole bunch of tool sets here as well. Now supervised tuning is available on two own models and the Vertex Model Development Service, which we'll talk a little bit about. So this Vertex Model Development Service, what is this really for us? Well, basically, you can now launch a production cluster in minutes instead of days, leverage pre-optimized and post-training workflows, improve model accuracy, and basically fully automate all the infrastructure needed. This service is made so that if you want to build your own foundation model, you want to fully train your own foundation model, this service allows you to do that. And it's very exciting because basically what it allows you to do is it makes it so that your ML teams can build models instead of managing infrastructure. And next is evaluation. And this is a place where lots of customers that I talk to struggle with evaluation. It's a really tough area. We added a service last year that was pretty comprehensive and then we're adding actually more right now. And you can see these green boxes, all sorts of new. So today, part of evaluation, we're announcing agent eval, which allows you to trigger agent execution in a single line of code to get metrics on the trajectory and the response to the evaluation. And of course, this is about open frameworks. This works with different models, different frameworks. You can use that with LandGraph, Crew AI, whatever you want. Multimodal. Last night at dinner, I was talking to one of my PMs about multimodal evaluation. This is a very tough area. When you add video and you add speech and you add text and you put all that together, it's a very tough area. So we're announcing basically multimodal evaluation and batch evaluation. And so with multimodal evaluation, it allows you to really understand those different types of modalities and how they're doing. And batch evaluation is you have a really big data set. This makes it very easy to do that error free. And then finally, let's talk about the last piece. We're excited to announce Vertex Global Endpoint. You know, this is our worldwide load balancing system. We incorporate intelligent health checks, automatic failover, and we guarantee high availability using Google's robust international networks and infrastructure. And so we're super excited about people being able to use these things and really exploit the best of these models. So let's move up. Agent Builder. I bet a bunch of you are really here for this. We have a ton of interesting things to talk about with an Agent Builder. So follow the, we had an introduction last year. I introduced Agent Builder. This is kind of like this next step in the evolution. And, you know, it really helps enterprises turn processes into multi-agent systems. And so we're announcing a huge bunch of stuff here. It's actually just mind-blowing. But again, it really comes down to these four verbs. Develop, connect, deploy, and operate. And we're putting things in each of these boxes to make it really easy for you. Well, the first piece is Agent Development Kit. Agent Development Kit is this new open source framework that simplifies the process of building multi-sophisticated multi-agent systems. You know, you can build a multi-agent system with 100 lines of code. You can steer agent behavior with guardrails and creative reasoning. And you could actually work with your preferred model. Again, this is an open system. You can use different models to use this in different frameworks together. And it's really ready for enterprise scale. Next, agents are only as powerful as the data they connect to. And so with that, we have pre-built connectors. And we're really excited to have all those in the box. So we also believe that MCP is going to be the new way and open standard that models are going to connect to data and tools. And we'll have MCP out of the box day one with the Agent Development Kit. Developers can use custom APIs with Apigee Hub or any of these pre-built connectors so you can connect to these open systems. So beyond simplifying data access, we also add things like task planners, deterministic workflows, knowledge graphs. It gets you the power to shape how this actually works. Last year, we announced grounding with Google Search, grounding with your own data, and now we're announcing grounding with Google Maps. So you can actually ground your applications with Google Maps, which has 100 million updates a day on factual, real information. It's just a fascinating thing. And so Realtor.com uses this right now to actually find that little pink house that you've been always dreaming about with a white picket fence. So it's just an awesome thing that you can go and actually ground in live data. You know, one of the biggest challenges for enterprise AI and adoption is getting agents on different frameworks to work. And that's why today we're announcing a new agent-to-agent protocol, A to A, designed to let agents across different ecosystems communicate with each other. We're driving this initiative because we believe this protocol is critical to support agent-to-agent communication, and we're inviting the community to help evolve this protocol. In fact, as of today, we have more than 50 partners signed up to help us evolve and have a shared vision on what this looks like. Salesforce, UiPath, Palo Alto Networks, Oracle, ServiceNow are all helping us right now evaluate and build this cool protocol. Finally, deploying agents in production remains really a big deal. And that's why today we're also introducing Agent Engine. Agent Engine is a fully managed enterprise-grade runtime. And it handles all the complexities of infrastructure scaling. With Agent Engine, developers can deploy agents using any framework. Again, open. We're about open, about choice. You want to use ADK, you want to use Langchain, you want to use Crew AI, you want to use Gemini, you want to use Llama, you can do this with Agent Engine. Create multi-agent systems with the agent-to-agent protocol. Again, evaluation comes up here. Measure and improve. And then publish your agents to AgentSpace, if that's what you want to do. So, we talked about agents. A ton of new announcements there that we're super excited about. From that, let's go to the top of the stack and talk about AgentSpace. Some of you might have seen just this amazing stuff that they demoed in the keynote. We're going to show you even more stuff here. And so, AgentSpace fundamentally changes the way that you actually can interact with data. You know, AgentSpace really helped you unlock all that data and allows you, your employees, to basically go across data silos and synthesize and understand it. It uses Gemini's multimodal intelligence and it can act on it with AI agents. You can find any piece of information across your organization. It doesn't matter what the format is and uses the power of Google search effectively underneath the covers. With AgentSpace, you get this multimodal search experience. So, regardless where it is, where it's stored, what it is, text, whatever, you can find it. The right information resides in common workplace apps like Google, Microsoft 365. Yes, I said Microsoft. Applications like Jira, Salesforce, ServiceNow, Contacts from the Web. AgentSpace breaks down all those walls to deliver organizational content as a response. Next, we want to meet employees where they are. So, this cool search, you can put it right in Chrome. Chrome Enterprise in the search box, you can enable this right now. Hundreds of millions of business users use this today and this just makes it so easy to meet employees where they are instead of having to deploy some new thing. Next, we have AgentGallery. This is really a cool thing. It's really a centralized hub for your enterprise-approved agents. So, you can actually deploy them to your directly into AgentSpace. And it's very nice because you could actually have purpose-built agents. You can have expert agents. You can have partner agents. And you get to control deploying those agents directly into AgentSpace. And talking about agents, we're announcing two new expert agents today. First one is effectively idea generation. That goes into preview today. Okay. This is a little bit complicated to explain. So, just go use it. But let me tell you what it kind of does. So, it autonomously develops novel ideas. So, you can tell it things like, hey, how should we make our social media campaign better? How should we, what's a new product line that really would be interesting? And so, you can actually feed it all this information. And it uses this Terminant South system to actually figure out what the best idea is. And it will actually evaluate them together and feed them out. It's absolutely fascinating. And I don't know I did a great job explaining it. Go use it. You'll see how amazing this thing is. The next thing we have is deep research. Really lets employees condense hours of work into a single prompt. So, you can synthesize information from internal sources. And take that analysis and the disjointed information and turn it into actionable knowledge. Of course, it's not just about our agent experts. Your employees can make agents too. Agent Designer, it really democratizes the ability for you to build your own agents within agent space. But they actually respect and they're compliant with data security and access controls. So, with Agent Designer, you can basically use a chat type interface and start automating your tasks. So, your employees can build their own agents and it has 30 pre-built tools and actions right in it. And so, we're super excited about the ability to kind of unlock the innovation within your workforce. Today, we have a bunch of partners who've also built agents. You can deploy them right today into Google agent space across your enterprise. And of course, finally, it's built on the same trusted infrastructure that billions of users use today at Google. So, what we're going to have is Sri is going to come out and do a little demo at Agent Space and show us what it's all about. Sri, why don't you come on out? Sri, why don't you come on out? Sri, why don't you come on out? Sri, why don't you come on out? Sri, why don't you come on out? Sri, why don't you come on out? You come on out, see you. I'll show you a specific example of how Agent Space empowers employees with AI agents. In this scenario, I'm a program manager that manages several projects at my company. And what you see here is the employee homepage of my company powered by Agent Space. Let's get started by asking a question. But I want to use the clipboard here so that I don't run over the previous session with my typing speed. I want to know what is the latest update on the new Ninja project that I'm managing, which is about our website redesign. Let's ask that question right here within Agent Space. And when I do that, I see an answer across several data sources that I have access to, like Salesforce, Jira, SharePoint, and more. I can also click on Citations to see that everything is grounded on enterprise data. And as I scroll down, notice that financial information is not included in this answer. That is because I do not have permission to those data sources. Agent Space ensures enterprise compliance and security. I also see that there is a statement of work review pending from my site. Now, as a program manager, this is a bane of my life. I have these vendor SOWs take up a lot of my time. But thankfully, I noticed a suggestion to use this out-of-the-box agent for reviewing contracts. Let's take that for a spin. The AI agent has already loaded the correct statement of work based on my previous conversation. And I can also verify the same on the right here. Let's start the review process. Now, previously, I had to review these company guidelines and the contract line by line. Let's see how that gets simplified for me. I already see a few suggested changes. Notice that it provides me with a rationale from our company guidelines and shows suggested text in line within the contract. This is great. I'll accept this suggestion. Moving on. This change is not needed for this project. So I'm just going to reject it. This one is a great example of something that I missed, but AI caught it. We need this convenience termination clause for website-related projects. I'll accept that one. And with all of these changes resolved, I'm now ready to send this back to the vendor. And what I'm going to do is ask AgentSpace to email this to the vendor, summarizing all of the changes. And when I do that, notice that it connects to my Outlook. Yes, Outlook. And generates this email interface so that I can verify the email address and the body of the email so that I can send this right from within AgentSpace. Now, notice three things that are fundamentally different about AgentSpace. One, I was able to perform multiple activities, like reviewing contracts, emailing, all without switching context. Second, I was able to operate on multiple systems, whether they're internal or external, to Google's ecosystem, like SharePoint, Salesforce, Outlook, and more. Third is the AI agent kept me in the loop throughout the decision-making process wherever necessary, like reviewing the contract, reviewing the email. Now, using this agent, I was able to automate this contract review task for one SOW. But how do I automate an entire workflow for multiple SOWs? That is where the agent designer that Warren was mentioning earlier comes to the rescue. And I can get that started by clicking on this suggested follow-up. And I see that a whole plan is generated with a series of steps based on all the conversations. Previously, I was only able to automate this one contract review process. But now I can automate an entire workflow with steps before and after, like receiving the SOW and emailing it to the vendor and so on. This is great. I'll confirm this agent. And within seconds, my agent is ready for me. Let's see if it got everything right. Clicking into it, I'm presented with a form view with generated content for me, with goal, triggers, instructions, and tools that are deeply connected to my systems, like Outlook for email, OneDrive for my SOWs, Confluence for our company guidelines. I want to add one more thing here. I want to get this entire workflow started whenever there's a new SOW added to our OneDrive folder. How do I do that? I can just ask in natural language. And when I do that, it automagically updates this form and adds this new trigger. This is how easy it is to create agents using the agent designer. With that workflow automated, I now have time to have those quick hallway chats, which turn into 30-minute therapy sessions on our latest project. But I'll tell you that story another time. Back to the demo. Now, this was one example of an AI agent. We have a lot more agents for you. Welcome to the agent gallery, where you can see expert agents built by Google, agents built by my own organization using the agent development kit, agents built by partners, and agents that I've built myself using the agent designer. This is one story of a program manager. We are excited to hear your story on how you would leverage agent space for your work. Thank you. And back to you, Warren. Thanks very much, Shree. That was awesome. I'm sure that that quick hallway chat time could be utilized. I'm sure your boss is not in the audience listening and thinking the new stuff that he can give you for that. So I won't tell him either. I'm sure it's just a secret between all of us, right? As Thomas mentioned, you know, since the launch, we've seen tremendous interest in agent space. You know, we have customers using this right today. Banco BV, Gordon Food Services, KPMG, Rubric, Wells Fargo's. Clearly because it's demonstrating value that our partners like to see. And now I'd like to welcome another one of our customers, Dave Treat from Pearson to stage. He's going to talk about his AI journey with educators and Google Cloud. Dave, you want to come out? How are you calling, man? Thanks. Good to see you. All right. Hello, hello. So how many of you have not asked what you thought would be that dumb question? How many of you remember sitting in a 300-person classroom and not being able to ask the question? Because you just couldn't get the teacher's attention. Or maybe you're an employee and you're eager to learn that next skill, but you are overwhelmed by your job. Right? The whole notion of being able to get support when you need it. We have AI products in market. We're super proud of. We've had millions of data points with our customers around our AI tools showing love for them to be able to access learning when they need it, personalized to them, and grounded in our learning science. And so this actually is my favorite stat. 11 p.m. to 1 a.m. For our college students, this is when we see the peak traffic for our AI study and tutoring tools. So it turns out that students need help in the flow of their lives, and that is long after the professors have gone to bed. So what we do is we deliver AI learning solutions for everyone that can show up in the flow of work, in the flow of school, really in the flow of life. And so we're very proud to partner with Google on the AI domain. And listen, we're Pearson. We do three things. We create and curate content. We distribute that content through digital experiences of a number of different kinds. And we help people prove what they know and what they can do. So think GMAT, MCAT, GED, cloud certification, through the entire lifetime. So we do these things across K through 12, big K through 12 business, higher education and colleges, and the enterprise. And AI is at the heart of all of that, and we're proud to partner with Google. So there's a problem. We're actually facing a huge challenge here in the U.S. and globally, but we've got the data for it in the U.S. We put out a report in January. There's more than a trillion-dollar GDP gap that is potentially now starting to grow around the transition points from going from school to college, college, you know, so from college to work through redundancy from unemployment, you know, often as a result of being displaced by new tech. And the system that we have is broken. The system is I'm going to learn to the test. I'm just going to pass the test. And the slingshot model of I'm going to learn everything I need to learn in college, and then I'm ready for my career, which has never really been the case. So what we have to do is change to a learn-to-earn, direct pathways to jobs, or learn-to-learn model, constant learning throughout our lives, just in order so that we can prevent this skills gap that we have right now turning into a skills chasm. And so Pearson is using AI to help educators and students through transform learning across all stages of life. And we have AI products and market that help learners at all ages decide what to learn next, have the resources and access to be able to get at that learning through amazing learning experiences. So we're using AI to help learners envision what jobs they could get, what's needed to get them, and how to be successful in their careers. So Pearson's agentic future. It's time we've realized it's time for us to think outside the book. And we're really just at the beginning now of creating super effective personalized learning experiences using agents. So we're envisioning a team of agents working together on behalf of educators and students, using natural language interfaces like you just saw, integrating all of the tools and resources that they need, all guided and shaped by our learning science and trusted content. So this is going to change not only the product that we have in market, but it's going to change the nature of how we build. So the agents' impact on the engineering, on the software development lifecycle, we've already been using Gen.AI to material contribute to our code creation and our content creation. The stat that's out there that we're all seeing, right, is we're seeing the 20 to 50% of code being written by AI. But now the notion of using agents to not just help write code, but actually help run the software development lifecycle in partnership with humans is going to be incredible. So we have specialized agents, or we can have specialized agents that are specialized in developing solution architectures, doing documentation, specialized in specific coding languages. And so that ability for agents to be directed to not just write code, but actually run test scripts, repeat until successful, create the documentation, that whole construct is going to be super powerful. We're also envisioning it's going to change the nature of our operations itself. We're all going to be hybrid AI, right, as you've seen in the presentation so far. Agent space can be used as that control plane to manage the team of multiple provider agents. So, you know, think an end-to-end workflow that's using a, you know, Salesforce agent, a ServiceNow agent, you know, a combination of agents to really tackle a true end-to-end workflow. Just as with humans, there's also the dynamic of there's going to be the right agent for the right job. There's going to be higher-performing agents than others. There's going to be agents with the access to very specific data sets and tools. And how do you know how good an agent is? How do you know and assess their skills and match them to the right workflow, match them to the right human, and get those two, you know, skill sets matched together? So just as we focus on helping humans prove what they know by taking tests and exams and assessments, we're focused now on the same for digital workers and the mash-up between the two. I'll end with this quote. Chris and my team, I'm sorry, we've got one more. So the hybrid agentic control plane, I was off a slide. Let me go one more. Let me end on this note. Chris and my team, I thought, had a profound statement the other week. He basically said, you know, we quickly realized that we're switching from adding products, adding AR to our products to adding our products into AI. And I think that really is very much a profound statement as to what's about to change as we think about our agentic future. So thanks for your time. And, Warren, back to you. Thanks very much, man. Thank you, sir. Thanks. Thanks. I don't think many. This is like a very not a well-known fact, but I was a classroom teacher at one point. I would have loved to have those tools in the classroom when I was teaching. We really understand the importance of enterprise readiness. And it's really at the core of our approach to Gen AI. You know, I was in Europe a few weeks ago talking to the CEO of a really large company. And he was saying to me, he's like, I just don't know how I can trust it. How do I trust it? And really, this is really the center of what we're doing here. Data governance and privacy, security and compliance, reliability and sustainability, safety and responsibility. It's really, really important. And it's the cornerstone of how we build Gen AI. And as part of that, and we've said this before, and we'll say this again, your data is your data. Customers own their data, not Google. And at every layer, we have built-in data governance. And we have enterprise data privacy and control, so you get to control your data. And in fact, we were the first in the industry to publish an AI ML privacy commitment, which outlines our belief that you have control over your data and the highest level of security and privacy. We have years of experience doing data privacy designs, and that all goes into our products when we build them. The other thing that is unique and novel in the industry is we provide indemnification. Not just indemnification on the generated output, but indemnification on the training data as well. So we will stand there with you if something bad happens. And of course, today, we're also announcing sovereign AI services across the Google Cloud portfolio. These new services are going to provide enterprises and public sector companies with great control over the AI deployments. Sovereign AI enables customers to maintain data residency and provide administrative transparency of Google operations. And specifically for our government customers, we're excited to announce FedRAMP High for Vertex AI. And so you could use these capabilities in federal agencies today. The next thing that I've been very involved in is Google Distributed Cloud. And so we're announcing that Google Distributed Cloud will have Agent Space and Gemini to bring the latest models on-premise and environment soon. So you can do that either deployed as connected or air-gapped. And it really brings Google quality search and Gemini intelligence into your on-premise environments. And finally, we work closely with partners across the stack to help harness the power of Gen AI. And we're partnering with leading consulting companies. We're training 400,000 experts on Google Cloud AI. You know, the last 24 months have been unbelievable. You know, I live in dog years. One year is five, six, seven. I've been in technology a long time. I've never seen the accelerated pace of innovation that we're going through now. It's actually unbelievable. You know, with Vertex Agent Space, we're unlocking all this power of Gen AI and giving you this full platform that you can use to build agents and put them in your enterprises. So we're super excited about that. There's all sorts of cool things happening. We had a ton of announcements today. Those are all the announcements. If you want to learn more, please feel free to continue your learning journey. There are breakout sessions with my colleagues. Lots of people will go deep into every single thing that we talked about today. So thanks very much. Enjoy the rest of the show. And wait for your T-shirts. Thank you. Thank you.