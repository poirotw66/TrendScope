 I'm Karthik, your moderator for this session, turning AI into true operational efficiency inside Nokia's transformation. Let me welcome our speaker, Bernard Furman and Deepak Chauhan on the stage. Hi, Bernard. Hey. Good morning. Hi, Deepak Chauhan. Good morning. Please. Thank you. Bernhard is the head of cloud transformation at Nokia, overseeing the company's cloud strategy. He has extensive experience in cloud technologies, and as part of his role, he's responsible for driving transformation and leads the charge in adopting new technologies. We're excited to have you here with us today, Bernhard. Thank you. Our second speaker for the session, Deepak Chauhan, is a vice president and global cloud industry principal at HCL Tech. Deepak brings his experience as a founding member of the Google Cloud ecosystem unit in Europe and leading the go-to-market efforts in Europe and Asia-Pacific geographies. Excited to have you with us, Deepak, today. Again, thanks a lot, Bernard and Deepak, for being here today. I'm excited to know more about Nokia's transformation journey to Google Cloud. How Nokia tackled the challenge of industrializing at scale, while at the same time modernizing their infrastructure services with infusion of AI and Gen AI. This is a fine example of how a combination of bold decisions and AI adoption at scale helped Nokia achieve ROI and meet their strategic objectives. So I'm really looking forward to Bernard talking about his journey, the challenges they faced on their way, and what were the key takeaways. HCL Tech has been Nokia's partner in their cloud modernization journey. Deepak will be talking about the journey and how the industry is shaping up with the impact of Gen AI and challenging the status quo. He's going to talk about how they are infusing Gen AI into their cloud smart industrialized services framework. We all know the lines between infrastructure and the application world have been blurring over the years, and with Gen AI, this process is only getting expedited. We see many enterprises embarking on large application modernization programs and finding their way on how Gen AI can help with their journeys. Deepak will also be talking about the direction and evolving nature of agent tech framework. Excited to have you with us there, Deepak. Thank you. Before I request our first speaker, Bernhard, to take the stage, we have a video for you from Nokia. Let's take a look. Today, as a technology innovation leader, we're driving the next evolution where networks meet cloud. For us, we're not a technology networking at all who choose a scheduled cloud. We need places like your certification platforms that love the country, the currentия. And we drive eins leading companies, network boats, agrade directions, and we're taking things that we're dominating. And that's why we're going to eu lactate Fort Pier zone of homeowners. And we're making a lot of concern my life. The most important thing is, unfortunately, we're taking the way lather so good. We're gettingНе&Level engageable out... for monetization and automation, unlocking new forms of collaboration and delivering trusted performance through trusted networks to realize the full potential of digital. Because it's only when people, machines, and devices work together in sync that we can create a sustainable, productive, accessible future. This is Nokia. We've always connected people. Now, we create technology that helps the world act together. That was a cool video. Thank you. Bernhard, the stage of all yours. Over to you. Thank you. Thank you, Karthik. Pleasure to be here today. And I'm very excited to share Nokia's cloud transformation journey and how we are building modern infrastructure and integrating AI into our operations and driving continuous innovation. So let me start with our cloud journey, how we came to public cloud. So in early 2020, we at Nokia embarked on a large-scale cloud migration program, partnering with Google Cloud and other partners. Our objectives were very clear. We wanted to modernize our compute infrastructure, consolidate and reduce our data center footprint, and simplify our operations. At its core, this was a transformation at scale, focusing first on public cloud infrastructure, but also from the beginning, we recognized that modernization isn't just a matter of lifting and shifting. To truly benefit from the cloud, we needed to redesign how we operate, secure and evolve our environment. So we built a strong foundation to support a secure, efficient and scalable cloud estate. This included governance, automation, security frameworks and the ability to manage a broad and complex set of workloads across different business domains, geography and also compliancy needs. At the same time, we started modernizing existing workloads as well. So moving from legacy infrastructure towards more managed services, cloud native architectures and that wasn't limited to infrastructure. We also transformed the tools, processes that support our operations. Monitoring, backup, security tools, all were re-evaluated and where possible, replaced with modern, more cloud native alternatives. So the result of this was a leaner, more agile operational model, less complexity, more automation and a significantly improved efficiency. More recently, also AI has become a very powerful accelerator for our transformation. It's unlocking value that was previously out of reach for us. As an example, we're using AI assisted tooling to analyze legacy databases and application code. And this helps us to identify modernization paths that weren't obvious or even possible before. We can now transform some of our more complex workloads in ways that are faster, less risky and more cost effective. We are also embedding AI into our operations. One area is self-healing runbooks, where AI automatically identifies issues before they actually are escalating. So it's not just about saving time. It's about improving reliability and resiliency across the board. So let me summarize a bit where we stand today. We have successfully migrated and modernized hundreds of workloads already. We have closed several of our data centers and decommissioned them entirely. We now operate a hybrid infrastructure platform that spans public cloud, private cloud on premise and also includes bare metal services. And this platform supports a wide range of services for our business, from traditional infrastructure to cloud native workloads to emerging AI powered capabilities. And it's all aligned with Nokia's strategic focus on agility, innovation and operational excellence. Now let me highlight three key principles that have guided us on this journey. First, it starts with clarity. Having a clear strategy set out, it's key for every transformation. So we need a very solid strategy that answers more or less the three basic questions. It's the what, the why and it's the how. So what are we building? What are we doing? We're building a secure, scalable and cost efficient infrastructure that can support both current business systems and future digital services. And why are we doing this? We need to reduce technical debt, support new services, remain compliant and optimize cost. And basically we do all of this at once. So how do we execute all of this? That's the key point obviously. By applying a cloud first approach to new workloads and modernizing existing ones during migration. We assess each workload to see if it can benefit from new technologies, whether that means containerization, managed services or even serverless architectures. But at the same time, we're also working to streamline our operations. We're driving a consistent cloud like operating model across all of our environments. Public cloud and also on premise. And automation plays a very crucial role here. We rely on infrastructure as code, native tooling and standardization of our processes. In fact, over the past two years, we've significantly reduced the number of tools we're using, cutting out complexity and boosting productivity in our operations. The second part, building a very strong platform foundation. So a robust platform is fundamental and critical, not just technically, but also strategically. When we started building our landing zone on Google Cloud, we basically looked at two things. One is the current state of our workloads, making sure the platform can accommodate all workloads we have in our environment. Second, the future state. What do we want to reach? What services do we want to bring into production? We knew we need flexibility to support rapidly evolving product and service portfolios. So we built a platform that's extensible, modular and secure by design. Because security and compliance were baked in from the start. We didn't treat them as add-ons. They were central to our design. This is very important. And as the platform evolves, our governance also evolves with it. And equally important is how we operate this entire environment. The cloud transformation isn't just about infrastructure or technology. It's about people and processes as well. We've had to adapt how our teams work, how decisions are made, and how our value is measured. And that cultural shift has been just as important as the technical one. Third, a continuous learning environment is critical. Continuous learning and adaption in the cloud area, and even with AI services around the corner, is important. All the services evolve at a very rapid pace. Every quarter brings new capabilities, being it on the platform or being in tools. So to stay competitive, we foster the culture of continuous learning across all our domains. We are always evaluating new tools and services, and not just from a technical standpoint. We also look at this with a business lens. Do they unlock new value? Can they accelerate our transformation? Do they improve the cost-benefit ratio? One tangible example I want to bring up here is our FinOps practice. We've built a dedicated function focused on cloud cost optimization. And this team serves as a challenger, continuously analyzing consumption patterns, evaluating new services, and driving cost performance and improvements across our platforms. So it's more than just a cost-tracking function, and it has to continuously stay on top of the technology to be able to kind of challenge everybody and drive our development going forward. So let me close by sharing a bit of what's next for us. Obviously, this is not the end of the journey. There are two key areas where we also see NI really helping us going forward. One is AI-enabled modernization. We still have legacy systems in our environment, and we're using Gen AI-enabled tools that can analyze and transform these systems faster and with way less manual effort. So moving them to more modern cloud-native platforms that are more scalable and more cost-effective. The second part, autonomous operations. This is where things get really, really exciting, actually. And Gen AI introduces a new paradigm where intelligent agents can proactively monitor our systems, trigger automated actions, and even optimize resources in real time. So we're imagining a platform where agents detect anomalies before they become incidents, also resulting in way less tickets, by the way. Learning systems adapt to evolving business needs. And agents perform cost optimization in real time without human intervention. So, obviously, we're not there yet. But we are building the foundation. And with full stack of observability, automated remediation like automated runbooks, a culture of continuous improvement, we are well on a path towards this self-managing infrastructure. So, I hope that was interesting. Karthik, over to you. Thank you, Barnard. Yeah, thanks a lot, Barnard. That was really insightful. I do have some questions for you, which probably will take in the panel discussion. With that, over to our second speaker for the session, Deepak Chauhan. The state is all yours. Thank you very much, Karthik. And thanks, Barnard, for sharing the Nokia vision and transformation journey you embarked with us on. We're really privileged to be Nokia's partner on this journey. And thanks for sharing the stage with us today. So, in the next six to seven minutes, let me share a couple of things. Let me move the slides first. Yeah. In the next six, seven minutes, let me share a couple of things. First, I would like to outline the overall GenEI industry evolution journey largely in three waves or epochs, as I would like to call it. And subsequently, an example of an offering that's been pivotal to each of these epochs. And this also closely reflects our own journey with Nokia as a transformation partner, and of course, with Google Cloud. For the industry, the first epoch has been of intense industrialization of cloud services and intense simplification, if I may say. HLT Tech has obviously seen a number of large data center transformation programs moving to cloud, a number of them moving to Google Cloud. And we have done a lot of learnings from several cloud transformation programs. And in this phase, we moved to pattern-based catalog of cloud adoption services with an outcome-led model. Now, GenEI was infused into the service runbooks to bring higher efficiencies during the process. And industry has been seeing basically the following three trends, right? The wave has largely been the simplification of cloud adoption services. The whole infrastructure has largely become modernized. But what we have largely seen is it is centered around the IaaS past patterns, which were largely cracked in this. GenEI induction made its way into the industrialization, into the service runbooks, et cetera, et cetera. But the whole application modernization conundrum was still not completely resolved. And the tangible business cases were still challenging to create in this epoch. But as we move on to epoch two, we saw three key trends. And these are still playing out in parallel with the first one. Large number of customers still had high technical debt despite moving to cloud. An example of this is where customers have completed the migration journeys, which have helped them become a satellite. But the applications were still left to be modernized. And that's a huge opportunity area we see. And GenEI, well, GenEI came arguably late November 2022 or early 2023. And as it started maturing, GenEI offered opportunities in reducing task complexity by simplifying the whole services framework. The whole software development lifecycle has been disrupted and shortened, including the whole operations framework, with huge savings. And GenEI brought in the opportunity to reimagine the business processes. Start of platform-led, we're seeing the start of platform-led industrialization for modernization. And this has been aided a lot by GenEI. And the business case has finally started turning positive. As the app modernization journeys started shrinking, cost savings were getting realized. And as we move to agent-tech AI, the current era, the very recent, and we have all seen the keynote yesterday morning, big revelation. We saw what's coming out of it. Very exciting times, right? And so agents have become now what I would like to call it as a basic Lego blocks. So this is actually a heavy industrialization of the GenEI AI era. The Lego blocks which can help you create any large solution you want. Now Gartner has reported that by 2028, around 78% of the enterprise software applications will harness agent-tech AI capabilities up from virtually very few today. After seeing the keynote yesterday, I would probably argue that maybe might be a lot sooner than we expect. So we are seeing a tremendous disruption beginning to get enabled by adoption of agent-tech systems. So let me move on to the next slide and talk about very briefly and very quickly of three key areas that we were talking about. What's enabled us in this first epoch that I was talking about is the whole cloud smart industrialized services model, which is the framework that we created, which stitched up the entire platform from creating a pattern-driven outcome-based model. It also stitched the whole processes, the people, the policies into one single platform. And this is the foundational offering on wave one, where we inter-slide journeys to cloud. Okay. The great part of this model is that you can pick up any service. For example, you're doing a migration of VMs, large complex workloads using GCV. And you can actually get a price on an outcome basis rather than talking about resource units. You come down to service unit and you'll be priced on the outcome. And so this is something that we've been working on with a number of customers. And it has simplified the whole intake and uptake and utilization of these services across the board. And just standardized it a lot. So this is what I was talking about on this slide. I'll probably quickly go on to the second epoch that I was talking about. And on this particular slide, what you can see represented is three different layers. One is the application, the LLM models, the data repositories, which are customer-owned largely. And what you see underneath that is the whole GenEI platform that we're bringing in, which is AI Force. And AI Force is HCL's flagship service transformation platform, which uses patented AI accelerators in the software development lifecycle. And obviously into the ops space as well. And by injecting GenEI into every aspect of software development, from requirements gathering, to software design, to coding, to testing, to DevOps, and even to support and maintenance, AI Force is delivering huge productivity gains and accelerating the time to market. So AI Force platform is acting as an interface, ingesting all the applications, the whole data sets, and the business processes for scale to modernization. And we're seeing a vast number of customers utilizing this platform-centric approach to invest in modernization. And create a successful business case for the modernization journey. And creation of the business case is very central to what we do. But the three key things that stand out. There is no tool lock-in. The LLMs that we're using can be LLM agnostic. The customer can bring their all LLMs. We are obviously using Google Gemini in a number of places. So there's no vendor lock-in. It's customizable. And it is also available in agentic architecture now. And final thoughts on what we are doing with Google Cloud right now. Building a library of agents. So in the agentic space, very briefly, if I can talk about, we've got a library of 45 plus agents. And we are building up a backlog of about 300 plus agents. All of our agents will be available for use via agent space in Google Cloud. And as I said earlier, the agentic wave is more as an industrialization at scale of GenEI. So from an HCL perspective, agentic AI offering goes across multiple areas. And of the three areas that we broadly talk about, one is we create agentic solutions in the enterprise space. Like customer services agents for specific functions. Or in the engineering space, for example, ticket resolution, et cetera. Or in the industry space, a number of solutions there. Actually, I welcome you to come to our booth and witness these and have a look at some of the solutions that are at display. NetSight is a GenEI-led network performance monitoring and optimization solution, which we have been working with a number of customers on, which works on Google Gemini. And it has multiple agents underpinning the solution. Like there's an agent for root cause analysis. There's an agent for gathering performance data. An agent for analyzing tickets. And suggesting the most optimal network configuration. So with that, I would like to, you know, sort of thank Bernard, you, and Nokia again. And hand it back over to you, Karthik. Thank you. Hey, thanks a lot, Deepak. There's a lot one can take away from your session. The areas that you spoke about, such as infusion of GenEI in the modernization journey enabled by Air Force, Google Gemini, and several other solutions. That was really insightful. With that, we move to the panel discussion. Okay. So, Parnath, you spoke about autonomous operations. You know, do you want to share more about that? No, I'm very happy to do so, Karthik. Obviously, autonomous operations is a big topic for us. And I think everything kind of over these days is about agentic. And the agentic AI system is what we see as a key driver for us kind of towards this autonomous operations. So, when we talk about this, what do we need? What do we actually need to drive autonomous operations? So, there's a lot of things that have to be in place. One is, obviously, the infrastructure layer has to be modern. The automation has to be in place to be able to benefit from the, you need full stack observability. You need to have a learning system in place to enable self-healing capabilities. But also, you have to adapt your processes. So, the way how kind of I see this evolving kind of, we will continuously kind of obviously improve on those topics and infuse agent into our everyday of working. It will be on every process that we kind of do, being in provisioning, change processes, how we kind of patch and upgrade our workloads, being it on premise or in the public cloud, kind of where agents will come into play. When you think about monitoring the environment, if you have full stack observability, it should be very easy for an agent kind of to monitor and identify and optimize things before they actually become incidents. So, we see a lot of potential there. And if you then look at the landscape we are kind of, we are operating. I was talking about we have legacy, more legacy type workloads in our environment. We have more modern workloads. So, we have to take care of everything. So, we might see faster adoption towards, let's say, the more, let's say, less critical, non-production environments, starting to see kind of how these agents come into place. But then moving towards rolling this out across our environment, kind of to driving this towards autonomous operations. That will not, that doesn't mean at the very end there is not kind of people involved in managing still. That a lot of the things that are kind of the processes currently being in place with manual effort, kind of can be supported by autonomous agents. I think that's absolutely right. I think we've had conversational agents for being a while which were able to understand the intent and the entities in, you know, specific persona. But with Agent Take AI, now these agents can take decisions which, you know, they're context aware and they can reduce the manual work a lot. And you also spoke about the legacy modernization and going to full stack observability. I think you're heading in the right direction with that. And you'll be able to keep the benefits of that. And the foundation is already there in place. So, thank you for sharing that. Deepak, you spoke about HCL Tech's role in Nokia's cloud transmission journey. Do you want to share more about that? Yeah, definitely. So, we started our cloud modernization program with Nokia approximately about, yeah, roughly two years back, possibly. And we've been engaged with you for much, much longer, obviously. But as a key transformation partner with Nokia, I think we set out first to support Nokia's vision of one cloud approach. And the idea was to lay the foundation for innovation and create a ground for modernization, for higher ROI savings. So, that was the simple one-line objective. And obviously, the success of such a large transformation program goes beyond just the technical and the technology components. And, Bernard, you spoke about having a clear strategy is one of them, right? I mean, clear infrastructure and cloud strategy you spoke about. And there are several contributing factors. So, you need strong change management, robust program governance, best practice-led frameworks, continuous learning enablement. I think learning, I remember when we were getting inducted into this program, even before we were brought in, we were actually put to test by Nokia in terms of share whatever you learned from your programs. You keep saying that, you know, sort of you've done this and then done that. And I think a large part of what we built in the cloud smart framework, we had to demonstrate and show how we have seeped in those learnings and created that. And that actually went a long way in doing what we were doing with you, Nokia. And I think the second very key important part is the complexity. The whole complexity that comes as a large R&D company. Nokia has a mix of estate, right? I mean, a lot of on-premise and private cloud. But most, there are a lot of workloads that you can't migrate to cloud. And as you have seen with very large asset-heavy customers, the complexity of these workloads, which cannot be taken to cloud, plus then you've got a private cloud and then you've got migration to Google Cloud. One of the key things was how to have a uniform operating layer with a consistent user-end-user customer experience. And that was the objective that was set for us, that you have to have a seamless experience for the end customers and consumers, irrespective of which, where the app's at, whether it's on-prem, on cloud, or on private cloud. Secondly, the industrialized services at scale have been used using the cloud smart model that we're speaking about with Genia-infused runbooks, and I think that's come to good effect. And one of the, and I would highlight then three specific architectural principles that Nokia set us out with. One is full-stack observability, which we had to ensure. End-to-end complete automation, ability to orchestrate end-to-end across private, public, cloud, and on-prem, with a seamless experience. And I think finally making sure that we are learning from each step of the program. I think these are the three key takeaways. Maybe Deepak just said the learning part is extremely important. I think we're on this journey now for two years, two and a half years. Yeah. Kind of in a joint endeavor, I would say. Yes. And taking the learnings, adapting the processes, adapting kind of the way we work, adapting our operating model, kind of has been a success factor, kind of being able to kind of really kind of use the learnings we gained from all of those transformations and taking them in. Absolutely. I think this was a key factor just to add to here. Yep. Thanks Deepak for that. And, Bernard, taking Q from what you mentioned, you've come a long way in this journey. So what were your key takeaways or learnings, you know, because there are a lot of customers out there who are, you know, in flight and doing these journeys. And the second part, if you're given a chance to do this, you know, all over again, which is that one thing you're going to do differently? So I'll start with your first question. Sure. So kind of what are the things I can talk about what are good. So focus on foundation. Getting the foundation right is very, very critical. So I was talking about how we set up our Google foundation, for example, on the cloud platform. Having a strategic mindset of kind of what do we want to achieve with this overall, not just lifting and shifting workloads from left to right and hope for benefits. That doesn't usually fly. So it's really about the strategic thinking. How does our compute platform evolve and kind of what is the target we want to serve? So what should the platform be able to do? That was very key for us. I think a very important factor for success to make sure we can serve the workloads. Kind of there's security compliance. So you don't run into trouble afterwards when you want to deploy new services. And all of a sudden you run out of compliance and you get a lot of blockers and questions from your security department or anybody from compliance. Hey, you can do this because that service is not kind of certified or enabled. So spending time and putting focus on that and investing into building the right foundation, I think, is a very critical point. Second, obviously focus on the highest value use cases. So doing everything at once kind of is challenging. I guess a lot of things you have to do in parallel. But the identification of the real business use cases, where do I get the biggest ROI for my transformation? How can I do this with predictability? So not to disrupt my business, not to kind of create a lot of trouble that impacts the business users. We always have to keep in mind, in my case, kind of we have internal clients that run workloads. We serve clients or internal customers. So they need to be able to run their business with business continuity and predictability. So focus on those high value use cases with keeping in mind use cases from a business perspective, very, very important. Because that also creates the alignment within your organization, kind of to build momentum. And third, I think yesterday a number was mentioned, like Google is investing $75 billion this year into new infrastructure and building the platforms. So we are also capitalizing on the partner ecosystem. So you can't do this alone. I think as an organization, we would not be able to kind of keep the speed up with those type of capabilities like Google or partners are doing. So using partner ecosystems, using partners with capabilities to support that journey, accelerate the journey, help in analyzing was a very, very important factor for us as well. Like to keep the speed up. Otherwise, things might have slowed down very much. Definitely. Thanks a lot, Bhan. I think I completely agree in terms of having very robust and strong foundation in keeping the peripheral functions also in terms of larger strategy of modernization that you're taking. Absolutely agree with you. And also, you know, at the same time, moving up the value-tree metrics, the use cases that you spoke about. What is the benefit to the business or your users that you're providing? And I think with GenEye, the touch points to business is only going to increase. So we're looking forward to that. Deepak, next question for you. So we've been seeing and hearing a lot about GenEye. And I want to know that GenEye is disrupting the status quo, definitely. So what is Etcirtag doing to be relevant in this space and leaders in this space as well? Do you want to share some thoughts about that? Yeah, sure. I think, firstly, we are seeing that that option has started, now started scaling up for several customers. I think that is one prominent thing. And there's a clear need to, we also see the other side where the headwind is always that too. We need to establish trust with the GDI, AI-baked offerings that we have got before we commit them to production. And there are perspectives on the ethical side, the reliability side, the regulatory side that we need to address. Employee upskilling, enablement is a hugely important topic which can't be underestimated. Beyond the technology components which we are all trying to crack, I think the larger frontier lies there. We are also handling a lot of challenges with the clean data availability and preparing the ground for customers in that area. But I think the good, from an HCL perspective, if you look at it, we have a clear method to help customers with respect to these challenges of adoption. So beyond just cracking the platform and providing all of that, we need to make sure that we are able to enable the customers on this journey, establish the trust, give the governance frameworks, bring the best practices, etc. And I would call out that we have invested in what we call AI labs. And labs, AI labs are obviously a lot of physical, number of physical global locations in the HCL, but can be virtually taken to our customers to help at various points through the lifecycle of adoption. And very interestingly, you have the AI pop-up labs at our booth where you can walk in and work with AI experts to build an idea to MVP, an actionable MVP within 30 minutes. And it's been one of my favorites, so please do visit the booth to experience and witness it. But this is obviously a small scale, kind of a short, you know, sort of experience for you to sort of immerse yourself in. But that just goes on to tell you that we are helping to train a number of customers, enable, coach, certify their teams, etc. as a part of the AI adoption topics that I was talking about. And we have what we call idea to impact workshops to start with, which take you from hackathons to POCs to proof of value workshops to MVP, using real-life customer apps data so that the customers, the business can actually experience how the final solution is going to look like. And that comes out of the AI force platform model that we have. Governance is then an extremely important topic, and we bring frameworks which are based on best practices and then tuned and tailored to customers operating environment, and that is a very, very important topic. And finally, I think what is most important is, as I was talking about in the second epoch right now, which we are going through, and now with Agentic coming in, the business case is now turning positive. The whole acceleration, the whole multiplier effect that Agentic is going to have, especially we are at the cusp of that revolution, I would say. We're seeing more agile delivery models that are coming out and solutions that are getting developed. And that will help, and we are seeing that business cases turning positive, the in-year savings are becoming positive, and that's easier to demonstrate. So we are actually demonstrating savings by looking at, you know, areas like where can you do quantifiable technical debt reduction, license costs optimization, fin ops that you spoke about Bernard, which is an extremely important area, efficient operations. You were talking about the ticketless, you know, sort of framework that you were low touch, and whole organization enablement. But I think I would like to add one more very interesting discussion that we were having yesterday, is on the edge. Okay, now 70 to 80, maybe arguably a larger number of, a lot of compute and analytics are shifting to the edge. In case of Nokia, that's true as well, but we are seeing that outside of the telecom market as well overall, and in other industries as well. And the whole power of what we have from Google, Google Stable, obviously, Google Distributed Cloud, and the Distributed Cloud Edge offering, using GKE clusters with AI enablement and everything so on. I think that's the next frontier, and I think that's the place where we are investing a lot, and we are going to, you know, sort of work with a number of customers on that topic. Nokia has its own offering, and I think the opportunities are just huge in that area. And so I just want to talk about that and say that, you know, as a final point, that that is one area you will see and hear a lot from us. Thank you. Thank you, Deepak. And I think definitely the announcement that happened yesterday, you know, GDC on the edge, Gemini in it, you know, looking forward to how it shapes the industry. So one more question for you, Bernard, before we open it for the audience Q&A. How do you see Gen.E.I. impacting your role and, you know, the immediate tactical objectives and the long-term strategic objectives that you have? Because the way the technology is pacing up, development is happening, it's so fluid and innovative at the same time. So how do you see that impacting your role? This is extremely exciting times, actually. I'm kind of leading strategy and transformation in our digital office for our infrastructure. So kind of AI and agent space is unlocking kind of plenty of new cases for us to look into, especially kind of to drive at pace. Kind of obviously we don't, transformation is not about just doing things for the sake of transformation. It's about the value we get as a business, kind of as I was mentioning, our business customers, the Nokia organization. What do we get out of this? How can we do better business? How can we be more reliable in our platform? So I see a whole lot of kind of opportunities for kind of us and for me in particular, kind of driving transformation faster, more efficient across the entire organization. The entire state is impacted. And it's not just the infrastructure that I was mentioning. There's infrastructure layers, there's service layers. We see adoption in our organization with AI services that have to be managed on the cloud as well. So it's a huge area kind of that I'm very happy to look into. And there's obviously short and midterm goals. So if you ask me as kind of leading transformation, I was going to go faster, obviously kind of go as fast as we can. Then obviously there are other other sides of the metal kind of that kind of might be more considerate, which is also very important, like security compliance and other aspects. But the real potential I see, and that's the impact then on my role in terms of driving the transformation is it's like a tool set. It's like an entirely new tool set at the hand of every transformation manager kind of to define how do we get to that end state faster and more efficient. So for me personally, extremely exciting. So very much looking forward. That's a really good insight. Thanks. Thanks for sharing that perspective, Barnard. Okay. With that, we open for Q&A from the audience. If there's any question you want to ask our panelists. How are you actually measuring success in ROI as you're adding generative AI into your cloud transformation journey? Oh, thank you. I'll start over with the mic. I'll start over with the mic. What is success at this point? What is it? What is success at this point? What KPIs are you tracking? What is success at this point? I can't start with this. So number one is cost. It's very simple. So, if you take an AI-enabled transformation, I was talking for example about database transformation or workload transformation. transformation I was talking for example about database transformation or workload transformation so the ultimate target is kind of to run this this workload more effective that translates into less cost so kind of then there's it's a very simple calculation on the business case side can I use an AI tool AI kind of enable transformation that accelerates the transformation from a high cost to a lower cost and that is the measurement kind of that drives a lot of these transformations and I would just like to add to what you said but not and without our experience is exactly the same obviously there are a lot of intangibles that come with a from a KPI perspective a lot of intangible cases you've got business availability and you know sort of agility obviously on the business side you've got higher revenue etc but I think cost and being able to or on the other side you can pull was possibly have a business case based on ability to generate new revenue channels these are two areas which we are seeing the maximum intake obviously we've got a lot of intangibles as I keep saying and which which which is a big portion of the business case but I think this always starts with the tangibles first thanks for not thanks Deepak I think you've got a question out there hi thank you for the good session so I have a question around with the way AI is evolving I imagine a near future where we'll be able to download the agents just like we download Python packages Java packages node node packages and just you know plug them use them in their in our operations and use cases so that could massively accelerate time to market for the intelligent apps so do you think like we are already there and what are those gaps that we need to fill in to really be in that space where we just you know use whatever is available in the market for instance you one of the slides you mentioned that no ACL you guys develop like 45 agents one of the agent probably is to modernize the application once you have migrated the work workloads into in the cloud for now maybe you don't have any plans to make it open source of but in the future for instance someone develops agent they may be perhaps that you just open source it so do you think we're heading in direction and what are those gaps that need to close in that's a good question I think you're absolutely right just having agents doesn't mean that you've got the adoption started right I think but it starts that's the first foundational layer that you have to build and there are I was alluding to some of the facts where we need to have a law which would not necessarily you know only revolving around the whole agentic framework but generally Jenny I in particular but with agentic you to understand that bringing a set of agents your ability to construct the whole orchestration layer almost like a human like you know sort of trust and reliability framework the whole governance model around it needs to be stitched for the customer and not just from a technical standpoint and I think that layer of you know and there are there are some low I would I hate to use the word low hanging fruits but I think there are slightly more easier cases which way where you can actually which are more internal in the enterprise which are good starting ground for that the customer service or ticket analysis or you talk about certain places where you know policies internal policies or search within the organization these are kind of slightly early starters but when you come to customer facing or on business you know sort of on the revenue side then I think that there's going to be a lot of lot of tires being kicked before you start adopting so the frameworks are coming out the open protocols are being written there are a number of protocols that are getting announced I don't think any of them have been industrialized to that level but that's that's where the direction is and I think that adoption journey is going to be more than these technical components that we have to when we are working on all of them here by the way Thanks Deepak I think we have time for one more question yeah you can squeeze in the mic there please I think we're over time so we can take it offline yeah thank you okay so thanks a lot for you know joining us today for the session thank you