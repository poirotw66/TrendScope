 Welcome everyone, thanks for being here with us today. It's going to be a very exciting talk and it's going to be a very practical talk and what we're going to cover today is we'll look at how Shopify runs the biggest business event of the year with GKE. So lots and lots of stuff to learn. Let's start with some introductions and I'll ask our Shopify colleagues to start with themselves. Yes, hello, my name is Justin. I'm an engineer on the infrastructure group at Shopify and this group is a ragtag group of individuals who run all the compute, network, databases, storage, search, everything at Shopify that runs the platform. Jeremy? Yeah, hi, I'm Jeremy. I'm working with Justin for now seven years on the clone alpha at Shopify with a lot of challenges on the same, about the same thing. Yeah, exactly. Victor? Yeah, hey everybody, I'm Victor Salve. I'm a product manager. I'm focused on GKE infrastructure, auto scaling and yeah. Yeah, and I'm Roman. I'm one of the product managers on the GKE team covering our core capabilities. So again, excited to have you here and I'll give it to Justin to kick us off. Thank you. Okay, folks. Hello. Welcome. It's an honor to be here on stage. I won't reintroduce myself. I got my speaker notes to reintroduce myself, but that's, you know who I am now. I'm excited to share with you today how Shopify handles our highest traffic time of the year, which is called BFCM internally, which is Black Friday, Cyber Monday, and how we use GKE to power that event. So first up, what is BFCM? People in North America, would know this. It started in the US, but has grown to be a global phenomenon. It kicks off the shopping event every year or the big shopping season every year, and it's the day after American Thanksgiving and follows through the weekend. Shopify prepares for this for months ahead of time. We run large scale tests where we scale our entire systems up to the levels we expect for that year's Black Friday. We run, again, many of them through the year in order to stress the infrastructure and make sure all components can handle that scale. And Shopify is a constantly evolving platform. So developers are shipping changes to the core applications and all the applications that run Shopify. And so running these tests ensures that we gain that confidence before the big event. And this is a quick look at last year's Black Friday, Cyber Monday in 2024. We share these publicly in our press releases on Twitter, X, and LinkedIn, and all these things. We handle a ton of traffic during this period, tons of requests to our edge, trillions of database queries and writes. And this year, or last year, I should say, we hit that peak of 284 million RPM. You can go and check this. There's tons more on this on our press site, and you can go and check that out if you want. So there's another way to look at this scale. We have a team internally that every year, it's a bit of a pet project. It's been going on for about 10 years or so. Started with our CEO, Toby, wrote the first one himself. But we make this thing called the BFCM Map. It started quite simply 10 years ago, and it's grown into something quite amazing. The team really outdid themselves this last year. And what it does is it takes a real-time sales data checkout from the world, real-time via our event stream system, and feeds it into a 3D visualization. So to give you an idea of what you're going to see here, it is a fully 3D. You can, in your browser, look around a spaceship above the globe. Every dot on the map is a sale. Every arc that you see that travels around the globe is the, as you can imagine, like a sale, like a package going to the destination. And anytime you see fireworks, this is a merchant's first sale, which is a really big event for Shopify. That means that at this, at that exact moment, someone had the first sale from a customer, a real customer on their site. So here's what that looks like. And this is me with my mouse pulling down the launch pad. Now this is a replay of the peak of Black Friday last year. This map, which I can't do now because we are, you know, just looking at the video, but you can go to bfcm.shopify.com on your phone or on your laptop and play with this yourself. This is full of really neat details here. The team even internally made a VR version and you could put like a VR headset on and be in the spaceship. You can turn the gravity off. You can play with all of the buttons and knobs. The team also added a MIDI output. And so you can plug this into MIDI gear and listen to the sounds of the sales happening at that moment. This was up inside Google's compute team's office. That was a nice thing to see as well in London, England while they were watching the computers along with us. And everyone inside Shopify watches this as well. It's like in your tab the whole time watching what's going on, making sure that the numbers are going in the right direction. And the infrastructure team makes sure they stay up. That's our job. Yeah, like I said, it's fully interactive. So please go take a look. It also has a bunch of Easter eggs. Paul will open the console and see if you can poke around. And I'm sure the team will have some really amazing stuff this year. Here's a look at our current global infrastructure. We run on GKE and GCP in general. We use lots of Google services. We currently run in a number of regions around the world. And our aim is to handle those, to request that users make the Shopify's platform as close to where they are physically in the world. We are constantly evaluating and reevaluating the impact of spinning these regions up, cost, performance, and impact on latency for users. And we can spin these up and down as we need to. So right now we have something in Sydney, Australia, for example. We could move that to Melbourne and we can move it to Taiwan. It just depends on where buyers are. But our fleet kind of is that big, big fleet there. So what's critical to Shopify here is performance, scalability, and availability. It is critical that we are up, especially during Black Friday. And all of the work we do in the infrastructure group is to make sure that is true. So now I want to talk about how we used GKE and a new feature called custom compute classes in order to handle compute availability in some regions. This example here I have on screen is an example of where we have two node pools, both running N4 machine types. One in node pool one is in zone A, node pool two is in zone B. And this is just an example. So sometimes every region has different zone letters as we all know. But in this case here, we want to primarily run in zone A. And this is because of performance, low latency on the network, various cost implications. But sometimes the compute is unavailable in this zone. Could be any reason. Could be quotas, availability on the compute side from Google. And so custom compute classes allows our applications to automatically spill over into zone B. This is okay. In this case, we're okay paying that penalty of performance in order to gain that availability. And so during this time period where we are in the second zone, once the compute becomes available in zone A, custom compute classes moves our workload back to zone A, which is ideal. This is a good example of where we have the same machine type in both zones. Here's an example are two different machine types. And in some regions, we have availability for an N4. And then we do not have the ability to run N4 in the second zone. And so we'll make the consideration to run N2s in the same zone. So in this case here, we're optimizing for that network latency. And we're okay with the compute performance being slightly worse on the N2s. And this is an example where compute classes give us that flexibility. And then we can mash them all together. And so here's an example of where we have N4s. We want to optimize in zone A, N4s in zone B. But then if those are both out, we want to go back to N2s in zone A. And this setup here is basically what we ran for Black Friday last year. We were able to customize per region these node pool configurations. And that meant that in Singapore, we were all N4 across multiple zones. In Sydney, we were in two different machine types across multiple zones. In US Central, we had multiple zones and machine types and shapes of machines in some cases where the application could be on 80 core VMs or 48 core VMs. And we were allowed to kind of customize that. So it is all the compute class stuff ran BFCM last year. So all those big numbers and that massive scale was possible because of GKE, because of Google's scale, and especially because of compute classes, it removed a ton of operational complexity for us and allowed us to simply serve our customers the best way we knew how. This is just one case of how Shopify uses compute classes. I'm going to hand off to my colleague, Jeremy, who's going to walk you through some other areas where Shopify is running compute classes. Thanks, Jeremy. Jeremy. Nice. So yeah, we are using more and more the compute classes and I would like to present to you another case. Recently, we integrated the compute classes for a small case. So usually, when we have to upgrade the cluster fleet to a new GKE version, what we like is what we prefer is to recreate the cluster instead of doing the in-place upgrade. Why? Because it's easier for us to manage the resources. It's easier also to manage the risk. But with machine learning things on a new application on a machine learning cluster, we have new challenges and we have been able to resolve some of them with compute classes. So I'll try to explain how we deal with GPU resources, especially with GPU resources with compute classes. So let's take a look at a small case. So usually we have a cluster with net pool. In this case, we have a three net pool with a reservation. In this case, we have an application with two replica and two net pools and the reservation is fully used in this case. So if we create a new cluster, we deploy the same application on the new cluster. We don't have the resources from the reservation. So what we did, we added two new net pools. The A3 on demand and pool. And another one, A3 spot net pool to have a fallback. And we added a complete classes, a complete class for this application to manage that. So let's see how we can... Sorry. No, it's nice. So when we have to migrate to an application like a machine learning application using a reservation for the GPU nodes, we create a new cluster like this. So this new cluster uses exactly the same configuration, the same shape of the cluster of this type of cluster. So we have three net pool because we have added just two new net pool. One with the reservation configuration, another one with the on demand nodes, and another one with spot nodes. So after this step, when the cluster is ready, when we check it, all this process is automatized almost for all our cluster, especially the cluster commissioning and the cluster decommissioning, but also the application migration from one cluster to another one. So after that, we can deploy this same application, but because we don't have the reserved node resources, the complete class will provision two new on demand nodes for the application with the two replica. We still have all the traffic on the first cluster, and we slowly, the automation will slowly shift the traffic from the old cluster to the new cluster because all of the things looks good. So that should shift the traffic slowly to the new cluster. When we still have a good situation with all traffic to the new cluster, we can scale down the old application, the old application of the old cluster, and that will release the reserved nodes. Because we have a complete class, this complete class have three level of priority. The first one is A3 with reservation, the second one on demand on the last one spot, but we also activated the reconciliation to use the predefined resources by level like this. So that will do because we have a new resources available on the reservation that will commission, that will commission a new node with the reservation node pool. Sorry. So we have the complete class that scale up the first node pool, but also we have the pod distribution budget to don't do that at the same time. Because if we do that at the same time, we can have some issues. We can handle all the traffic. And then because we have some resources from the reservation, we can use all the reserved resources like this. So what we can say with this usage of the compute class is we have been able to manage reservation, especially the GPU resources for this type of cluster without to do a lot of thing. We just add two definition of the two new unit pool on the template of a cluster, this type of cluster on. We deployed the compute class with the application. So it's very simple, but we have been able to do to take or integrate that to our standard automatic automation of cluster commissioning, decommissioning and application migration. So as you can see, with the Justin example on the, this is this example on all others. We have all those small example of that we use as a compute classes. We are more and more using small little feature like this on that a lot to, to solve on to, to integrate our process. To a commission and decommission cluster to manage all of cluster cluster also to, to handle the, the, the load of traffic. But I let, uh, uh, Victor to, to speak a bit about, about all this feature, especially the details of the compute classes. Now we, uh, we can configure this type of thing. Yeah. Yeah. Appreciate it. Okay. Yeah. Yeah. Really exciting to hear from Shopify and how they've been utilizing GKE, um, and the new, the new compute class capability. I just wanted to take a moment, um, and unpack a little bit the tech and just talk through the feature at just kind of a raw feature level. We've seen the use case now, both for traditional compute, right? Uh, that, that Justin outlined and also AI ML, which, which Jeremy walked through, um, both are our target, um, you know, use cases. Very quickly, if you're unfamiliar with GKE, GKE is, um, you know, the fully managed, it's the most automated and scalable Kubernetes platform. And it's run by the largest contributor to open source Kubernetes, which is us. Right. Um, but there's this challenge that I think platform teams face, right. Which is how do we scale to meet surge demand, right? You can over-provision. You over-provision, then you have the issue with respect to cost, right? You have extra resources that you may not need, uh, for every moment. And how do you do that, uh, without over-provisioning? Well, you can auto-scale, right? So auto-scaling is powerful, but you need to do it quickly. You need to do it with the appropriate compute shapes for the job, right? Um, you also need to have a system in place that doesn't overly complicate the developer experience overall, right? So you don't want to make this so complex that your app teams are just fumbling with the, with the technology either. So we've introduced this new notion of compute class. This launched to GA back in August of 2024. Um, and really the idea here is to provide you with a declarative in cluster API. So this is a CRD it's available as of, uh, 1.30 in, in, uh, in all GKE clusters automatically. It's not something you have to manage or install. It's something we manage for you. But what it does is it provides you with the opportunity to define at the highest level fallback compute priorities, which I think both, uh, both Justin and Jeremy talked through. But just to be clear, the idea is you can say, look, I would like to have my set of workloads that consume this particular compute class to land on the following priorities. And in this example, I just have an N4 spot as my number one priority. Number two, I have N2D perhaps maybe if, and, and, and four is not available in that particular, you know, location. Um, I can add some attributes. Like I want a minimum number of cores. In this case, I say, I want min core 16. I also want it to be spot. In this case, I'm trying to save some money. If those spot resources are not available. And as we know, they come and go. So they might not be available. Then I'll take an N4 standard 16 machine on demand. So there are different ways you can, you can, uh, work within the CRD to basically, uh, illustrate your compute preferences. You can simply say, look, I'll take any N4, right? So machine family, you can say, I'll take any N2D with a certain amount of cores with storage options with whatever you need, you know, for the job. Or you can say, look, I want a particular machine shape. I want an N4 standard 16, um, and so on. You can also use node pools, right? So if you have predefined node pools, you can use those and say, look, here's the order of preference that I want to fall back between my node pools. Or you can use a combination of node pools in these descriptors. Okay. So it's very powerful. Encourage you all to kind of check into it, look at it, see if there are use cases for your particular, uh, uh, scenarios. Uh, we, we, we support a number of different things. Of course, GPU, TPU, um, traditional compute, uh, reservations, as I think, uh, you know, Jeremy talked about as well, are also supported. So we can, you can explicitly consume a particular reservation and fall back between reservations. One interesting, uh, capability with this feature is the ability to auto reconcile. So say you have a scale event and you happen to have, uh, an outage with respect to, let's say we don't have spot for your top priorities here. You land on your third priority. It's more expensive. Okay. Okay. So what are we going to do? GKE will auto hunt in the background for availability of your top priorities and then actively move that particular workload to the higher priority. Right. And this happens, uh, it's an option. So it doesn't automatically happen, but you can turn this on and it will respect things like PDBs and not disrupt your, you know, safe to evict annotations and so on. Right. Node consolidation. So another use case for this, if you don't have a, if you don't have a fallback use case, you can simply use it to control how quickly we consolidate auto scaled nodes. So when you scale up today with, with GKE, there's like two levers you can kind of choose from balanced or optimized utilization. They have different characteristics with respect to how fast they, um, consolidate away nodes. Again, for cost savings, you can now explicitly set a number. You can say, look, CPU threshold hits X. I want to consolidate this node. Or if this, if this node is underutilized or it's not utilized for a certain amount of time, you consolidate it away. Okay. Let's get into the actual CRD and what it looks like. Um, you know, it's basically something, hopefully the general structure is relatively familiar. It's a YAML definition. Um, you can see kind of where some of these features that I talked about come in. So in the very top there, I have active, uh, reconciliation, seek your, seek your priorities actively. Um, the next block down says node auto provisioning, uh, node pool auto provisioning. So this will automatically create node pools for you based on just high level machine descriptions. I want an end floor. I haven't created a node pool for that. Please do that for me. And it will do that. The block below that represents your priorities. So there's all your priorities that have been defined. The end for spot, the machine family and 2d is next and so on. And then finally the consolidation delay down below. Now there's a lot of other things you can do today. You can now set sys cuttles. You can do all sorts of things, uh, storage options, local SSD. So, so on, all of that can be kind of spec'd out in this. This is a relatively simple example, but there's a lot of richness there. Now, how is this consumed? I talked about developer experience being really simple. It can be consumed in two ways. One, you can set a namespace default for this namespace. Use this particular compute class. The developer doesn't have to know anything about compute classes. They just deploy their application and it will consume it. And, you know, into that particular namespace, or you can explicitly select for it with a node selector. Okay. Accelerator use cases. I won't get into this too much, but you can imagine this, this extends to accelerators as well. So we have specific flags that you can go with here, you know, with respect to GPU type, the count and so on. Of course, reservations are also, you know, key with some accelerators like the H100s. Um, we also support TPUs and topology and so on. All right. So one last thing I wanted to show you is just a real world scaling example. Okay. So this graph that you're seeing is from an anonymous customer, not to be named customer. It's not Shopify, by the way, but this shows, uh, a scale, a scale event over time, scale events over time. So the peaks you're seeing are scale events, different scale events. Okay. Now, what are these colors? The colors represent the priorities in their compute class. So I talked about the priorities and the fallbacks, right? That baseline color, that sort of pukey green color, that's their first priority. Okay. So normal operating mode, they're in their first priority most of the time. And then when you see those peaks, you'll see other colors. And those represent different fallbacks that are being traversed. So for whatever reason, I don't know literally what underlied this, but in terms of actual machine families, but when they tried to scale up to say a thousand nodes or so in these peak events, you can see that it incurred additional, it required fallbacks to additional compute classes. Now, had they not had this defined, what would happen? They would have been kind of stuck at that first level and a lot of frustrated and users, right? Because they're not scaling to meet the peaks. You can see also that it scales down really quickly and scales back up and down periodically throughout this timeline. Okay. I'm going to invite Roman up to talk about other aspects of auto scaling and other aspects of performance. I'm going to hand it over to Roman. Thank you. All right. Thanks, Victor. So let me ask you something, folks. I mean, you've watched this. How many of you are already using compute classes today? Jackpot there in the middle. Some more people there. Yes. Perfect. How many of you heard about it for the first time today? Awesome. So I hope it's time well spent because one thing that I want you to internalize as you think about GKE and what we're doing with our investments is that compute classes is our way forward to give you this predictive way to manage your infrastructure, to give you the predictive way to consume your reservations, to consume your spots, your own demands, to be very precise in terms of compute that you want to consume because maybe you have some special discounts. It's a big deal for us and we're very much invested in this. But then there is more. And let's talk about what more is. We are on a mission as GKE and our mission is to put in your hands the next generation near real-time, vertically and horizontally scalable compute that provides capacity when needed at the best price and performance. And you've seen a part of that promise now with compute classes and how we help you provision the capacity when needed. But then there is the best price performance aspect and there is the near real-time compute aspect. And before I go and explain what's that mouthful or actually show you an example, let me ask you something. How many of you here are running services on which end service latency and response time matters? Everyone. That's exactly it. You know, if you're in the business of running software in cloud, you care about your APIs being responsive, your websites coming online in time, and by the way, you don't want to handle like a ton of over-provisioning. So, we're trying to make it happen for you out of the box. And just to give you an example of some of the advancements that we are landing and we've just announced yesterday, I'll go through some demo. And what you'll see in this demo is a completely new experience that we're bringing starting with Autopilot that required us to completely revamp the GKE stack. All the way from the work we're doing in hardware with our partners in GCE. The new container-optimized compute that I'll show in a second. Enhancements to cluster autoscaler. Horizontal pod autoscaler. All of this has undergone a complete rework. All right. So, yesterday we announced the new container-optimized compute for Autopilot that can deliver up to 7x faster pod scheduling times. Let's have a look at this together. So, in this case, what we'll see is a very simple test. In this test, we will try to schedule 10 pods on the existing GKE Autopilot stack. Let's say version 129 or 130. So, we're trying to add 10 pods here. This is like the normal scheduling time, something you'd expect from any GKE system today. I know it's been very fast. I don't know if we can rerun this once again just to make sure that we're all seeing what's happening. It takes about 100 seconds to add a pod in the current environment. Let's have a quick look at this again. So, this is the normal stack, something that you'd come to expect from any type of compute environment. So, now what does the near real-time compute direction look like and where are we going with GKE? Let's look at the newest GKE stack, something that you can actually try today on the rapid channel with Autopilot. Let's have a look at that. So, watch it because you just might miss it. Same test, trying to get to 10 pods, bum, bum, running. Okay? This is what we call near real-time compute. This is where we're pushing Autopilot. And, by the way, we know that many of you are using standard clusters. So, as we announced yesterday, we will be bringing that technology of container-optimized compute with resizable elastic compute underneath it to standard clusters as well later this year. All right. But then the question is, okay, that's fine, 10 pods. No one cares about a test like this. What you care about is you have real environments. They need to auto-scale. They need to respond to the user demand. So, the question is, what does that performance mean for your application latency? Let's have a look. In this case, what we did is we ran an auto-scaling test. It goes for, I don't know, many, many minutes. It's sped up a bit. We're going from something like five pods to about 40 pods. It's your normal auto-scaling scenario. It could be an API of any kind. Because we have a new revamped stack that, you know, with a change in HPA, we'll talk about that. New cluster auto-scaler. New underpinning container-optimized compute. You see that pods are actually scheduled really, really fast. Let's see what it does to your application. So, in this case, we ran Hay as a benchmark to show us end-service latency. And this is what the latency of an end-service, it's an HTTP latency distribution on an existing autopilot stack looks like. So, you see it's a bit all over the place. And there is quite a bit of concentration of requests that really, you know, the 50th percentile are responding at 1.4 seconds. At 90th percentile, it's 3.8 seconds. I don't think that this is an acceptable latency on any API, really. I don't think this is a usable service. So, in this case, you'd probably over-provision the system just to give you a bit more responsiveness. Let's look how this would look like on the new stack. Exactly the same scenario. You see the 50th percentile is actually 370 milliseconds compared to 1.4 seconds in the old stack. And at 90th percentile, we go up to a second, which is, you know, four times better than you'd get in the old stack. So, same setup, less over-provisioning, better handling of your service latency needs. All right. So, that's available in Autopilot today in Rapid Channel. We'll be propagating it to regular and then eventually to all other channels later in the year. Now, this is just one example of those investments. Let's look at other things that are happening in GKE to help you build infrastructure for the critical business use cases that you're running. One of the things we've been advertising, and you've probably seen the slide now 10 times, if not more, is our support for 65,000 nodes. And, of course, you know, most of the customers we talk about, they're telling us, hey, we don't care about 65,000 nodes. We don't run 65,000 nodes, right? You're telling us about this. But 65,000 nodes has massive implications for what we do for each and every use case out there. Even in basic things, just imagine for a second what does it take to upgrade non-disruptively a 65,000 node cluster. So, when we stretch Kubernetes to be able to support this level of capabilities, we improve the reliability of the system, we improve the upgradability of the system, we push the boundaries on networking, we push the boundaries of compute, we benefit from things like custom compute classes that really need to provision out this massive scale and orchestrate environments. So, this is how you can think about the value of 65,000 for you and your business and why it matters with GKE. But, as I said, we also revamped the very core of GKE capabilities, starting with Cluster Autoscaler. So, Cluster Autoscaler has undergone a complete rework where we have bumped it up to support up to 500 node pools. For those of you running large environments, if you tried our GKE just a year ago with 100 node pools, you'd probably be looking for trouble. Today, we're actually capable to support 500 node pools, but also our capability to schedule pods really fast has improved. In fact, if you schedule 5000 pods on GKE today, time to scale would likely be half compared to what you'd see in the previous versions of GKE. Same is with Horizontal Pod Autoscaler. We have literally outsourced the brain of Horizontal Pod Autoscaler out of the node. You know, it's not running on the node anymore, and we've made HPA about twice faster compared to what it has been before. This is a picture. It's not a picture from us, it's a picture from one of our customers showing how with new HPA, we are actually getting to provision infrastructure much faster than before. But this also comes with extreme levels of reliability, where per cluster we now are capable to support 1000 HPA objects with SLOs. Vertical Pod Autoscaling has seen massive adoption with our customers. This thing here is actually the customer adoption trend of VPA. Three years ago, resizing your pods manually was the name of the game. You want to set resource requests and limits, and you'd want to tune it, and you'd want to have a process of cost optimization. We've seen a massive shift in automation of this work, and actually we've seen a 40x increase in customers who now use VPA with automation to actually simplify the operations and resizability of their workloads for that best price performance. And by the way, what we have been doing on top of basic VPA is we've been very much invested in open source to bring the new in-place pod resize capabilities to GKE. How many of you have heard about in-place pod resize? How many of you think this is an exciting evolution in open source? Lovely. That's the level of feedback. In-place pod resize changes completely the resource management model of Kubernetes. It allows us now to change resource requests and limits non-disruptively in Kubernetes so that not only do you provision infrastructure at the right time, but also you can provision resources to your pods when they need it without actually having to restart and disrupt the pod. And what you'll see very soon this year is new capabilities that will be coming into GKE that are actually backed by this capability and will open up an entire new era of new efficient use cases for the databases, for your Java workloads, for your CI, CD applications, so you can provision those at the best price and performance. Image streaming has been lately in the news with GKE with the advancement of Gen AI. And specifically with Gen AI, we have very, very large images that need to be downloaded to the node. Now, what has happened is we've been investing pretty much in image streaming to make it as much universally available to all of you out of the box easily. And if you haven't tried it yet, we really recommend that you do. Here you see a very simple example of pooling an 8-gigabyte image without image streaming enabled and with image streaming enabled. We've seen on images of 8 gigabytes, sometimes performance improvements of up to 30x on image startup times, actually giving you the startup latency improvement and the improvements to your application that you desire and seek with large images. We've G8 our traffic based HPA last year. And we've seen it super being becoming super popular with those workloads where CPU and memory just don't cut it. But also one important aspect of us moving in the direction of more precise horizontal pod auto scaling is that we are actually completely revamping our custom metric stack. And again, what you'll see later in the year is more of a native out of the box custom scaling experience with GKE. And then just two weeks ago, we released our new embedded monitoring dashboards because we know that you care about latency, but we know it has been extremely hard to get the level of observability that you need at every layer of GKE, at node layer, at pod layer, at image download layer. So today out of the box with GKE, you can see the type of things that matter to you. Image pooling, HPA scaling, node latency. If you haven't seen it yet, go ahead and check it out. It's very exciting and you don't have to do anything with this to make it work. Okay, so GKE is invested to help you handle your service level objectives at any scale, enabling confident execution of business critical events. This is what we're all about. What does that mean? Well, scalability to up to 65,000 nodes, as we discussed. Fast ramp of consumption to target. So not only do we care about scale, but we are also invested in making sure the time to scale is as short as possible. So you can go to your 100 nodes, 500 nodes, 1,000 nodes in as short time as possible to power your use cases without much of a provisioning. We've introduced a new advanced infrastructure consumption API, the custom compute class, built to fulfill infrastructure with intelligent fallbacks at scale and cost effectively. And then low latency workload scheduling backed by investments in compute startup latency that I have just shown to you on GKE Autopilot. And of course, enhanced observability, security, upgrades suited for large consumption. So a call to action to all of you. If you haven't yet experienced custom compute classes, this QR code will take you to the page where we talk about it. Have a look at it. Explore custom compute classes with us and give us feedback. And of course, we're interested in your feedback. If you're willing to take a second and fill in the form and tell us what you think about this session, we'd love to learn more. Thanks for coming, folks. We really appreciate your time. Thank you. Thank you. Thank you.