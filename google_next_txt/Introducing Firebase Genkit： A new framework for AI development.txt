 Well, I hope everybody had a good night. It was a good party if you made it. If not, hopefully you still enjoyed yourself. Thank you for being here. We are going to talk to you about GenKit today. I'm Dimitri. I'm the group product manager for a bunch of stuff in Firebase. GenKit is one of my products. I'm really excited to be here with Chris. And Esther, Chris, you want to go next to introduce? Absolutely. Hi, everyone. I'm Christopher Gill, and I am the product manager for GenKit, and I'm really excited to tell you all about it. I imagine you haven't heard nearly enough about AI or agents yet. So I wanted to give you one last presentation to make sure that you learn something about AI at Cloud Next. Chris has been saving that joke for days to tell me. Let's make him feel good about it. I even look at the notes. Yeah. It's well practiced. All right. Esther, take it away, please. This is where I wish my last name was Smith, so I could be like, and I'm Agent Smith. No. Hi, my name is Esther. I'm not wearing a Firebase T-shirt today because I'm actually a customer engineer at Google Cloud. So I help to work, support amazing enterprise customers using the best of our amazing technology, including, including, including GenKit, which I'm really excited to come here and help present and do a little bit of a live demo, which probably will go right or wrong. We'll find out. It'll be good. It'll be good. Perfect. What could go wrong? It's a live demo. What could go wrong? It'll be fine. Definitely not the Wi-Fi. Okay. All right. Well, I want to get us started, and I love to start with questions, so I'm going to go off script for a minute and force you to raise your hand. If you were at the party, you raised your hand a lot yesterday, probably, but let's do some more of that. Yeah, there you go. Some of you guys know what I'm talking about. Who here has a question to kick us off is actually using large language models, even if you're just exploring it, but, like, for work purposes? Can I get a show of hands? All right. Really, really, really good. Does anybody have a really exciting side project, their next startup or their next hobby thing that they're using large language models with? All right. People tinkering. I love it. Anybody have LLMs in production in any of those scenarios? Okay. You're actually a more excited bunch than usual, which is great. I feel like this LLM thing might take off after all, Chris. It might just happen. Anybody here using LangChain or LangGraph? It's just a bunch of random things together from our friends there. Versailles SDK? Okay. All right. One hand, I think, or about that. Does anybody here want to use LLMs, but, like, you don't know for what? You're excited, but you don't, yeah, you don't have a use case. Okay, a few hands. You'd be surprised. A lot of people raise their hands for that. There's a lot of, like, well, how do we use this thing? Well, this is a great crowd. Thank you for being here. Let's talk to you about GenKit. We created a product. So we're the Firebase team, but we created a product that is actually not a typical Firebase product. It started off with having the name Firebase on it. We recently took the name off because it was causing too much confusion. So now the product is just called GenKit. It's an open source framework, and it's meant to make your lives easier working with large language models. It's still built by us, the Firebase team, but it's definitely not a service, and it's definitely not limited to Firebase. So we're excited to talk to you all. I know there's a lot of probably cloud-run developers here and other things where you need broader capabilities. So what is GenKit? It really is a product that is trying to give you a framework, tooling, and observability. Now, you can probably just, in your minds, imagine the very, very stereotypical loop of software development, right? You've got to start building the thing. You've got to test it. You've got to tune it. You've got to debug it. You've got to deploy it. And you have to have something you can depend on while doing all of that because, let's face it, large language models are changing, evolving. Which models you need to use? Do you need a RAC database? Do you not need a RAC database? All of these questions mean that your code is taking dependencies on all sorts of things, and hopefully Gen can be one dependency that doesn't fluctuate as much in all of that. And luckily, we have the team here to give you all the details, so I'm going to hand it off to Chris to go jump into the details, and, of course, we'll be here for questions after the talk. We have lots of content, so. All right. Take it off. Thank you so much, Dimitri. By the way, you asked about who's using LangChain, LangGraph, the AISDK. There is one more framework. There is? Yeah, that I would have loved to hear about. Is anyone already using GenKit, by chance? Anyone already tried it out? Okay, there's a few hands there. That's really exciting. Thank you, sir. I appreciate the enthusiasm. All right. I love it. Only one hand from someone who's actively building GenKit. I think the opening act yesterday did a really good job. The guys, like, you know, the main act, sorry. They're like, you might not be a fan of the killers, but when you leave here, hopefully you will be. So we're going to take the same mindset. We're going to hope more hands will go up about excitement about GenKit. Yeah, and if, you know, you want to actively code while we're talking, that's okay, too. All right. So let's get into more of the details about GenKit. So in addition to wanting to introduce you to GenKit, I also have some really exciting announcements that I want to share with you. One is that just a little over a month ago, we announced that GenKit for Node.js is officially stable or officially generally available. That means that you can build AI-powered applications and agents using GenKit.js in production with confidence. Any major, any breaking changes that happen from here on out are going to follow Semver. You'll get a major version update. So this is a version of GenKit that you can absolutely depend on. The next announcement, and this is actually very new as of Cloud Next, is that we also upgraded GenKit for Go to beta status. That means we added a bunch of new exciting features. We significantly improved and stabilized the APIs based on all of the developer feedback we got during the alpha phase, and we are rapidly approaching parity with GenKit.js. So if you love developing with Go and you want to build scalable, highly performant, AI-powered applications, I would love for you to give GenKit for Go a try. And then last but certainly not least, we also announced our first release of GenKit for Python, Alpha. So that means GenKit officially supports three of the most popular back-end languages for you to be able to build your AI-powered applications and agents. The alpha release does mean it's very early, so we encourage you to try it, give us feedback, so that we can rapidly iterate and ensure that we provide an amazing killer, killers, developer experience in all three languages that we support. That one did not go over as I expected. No, but Python's exciting, so we'll have that. Thank you. All right. I hope I didn't kill the announcement with that terrible joke. All right. So now, for those of you who aren't familiar with GenKit at all, you already heard the high-level definition, but I wanted to add a little bit more concreteness to what it is. So GenKit is composed primarily of three main components. One are the open-source SDKs for the three languages I mentioned earlier, for JavaScript, Go, and Python. There's also the plug-in ecosystem. The GenKit core SDKs are built to be model-agnostic and generally provider-agnostic for a lot of different platform integrations. So we have a constantly growing plug-in ecosystem that gives you access to a variety of different model providers, vector store providers, and platform integrations that make it much easier to build your end-to-end AI feature using your providers of choice. These plug-ins are created both by Google and by our wonderful open-source ecosystem of contributors. And lastly is the developer tooling. You'll see more of this in the demo that is coming up, but this is something that I think really differentiates GenKit. When we talk to many developers who are actively building AI-powered features, what we realize is that they need dedicated tooling that makes it easier to deal with all the challenges we listed for building AI-powered apps in the previous slides, something that helps them iterate faster, something that helps them go from prototype to production with more confidence. All right, now let's dive into the developer experience. I know that developers love to see code, so I want to be very concrete about what the developer experience is like for someone using GenKit. So GenKit is very easy to get started with. As Dimitri mentioned earlier, it's not a hosted service. There's not a whole lot of APIs you need to enable to get started with it. You can do so right in your local machine. All you need to do is install the GenKit packages just like any other library you've worked with before, choose a model from the variety of options you have available to you, and start writing code. And when I say start writing code, I mean to get started, really not a whole lot of code. So on the slide above, you can see our kind of like most basic getting started example for all the languages we support for GenKit for Node.js, Python, and Go. And I hope one thing that you notice is that it only takes a few lines of code to do your first generation. We designed GenKit in such a way that it is just as easy to get started as any dedicated model API, but also scales to very complex use cases as your demands grow. So one of the key features that we offer through GenKit is the unified model API. So I already mentioned that we support a variety of different models, but really what makes GenKit more convenient than using, let's say, a bunch of different separate model APIs on their own is that we provide a unified interface for interacting with all of these different models. So as you can see in the code snippet above, you can use the plugins for Google AI, Anthropic. You can have access to like the Vertex model garden and all the many models that are offered there, even OpenAI. And just by switching a single line of code, you can change what model you're generating from without having to refactor the rest of your code base, which is really exciting. If you want to be able to compare models, see what works best for your use case, GenKit makes that very easy to do. However, you can also access provider-specific capabilities. For example, if you want to use the groundbreaking grounding with Google search through the Gemini API, you can do that so that you're not reduced to the lowest common denominator across all the different model providers. Next is structure and type safety. Now, it's pretty easy to generate like a string from an LLM. However, unless you're building a chat bot, you're probably not returning exactly just the string that the model created straight to the user. Oftentimes, if you're trying to build UI components where the data is generated by an LLM, or you're trying to integrate LLMs into other parts of your app architecture, you need to follow a reliable shape and schema. GenKit makes this very easy and compact to do in all of the languages we support. In Node.js, we use ZAW, the very popular schema library. In Python, we use Pydantic, which many people already know and love. And in Go, because Go is awesome and already strongly typed, you can just use Go structs to specify the schema that you want to generate. Now, I hear some people are interested in building agents, right? They're interested in building systems where the LLM is able to make decisions about what functions need to be called, about what steps need to be taken in order to accomplish an end task. One of the fundamental capabilities that LLMs have for that today is function calling. Now, GenKit provides a nice developer experience on top of native model function calling capabilities to help you to find reusable tools that can be used by multiple agents in your AI application or your AI system, and also provides ways for you to specify how many iterations you would like for tool loops, as well as tooling that makes it easy to iterate on ensuring that the right tools are called depending on the use case. Now, if you do need to ground your generations with private data from your company or maybe from a user's data who's using your app, one way to do that is using vector search or retrieval augmented generation. GenKit does provide integrations with various vector store providers and really intuitive APIs to make it easy to ground your models with custom data. Now, oftentimes, if you're building a production-ready agent or work or agentic workflow, it's more than just making a single model call. Oftentimes, you have steps that proceed and follow the model call, or you might have to chain multiple model calls together to get to your end result. In this code example, I am generating a story, and I have multiple kind of dedicated agents or generations that are creating the initial idea, the best idea, and then ultimately the story, and they're all feeding their responses out into each other. GenKit makes it very easy to aggregate all these different steps as part of your agentic workflow into a single overarching flow, is what we call it, that is very easy to deploy as an API endpoint and is also well integrated with our tooling for rapid testing and debugging. Now, prompt management is still very important. We provide support for .prompt, which is another open-source Google project that aims to create a standardized format for prompts that combines both advanced handlebar templating capabilities for more complex prompts, as well as the model metadata that's necessary to create the end generation. What's really nice about this is that you can then iterate on your prompt and really all the data you need to create a generation all in a single place, and if you have any subject matter experts on your team who you don't necessarily want changing settings in the code itself, this is a more accessible way for them to contribute to the prompts, add their expertise, with a degree or layer of separation from your code. And then the final feature I'm going to go into more detail about is building conversational agents. Now, we know that chatbots and conversational interfaces are one of the most popular use cases for LLMs today. GenKit offers very intuitive and streamlined APIs for both being able to save and persist conversations and then reload the conversation history and feed that into a chat abstraction so that you can easily implement it in like a stateless, serverless environment. Now, I want to talk a little bit about our platform integrations or our supported integrations and platforms. We mentioned that GenKit is very open, and even though it's built by Firebase to provide the developer experience you would expect from Firebase, we've also made it to be a true open and extensible open source project. So I've mentioned our support for multiple models before. These include the latest Gemini models from Vertex AI and Google AI. Also, the many supported model-as-a-service models from Vertex Model Gardens, such as the Anthropic Cloud models, Llama, Mistral, and more. Self-hosted and open source models through Ollama like Gemma 3 and Llama, as well as community plugins that, there are way too many for me to be able to list them here, that offer support for everything from OpenAI, Anthropic, to GitHub models, and even models from other cloud providers. If you want to integrate RAG or Vector Search into your applications, we also provide a variety of plugins to make that easy, including for Firestore, Vertex Vector Search, PG Vector, as well as third-party plugins that we also recently announced with official partnerships from DataStax, AstroDB, Neo4j, and others. Now, when you're ultimately ready to deploy your AI-powered application or agent to production, you have a number of different options. GenKit is not tied to Firebase for deployment. You can very easily deploy your agentic flows to Google Cloud Run or to GKE. Now, if you're building a Next.js app or an Angular app or another modern web app, you can easily deploy it to Firebase app hosting, or if you want a secure way to call your AI-API endpoints from your mobile app or your web app client, you can also use cloud functions for Firebase and the convenient integrations with Firebase Auth and AppCheck that they bring you. And finally, if you self-host your own infrastructure, you can also deploy to anywhere that supports Python, Node.js, or Go containers. And finally, GenKit, I want to really take this point home, is a true open source project. There is no vendor lock-in here. You can use whatever model you would like, whatever vector store provider you would like, and we have an Apache 2.0 license very permissive to enable everyone who wants to build with GenKit to be able to. If you have any issues, you can file them on our GitHub, or if you have suggestions, you can do the same. And we also have a very active and vibrant community. All right. Now, with that, I want to pass it off to Esther to show you more concretely what you can build with GenKit, what the developer experience is like, and then a few options you have for exploring what's possible. Here you go. I'm excited. It's my new detested word, but I'm going to use it. I'm feeling the vibes. That was awesome. That was a lot of slides, but how do you actually put it together? And I don't know if you're like me, but I learn by getting hands-on. I'm also a rubbish programmer, but I use a lot of code assist nowadays and a lot of AI assistants, but I still like to fail fast from the safety of my IDE. So I want to explain today a little bit about how GenKit can help basically enable me to build agents from the safety of my laptop without people actually knowing what I'm up to until it's ready. Right. So straight after this talk, quite literally, and if you've got important questions, Dimitri's going to be the person to be able to answer it because I'm going to be mic dropping and then running into a taxi where I'm going to go take a plane to go back home to London. And one thing that I'm always concerned about as someone that lives in the UK is what is the weather back in London and what should I be wearing? Now, instead of Googling that, why don't I create a weather agent? Maybe. That sounds pretty exciting. Yeah. Why not? So I'm going to start with a simple example using the Python SDK just to celebrate the launch of Python because I think that's a really, really exciting new development that's happened just this week. Absolutely. Can we get ready to show the demo, please? Yeah. We're going to switch the screen where everything will probably go wrong. But, oh, right. Cool. So I'm going to start off by, so I don't know if you've heard, but we've released Firebase Studio. So Firebase Studio is a lot more than just vibe coding. It's actually just a full IDE experience in the browser tab. And that's where we're going to start our journey today. Now, what I've done is I've taken the amazing code snippets that you can see on the documentation and put together a little main.py file. I haven't touched Python in a while, so this was good. It was really easy to get started. I have got some API keys that I'm pulling in from my .env environment variable file. So I've got my Google API key. I'm calling a model here, so you can see that defined with the GenKit plugins. I actually started my journey using the AI studio for Google, and then I was like, wow, Pydantic, amazing. How can I put determinism into something that's indeterministic? So schema definitions. So I've got here now a weather input, so I need a location. And I quite like these new GenKit decorators as well for Python, so I've got the AI.tool. And right now, this tool that is going to be called by my flow or by my agent is actually a mock service, but we'll go on to how to actually, the next steps and how to actually make this real in a second. This mock service is very exciting because it's 20 degrees and sunny all the time in London, which I'm very happy about. It's a very optimistic agent. It's very optimistic. Tool, anyway. Tool, yes. We haven't gotten to the agent yet. Seems a little bit too good to be true, and that's degrees Celsius, not Fahrenheit as well. And then I've got my flow. So I've got a simple prompt, what is the weather in that location, and then I have a system prompt behind the scenes that is going to be able to help explain what the agent is there to do and then the tool that it's going to be calling. Now, this all looks pretty cool, but how do I actually see this running and how do I play around with it? So you can see here, I've actually got my local developer UI booted up and ready to go. So it's actually listening and running this script. How did you start it up? Was it easy? Or do you have to do a ton of work to get the developer UI going? It was so hard. It took me many months. No, it was super easy. I used one command, which I actually put into my package.json, which you can see here as a custom script. There we go. Got two scripts. Genkit start. And then I call whatever file that I want to have with my flows. I've got two flows. I've got one in Python, one in Node. I use naming conventions appropriately. So now, it's ready. It's running locally. Again, this is just port 14 in the Firebase Studio and the IDE. And I can see, if I refresh, hopefully, there we go. I can see my flows come up on screen. So right now, I've got a weather agent and I've got a clothing agent flow. Now, if we go into this weather agent, we know that it needs a location to be able to call. We'll put in London and I can run it directly from my IDE. So, the weather in London is sunny with a temperature of 20 degrees. Shock, horror. Who was surprised at that? That's really cool. Seems too good to be true. Let's find out why. I now can go straight into the trace. So, something that's really cool out of the box is that all the flows are actually automatically instrumented with open telemetry. So, I can actually be able to visualize every step of that process into why it's returning that result. So, at the beginning, I had my weather agent. It is then calling the GMI 2.0 flash model, which I can see here. It's making that tool call. So, that's using the function calling. So, it automatically inferred, okay, I need to be able to get the weather to be able to ground this prompt into the actual weather from my fake mock server, which returns it and then generates everything at the end, which is very, very handy. Now, let's see this in node. node. So, I'm going to do a, I'm going to call the npm run and then actually call the node service. Now, so that was just one example of getting started with Python. Now, I have another service which is doing the same thing, but it's sort of changed a little bit. So, my weather agent seems to be a good idea, but I want more. I want more from my weather agent. I probably could have just Googled that, to be honest. I didn't need to write a full agent to be able to do that. So, I'm going to think about taking this maybe to production and I want to call some of the newest models. All right. But, Imogen 3 is pretty good. I don't know. We'll play around for that. I think that's pretty exciting. That's pretty exciting. So, I start off in Google the AI studio and generate an API key, but for this flow, I'm actually going to be pulling in another plugin, so the Vertex AI plugin. So, in the Vertex AI, I think, how many models are available in Vertex AI model? Well, just the Gemini ones is already a ton of Gemini models, including the latest ones, but you also have access to the Vertex AI model guard, which gives you access to even more models. So much to play with, and it's as simple as just pulling them in as I need. So, you can see here, I've got three models on reference. I'm pulling in the same config, and you can see here, I've got a bit more information. So, one thing that I've changed in this example is I've actually got a tool that's doing something and making a call. Very excitingly, the Google Maps service has a new service which is a weather API. So, you can actually pass in locations or, like, coordinates and get the current weather. So, this is a great way to actually, instead of it always being sunny and 20 degrees, I can actually ground my prompt with the current weather conditions for a valid location and return that back to my flows. But it doesn't always call it, right? Only if you ask it a question about the weather. Like, it knows that it needs that tool to be able to answer that specific question. That's exactly it. So, you can see here that the weather agent still has that tool under its tool belt, literally. That's actually a good pun. That's two bolts. And you're right. So, when you are prompting that agent for the weather in that location, then it will infer, actually, I should probably make a call out to that tool that's available to see what it returns to then be able to maybe pass off to another agent, which it's doing in this case. So, we've got another agent called the clothing agent and a multi-agent. So, essentially, I want to understand, okay, given the current weather conditions, what's the current vibes in London and what should I be wearing when I go back? So, we spun that up. So, going back into the exact same experience that we saw before, we can now see the non-snake case flows appear up. So, I've got three agents and I think we just start with the multi-agent experience and go into the trace to see what happens. So, we'll do the same example. London. London. We'll just run that. Now, you can see here it's pulling in that schema on the side. So, I understand exactly what I need to put in as my input and what is required and I'm getting an output with a nice image, which is cool. So, it's clear in 12.1 degrees Celsius. That's handy to know. Consider wearing a light jacket or a sweater. Good. And this is the current... I mean, this looks quite nice. Fun fact, I tried this earlier today and it came back with 21.9 degrees Celsius. Chris had no idea what I was talking about because he doesn't understand Celsius. Yeah, if we implement one more tool, it's going to be a Celsius to real units converter, you know. I'd like to... The API actually returns Celsius by default, by the way. Just saying. Sorry. But I didn't believe it and I thought I had just actually mocked out that tool call or the tool call wasn't happening and Gemini was hallucinating. So, I actually had to go into the trace to be able to check if it was 20-something degrees because that doesn't happen at this time of year in London. So, again, I can go into these traces and now, actually, what I can show is if I pull up this and once it starts loading to be able to show a whole lot more information, which would be good. Let's just casually refresh this to see what happens. I've got too many traces because I've been running this really regularly and it's also pulling in a lot of images. But that will be able to show all the agents being able to call each other and how it's actually being generated and that tool call. While that's loading in this nicely... Do you want to maybe restart the GenKit server? See if that helps. Yeah. So, what that's doing for my local environment, that's a good idea. See, I mean, things can either go perfectly well and you're like, is that real? It's always a risk with a live demo. It's always a risk. We just restart it. But what it's actually doing just to, I don't know, pull behind the curtains. It's pulling back... See all these traces? This is how many times I've been wanting to know the weather. So, it's pulling in all those traces to be able to render in the UI locally. Now, that is the local experience, but also, what I can do is I can actually authenticate with my credentials and if you're deploying to production, that open telemetry and all that data actually gets captured and put straight into cloud operations suite, which I'll show in a second. So, I should probably just like... I might just delete. Delete. Let's try this again while that's running. I'll do Las Vegas this time, maybe. No, London. Sorry, I'm backseat demo driving. We've been inside all week. I'm pretty sure it's like 35 degrees or something outside. Right. Let's go into this trace. And while that's loading, what we can see is if I was shipping this in production or even if I want to see what this looks like in dev and push this to the console, what's really, really cool and that unique experience and the edition ad by Firebase is that in the console we've got this nice little gen kit tab and we can see all of these amazing dashboards and metrics straight from here. How hard is that to set up? Is it like a ton of extra code you need to wire it up to the production monitoring? Absolutely nothing. Actually, if you go back into the code, it is just one little call right at the beginning which I can't actually see right now but basically I pull in to be able to say that oh, because I basically just enable the telemetry and then it will pull in. And you can see here I've run this a couple of times. Some things that I personally really like is that you can see all the input token and output token count. So if you're using multiple models, you can see all the models listed here. You can start thinking about if you're going to be hitting any of your rates and you might want to optimize how much you're actually inputting to be able to save on costs. And you can see here that we're generating images as well. Now, the other thing is that not everything goes to plan, right? We can see that just as a case in point, right? Much like this error that has coincidentally appeared on my screen. So that multi-agent process, so this is exactly the same process that you'd be able to see in your local, but you can see here it's calling the weather agent, but instead of going to the clothing agent, it's actually erroring on get weather. So that's that tool called, that's erroring. Now, it's erroring because I put in a location called error, which I'm pretty sure doesn't exist. Double-check, by the way, there is no place named error. I did actually Google just to make sure. I haven't found a place called error. But I really like this as an experience, so then you can actually go back in. So if this was deployed, say, as a service, the cloud run, you can go directly in and you can see what is causing the error and go into debug it. Now, if you want more information as well, so you can go straight into cloud trace from here. So it's all built into observability suite on Google Cloud. So you can see here that is that whole span and all the calls that are going out. And for something that might be really handy for this error is to go straight into cloud logging. So this should hopefully be able to give me a little bit more information about what is causing that error. I probably need to actually increase the time, but you'd be able to see all the log entries in there and be able to run it across multiple spans. That's really handy. Right. So the main thing here as well, the easiest way to get started, how would I get started apart from going in and copying all the amazing code? This is an excellent question. So you could go back to the slides. I saw some of you were taking pictures on your phones and you could just go ahead and copy and paste some of those samples. But I think there's probably a more convenient way. That's why we built GenKit by example. It's essentially a site that has a bunch of miniature demos that make it really easy for you to try and see what using GenKit is like. Alongside the actual code that powers the demo. And then you can even view the source in GitHub if you want to see the full code available. Now, in this example is one of my favorite ones to use from GenKit by example. By the way, you don't need to bring your own API key or write any code or anything. I'm going to generate a character sheet. You can kind of see the code that's going into this fairly complex schema. It's going to be a fairly detailed character sheet. And it's going to generate a Dungeons and Dragon character based on the input. So I'm going to input a valiant Google Cloud Next attendee who is very into AI. Agents. Oh. See, now you're back. Now you're back. See, demo drive. Sorry. All right. So as expected, intelligence is the highest stat. All right. I think we all saw that coming. And you're also high elves and wizards. Excellent. And always very eager to learn and share knowledge. That sounds about right. That's exactly what we're doing. And this is really handy. Like, I like the way that you can actually see all the different examples. And this is where I got the inspiration for the weather agent. That's right. If you go into the tool cooling, you would actually see some of that sample code, which I then took to be able to enhance. So let me ask, what is the weather like in Vegas? Since I get to do that this time. And it's in Fahrenheit. Excellent. I love this demo. I don't understand that. Wait, is it raining? Yeah, okay. This one isn't actually connected to the same Google Maps API. But it is in Fahrenheit, so I'd call it even. All right. And I think, can we switch back to the slides, please? All right. So if you are excited by these demos, if we've inspired you to go out and try GenKit, I'd highly recommend going to our GitHub. You'll find links to the documentation in all of the languages that we support, as well as links to some of the supporting materials like GenKit by example. If you want to join our community and talk to our team directly, we're very, very active with our customers. You can also join our Discord at genkit.dev slash discord. It'll take you to the open Discord invite, where we have, I think, over a thousand members in our Discord at this point. So it's pretty active, and we do our best to keep up with all the questions and suggestions. Awesome. Thank you so much, everyone. Right. And Dmitry will be here afterwards.