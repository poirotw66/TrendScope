 Hey, everyone. Welcome. It's Friday afternoon. Hope you've had a great week so far. Thanks for sticking around for my session on prototyping in the Gen.A.I. era. Let's get started. So the title is Ditch the Frameworks, Embrace Core Technology. It's a little bit of a provocative title, but really what it's about is there's some different approaches when it comes to Gen.A.I. In terms of code generation and how you approach prototypes. We're going to talk about tools, best practices, really cover a variety of things across Google Cloud. Hope you think it's fun and interesting and take some great things away from it. So this is me, Carl. I'm with our advocacy team. So we're basically a team of engineers that works worldwide doing content creation workshops. I'm based in Austin, Texas. And glad to be here this week. So our agenda today. So first, we'll set the stage a little bit with why prototyping is so important. We'll cover a startup scenario. So throughout this presentation, we'll kind of walk through a hypothetical startup from coming up with an idea to launching it and improving on it. And we'll walk through each of those three stages. Okay. So why prototype? Well, if you're in the room, you probably think it's valuable already, but let's say a few more words about it. So I think this is a good quote that sums it up that nothing's invented and perfected at the same time. Especially, I know this from experience. A lot of my best ideas didn't come right away. You know, they kind of took a little bit of baking. And so that's why prototyping, getting something out there, getting that feedback is so important. If you've heard of the lean startup approach or this loop, the idea is you have these three phases. You build something, then you can measure it, get some feedback, and then with that, you have some learnings and you continuously refine that. So should it be that hard? I know I made this a little complicated on purpose. But the idea is, like, if you're in the real world where you want to develop a prototype for your project, you might have to create a business justification, work with the design team manager, get some resources, get your licenses, you know, all kinds of stuff to just test out an idea. You know, and with generative AI, that loop has become a lot simpler. So as a lead, whether you're a software engineer, CTO, product manager, design manager, you alone can really move the ball forward with the tools that are available today in terms of prototyping. Let's launch a startup together. Let's walk through this process. So this startup that a fake startup came up with is called AI Praiser. So it's for generating appraisals or valuing different items. So imagine with your mobile phone, you could walk up to any item, take a snapshot and get an estimate of the item's value. And then, you know, you could use that for donations, selling on ebay, anything like that. And so that's what this app is all about. Here are the three stages. There's no, you know, exact framework for this, but this is how I look at it in that there's a, there's a first stage which is about lo-fi prototyping. Okay. So this is where it's about understanding, getting everybody on the same page. What is this that we're trying to build? Why? Get that idea clear. And it could be disposable. Just get an idea out there, throw it away, keep moving forward. Early build. This is your MVP or minimum viable product. Getting a product in the hands of users. And then finally, production. So your idea really has legs. Let's scale it to more and more customers. All right. So let's start with the first phase of lo-fi prototyping. Okay. So another framework for you. So we're going to talk about this. This is where the thesis of this talk comes in about ditching some of the frameworks comes in. So let's kind of look across the board at this spectrum here where we have the most granular low-level ways to write applications. And i'm just talking about web applications right now. You can take this analogy into, you know, other languages. I happen to be using javascript here. But you kind of have your bare bones stuff where you have a lot of control over it. Then you have utility libraries where they do a certain thing. They do it well. You have component libraries that have a lot of functionality. And then you have frameworks that often contain the components that are very opinionated that say, This is the way to do things. You know, batteries included frameworks. And they all have their places. But, yeah, what we're going to talk about is when you think about generative ai, A lot of models often have this notion of like a knowledge cutoff date. Right? That's when the model was trained. And if you think about a lot of frameworks are evolving very quickly. There's new features being added. So we'll talk about some tricks to kind of get that newest information into the model. As well as maybe thinking about in some cases your lowest common denominator here When you're talking about the bare bones stuff, the model is going to be very good at just iterating on that, Changing some pixels and so forth. Okay. So for lo-fi, i look at it like there's two paths you can take. So one would be if it's a ui-centric type of thing. You're really trying to get the look and feel right. You know, you just want this amazing mobile app that is going to impress users with the ux. You probably want to, you know, focus on the field. Maybe go down a little bit lower level, get those pixels just right. If it's about the technology and you're really trying to prove out the concept, Then maybe go ahead to the higher level abstraction frameworks where they have, You know, various integration data, integration and so forth built into the framework. Okay. So now let's get into some of the practices around prompting the model. So we're going to walk through talking to gemini and so forth. So here are some common prompting strategies. Before i get into this, i will say that some of the reasoning models like gemini pro 2.5 Have thinking built in. So you don't have to think about this stuff as much anymore. You can just ask it a question and it's going to really think through the answer for you. But it's good to know a little bit of this, you know, where background of where we got to where we are. So, you know, there will be real quick about this. So this notion of zero-shot prompts. You just ask a simple question, it gives you an answer. Or one shot or few shot, you give it some examples and it kind of knows what you're looking for. Chain of thought, you actually walk it through the sequence of steps you're asking. And then the final one is a little bit of a hack for a chain of thought, which is you tell it to think through it. So you don't actually provide the steps, but you kind of trigger the model to think through it. So again, a gemini pro 2.5 will do a lot of this built in. If you kind of open up the thinking twisty there, you'll see the thought process in there. So often you don't have to do this, but it's worth knowing that. Okay. So let's start building this application. And sorry in the back if you're not able to read all the fonts and everything. But what I've asked it to do is just write an app that appraises a household item with a photo and an optional text description using gemini flash. And it built this application. It worked right away. Let's look at what it built. So it built a streamlet app that's kind of often used for prototyping, a nice python based environment. So what we're going to do, we're going to open up a file, this chromecast remote and appraise it. It's going to go out to the model and we should get a result pretty soon. So this was fairly basic, right? But at least started to get the point across of what we're trying to do in this application. And that was providing google ai studio just like that. But now let's show gemini canvas. This came out about a couple weeks ago. So we're going to open up a picture here of a hammer and appraise it. And we have more of a web application kind of look and feel. Has anybody tried gemini canvas yet? Anybody heard of it? Okay. A couple of folks here. Yeah. So what's neat about that is you have your prompt on the left side and then the web application on the right. And you're actually seeing it deployed live. And you can say, all right, change this, change that. And it's constantly changing the code but then rendering it for you so you're seeing the look and feel. So worth checking out. That's gemini canvas. You can download the code when you're finished from doing that. All right. So this isn't to say that ux prototypes aren't an option. They absolutely are. So I built this in figma. I'm not a designer. So I know this doesn't look super awesome. But this, again, is a great way to get the ball rolling. And a lot of these tools are starting to embed generative AI in them as well. So despite what some of the influencers might say that this area is dead, it's absolutely not. But it's just good to know that with gen AI you can shoot right to the code and get a working prototype and maybe skip a few of the steps if you need to. All right. So to summarize, some of the products you can look at are our studio tools to generate the code. Google AI studio, vertex AI studio, and gemini canvas using our latest two models. And we talked about using prompt engineering best practices. It's important to be very specific in your prompts, right, because when you're trying to be creative, you're doing a prototype, you're not necessarily looking for the most general answer. So if you don't provide a lot of detail, you just say, hey, give me a website that appraises a photo. That's what i did. It's going to give you an answer. But if you're trying to differentiate and if you're trying to have something that's a little bit, you know, unique, then make sure you really think through it. Give it some ideas. Have it think through some options. So anyway, just always the best practice is spend the time on prompt engineering. Cool. All right. So we've built our prototype. Now we're on to the next phase of offering it to users. Okay. So this phase is about validating it, seeing if we're building it in the right way, seeing what users think. Okay. My opinion, the right sweet spot is somewhere in the middle, not super granular with HTML and so forth. That's just going to slow you down. Also, you might not want to use one of the really opinionated frameworks yet just because you need the options. You want to still respond to feedback. So be able to develop quickly but not necessarily be locked into anything at this point. Here's a trick that i use a lot when i do want to use frameworks that takes advantage of the large context window of gemini. So here's a framework fast api. Anybody use that one before? Okay, cool. I love it. Yeah. I used to use flask and now i've really started to use fast api for almost everything in the python world. So what we're showing here is i start with the documentation. I go to the website. I might see, okay, here's a link to the github page for that website. And then i navigate into the docs folder. And that's where i see, okay, great, all the markdown files that describe the apis, the reference. So why am i doing this? Because, you know, when gemini was trained, maybe it doesn't have the latest version of the model. Maybe all the little details aren't readily accessible to it. So i'm going to grab all of the docs. Use a handy tool called get ingest.com. Anybody tried that out? Okay, so this is super easy to use. All you have to do is say you have a github link here. Replace github with get ingest.com. And then it will basically pull in all the code from that root directory. It will basically concatenate it together, create one big text file. It's got some handy options for things like excluding binary files and stuff like that. So what you end up with is this kind of directory tree and all the files. And then what i do is i'm asking gemini or google ai studio here create me my web app. And then i paste in all that stuff. And with 1 million tokens, totally enough room for that. So again, if it's a huge library, then you can filter some things out. But that works great for me. Okay. So we've gone through that. Now we have a functional web application. Let's take a look. So now we have our input on the left side. We're going to estimate the value. And cool. So we're starting to get better value as you're seeing here. One of the cool things i was showcasing there is gemini has a grounding with google search feature. So that the results get grounded in real world search results. So you get amazon, ebay, etsy really giving more precision to those estimates versus just the llm sort of thinking what the right answer is. It's going out and it's providing you some links and sources. So kind of a neat combination of llms and google search results. All right. So we've got the web application. Good news. We've got some early feedback from our users. There's new markets outside of the united states. They're saying, hey, we'd love to use this tool, but it's only showing up in dollars. How can we use this? Right? So, okay. Now we've got to iterate on it. We have our base. What can we do? Well, this is where gemini code assist can come in. So you've got your vs code, jetbrains, whatever environment you use. So here we have, you know, our nav bar here. What I'm doing, notice I say at main.py, at index.html. So when you can reference certain files in your workspace, and that's what they call local code base awareness. It's going to pull it in. So gemini is going to add this multi-currency support in those files. And if you've maybe seen some of the code assist sessions so far, you'll know that we upgraded to 2.5 for our individuals free tier. So that's available today. So cool. So we have our code coming back. Also notices external sources. So you can be assured if there's anything that's a bit of a direct quote. It's going to make sure that the citation is there that you can review on your code generated there. And so great. So now we're in that mvp stage. We're iterating on that. We're expanding our application. We've got our feature request. And now, yes, we have a drop down with the currency. We've got values and more currencies besides us. Sweet. Okay. So to wrap up again on this section, the tools that we used were the studio tools. And we added code assist. Also the 2.0 models are great. A couple best practices to remember. One, use a large context window to supplement frameworks and all sorts of other code. Something else I didn't mention here. But generate your unit tests early. So when you're doing a lot of prototyping, it's easy to kind of fix one thing and then maybe something else changes and you didn't really realize it. And having those tests will kind of keep things on track as you make a lot of changes. All right. Production. Okay. So we're moving on. Now we're ready to, you know, expand this application all over the world. I'll look at it like there's a bit of a fork in the road at this point. You could either continue with what you've got and refactor it or just say, okay, now's the time for a rebuild. We're going to start from scratch. We've learned a lot. You know, we're not starting from zero, but we're going to kind of start with the new code base. Maybe some of the considerations might be if, you know, you feel comfortable with your code base or maybe you've got some time constraints. You would just continue if you feel like, okay, we just have to start fresh. You don't kind of got all the spaghetti code in your code base. You might want to do a rebuild. So let's look at some best practices for both approaches. One thing I think is kind of neat to try is asking the model to be like an architect for your application. Say, all right, cool. We've got this prototype now. Oops. Like, oops. I'm sorry. Let's go back here. As a seasoned cloud architect, look at improving in terms of reliability, security, looking out for things in your application that could be better. Not just finding bugs, right, but, you know, how you could do things better that aren't necessarily functional problems. Then I ask it to prioritize as well because often it will just dump out a bunch of stuff. So prioritized list, focusing on scalability. And so it thought of some interesting things like the way I was handling exceptions, a retry mechanism, right? So if, say, an API isn't available to kind of give it some time and back off and all that good stuff. So that's at a high level across your application perspective. Another thing to try is if there's a specific part of your code, ask it to clean that up. So this is something that's real as I iterated on the application a few times. There's a lot of cruft that accumulated. You know, if you've noticed that models sometimes, they add stuff. They're not always great at removing things that they add. And that's not necessarily a bad thing, right? They'd rather err on the conservative side and not, you know, delete something they shouldn't. But if you're doing prompt after prompt and fixing things, you start seeing a bunch of extra stuff. And so what I did is I asked it to, yeah, just look for unnecessary style attributes. Try to avoid disrupting the UI. These were just a few. I had about 25 different things that were all valid, all these extra tags that weren't used anymore. So just a thought process here in terms of as you've used a generative AI model to help your application. Come in and clean things up. Go through cycles of adding and then cleaning up when you're finished. Okay. So for the final stage here for rebuild, I think now is the time if you're starting from scratch, work at this level of component frameworks or all-in batteries included frameworks. The reason is a lot of these are built with best practices in mind. Things like security, cores, all that good stuff is in the framework and you don't have to do it yourself and reinvent the wheel. So a couple tools from Google to consider at this stage is application design center. It's got a set of templates in the console. So there's, you know, web application, different starting points you can look at. Generally the type of application you're building, what template do I want to start with? And you can customize some things in it and then it will generate Terraform for you to roll out your application. Something else to think about when you're starting from scratch as well is generating an open AI spec. So you can ask Gemini to create this YAML and then what's nice about that is it's helpful for diagrams, it's helpful for documentation. And it's kind of an intermediate artifact where you can then generate your service code off of the specification. One more tip to think about with Gemini code assist enterprise, it has a feature called code customization. And code customization is where you link to a private repo within your organization. So maybe it's got style hints in terms of the look and feel at your company. It's got back end services, style guides, conventions. It is going to basically understand how your code base works because, you know, that's not indexed as public GitHub information. And so you can link that and then link to your prototype or internal source code. So that will help as well. All right. So the products we talked about were adding on were code assist enterprise and ADC. Some of the best practices were around prompts to make your whole code base more scalable, Cleaning up with more granular prompts. You can generate some infrastructure artifacts if you like and then include code customization. All right. So let's wrap up. We kind of walked through these three phases from lo-fi prototypes where the idea was if it's focused on UI, Kind of start at the HTML, CSS, JS level. If it's more of a technology-focused prototype, go ahead and work at the framework level. And we learned about these different phases and how to use Gemini AI at each step. So one thing I'd like to leave you with here is when you think about a prototype, it's not a deliverable. It's not just a task on your task list. Think about it as a question. And so generative AI is going to help you craft that question. It's going to help you answer that question. And it's up to you to decide how you want to work with that answer from the question. That's my talk. Thank you very much.