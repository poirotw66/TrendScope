 . Good afternoon, everyone. Welcome to the session. I hope you had a great time at Google Cloud Next. My name is Jatin Sharma. I'm a product manager in modernization and migration team at Google Cloud. Today, we're going to talk about how you can migrate and modernize from AWS and Azure to Google Cloud. We're also going to share Nokia's transformation journey with you as we think both of these topics is very relatable to our customers in their transformation journey. So you'll hear more from our co-speakers today. Today, I have Aitan from Google and I have Bernard from our customer Nokia and Brinda who helped with this transformation journey and she's from our partner team Sears. So, agenda today is we're going to give you what are the key elements when you kind of migrate from the AWS Azure to Google Cloud, what key elements you have to keep in mind. Then we'll talk about when you migrate, why not think about modernization. And we'll share the Nokia's transformation journey as part of our panel discussion. And then Aitan will share some of the demo tools that can help with this modernization journey. And we'll leave some time for your Q&A. All right. Let's jump into our topic today. So, Telegraph Media Company is one of UK's oldest media group. They have millions of users and they've sometimes faced a spike in their traffic because of known and unknown events. And for example, King Coronation. During that time, they had a big spike in their users and they wanted to focus on the code, not on the scalable architecture. So, in order to have a scalable architecture, they migrated from their microservice architecture to cloud-run serverless architecture. And by, through this migration, they not only achieved 90% reduction in the cost, but they also achieved 90% reduction into their carbon dioxide emission. All right. Let's talk about why customers consider Google Cloud from other cloud hyperscalers and how we provide a differentiated value. The first thing is Google AI. I don't think any company is as integrated as Google Cloud. It starts from our workload-optimized infrastructure built for AI. And then our fundamental research going into building models like Gemini and how Gemini models are integrated into our different products like Workspace and Google Cloud. The second one is our workload-optimized infrastructure. So, we have our infrastructure built for AI workloads, cloud-native workloads, and also enterprise workloads, which gives a lot of performance improvement while keeping your cost and price down. Security and reliability is the next one. So, it's Google's deep SRE culture, you know, that leads to zero security vulnerabilities in the last many, many years and much better than over our competitors. Modernization. Modernization. So, Gartner has predicted that by 2027, 90% of the companies will be running some sort of their apps in the containers. I think no company is better set up in taking that modernization journey for customers moving forward than Google. Lower TCO. So, combining all this, the Google AI, our optimized infrastructure, our modernization journey can help our customers lower TCO because we offer a lot of this workload-optimized infrastructure like Gen4, our hyper-optimized storage pools, our hyper-optimized storage pools, and also our auto-class storage journey. So, let's talk about it. If you decide to move to Google Cloud from other cloud, what are the key elements that you have to keep in mind in order to make sure your cloud transformation and modernization journey is successful? The first thing is assessment. You must get a comprehensive understanding of what you're running in your environment. And this starts with comprehensive inventories of your workloads, data, and applications. Then you must have understanding what sort of dependencies you have. And these dependencies could be network dependencies and databases you're running. Then you should have some sort of knowledge about, like, you know, supporting services. And these supporting services are an integral part of your infrastructure. And these could be your source repositories, your CI-CD pipelines. And then your physical appliances, such as your network devices and firewalls. Once you have all this picture clear, then you can have a better assessment and better TCO for your migration journey. The second is understand the differences between AWS and Azure to Google Cloud services. A lot of customers think that it could be a simple migration journey, which we want to make it for you. But you should have a clear understanding how these services differ in terms of functionality and how they're built. Pay closer attention. It's like, you know, when you migrate to your private clusters, your endpoint access controls, and how your authentication works in AWS and how they're going to be working in Google Cloud. The next thing you should pay attention to is the data migration challenges. For many customers, when they migrate, the first thing they do is data. And for them, it's as simple as it could be like a file transfer session, a protocol session. It means the data comes in and comes out from other side. While we think we could make it as simple as for you, but you should have some closer attention to some of the key points. For example, you should look at it, you should have a team in place who works on this data migration. And the team works on the execution of this data migration. And they also work with your business stakeholders who may have been nervous about, you know, the value and the data migration. The second thing that this team should take care of is what sort of tools they have for their data migration. How much these tools are going to cost? What resources are required for such tools? So this team should look at the comprehensive tools. We have recommendations that can help you with the data migration and make your data migration journey easier. The last thing is the data transfer challenges that you should pay attention to, which is network bandwidth or the data that is in active use or the protecting and monitoring data that is in flight. The last one is important part of your cloud to cloud migration journey is the deployment processes. The deployment and operational processes are your artifacts that helps in your workload, that helps, you know, work in operation of your workload. So what sort of things you should take about is like, you know, these artifacts could be your operating images. These are your application deployment packages. These are container images. So you should gather information about these artifacts and make sure these artifacts are compatible and these runtime configurations can work in Google Cloud environments. So when you have all these things work together, I think your cloud to cloud migration could be much, much easier. All right. So when you think about migration, most of the time customers just think about lift and shift. This thought has limitations because when you talk about just lift and shift, there's so much cost benefit analysis you can have. And also there's so much of scalability, there's so much of innovation your organization can achieve just by doing the lift and shift type of migration. So why not think about modernization when you talk about migration? And there are ways modernization can help. And let's talk about that. Let's discuss about that. The first thing is business needs. Modernization can drive your revenue. It can help you reduce cost. And it can provide you a competitive edge. So make sure you align your modernization with your business objectives. Assessment. We just talked about in detail how assessment is very, very critical. So assessment is even more critical when you want to do a modernization. As we talked about it, the assessment is like, you know, if we are current set up, you know, identify your dependencies and any tech debts you have, it becomes more critical when you want to do modernization. Visibility and risk. So modernization requires certain sort of skill sets. It requires some technical feasibility. So there could be a risk that's involved. So a lot of customers just drop their modernization journey because of these requirements. We do not recommend dropping it. Rather than dropping it, take a phased approach. It means start with lift and shift and then consider modernization. So modernization could be a longer journey. It should be a five-year journey, you know, that starts with sometimes moving from, for example, VMware to compute engine. And then you can slowly move from compute engine to our GKE and move your VMs to containers. Then let's talk about foundation. The foundation is very important when you kind of embark on your modernization journey. So make sure you have a resource hierarchies, your securities and your networking and your access management is set up when you embark on this modernization journey. Last one. Modernization is not a one-time job. It needs to happen continuously. It needs to align with your long-term goals as we talk about it, that it could be a five-year plan. And you can start with lift and shift and then you can move towards modernization. As you embark on modernization journey, it should help you improve your scalability. It can help you with the performance and security for your businesses to scale and innovate. With that, we'll take these key points that we talked about for your migration and modernization. And we'll see how these key points were applied for Nokia's transformation journey. And I will hand over to Vrinda and share how they applied these things on Nokia's transformation. Over to you, Vrinda. Vrinda. Thank you, Jatin. It's a big crowd. We were thinking about this probably being a very, very small crowd session. But clearly, AWS to GCP or Azure to GCP seems like in demand. And we are happy to be on the other side of this journey with Nokia in terms of all the slides that Jatin showed seem good in theory. But nothing speaks more to what it really means to go through this and be on the other side of the outcome itself. So briefly, when we started this journey with Nokia, you know, the main items about their scale were this particular workload represented about 100,000 plus pipelines running about 27,000 plus jobs. And servicing about 7,000 plus users. Right? So obviously, a migration of this size and scale needs to be planned very, very well. And that is something we actually invested a lot of time and effort in. And all the while making sure that it has zero to minimal end user impact as well as very minimal downtime given the scope and scale of the solution itself. We obviously started with some of the similar stages that Jatin described, but also weaving in our own expertise of doing around 500 plus AWS to GCP migrations over time and building some use cases or repeatability around what do AWS architecture looks like? What would the potential GCP endpoint look like? And obviously, it started with a detailed assessment. Post that, we went into how does the technical design look today? And what should we be looking at in a 2B architecture wave? We then actually did the real migration, touched upon some of the items that in terms of how the data migration should happen, what kind of downtime should we be planning for, so on and so forth. And all of those items were quite critical in making sure this migration was ultimately successful. With that, we then planned a very, very detailed cutover because no matter how well you do the actual migration itself, if the production and go-live cutover doesn't go well, the users from the end customer are not going to be happy in general, right? So that clubbed with how are you going to run the day two operations was also something that was important and baked in as a part of how we decided the entire project plan and rolled it out at scale. With that, I don't want to bore with just general slides. Let's call the customer itself, Bernard from Nokia, Eaton, and I'll probably invite Jatin back. We'll kick off our panel discussion and get some of these questions answered right here. Bernard, thank you for being here. Thank you. It's great to be on stage with you, Bernard, now that we are at the end of the go-live as well. Would you please introduce yourself and also help us understand what was your motivation of moving from AWS to GCP? Thanks a lot for having me here and happy to be and talk about our migration journey here for that particular workload. So my name is Bernard Fiermann. I'm responsible for cloud transformation at Nokia in our digital office. So I look after all large-scale transformations when we look into strategically migrating workloads from kind of consolidating our platforms from on-prem to cloud or like in this case, go and undergo a modernization during the migration as well. And just answering your question here. So what was our motivation to start that journey? Our CICD pipeline was running on AWS. We had some kind of tech debt accumulated over a bit of time. But we also set out Nokia's strategy with targeted cloud platforms and there's a deployment strategy which environments we want to run on which tech stack. And kind of when we looked at this CICD pipeline, we saw there's improvement potential by migrating and modernizing at the same time from AWS to GCP. So it was more a strategic decision kind of to consolidate also on a target platform. But as you said, it's not just lifting and shifting. It was very clear we have to also modernize. And we took the opportunity to realize both of those effects. Makes sense. Did you evaluate any other cloud platforms for this workload specifically? We did look into obviously other cloud platforms as well. I said this came from AWS. But we follow the kind of overarching Nokia strategy here. Kind of look at kind of how is the environment around that particular workload also placed. And kind of where is that embedded to maximize the end-to-end environment kind of benefits by consolidating this on the target platform. So we did look into others. GCP, obviously, great partner and has a very good tech stack so it's decided that's the way to go. Makes sense. And we were glad with the decision. I remember when we initially started talking, this was one of the key requirements that Nokia's team had highlighted to us. That it is part of the broader strategy, but we want to make sure that we are not just doing lift and shift. Any chance, any opportunity you see to improve or modernize whatever is being done, that should be considered as a part of the GoFlow. So what actual success criteria or critical success factors did you benchmark for this kind of a journey? Yeah. So we looked at this from a kind of actual performance. So this is a very critical workload for Nokia, the CACD pipeline, supporting a lot of things like 7,000 users across our company. This is for deploying our products, our code. So it's very critical for the business as a platform. So the goals were we need to ensure one, performance. Kind of we can't compromise on performance. This is kind of what our R&D teams, it's their daily business. So we can't compromise on the performance. That was very, very key. So that also kind of day one after cutover, there's a seamless experience. Maybe you can't go like a three-month iteration and kind of have trouble with your R&D teams, kind of why things are not working. So ensuring performance is very critical. Also kind of business continuation. One of the key points that I will talk about a little bit later, I guess, very, very short downtime at the cutover. So we needed to find an approach to cut this over and make sure after this very short cutover time things are working. Ensure business continuity and don't run two things in parallel. We don't have the team to kind of support two platforms. Parallel and bug fixing doesn't fly. So critical approach, critical goal for us to make it a business continuation that flies. And that's on the kind of third part maybe, looking to a partner kind of who can help modernize during that migration. We have a team that operates kind of the platform but can't operate and build and modernize at the same time. So we have to focus on being the partner who can do the modernization part for us with the team to get there. So I think those three factors have been very critical in our decision making process, kind of how to embark on that journey. Did we deliver? Put that way, we're sitting here. So I think that's already a good proof. It's a very good proof point. So I would say yes, you did. And maybe to highlight kind of what was also critical is kind of, not as an organization, needs a lot of stakeholder alignment. So what was also, from an execution perspective, it was very critical that we have a lot of people aligned, stakeholders aligned across our organization to get the buy-in, get also the knowledge transfer happening. And I think your team kind of helped a lot in doing this. Then obviously, slides are always great and approaches, I can tell. But you only kind of, when you start looking into this, when you do the discovery, when you do the analysis of your essays, you will find out kind of where the nitty gritty details are. And the flexibility your team and also the Google team that brought through the table with access to the product managers, kind of to all the kind of experts who helped them kind of overcoming potential roadblocks, solving issues on the fly. That was also a very critical factor and helped us. And kind of, that's right, I think your team did a great job in here, kind of getting us over. Because this cut over planning has been very critical. Yeah, we actually had a war room completely set up during the pre-cut over phase at cut over and then post cut over as well. And I think it was also critical for your teams to be fully aligned with those plans and be available as that cut over was going on. So I think the teams worked quite well. And ultimately seeing a 30% improvement on the actual efficiency and the way the performance was working was something that worked out really well. Jatin, do you have any thoughts? Yeah, so, Bernard, share with us, like you talked about some of the performance improvements and gains you had. Can you also talk about what other improvements and benefits such as operational development benefits utilized by transitioning to Google stack? Like, you know, to modernize from EC2 to GKE. So, I think first, scalability. Scalability is a critical factor in this environment. So, being able to adapt to all kind of business needs, scalable kind of demands from our R&D teams. So, I think this is a very good achievement and the team is very happy with the product and how the platform is running today. Also, kind of how you operate with operational efficiency. Kind of less time to kind of spend time on fixing and operating the platform. That has been also a very good benefit for the team. Kind of less manual effort, more automation brought through the modernization into this platform. Less overhead, actually. Kind of also, let's say, just pure kind of operational efficiency in terms of how you manage it. And we also have benefits from improved security because we brought also kind of the entire platform into our kind of overarching Nokia GCE platform with all the policies, all the security, all the tooling. So, there's also benefits kind of not as visible from the pure money project itself, but how we set our journey up as Nokia and bring things strategically under one umbrella. Okay. So, you also saw some sort of developer productivity too? The developer productivity for this, yes. But this is more the R&D teams, kind of the deployment efficiency. Kind of how fast, less rollbacks, how the jobs run through. Basically, this is very seamless, very good statistics kind of after the migration. So, teams are very happy. Okay. Sounds good. Thank you. Bernard, can you share with us how did you leverage Google's and Sears expertise in containerization and Kubernetes in particular to ensure a smooth and efficient migration? Yeah. Well, I think I mentioned already kind of access to the teams. This was a very critical factor. So, Google and Sears brought like experts to the table in this project team which consisted on the Nokia that also have a lot of kind of different teams. But having the expertise and kind of the access to the right people to solve problems as they occurred was critical. And this was a very good approach and how all the teams blended together. When you talk about simple stuff like going through documentations, make it available, also empower our teams. Even after the cut over, our teams have to run this. Like project ends, operation continues. So, also the knowledge transfer that happened kind of from experts, from the teams, from the continuous access beyond the hyper care period was very, very critical. It was very good to have that access from all parties. Second on like guiding and advice on the migration tooling for example. There's like maybe five or six choices how you can transfer data. In this particular case, you mentioned it, downtime was crucial. In the initial planning, we have to transfer so much, just a sheer amount of data was just large. So, finding the right approach, how do you now transfer this and bring this in line with the goal of minimal downtime? The initial planning was like five days. It doesn't fly. We all sat together and said that's a no-go approach actually. Finding a way to mitigate that and bring it down to less than kind of 12 hours. 30 hours or so is what we were. Yeah. We brought it down in a joint effort, right? With all the right experts. I think that was also one of these examples of how we kind of leveraged all the experts basically and made it happen. Awesome. I know we have maybe a lot of audience team members who might be either looking to consider a move or are in the middle of it. Any specific gotchas or learnings that you may want to highlight for our audience? I think it was mentioned a couple of times, planning, planning. I just spent more time on planning. This is very crucial to achieve your goals. And as I said, kind of the slides are great but once you go into the details with the technical teams, this is where planning is so important. You need a team kind of that can work through the challenges and identify challenges and get it over with. And that's also kind of where Sears came in with kind of broad knowledge from use cases. You had migrated, brought this experience of kind of how did you solve this with other cases and bring that kind of best practice into the table, into the team. So I think just planning is important and having kind of a good partnership and good people kind of that just really can work through it. Makes sense. Thank you so much, Bernard. You're welcome. With that, Eden, I'll pass it back to you. Right. And let's look at some interesting upcoming announcements. Yes. Thank you so much, Bernard. So, right. Let's get to the tools and talk about how Google can help you in your cloud to cloud migration and make it a success. We've got solutions for every phase from assessment to modernization and migration. And in the next few minutes, I'm going to show you demos of how these work. First, understanding your source environment is key. Migration Center provides a unified hub for all of your migration. Migration Center Discovery Client inventories your current cloud infrastructure, providing a foundation for a smooth transition. This will be the focus of our first demo today. Next, we can improve application as part of your migration. If you're considering legacy code modernization, CodeMod uses AI to analyze your application, helping you modernize them by rewriting legacy code. This will be our second demo today. Now, let's talk about migration tools. For virtual machines, we have Migrate to Virtual Machines to lift and shift your VMs from your current cloud environment to Google Cloud environment. And I'll show you how easy it is to lift and shift your VMs to Google Cloud. This is our third demo today. And finally, for modernizing VMs and re-platforming them, we'll show you how Migrate to Containers can help you take applications running on VMs and containerize them to run them more efficiently in a cloud-native architecture. And this will be our fourth demo. And in case data transfer is a concern, we have database migration service to simplify moving databases between clouds. And we have storage transfer service to handle transferring large volumes of data securely. Now, with that, I have four demos for you today. They're all recorded because migration takes a bit of time, so it's going to be fast and furious. And I hope that I can keep up with them, right? Let's take a look at our demos. The first demo that I'm going to show you is how we use Migration Center Discovery Client to collect information from your, in this case, AWS environment. But all these tools work on Azure as well. And we will collect information and use Migration Center to assess and create some reports from your information. So, let's start. So, here I am in the AWS console. I have a multi-tier application, front-end, back-end, and web application in addition to a pet clinic application. And I would like to assess my environment. So, I'm going to use the Cloud Shell environment to install Migration Center Discovery Client. I'm going to download the CLI. And I'm going to run the command MCDC discover AWS to collect all the information from my AWS environment. I'm going to point it at my region and look for VMs with a specific Wave 1 tag. Now, when all the VMs information is collected, we can list all of our information locally. But then we really want to be able to process this data. So, we're going to export it into Migration Center by running the MCDC export command. We're going to export all of this information into Migration Center. And then we're going to switch gears and move into the Migration Center console. So, here we are in the Assets page of Migration Center. We can see all of our VMs from AWS environment with a specific Wave 1 tag show up. And then we can double-click into the VMs. We can see some migration insights, and we can double-click into the details for each VM. Each VM will have vast amount of information about everything that is needed in order to have the knowledge about your environment. We even have things like collect things like performance data, which we later use to right-size the VM. So that when you run it on Google Cloud, you're not paying for any resources that you don't need. Now, in order to create any reports on it, we have to group all these VMs together into groups. We will create the Wave 1 group and add all these VMs to the group. Later on, we'll see how we use this group to create reports. And then one of the most important features of Migration Center is the migration preferences. This is where we allow you to configure how your target environment will look like. So, here is an example. I'm going to deploy the VM, run the VMs on US East 1 on Google Compute Engine. I'm going to use the one-year committed use discount. And then, very important, I'm going to use the moderate right-sizing strategy so that I can very efficiently use the resources. Then I'm going to create an additional preferences with similar characteristics, but the only difference is going to be that here I'm going to use a three-year committed use discount to gain even more benefits and additional discounts when running on Google Cloud. Again, I'll be using the moderate right-size strategy. And then we have all kinds of reports in Migration Center. There's a TCO report, a network dependency report, to name a few. So, let's create a TCO report. We're going to call it Wave 1 TCO. Then we're going to select the group, a Wave 1 group of VMs. Then we're going to select the preferences, the GCE one-year and GCE three-year preferences, so that we can compare them side-by-side and see how different pricing tracks may affect our total cost of ownership on GCP. Now, within a few seconds, we have a TCO report ready for you to see. I'm going to click next here, and then we'll have a summary of all the resources from the AWS environment in this case. And then in the next page, we're going to get a summary of the actual costs that it will cost us to run these VMs on GCP for our different pricing tracks. And then going even into more depth, we can see the breakdown of what kind of machines and how much it will cost, what kind of licenses and storage are going to be included in the costs per pricing track and their differences. Okay, and now, if infrastructure assessment is not enough and you want to go deeper and look into your application, and we can't have a session without AI today, so we're going to see how we leverage AI to assess your code and your legacy applications. So, code mode is a new CLI tool that looks at your code base, leverages Gemini to generate some deep insights and an HTML report on your legacy applications. It's a command line. We're going to run it and point it at your source folder, and then it will generate our HTML report. Then in the HTML report, we can see things like your current architecture. You can see things like the technology stacks that is being used in your legacy application. You can see what APIs and endpoints your application is exposing. And we can see modernization strategies from short-term improvements to long-term improvements to guide you through your modernization journey for your legacy .NET and Java applications. Okay, enough assessments. Let's move on to migration. Let's see how we can lift and shift VMs from Azure or AWS to Google Cloud. I mean, migrate to virtual machines console. I will add a source to point at my AWS environment, give it a name, configure the GCP region that I'm going to run my VMs on, and point it at the AWS region that my VMs are running on. Then all we need is an access key and a secret key, and you may want to add some text to identify those migrated VMs and create the source. Once the source is created, we can see all the VMs that we have in our AWS environment. And then we can start seeing how we can migrate them. So you can see we have all of the VMs that we saw on the AWS console previously. We have some information about the zone they're running on, all the tags that they had on AWS. And let's say we want to start by migrating and lifting and shifting our back-end servers. We can group them all together into the back-end group and then migrate all of them at once. So you can do that individually per VM or in bulk. Let's create a group and go and see what we have in that group. Okay, here is our back-end group of VMs. We can now select the VMs and start the replication. The replication copies the source disks of your VMs without disturbing the running applications. And the first replication may take a while. So in the meantime, we're going to edit our target environment. We can configure things like the names of the VMs that we want to use on Google Cloud. We have to configure the project that we want to run those VMs on. And then lastly, we're going to select the zone that they will run in. You may want to add some labels to them as well, which is possible at this stage for all the VMs in the group. Then we're going to select the machine types and a specific machine. In this case, we're going to use the E2 HighCPU2 for our back-end server. It's very important. Let's go on to the next page where we're going to set up the network where the VMs are going to run on. We're going to select the default network and the default subnetwork for our simple demo today. And we're going to save it. Now, while I was talking, my way to virtual machine is copying the disks of the VM. And once the first thing is going to complete, we will have two options. We can create a test clone to test the VMs without disturbing the production VMs on your other cloud. Or, and once you verify that everything works as expected, you can cut over, which is what I just did. Cutting over means that we're going to shut down the VMs on your source environment. We're going to do a final sync of all the disks, all the changes, recent changes to the VMs. And then start the VMs on Google Cloud. Once the cutover is over, it's finished, we can switch and go to our VM instances page and see all the VMs, all the back-end VMs running on Google Cloud now. Okay. Let's see some modernization in action now. Let's say you're not really happy with VMs and you want to move to containers. You want to start leveraging GKE and Cloud Run. Well, we have a tool for you there. Migrate to containers. Straight from Visual Studio Code, you can connect to the VMs running on AWS. We can run our assessment script and immediately get a local report showing the potential containerization journeys. You can find the applications that are running, in this case, on my Tomcat server, and I can re-platform them. I will re-platform this VM to run in a Tomcat container, set up some environment variables, and then we create a local workspace for you where you can complete your re-platforming. We can see all the environment variables, and then there are three commands that you need to run in order to containerize your VM. You need to copy the source file system, analyze it to create a migration plan, and then generate the artifacts. You can even add some filters so that you don't copy any unnecessary data from your VMs. So let's run, quickly run the copy command to copy the file system and then run the analyze to generate a migration plan for us. The migration plan is just a YAML file that shows you your application, the setup, where Tomcat is running. You can configure probes and the ports that your application is listening on. And then once you're satisfied, you can generate the artifacts. And what are the artifacts? We can automatically generate for you a scaffold YAML so that you can build and deploy your application in the same way in your development environment, test environment, and production. You can see the application binaries, a Docker file to build your container image, and even a deployment spec, a deployment YAML, and a Kubernetes service to quickly deploy and expose your application. And you can also do the same thing to deploy to Cloud Run as well. Okay, this was our last demo. So let's take a round. Thank you all. Hello. Thank you all. Thank you. Thank you all. Thank you. Thank you. Thank you. Thank you.