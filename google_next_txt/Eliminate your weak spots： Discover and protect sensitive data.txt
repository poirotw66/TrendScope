 All right. Thank you everybody for joining us. We're going to talk today about how to eliminate your weak spots and specifically focus on sensitive data and how to understand it and protect it better. My name is Scott Ellis. I'm a product manager at Google and I'm going to be joined later by my colleague Jordana as well as one of our strategic partners Nathaniel who works with Strata Prime. And we're really going to talk about weak spots and unknowns that cause risk and we'll go over that a little bit and then walk through an example with something that's top of mind for a lot which is securing AI data. Now when we think about cloud risks a lot of there's a lot of risk in the unknowns because generally there's something in your environment you might not be aware of. There could be a project that was started or data that was created that you just don't have insight into and that can actually create you know unknown exposure or a high value attack target. So when you think about like your cloud environment if you if you imagine this kind of is your cloud environment all these dots floating around or all your workflows and your assets the first thing is really understanding the high value assets the things that you really want to protect and make sure don't get exposed to the wrong people. Maybe that's things like personally identifiable information. It could just be credentials and secrets that would give someone access to more resources or things like financial or medical or other types of data that just is very sensitive for your company. Now the next thing is really to think about when you look at your cloud environment how would an external or internal user or maybe an attacker get access to something. What are all the ways that they could get into your assets? Some of it might be pretty straightforward they just have access to it and other things can be you know complicated paths like the ones we see here. So when you think about combining those two signals now you start to get insights into that unknown. You can start to say how is data exposed to misuse or attacks by understanding how they can get to it what they can get to and whether or not those assets are sensitive or high value. And with Google Cloud our sensitive data protection service along with security command center and some technology that we call virtual red teaming can help you do this. It can help you light up where your assets are and combine that with these attack paths and these different ways that somebody could get access to your data. Again in ways that you might not be aware of this can bring those unknowns into prioritized risk for your environment that you can go remediate. Now let's look at a very specific example. This is a real world example. This is an environment I created. It was a test environment. And I don't know if you can see. Oops, sorry back here. This virtual machine here called scheduler VM1. It was a machine I created. I ran a bash script on it. It really wasn't important to me. I didn't really care that much about the VM. I just set it up. Took the easy path. But what we're really looking at is, you know, that virtual machine here has a lot of exclamation marks that you can see here. These are all vulnerabilities or misconfigurations or something that could be taken advantage of. Now, I really didn't care about the VM very much. If someone got access to it, I didn't really lose anything. The bash script wasn't sensitive. But what this path tells me is that that virtual machine has a lot of privileged access down to this bottom asset, which in this case was a storage bucket that contained a lot of sensitive content. And not only did it have access to expose it, it could create, it could delete, it can manipulate that bucket. So again, this idea of this attack path is even though I didn't care so much about the VM, maybe up front, and I felt like I locked down the bucket to the right access control, this vulnerabilities on that VM actually exposed my bucket in a way that was unknown to me. So lighting up that path and lighting up the fact that it had access to the sensitive data is really what we're talking about here. Now, a lot of this technology is also, and this is hot off the press from March, came together and as part of the data security portfolio wave, Google was named a leader in securing enterprise data. And for a lot of the data threat, risk visibility, access controls, come together to really help that. So we're really excited about this. You can read more about this report. It was just published about a month ago. And what we've been investing in over the past year is really how to expand coverage of giving you that assessment. discovering assets, assessing them, and really understanding where you have those high value targets, and feeding all that information upstream or downstream into the workloads you need, like that risk engine and the virtual red teaming technology. We've expanded to cover Vertex, BigQuery, Big Lake, cloud storage across multiple clouds, including Amazon and Azure storage, as well as databases. And we're not stopping, we're continuing to do this, but this is the stuff that we've done over the last year. Now, I wanted to go through a very specific example, like walk through how this can actually help you understand and secure your data. So we kind of give a high level overview. Let's walk through an example using an AI workload. Now, AI, ML, and generative AI, obviously those are very top of mind. But the key is that they are fueled by data. Whether you're training or tuning an asset, or whether you're using a model to maybe access something, there's a lot of data floating around when you're talking about AI and generative AI. So understanding and protecting those sensitive or enterprise specific data is just really important to make sure your deployments are right, and you have proper use of your data. Now, here's another data set I created. And again, sensitive data can find its way into these assets. So here is a training tuning data set. And you can see here, I did a screenshot of this. My data set, when I uploaded it, had a lot of text files. I was building a text classifier. And it had a lot of credentials, secrets, and other types of PII. Now, it's pretty obvious here what you can see stuff you probably don't want to train in your data set. But when you have a lot of data sets and a lot of your engineering team working on it, again, key thing is, how do I understand that? So let's walk through the steps to really solve this problem. How do I make sure that data doesn't end up in my environment? How do I remediate it? So the first step is what we just talked about. Remove the unknowns. Make sure you have eyes on all of your assets. So continuous data discovery. So in this case, you can go enable sensitive data protection. It's our discovery product. And really get that bird's eye view across your org. Every one of these little dots on the map represents an asset or collection of assets that we found. And whether or not it had certain types of data in it. So in this case, scanning vertex data sets and making sure that they're in the right place, the data in the right geographic location, but also the data is in the right data set for training. Now, the second thing is, now that you know where your assets are and you have an idea of what's in them, really make sure you're using the right data for the right purpose. So in this example, you know, what if you had that sensitive data like I showed in my data set? What can I do to remediate it? Well, one option is to go in and mask parts of it. Here's some examples of masking data where you can go in and say, maybe parts of that data were useful, but the rest wasn't. So in this case, you know, we're masking things like someone's name, but retaining the context that we're still talking about a bill or an invoice. So that way the model knows it's an invoice, financial related. And same with credit cards. You might need to know, hey, we're talking about cards here. Maybe there's a whole flow of a conversation that you want to train on or tune something with. But you don't need the actual credit card number in there. So one option is just to go in and mask the elements. The other option might be to just remove the parts that you don't want. So in the case of mine, if I had full credentials in there, maybe the context isn't useful. I just need to remove that file, the JSON file that had the credential. Or maybe there's just things that are inappropriate for your AI environment. Maybe you don't want, you're training an agent, but you don't want it to really spit out source code or train on source code or resumes or certain context like financial or medical. So in these cases, you could just remove those elements while leaving the elements in that you want. So again, removing elements to keep the context or removing the entire sets of files there. Now, once you, you know, identify the process you want to do, it's really also important to automate it because these models are not static. You're constantly putting more data in or you're pulling relevant sources in to tune and train your models. So you can automate all of this. You can have all that sensitive data landing in one place, automate the redaction. We'll show this a little bit later, but basically taking all the sensitive data and continuously creating a redacted copy of it. And third, once you have all of this done, then make sure you have the right access control. You don't want to have all this great redacted content ready for training and tuning, but then have someone accidentally click on the wrong bucket, upload the sensitive data because they just forgot what bucket was the right one. So make sure you lock down the access control appropriately and also consider automating that. So one of the features that we launched last year has automated tagging, which means that it can, based on the contents of the asset, it can tag that asset. Let's say a BigQuery table or storage bucket. And then those tags can be used to automatically control access, like a conditional IAM grant. And this is kind of what it looks like. So imagine you've got this red bucket here where all your latest and greatest sensitive data is landing. You automatically make that redacted copy. So, you know, as stuff lands in, you're redacting it and making the green bucket. Automatically tag that one as high, tag that one as low, but monitor it to make sure nothing flips in. The green bucket is what you want to train on and tune on. That's the approved bucket essentially. And it's what you want to grant access to for your data engineers and maybe even the service accounts to prevent somebody again from accidentally clicking on that red bucket. So this kind of flow can be fully automated and give you that kind of proactive control based on the nature and the insights we know about the data. Now fourth, it's really to understand posture and risk exposure. So as we saw those two buckets as an example, making sure obviously like maybe neither one of them are publicly exposed or have the wrong access control, but then going back and looking at that more sophisticated risk analysis. So if we go back to that map or the attack path that we had earlier, this is probably looks familiar. It's that same scheduler VM one that I had. Well, it turns out it had access to a lot more than that one bucket. I had over granted privileges. I took the easy path and kind of gave it, you know, owner access to a lot of stuff. Well, it turns out it also had access to all of my vertex data. So again, even though I've locked down the vertex data from a, you know, access control standpoint, making sure you're continually looking at the risk and the exposure you might have from these more sophisticated attack paths. Like in this case, a VM that I thought was, you know, innocent and didn't really care about it getting exposed, but it's had access again to manipulate all of my AI data set. And for AI, I can put it at risk again for just exposure or something that's somewhat unique to AI like data poisoning. Someone in this case could go in and manipulate my data and cause my downstream models to do something I didn't intend. So that's why you want to make sure that those are locked down very well. So kind of just to summarize, securing AI data in this framework is remove the unknowns, continuously monitor your assets, always have eyes on what you're working with, and just make sure it's the right thing. Once you know what's in the data sets, second is mask or block unwanted sensitive data, and ideally automate that. Again, don't add toil by having this have to be a manual process. Have that automated. Next, again, set proper access controls. You're going to have data sources that are sensitive, some that aren't. You have eyes on them. Make sure that they're configured properly. And again, consider automating that with tagging and that conditional IM access. And even with all that, continuously assess your risk to data assets. Look at the more sophisticated attack path and really understand you have. Again, the idea here is identify your weak spots and really understand your unknowns so that they become knowns. And with this, let's see some of this in action. I'm going to welcome my colleague Jordana, who's going to walk you through and actually demo some of the stuff we just talked about. So I'm Jordana. I'm part of the engineering team for sensitive data protection. So I'm going to show you some of the things he's just talked about. So this is our dashboard for the discovery product. You can see here that we have a lot of coverage for a lot of systems. This is our test org, DLP-Bruckbrunn. And we've turned on discovery from both GCP resources, of course, Vertex, which we'll discuss more, Amazon and Azure. And I can see here that I have profiles all over the world. I have sensitive data. You know, here's something that's GCP. Here's something that's AWS and GCP. Some interesting sensitive data that I didn't know I had in Sol. And so this gives us that overview. And the nice thing about this, which I'll show you here in a second, is this didn't require any code. He kept on saying automation, and often that means coding. This can be turned on by someone who doesn't need to know how to code. We've really tried to make it one click, just enable it, easy to use. And although it has automation and APIs, Terraform, all of those supports for your engineers, if you want to let your non-engineers use this, it's meant to be easy to do. So this is our coverage dashboard. I'm going to jump into GCS, because I want to show actually, I'm going to show profiles first, because I want to do that one. So when we talk about profiles, like we feed those into like the those attack path simulations he was showing, but we have two main types right now. File store profiles and table profiles. And the idea here is that look, I'm an Oregon man, I'm essentially looking at my company, I don't know what my employees are really doing. Some of them name their tables poorly, some of them throw things in random places I don't understand with key names and acronyms that are very specific to their teams, but I essentially need to somehow govern them. The idea here is, you know, essentially I'll get these profiles and I'll see, for example, and this is a bucket, this is that one he had in his first attack pass simulation where it said there was something sensitive. What was sensitive in there? First of all, it's called my company web content, so it probably shouldn't be sensitive, it's public. But for some reason, I'm seeing in here that someone's put in social security numbers, sensitivity high, like person names, some hardware IDs, super SPI. So someone obviously made a mistake in my company and they've dumped this data in here. And now I have a quick overview of this potential big problem. I know it's part of a vulnerability too, because that VM is exposed. So I've instantly, you know, one click gotten this configuration. We do it for tables too. These are lovely because, say you have a column called data one. What were they intending with data one? Who knows? But look at that. Some other place with some interesting data. Why is it mixed? You know, it's obviously unstructured data. Somebody's notes field they're just dumping data into. It's not secure. It's not got a policy tag. So anyone with access to this table has access to this data. And I have, by just turning on discovery, been able to instantly see this centrally and see that there's something suspicious about this table. I'm gonna go back to our scan configuration. So these are, we have configurations for every single service. You can turn them on and off as you please. I'm gonna show the GCS one because the vertex data sets he was showing was trained on data sitting in vertex. And so to, I'm gonna just take an existing one just so you can see all the settings preset up. But all you have to do is create one of these discovery configurations. And I'm gonna say scan my entire organization. Maybe you don't want to do it organization level. You want to like split it up by folder. You want to look for different data in HR from your finance, from your interns. You can do by folder too. By default, we have like this default configuration and default schedule. But you can choose the cadence. How frequently does it update? Do you want it to rescan every day because you have a lot of data being ingested? Or is your data really stable and you're okay with like, hey, just scan it once and don't scan again? Maybe you only want to scan it when your lawyers have asked you to start looking for a new bit of information. So only when your inspect configuration is changed. So all of that's possible here. Each of our systems that we support scanning have different conditions and filters available to them. So maybe you don't want to touch your cold line storage because of the cost associated with that. You really do want to look at some regional storage and what's being replicated across your org. We have abilities to control whether or not you do your backfills or when you do them. So like, hey, somebody set up a new bucket. There's no data in it yet. Don't profile it. Wait until there's enough data in there that's interesting. So company employees will often like stage things. You can wait until the data is maybe a day old before you profile it. So all of this is configurable. So in this case, I'm using what's called an inspect template, which basically lets the user control what type of sensitive data I want to scan for. And that could be one of our many hundreds of built-in ones, but all of your own custom detectors here too. So obviously something you might consider, you know, some proprietary information sensitive that we wouldn't know about. You could build those detectors. I want to show these actions. So the actions are how we take these discovery profiles and connect them to the rest of the world. So we publish them to SecOps. So if you want to build event monitoring and event alerting in Chronicle, you can. Security command center is what lit up that attack pass simulation. So by turning that on, you control the ability to get those findings associated with your threats and vulnerabilities. Saving data profiles, the BigQuery, lets you have the raw results so that you can query and analyze it. And I'll show you this cool report that you get for free there. And the last important one to point out is tagging resources. So we mentioned you can automate this. This is all you do to automate it. Oh, it's a little fuzzy, isn't it? That's lovely. I'm going to... What happened? Well, you can roughly see it. You squint. So the idea here is you say like, hey, for my data profiles that are high risk, I'm going to tag it with this I am tag called high for the medium, low. And you can also say like, hey, for me, tagging is my governance. And so this is no longer a high risk asset if I've tagged it because I've set up an I am control to protect my data, which I'll show you in a second. So this is all you do to automate. You hit save, this deploys, and all of a sudden everything is getting tagged with its level of sensitivity. I'm going to show the... So I have this bucket that was tagged. And we see sensitivity level high. This one renders a lot better. And you can see like this one was automatically done. So I don't want my employees training Vertex on this bucket. And the way I'm going to prevent them from doing that is via I am control. So Vertex uses a service account called AI Platform Service Agent. And I've gone in and modified it. By default, it'll have like a default service agent permission. But I want to give more granular controls of it. So I've added this condition to say, look, when it's accessing Vertex, when Vertex is accessing GCS, I'm going to have this rule. And this rule says, I can only access data that's low or high or medium, sorry, and not high. And so you could do the opposite. You could say, hey, just deny, hi, but I've done the allow path. And so now when Vertex goes and tries to scan this bucket that I've showed you. And so we look at this bucket, it's some raw images. My employees are doing some form analysis on how to do form generation. And so they've uploaded all of these images of forms. And this one has somebody's name and address and some social security number data looking at it. I do not want them training on this. But, you know, maybe they've forgotten or a different person uploaded it. Now that I have this, when I go into Vertex and try to train it, it's going to say, no way. You can't access this. And it just happened, right? The employee setting up Vertex didn't know about this. This was set up at the org level. And I got instant control and protection. I'm like, okay, but I really want to let my employee train on that bucket. How do I get it safe? And we talked about redacting it. So I've got this bucket called Vertex Redacted. And I'll show you how I made that. So we have this service called, it's called Inspect Jobs. But it has an action just like Discovery. And one of those actions is to redact the content. I'm going to copy an existing one, test the demo gods here. I've got that bucket, that Vertex image bucket that we saw. It had some data that I don't want Vertex having access to. It's in a bucket profiled as highly sensitive. I'm going to set it up to search for the default info types that are built into our system. And I'm going to add this action that says make a de-identified copy. So basically, hey, I want you to remove and just, because it's an image, I'm going to just redact with, you know, colored boxes. We're going to try doing this live. And it's running. I do have a backup. Oh, there we go. Yay. Okay, so the, so we see that it found the person's names and the social security numbers and that street address that I saw. And I'm like, my Vertex team does not need to do that to do form analysis on how to generate forms. If we go to that redacted, so I saved to that Vertex redacted. And this one has low sensitivity. So it had been profiled before because I did the demo this morning. But that, you know, so Vertex can access this bucket. And if we look at the objects, so this was just redacted in that job, this is what the image looks like now. I'm okay with them using Vertex on this image. And so that was, that's the automation, right? No coding. It all did it for me. It went and crawled the bucket, found all the images. Obviously, I did it with one image today, but there's no limit as to the number of images that can exist in that bucket. And you get this automatic setup. And with the IAM controls, I'm not going to have any mistakes accidentally training on that other bucket that was a staging area. We needed to get it there, but we needed to not train on it. So the only last thing I wanted to show, I mentioned saving to BigQuery in the Looker dashboard reporting. So if we remember the, that web demo, the demo showed that like that website bucket had some sensitive data. The idea with this reporting that you get for free is, first of all, you can brand this. So if you want to like copy this report, put your own logo of your team on it and send this with your boss to say, here's the impact I've had, it just works out of the box. And you can customize it, make it brand correctly for your company. But now I can see exactly like, hey, here's this web sample. I can go and see that social security numbers were in this bucket. It was encrypted with Google encryption, but not C-MEC. And so it gives me a lot of visibility and research capabilities to go deep dive to remediate this issue. So even if I fix that security issue that was in the VM, this should have never happened either. So now I can go back and fix my data sensitivity issue. So that is the demo. I'm actually going to invite Nathaniel up. He is one of our strategic partners, as Scott said. He has worked with some of our highly regulated customers adopting this in their companies. And so he's going to share a little bit about that. Can we switch back to the slides? I can't believe you did that demo live. It worked. Okay. There we go. Perfect. Okay. So thank you very much, Scott and Jordana. As mentioned, I'm Nathaniel. I work with a premier partner, Strata Prime. We're going to talk a little bit about the hows and whys for getting set up with SCP or sensitive data protection in the first place. So let's start with a couple of questions that all businesses are going to have. They're two simple questions, but very critical for regarding your data at rest. First one being, how much do I have? It sounds like a natural place to begin, but let's be honest with ourselves here. It's not that useful. It's no more meaningful to know that you have terabytes or petabytes of data than it is to count the number of desk drawers. The real question is what's inside them, or in this case, what's actually in your tables or your storage locations. So that's where the real value and therefore the real risks lie, which then leads us directly to our second question. How do we find out what's inside? How do we discover what's inside efficiently, accurately at scale, as Jordana has actually just walked through a demo for us on. So luckily, that's why we're all here today. We're going to answer those questions starting with focusing on our profiling and inspection with a little more context. So this isn't just a challenge for big companies, you know, the ones flooded with acquisitions that are drowning in massive data lakes. Smaller and still nimble companies are faced with these same issues at alarmingly similar rates. The large organizations, they will naturally accumulate data, whether from mergers, new tools, or having just had many days of daily operations. Before they know it, they have massive amounts of unstructured, unknown, and often unmonitored data sitting across a variety of systems. Smaller businesses and startups, on the other hand, they tend to move fast. They're adopting different solutions, keeping up with sudden demands, and ever-present new challenges. But that agility, it's a bit of a double-edged sword and often leads to data sprawl and rapid spreads of information across multiple platforms with less or sometimes no centralized oversight. So regardless of size, all of our businesses need a scalable and efficient way to understand their data, protect sensitive information, and as required, remain compliant. So let's talk about profiling first. This approach is all about efficiency. It's going to provide a high level overview of your data without scanning every single record. This makes it incredibly cost effective. But it also means there's less noise. So you're not overwhelmed with excessive findings. Anyone who's used a security or scanning tool in the past is very aware of how easy it is to lose sight of the forest for the trees, and profiling helps you to narrow that down so you can focus where your efforts are best spent. As mentioned, it's also going to ensure you've safeguarded your AI and analytics platforms so you're not introducing unnecessary bias or risking any sort of PII by sneaking into a bucket that obviously shouldn't have been given access to. And then long-term usability. As mentioned, profiles are able to be set up on a scheduled cadence. So you can automatically have them update periodically, ensuring that you're not scanning to see what's been shoved under the rug in the past year, but rather maintaining a constant ever aware state of where your data is. As an example, for where profiling can be helpful, say a logistics company rushing to the cloud thinking their data is clean. A profiling pilot on just a small percentage of their data, boom, sensitive customer data in an older storage system they'd forgotten about. Starting with SDP meant there was still time to pause any migrations, tag those risky buckets, set up a compliance dashboard. Profiling can save the day. A term I like to throw around a lot as well is dealing with the wild west of data. A retail company, for example, may have a data lake grown with little or no rules. Using cloud SDP profiling and BigQuery, you can identify those unknown PII fields, set up data lineage and access policies, effectively turn profiling into your data compass. Most importantly for many of us though, you can have additional knowledge without blowing your budget. So a fintech company may be worried about profiling costs of this massive data they've accumulated over the years. After running some cost estimations, we can help them by filtering profiling jobs to only recent data, configure some subscriptions to help with budgeting purposes, and ultimately control costs while maintaining a high value. Profiling then becomes a proactive habit to ensure compliance going forward. Which then is going to lead us to inspection and when we may want that. So when we need additional insights, when we want a better understanding on every instance of what we have for audit or additional compliance purposes. One thing to be mindful of though is the cost risk. Because you're processing large amounts of data, however much you want, you set the percentage you want to scan, costs can grow quickly and scale if you're not carefully managing them. There is also some operational overhead. While profiling largely automated, inspection can require more of a configuration, certainly if there's any ongoing adjustments. We've worked with many orgs over the years who thought their logs were clean, for example. After discovery introduces or indicates some potential risks, you may want to run an inspection to find full names or other specific information left over from some dev testing, for example. This of course leads you to code fixes, log sanitization, but most importantly a mindset shift. Inspection helps you to turn the unknown into a culture of security by identifying all of the known. One example I always like to share here involves over-inspecting. This is something we've had a lot of companies run into. Imagine you have some of your company guides or procedural data in the cloud and you want to make sure you've not accidentally uploaded something sensitive. Think names, addresses, emails, phone numbers, you know all that stuff that we as consumers share with companies that we don't really want shared any further. So you as an IT professional go ahead and you set up a scan. You're now looking for names, addresses, emails, and phone numbers. But before you spend all that time and money configuring and then waiting for the scan to finish, remember inspection is going to look at whatever percentage of the data you tell it to. So it could be a lot of both of those. Anybody here ever seen a memo, letterhead, SOP guide, or really any company data that has your information on it somewhere that didn't contain perhaps a staff name, your address, emails, or phone numbers on every single page? So this is where you want to make sure you're tuning your inspections. Things like hot word rules and properly scoped jobs ensure that you're not finding data that you don't actually care about. As false positives go down and accuracy goes up, trust will follow with it. Inspection jobs ultimately are very powerful, but it's critical to make sure that you're not overburdening yourself with unactionable results. So let's take a step back and ask ourselves what is the point of all these results? Whether you're using profiling, inspection, or both, you're going to generate a bunch, potentially a lot. So that brings us to our next critical question. What do we do with them? Simply detecting the sensitive data? That isn't enough. You'll need a plan. It's easy to generate millions of alerts, but are you prepared to act on them? This is where reporting and response strategies come in. Organizations must define what they're going to do with these findings, whether it's removing the unnecessary data, securing access, implementing new policies that ensure safeguards are in place. And that's where a Google Cloud Partner can be a key ally in all of those moments, as they've likely seen something similar, and can help you with tailoring your templates and offer security advice necessary to make those informed steps going forward towards remediation. Specifically thinking of companies undergoing regulatory scrutiny or those who've recently absorbed another business, as they stand to gain the most from identifying what they have and assessing those security risks. But again, let's not forget those who've just begun their cloud journey. Knowing what you have from day one is a great example of an ounce of prevention being worth a pound of cure. So finally, and a little selfishly, but no less critical, the role of a partner in this process. As you're all aware, every business is unique. All of different industries, different regulations, and different risk factors leading to different destinations when it comes to terms like best practices. A Google Cloud Partner can customize the sensitive data protection tools to help it to fit your exact needs, ensuring optimal performance while maintaining compliance alignment. This is done through things like knowledge transfers with your staff, custom template designs, and additional reporting. We also will assist you with cost optimization, so strategically using the tool to avoid overspend. And then the ever constant security being more than just detection. It's about response. A partner can help work with your teams to set up proactive risk management strategies, including things like automated alerts, remediation playbooks, and workflows that use those results to trigger things like data redaction, encryption, access restrictions, the blanking out of forms as we saw earlier, obviously potentially automatically. A partner will also assist with accelerating deployment. So instead of spending months or sometimes years figuring out and writing the right balance of profiling versus inspection and the procedures your companies will follow, a cloud partner would bring deep expertise with their security frameworks, compliance, cloud tools, effectively reducing your setup time to get your team up to speed quickly. This ensures your sensitive data protection strategy not only meets the needs of those best practices, but also maturely evolves with your organization. So I apologize for the sales pitch. Now that we've discussed a bit about securing your data at rest, I'm going to ask Scott to come on back up so we can have a little bit more of a look at motion to the future. Thanks, Nathaniel. Great. And we talked earlier about a lot of this stuff that we've expanded to over the last year. And we're not stopping there. And one of the things we wanted to highlight today is a kind of a little bit of a new area, which is data in motion. Now, our service has always been able to help classify things at runtime. We have an API that will allow you to go in and actually build it into your applications, throw it in front of maybe environments where you've got like live chat or you need to have a response immediately. So we've had this runtime protection. But what we're really talking about here is how do I actually monitor or profile maybe existing data in motion, something maybe going through like a load balancer or secure web proxy. So if you imagine a workload running over here, you've got some destination service, maybe this is a virtual machine or web application, this could be another partner system or even a user. And the idea is that that's going through networking services like a load balancer or a secure web proxy or gateway. What we're looking at is the ability to effectively monitor that traffic and give you insights into the data that's moving between those two endpoints. The idea here again is, I want to know maybe this particular virtual machine isn't storing any data, we didn't find anything at rest. But all day long, it is processing things. So if somebody were to gain access to it, they could potentially tap into that process. So knowing that data motion is very critical. We have this kind of animated example here, it's going to keep repeating. But this is showing you what that looks like. In the left side, I've got a virtual machine, I've SSH into a VM, and I'm making curl commands, but essentially API calls, in this case, into Vertex. So you can see here, I've made a request in, I've asked a question, this is a response back from a Vertex model. And as a virtual machine, this is like a client just talking to that API. I'm not storing any data, Vertex isn't storing any data, the VM isn't storing any data, but that data is going back and forth to these two services. What's happening on the right side is our dashboard, that as I make this request, when you update it, you can see the finding count goes up. We're basically monitoring that traffic and detecting, in this case, hey, you sent some personal information through, maybe the prompt in this case had a credit card number, or the response had something in it. Again, the idea is it's all data in motion. So this is what we're looking into next. And we actually have this ready for preview. It's something if you want to try this out, you can take a picture of this and go to that link. It's going to take you to a Google form to fill out, put your information in, and we'll contact you and get you hooked up on the preview if you're interested.