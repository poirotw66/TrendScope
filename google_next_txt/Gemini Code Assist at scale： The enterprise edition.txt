 . You work too hard. And so do your developers. That's why you're going to buy them Gemini Code Assist to make them faster and more productive, make their life easier. That's also why you are sitting here, still working, on the very last session of the very last day of Google Cloud Next to find out how we can make your life a little bit easier and more productive. So let's get into it. Let's start with licensing. For you admins out there, big one right up front. Use automated license management. If you take away only one thing from this talk, that's going to save you the most time. Use automated license management. Why? Well, with manual license management, which is an option, your enterprise administrator can take licenses from your Gemini Code Assist pool and allocate them one by one to each of your developers as they have need. Just type in the email address in the dropdown, put that license over there, and then if your developer needs to move off of that project to some other project, you can reallocate that license. Take it away and give it to somebody else. All those licenses are available in a nice little view. You can see who's assigned licenses. And all of the UI that you're using to allocate licenses is also available by API. So if you are a large enterprise writing a bunch of custom integrations, you can create your own workflow to manage your licenses. But there's an even easier way, and that's automatic license management. With automatic license management, the Gemini Code Assist service will manage the licenses for you. As developers log in, they reach out to the server and automatically receive the license as they have need. Which means you don't have to worry about who needs a license ahead of time. It's only given at the point of consumption. And if that developer decides to move off to a different project or take an extended vacation, Gemini Code Assist can automatically detect that lack of usage, deallocate the license, return it to the pool for another developer to use, helping your enterprise be more efficient. And that can take place in a configurable amount of time, as little as seven days of inactivity. And of course, you still see a list of all of the users who have licenses assigned so that your enterprise admin stays in control. So that's great. And that is going to solve the problems for most of the customers, maybe even most of you in this room. But maybe you're a large enterprise. Maybe you have thousands of developers. Maybe you need some of them to automatically receive licenses, but maybe some you don't want accidentally consuming that license. How can you do that? How can you manage a bunch of devs at scale? Well, I'm going to go through a demo, and we're going to talk about scaling your license assignment using automated license management with custom IAM roles and groups. Now, the demo goes a little quickly, so I'm going to tell you what you're going to see. We're going to see a manual license assignment, the way that you would normally do it with anybody. You're going to see how to create a custom limited role. You're going to see how to allocate those licenses based on groups. And then finally, how to check your work and make sure that you did everything correctly. So let's get started. So here... There we go. Here we are in the Gemini Google Cloud console, and we're going to go up to the IAM and admin area. And here we can see a list of all of the individual users that are in our system. Now, we're going to go click grant access, and we're going to give access to a new developer on our team. So we type in the email address of this developer, and we're going to assign a couple of roles to this developer. The first role that we're going to assign is a just cloud usage role. This is a very common role. It's not actually needed for this particular demo. It was used from some legacy products. We're going to use it here as a placeholder. So after we add our service usage consumer role, we're going to add the Gemini for Google Cloud user role. This role gives this user all the access to the power of Gemini. It gives them access to code generation, code completion, chat, debugging help, and most importantly, the ability to go out and retrieve a license from the automated license assignment and management service. Now, if we type in our developer's name, we see that, yep, indeed, they have those two roles that we've assigned. Everything is looking great. And if we go down to our roles tab, we're going to take a look at the Gemini for Google Cloud user role that shows all those different permissions. Now, here I want to point specifically to one permission, that self-assign permission. Self-assign is what allows them to make a query to the server to get a license. Everything else is just about using Gemini. So I'm going to create from a role. This is going to be a derivative role that I'm going to manually configure. And I'm going to call this a manual assignment role. And this is going to give all the rest of the Gemini permissions with the exception of license assignment. So if I go there, I'm just going to go and uncheck the self-assign. And now we have our custom role ready to go, ready to assign to users. So now when I go to grant access, this time, rather than granting access for that limited role with only a limited set of permissions, I'm going to grant access to a team, a group. And I'm not actually assigning licenses to the team. I'm assigning permissions to the team. And so I'm going to type in my new team name, Team A. We'll call them the A-team. And we're going to give them the same generic permission that we gave before, that placeholder permission. But we're also going to give them this manual assignment for Google Cloud user role. There's our generic permission. And we're going to save that. And then we'll go and take a look at our team. Now, teams are managed at the organizational level. So when I go into the teams section, the group section, you'll see that I'm in the context of my personal project, the UX test project. And so I'm going to bubble up to my organizational level, which is where all the groups are stored. And there's my A-team, predefined. It's an empty group. And I'm going to go ahead and add one new user. This is going to be a business user. And so we're going to go ahead and add their email address here. And they're going to inherit all the permissions in that team that we've just assigned. So there's our business user added. Now, how do we know that we did this correctly? Because if you know that IAM roles and permissions and groups, there's a lot of overlapping assignments for individual users. And sometimes it's hard to keep track of exactly what the permissions are for any individual user. So we're going to go to the policy analyzer, which allows us to do deep queries on all of the policies and permissions and double-check that we did this right. So inside the policy analyzer, I'm going to create a custom query. And I'm going to specifically query on that kind of generic placeholder role. So there's our service usage consumer role that we're going to type in here. And then when we say continue, we're going to list individual users inside of groups so that we can see all the detail. And when we run our query, as expected, we see that it's the one developer that we manually assign, as well as our business user who inherited it from the group. And it's showing that the group has that role. And then just to close the loop and double-check, we're going to do the same thing. And as you see, as we go here in a set of service usage consumer, we're going to type in that manual assignment role we just created. It shows up right there in the autocomplete. And when we say continue, does the business user have that role? And does the developer not have the custom role? Because they got the built-in role. And yes, in fact, they do. So this is a really practical thing that you can take home. You can use this today to manage your organization. So great. So hopefully, all the admins in the room are feeling like you've gotten some practical tips. You're a little bit more efficient. Gemini is already making my life better. But what about the security? What about the CISO? How do we make the CISO happy? How do we protect all that enterprise data? Well, it turns out, let's start with everybody's favorite auditing. Hey, who doesn't love a good audit? We have the ability to turn on audit logs for Gemini Code Assist. Audit logs are so powerful. They allow you to collect every single prompt and response from every single one of your developers. You get to see all the context, the prefix, the suffix, any other files that were pulled in as context, whether they are local files or whether they're remote files from code customization for enterprise. And of course, all of this logging data is stored on a bucket that you control. You own this data bucket. You control the retention policy. You can even set your own custom encryption keys with CMEK. Google never sees this logging data. It's never used for model training. Never shared. Or for our enterprise customers that are currently using code customization, you probably already know that you can define an AI exclude file. Works just like a get ignored, drop it into your repo, and limits what the indexer is going to pull from your private repository. But did you also know that you can define AI exclude and put it right on your developer's local machine and limit local context as well? So if you have particularly sensitive data that you don't want used for context, you don't want surface to a developer, you can use AI exclude to remove that. And of course, because it's never included as context, that also means it's never going to show up in those logs. So if people inside your organization are looking at logs, they're not going to see it either. What about outbound data? Well, for our enterprise customers, exclusively for enterprise, we have the ability to restrict a lot of outbound data. Telemetry. These are all just the how many active users do you have? Are they accepting code assist suggestions? How many lines of code were generated? These are anonymized aggregated data points, mostly used to drive dashboards for you. But we've heard from some of our customers that they want to even restrict this data. And we have the ability to implement policies on your behalf which restrict all the outbound telemetry and block it from even being enabled in the browser. So if you're inside your IDE, your developers cannot enable telemetry, and all that will be turned off for your organization. Similarly with feedback. Every time that you type something in Gemini, maybe you get that little thumbs up, thumbs down button. We love your feedback. And as a product manager, I really want your feedback because that helps make the product better. But that feedback comes with a text box. And if you don't necessarily trust your developers, maybe they're going to write something in that text box that you would rather they didn't. Maybe they're going to attach a log from Gemini that you don't want exposed to Google. You have the ability as an enterprise customer to turn off all of the feedback controls so that you will not be able to send any feedback anywhere in your organization. And finally, network blocking. Now, this is not for most customers, but if you need it, you know you need it. We have the ability to completely block all Gemini usage from outside of your network. This means you're configuring a proxy on your network, you're injecting a custom header at the top of every request, and we're looking at all that code assist traffic to make sure that it's secure and configured just for you. We know that not everybody needs that, but if you do, we're here to serve you. What about legal risk? Well, Google carefully vets all the code used in our model training, and we know that any code that is generated by Gemini is safe to use, and we are so confident that we stand behind our code with an incredible AI indemnification policy. If you are challenged on copyright grounds, we will assume the responsibility for the potential legal risks involved. Additionally, we are surfacing in IDE warnings to your developers so that they can see when code that they are writing might be subject to a particular license, even if it's a permissive license. But exclusively for our enterprise customers, we have the ability to block all citations. We know that some of you work with large numbers of developers, maybe earlier in their career, who might not have the best judgment in choosing whether to accept that kind of cited code. So you can block it entirely so that it never even appears for the developers. And coming this year, we are working on making that even more flexible. So if you want to specifically or allow or block a very particular license, we have the ability to do that coming in a little while. Finally, I always get a question from a lot of our enterprise customers about data residency. This is particularly important to customers in regulated industries, customers in certain jurisdictions. And so I want to be real clear about where we are today, what we can offer for you today, and where we're going. CodeAssist is today a global service. That means that CodeAssist, the base model, is served by a global endpoint out of data centers in the United States, the EU, and the Pacific region. And in general, we will service a request based on the data center that's closest to you, generally geographically, but really it's based on latency and hardware availability. Today we're actually serving a large number of requests from Gemini out of our EU data center. However, that specific residency is not guaranteed for the generic CodeAssist model. But because the CodeAssist model is stateless, it's not storing any data at all. So if you're concerned about data at rest, you can use even the base model of Gemini. So you can use even the base model of Gemini CodeAssist in a global manner without worrying about data at rest. For Gemini logging, which we talked about, because you're in control of your data bucket with Gemini logging, you get to choose where that's deployed. So you can choose a particular region for all of your log storage and use log routing to make sure that all your logs are stored in the region of your choice so you can satisfy data at rest for Gemini logging. For enterprise code customization, it takes a little bit more configuration. Frankly, the enterprise code customization service is a fairly beefy service. It has some very specific hardware needs, so it's not available in all regions. But talk to our team, and when you set up your index, we can help get it deployed in one of the available regions. With code customization, that means that all of your data, the snippets from your code base, all those indexes, they are stored in the region that you choose in an AlloyDB database instance inside a tenant that is determined just for you. So you have data at rest with enterprise code customization. And we do also have data in use. And I've got a little asterisk there. So enterprise code customization, all of the indexing, all that takes place inside the data center that you choose. There are some potentially small ancillary services, some of the, like, back-end monitoring and logging. We've not yet guaranteed that all of those are going to be regional. So we're not showing a data in use guarantee on enterprise code customization, but I can tell you that the majority of the work is actually happening in region. We're going to be working on improving that, which brings us to our roadmap for 2025. We know that data residency is so important for our customers that we, and by we, hey, it's me, I personally am working on the team that is trying to make data residency faster and easier to configure with a single setting to specify where indexes are created, where Gemini is doing the inference, where logs are stored. This is not going to happen right away. It's going to happen maybe little piece by piece as different little bits come online and start to respect that setting. But this is where our head is at. We really want to serve the global market. And finally, regional expansion. As I mentioned, we have data centers in the United States, in the European Union, and in the Pacific region. But maybe you have a requirement for data residency in another region on Earth. If so, please talk to us, because we really need that data. It helps us allocate our resources. We want to build out data residency everywhere on Earth. But we're going to choose which ones to do first. We've got to buy a bunch of chips, got to build a bunch of data centers. Talk to us about what's important for you and for your individual customers, because that helps us make the right priority decisions. Gemini Code Assist is built for scale. We want to address the needs of large, complex organizations with tons of users. We are secure with options to control data and match the unique security posture of your organization. And finally, we are global. Our ongoing investment to support the unique needs of customers across diverse industries and geographies. Now let's hear from Scott, Group Product Manager with Google Cloud, to learn about how Gemini can manage all of your enterprise APIs. Isn't he great? Thank you, Andrew. That was awesome. We're going to switch gears a little bit, and I'm going to talk to you about how Gemini Code Assist Enterprise gives you some specific functionality in a couple of products that we have. So let's take a step back and look at what Gemini Code Assist provides to you. You can see on the left-hand side there's a bunch of code generation, lifecycle management, database, including Firebase and other databases, as well as mobile development, where you can generate code, you can generate SQL statements, you can generate a bunch of very useful things for your developers. In enterprise, you can see in the right-hand side in the blue box, there's some very specific features for BigQuery, for Apigee, and for application integration. We're going to drill into this box, and I'm not going to talk a lot about BigQuery. That's not my area of expertise. You can definitely read up on that. But I am going to drill into Apigee and app integration. For those of you that don't know about Apigee, it's our Google Cloud API management platform. It provides API management, security, throttling, analytics, all the things that you would need to manage your APIs and secure them so that you can expose those APIs to your partner ecosystem, build new channels of business, and have a really good control over those APIs. Gemini Code Assist in Apigee provides three specific features. One, we can generate open API specs, and we use your enterprise context to do that. I'll explain that in a minute. We give you assisted proxy authoring. So this is a feature that helps you as your developers are developing their proxy. And we centrally govern APIs in API Hub. So let's talk a little more about generating open API specs. What do we mean by enterprise context? We can actually use a Gemini chat interface in your IDE to create a valid open API spec. And we can intelligently reuse schemas, metadata, security policies that you have across all of your other APIs, which are registered in API Hub. So you can get a consistent schema across all your APIs, for example, for your customer object or for your address object. This gives you the enterprise context. So we're going to use Gemini Code Assist in the developer VS Code environment here using our Apigee Code Assist plugin extension. And this video kind of started in the middle. It's a GIF, so it'll replay. What we're going to do is we're going to go into the left-hand pane. This is where we have the Gemini chat interface. I'm going to try just going back the screen and forward and see if it'll start over. Nope. It's just plain. Okay. We're going to go to the lower left-hand pane and we're going to type in at Apigee. This brings up the Code Assist features. And then we're going to... Okay. Now we've started over. And we're going to say, hey, we want to generate an open API spec. And then we're going to tell it what kind of an open API spec. We're going to generate one for order management... Managing our online orders. So you can see that it generated a spec. We can see the notes in the left-hand pane. We can see the spec in the middle in the editor. And then we see a visual representation of the spec. Now we're going to go and look at the order object. And we can see that some of the addresses that it chose are not our standard address object. So now we're going to go back to the chat. And we can ask Apigee's Gemini Code Assist chat to replace that address object in the schema with our standard object. So we're going to type in a prompt in the lower left-hand corner there. And now you'll see that in the diff view, we can see what's been changed. And now we're going to go down and find that address object in the order. And we can see the shipping address and the billing address now are using the correct address object. So you can see that even though we generated the spec, it didn't have exactly what we wanted. We were able to actually use Gemini Code Assist to fix it and do what we want. So this brings you a lot of power into your developers. Now we're going to publish this to API Hub. So we go to the save bar. And once we publish this to API Hub, now this spec is available to all the other developers in your ecosystem. And it will now start being part of your enterprise context as well. So the assisted authoring we saw when we changed that address, this allows you to develop and maintain your proxy by using Gemini Code Assist on an ongoing basis. So even after you've generated it, you can continue to edit the spec as needed. It also helps with code explanations as well. Now, API Hub is a catalog, an enterprise repository, so to speak, of all of your APIs that are available. So once you've published your API into API Hub, it now becomes available to the rest of your developers. This gives you central governance of your APIs, and it's a catalog that's available to help with your lifecycle management. One of the benefits of Gemini Code Assist and API Hub is that it uses semantic search capabilities. So let's say that you're looking for something about an order. You can search for order, and it'll come up. Or you can search for maybe purchasing, and you might find the order because that's semantically related to orders, right? So it's using that semantic search to give your developers a full set of search capabilities, even if they don't know the correct term. Now let's switch gears again and go to application integration. This is the product that I own as a product manager, so I'm really excited about this one. And this is the problem that we're trying to solve with application integration. This is Google Cloud's iPads. And we have customers that have up to 500 different applications across their ecosystem. It could be packaged apps like SAP or ServiceNow or Jira Cloud or an Oracle database. Or it could be custom apps or it could be legacy applications. Data needs to be exchanged between these applications, and it is not easy, right? It doesn't come out of the box, and it has to be built. So this is the problem that our customers are facing. This is the solution that we propose with application integration as an iPads. We put application integration in the middle. We have almost 150 pre-built connectors to these common applications. And we make it easy then to connect and do things like data mapping and orchestrating the data movement between these applications. It's a visual integration designer, so it's all drag and drop. It's plug and play with the connectors, and then it's all managed by Google. So it's running in Google Cloud on the same infrastructure that we run Gmail and Google Maps. So it has enterprise scale capability. So it's a visual integration. This is how it works. This is how it works. We start with a trigger. We can be triggered by an API call, by a message queue, a message arriving in a message queue, by an event sent to us by a SaaS application, like Salesforce, for example, based on a schedule. And then we run it through a series of orchestration steps. So we can do data mapping. We can do data merging. We can look up data from connectors. And often you're going to use a connector either as the endpoint or as part of the flow to gather data to enrich the message. So you can build with clicks or this is where Gemini code assist comes in. You can actually generate an integration flow now. So from a prompt, you can see in this little video that's playing, we're going to create a new integration. We're going to select one of these pre-built prompts and then say go for it. And Gemini code assist is actually going to generate this flow with the tasks. And it also will generate some of the data mapping for you as well. So we're getting better and better at being able to generate more and more of your flow. This gives you a great starting point. And just like we saw in Apigee, you can continue to edit the flow with Gemini code assist as well. So if you want to add a new branch or you want to add a new task, you can ask via a prompt to add that. Another exciting thing where we're getting a lot of traction with customers right now is with agents. How many of you have heard about agents this week? I'm sure that this is not the first time. Well, we have a really sweet spot with agents because we can actually generate an agent based on an integration flow. And this can become your enterprise truth for a business process. If you think about it, you don't want your agent to guess what your business process is. You may have business rules that are very specific. You may have compliance requirements, regulatory requirements, where you have to do data validations and all kinds of different steps as part of your process. And that's what we call a deterministic flow. You don't want to guess that, right? You don't want the agent just figuring that out. So we can create those flows in integration and then we can expose them as agents. So sometimes you have a very simple operation. You just need to look something up in a database. So on day one, you might start with the connectors only and be able to do simple CRUD operations with a single table and a single database or an application. But as day two approaches and you have that complex requirement of an orchestration, business process rules, things that just have to be done the same way every time, you need that enterprise truth for something like create an order. Now you can move up the stack and go to the integration first approach and you can create an integration for that. Now you're ready to, on day three, take this to production and your enterprise architects and your CISO are going to have a whole list of things that you have to check off before you can go to production. And guess what? They're going to ask about security. Right? So you can put Apigee on top of these integrations to add even more security and to follow your company policies regarding API security. Now a very exciting announcement was made this week at Google Next for ADK, the agent development kit. And what's really awesome is that we're able to be a part of that agent development kit with Apigee and app integration with one line of code in ADK, you can call out to an application connector. So in five minutes, you can create an agent that talks with your SAP system or 150 other applications that we have connectors for. This is really exciting because it enables your developers to quickly create an agent which connects to your backend applications. And we all know that agents are only as good as the data that they have access to. Now I'm going to show you a quick demo. This is going back to and kind of relating to what Andrew was talking about with license management. So since we were speaking together, I said, hey, why don't I build a flow that automates this license management for a specific user? A specific department maybe where they want specific users to request a license and then have it approved by a human approver. So in the demo, what we'll see is a Google form that's used to request the license. It's a very simple form. It's just your email address. Of course, you can put other things if you want. It's going to kick off an application integration flow. We're going to send it to a human approver. Once that's approved, then we're going to call the APIs that Andrew mentioned, which are available for license management. So we'll be able to add that enterprise license to the user. And then we'll email the results to both the user and the approver when it's done. So here we are in the license management screens. We can see that there's no licenses that have been assigned. We go to a Google form, and we're going to request that this email address gets a license. That's going to send a message to PubSub and kick off this flow, and we're going to send that to a human approver. And you can see this is all drag and drop, low-code interface. And then we're going to call that REST API to assign the license once it's approved. So what we're going to show you also is that we can actually generate some of the data mapping that we need in order for this to work with Gemini. So we're going to put in a prompt. We have some complex input that comes from the form. And we're going to tell Gemini code assist, hey, we have this input. I'll give it a sample string. Please extract out the email address for me. Right? And so now it's going to think about that and generate some JavaScript that will go and parse through that message and give me the string that I need. And you can see how it generated this code. Now we're going to execute this by filling out the Google. We submitted the form just a little while ago. We can see in the execution logs that it succeeded. And now there's the email with the response. And now we're going to go to the logs again here. And we can drill in. And as you can see in our logs, we can see everything that's happened. And now we can see that that user was added to the licenses. So I'll leave this up for just a minute. You can scan this to learn more about application integration. This will take you to our main web page. And you can sign up for that. I'm going to invite my co-speakers to come back up. Andrew and Ed, who is joining us. Okay, so we're going to have a little bit of a Q&A session. Ed is joining us from Marsh McLennan. Ed, can you tell us a little bit about your company and your role? Yeah, absolutely. So Marsh McLennan's been around for about 150 years. We're a professional services company that largely focuses on risk. So we're the world's largest insurance broker. We're actually Alphabet's insurance broker. We're the world's largest reinsurance broker. And then we have consulting businesses from strategy the whole way through the human capital spectrum. I sit in a central organization, MMC Tech. And as it says on the slide, my role is API and AI innovation lead. And I think like a lot of people in the API space, when large language models came along, they came as APIs. And so we started engaging through that. And then as sort of AI has grown and grown, that's taken over more and more of the role that I play within the organization. So I'm now supporting enterprise services across AI. So not just LLM APIs, but also vector search, vector storage, web search, and other services like that. Awesome. So maybe, can you tell us a little bit about how your organization is using Gemini Code Assist today? Certainly. So we've got Gemini Code Assist in a couple of places where we're getting started. The first one is we've got actually with some of those AI groups. And so we've got some people trying it out, testing it out on the frontiers to figure out where it can help us as we move into a more AI-enabled development world. The second space, and the one that I know a little better because I'm part of it, is with Apigee. And so we have a number of things going on with Apigee at the moment. As an organization, we're in the middle of a cloud migration. So we are moving from on-premise to cloud. That also means we're moving from some of the older Apigee flavors to the new Apigee X product. And so we have, as you would imagine, for a large global organization like ours, we're quite complex organizationally. So when it comes, we've got about 600 Apigee developers, and they all have different roles, permissions, things they should be accessing, things that they shouldn't be accessing. And we're carrying out this migration in different ways. So a lot of things you just showed earlier about, this is how we assign permissions to groups, this is how we allow for flexible assignments of licenses. All those things are going to come to play over the next couple of years. Because we're going to be basically asking for specific areas of Apigee focus from development teams for, to your point, a month, two months, three months, as we move through a wave of migrations. And then we want the licenses to shift to the folks who are doing the next set of migrations. Awesome. So, Ed, I know you're in a global organization. It's also like a highly regulated industry. What factors did you have to consider when you were adopting Gemini Code Assist? So, I think the set of factors are changing. So, the first set of factors are, and I think some of the ones Andrew said at the start, but fundamentally, you know, we need to know that you are not looking at our prompts. You are not logging our prompts. You are not using your data to train models. All of that has become sort of the table stakes for the enterprise. Like, fundamentally, we need to be able to interact with any form of code assistance in a stateless manner. And then, as we've moved further down the journey, and also, frankly, as Genitive AI has evolved and the regulatory environment continues to evolve, what's becoming more important to us is the level of control we have. So, for example, in many of our businesses, you know, something like global LLM management, global, as I said, prompts might be okay. What we're finding now is specific geographies. So, the European Union is one example. All specific customers, such as governments, are now starting to put much more stringent responses on what we do. So, for example, we have, we do, there's a government entity that we're doing work for that is now saying all LLM data processing must occur in a specific country. And so, for us, that brings in a huge set of challenges, and I think some of the stuff you're talking about later in the year is going to help us there around, you know, basically, without that, we're going to have to start the unfortunate process of taking tools away from developers they've been used to for the last year or two. So, you're talking about taking tools away from developers that they're used to. So, what kind of benefits are you seeing with developers using Gemini Code Assist today? So, I think the main ones that we've seen are sort of two principle buckets. One is where are the developers getting to the experience? It's meeting the developers where they are. So, it's a little, it was a little hard to see in sort of the GIFs flicking by on the screen, but if you're an Apigee developer, the ability to basically drag over that section of code that you're looking at, and there's a tiny little button that appears there, and it's got a map, I couldn't actually tell you what the icon is, I think it's a magic wand, but you click on it, and that then brings two things. It brings the context of the snippet of code that you're looking at, but it also then, you know, it summons effectively the context of that Apigee policy. So, all of the documentation, all of the rules around how that happens. The second thing is once you get into that, what we found is, especially Apigee, it's a unique product. It's the way that it handles certain situations. I'm thinking edge cases like missing data, null data, blank strings, things like that, are sometimes a little different than you think it might be. And what we've seen with Gemini is it does a really good job of actually not just saying what will happen, but actually explaining and putting it in context. It's actually helping to upscale new developers to Apigee in those spaces. Awesome. Thank you. That's great. We're going to actually end our session now, and we would love to invite you all to be part of a selfie. Does that sound good? Final day selfie. We're going to take a selfie and have you in the background here so we can post it to LinkedIn. And you can all prove that you were here. That's right. So, to the Friday crowd. It's very bright with the lights, so I don't know what you're doing. Anyone's face will be recognized. You don't have to worry about that. But thank you for joining us today. It was really a pleasure having you. Thanks for sticking through to the end of the conference with us. And we'll be up here in the front for a little while if you have any specific questions. And if we get booted out of the room, we'll hang out outside for a little while. Thank you again for coming and enjoy your travels. Thanks, everyone.