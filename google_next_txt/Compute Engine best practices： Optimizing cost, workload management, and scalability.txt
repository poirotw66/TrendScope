 Hi, I'm Paweł Wenda, Product Manager here at Google, and I would like to introduce you to Compute Engine Best Practices from the session we have here at Google Cloud Next in Las Vegas. So what we are looking at is to target some of the most common challenges customers like you are facing. So to manage costs so that you guys get best performance per dollar out of your investment to ensure reliability so you get secure, scalable environment, and also how to keep track with all the latest features that we are releasing so you don't get overwhelmed but actually can benefit and make it easier for you. So we are finding it's actually very difficult to find a single best practice that will work for any type of application. So we classify it into three categories, each of them having different requirements and thus different best practices. The first one is AI, ML, and high performance computing jobs which are usually very compute intensive, often require GPUs and TPUs, and they run start to finish. On the other hand, we have cloud native applications built for cloud which are designed to be horizontally scalable to respond to the ever-changing traffic of demand for your application, and these need to be latency sensitive so you want to respond with enough capacity for the demand. And finally, we have traditional applications. So these are the ones where you took time to configure each of your virtual machine. So these are not easily scalable but they do need to be updated and also are often business critical so need high availability. So what I'll do now is give you one of the best practice for each one of those workloads one by one. So for AI ML, you wanted to check out our AI hyper computer, which is a suite of tools integrated together working as one to give you access to all the necessary tools needed to run AI workloads. And I'll show you the demo of dynamic workload scheduler which we will use to create virtual machines with the GPUs from NVIDIA. So dynamic workload scheduler gives you access to dedicated GPU capacity, which is time limited. So all you have to do is to provide for how long do you need the capacity, and how much capacity you need, and we will start it for you when the capacity is available as a whole. So let's see a demo of that. So here we have a managed instance group configured for DWS and all you have to do is create new resize request. You provide how many VMs you need. It's three right now and for one hour. And this will initiate a new request for capacity that is currently in a waiting status. But once all the capacity is available, you will get it all at once. So not partial capacity, but something that you can use immediately to start your AI ML training. Now for cloud native applications, we do recommend that you use managed instance group, which is the best way to manage a lot of VMs in a way that you will get high availability, scalability, and also a way to update your application even if you are in production all the time. What's new is that we allow you to configure multiple types of instances in managed instance groups, which will allow you to find capacity across different types of hardware. So for those of you who never used managed instance group, I'll give you a very quick demo how you can turn your existing configured virtual machine application and turn it into scalable group with all those benefits. So you just take a VM that already runs and click create a group from that. And you can review your configuration, but really all you have to do is to click create group button and that will immediately create a group for you. It will take a snapshot of your disk, it will take your configuration from VM, and there you have it. You have a virtual machine running that is now fully scalable. And to scale it, you only express how many VMs that you need, and in less than a minute, you get all your 30 VMs up and running to serve all your demand in a consistent way in a scalable way. Now for traditional applications, you need a way to update your fleet of Windows and Linux operating system. So we give you VM Manager. VM Manager allows you to patch your machines in a way that it applies to all of them. And also you can have a OS policy, which is a desired state configuration that gives you the right configuration and the right software so you can be sure all your VMs fleet is safe and secure. To summarize, whatever type of workloads that you are running on Google Cloud, we have solution for you. So look at those solutions and thank you for the time. Quick question we want to applyگ is once again at Commissions. All four details about your selection and nuestra with界 Hunt navigators, and it will be very important for you to consider EOS. Ensays. Then click on the site and find a list of DF and influencia. Listen tocze. 어디 it be, and don't Das returns to you,