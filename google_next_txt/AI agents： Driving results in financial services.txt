 Thank you all for making time for this and really investing your time throughout the week. Hopefully everyone's been having a fantastic time here at Google Next, one of our largest conferences. I would say probably I've been here eight years. I run a financial services business. We, I think, had 32,000 attendees. We were just reminiscing about what this conference used to look like years ago. So just a huge thank you to everyone here investing their time and energy to really learn and share with us. So we learn as well as we look to adopt these technologies at scale. I'm very excited about the conversation today. As you've seen, we've had quite a few announcements with the word AI in front of it. Hopefully that has not been exhausting. We're hoping to demystify some of those capabilities today and where those technologies and capabilities have not just matured, but have made dramatic impact to businesses, tangible outcomes that I think will really make this a bit more real than perhaps in years past. And you've seen our investments in this particular space at Google. We've been focused on ensuring that we are interoperable at multiple layers of the AI stack as we look at it. Models, platforms that help you manage those models, platforms that help you build agents with runtime environments and models, and then all the way up the stack to software-based services that allow you to build experiences, be it for your external users or for internal employees. I'm very excited to be joined on stage here today with three leaders of their industries that have, I will tell you, not just looked at these technologies, but have made it a core part of their business. And, dare I say, reinvented a non-trivial part of their businesses as a result. And so, today's conversation is really to provide the space for them to share a little bit about their journeys from two years ago where these technologies were fairly nascent to where we are today and some of the tangible outcomes that they've seen in their particular businesses. So, without further ado, I'd love to introduce or give a chance to introduce, and maybe Rajarshi can kick us off. Sure. Hi. Good morning, everyone. It's great to be here and, you know, excited to see so many people at 8 a.m. in the morning. I'm Rajarshi Gupto. I lead AI at Coinbase. I've been at Coinbase for three years now, and I used to be at AWS before that. We're all friendly. Alex, please. Good morning, everyone. Alex Balazs, Intuit's Chief Technology Officer. So, I lead all the technology teams at Intuit. Unbelievably, I've been at Intuit for over 25 years. Started off as a frontline engineer, building the first version of QuickBooks Online in 1999. So, a long, long time ago. And our mission at Intuit is to power prosperity around the world. So, I'm excited about the role that AI plays in powering that prosperity. Amazing. Ramnik. Wonderful to be here. Morning, everyone. Ramnik Bajaj. I lead the data analytics and AI function for USAA. We have a property and casualty business, a bank and life insurance business, and we provide data engineering, data platforms, AI development, and also the data governance and management functions for all of you. Fantastic. Fantastic. Thank you, and welcome. Thanks for making time for this. So, as you can see, three very distinctly different types of industries and businesses as we think about the financial services ecosystem. So, let's dive into this a little bit. Alex, maybe I'll come to you first on this. Can you talk a little bit about the role that AI has played in the business at Intuit and maybe highlight a little bit of not just the journey, but what the outcomes have looked like today as you look for the return on investment on these type of technologies? Yeah, absolutely. What a journey it's been with AI from basically prediction to automating a feature of a product to creating entire workflows that are delivered by AI. I remember 12, 13 years ago the first model that we trained at Intuit, which was to predict if somebody is likely to be an itemized filer or take the standard deduction in TurboTax. It was the number one drop-off location in TurboTax. Somebody goes itemized, they figure out the standard was better, and they leave the product and they go to a tax preparer. So, we said, wow, I wonder if we can use AI to predict this. And we were able to predict it with like 98%, 99% accuracy. So, that was the start of our journey. And then we went to, obviously, with more advanced AI and generative AI to say, are there features that we can basically replace? So, instead of the customer having to enter their own data into a form, can we read the form and actually enter it for them? And that's great, too. But, you know, we spent the first 40 years of Intuit as a company making it easy for you to do it yourself. So, we took things that were generally done on paper and pen or some other way, and we said, hey, here's a simple interface for you to do it. We'll use AI and actually make it even easier for you to do it. Now, we spent the past two years saying, no, we're flipping the paradigm. We're going to do everything for you. Instead of being software as a service, it's service as software. And so, if we start to deliver a service through the interface of software, what could we actually do that would be vastly different? And so, that gets into the automation of the workflows. You know, the ways that that manifests itself and the ways that it's already made impact is you can imagine a plumber who goes out to a customer, potential customer, and they talk to the customer. They scribble some notes onto a piece of paper in terms of what the estimate would be. And then they have to go to the next job. So, now they can take a picture of that handwritten estimate. We ingest all the data. We turn it into a digital estimate. It automatically sends the estimate to the customer. The customer can approve the estimate. It comes back to our systems. We automatically send them an invoice. And they can actually place a deposit on the invoice. So, what happened normally was that that plumber would go home at night. They would go through all the different estimates and all the different notes that they had. They would send out estimates. And now, by the time they come back to their office at night, not only do they have the job, the customer has already made the deposit. So, that is a fundamentally different experience. And all of that is driven by AI. Incredible. Incredible. Jarshi, I think there's been an interesting journey over at Coinbase. Not only looking at how these technologies might have impact in things like compliance technology, but all the way across the stack. Maybe could you share a little bit about the journey that you've been at Coinbase and some of the outcomes you're seeing with these technologies? Yeah. So, I think, you know, in a setting like this, I normally start by asking how many people here have a Coinbase account? Okay. Okay. That's a pretty big. So, for those of you who didn't raise your hands, Coinbase is the largest U.S. crypto exchange. And we serve many, many tens of millions of customers through our platform. And as you might imagine, if you think about crypto as a space, right, it is to do with people's money. Yet, it's pretty new and it's confusing for a lot of people. So, that ends up. So, you know, people do want to engage with crypto and invest in crypto, but it is scary and confusing. So, naturally, you have a lot of questions and people reach out to agents. And our interaction with customer, with a typical customer, is a lot more than a bank or an E-Trade. So, here's where AI comes in, right? So, AI comes in and what we have been able to do in the past several years. We were using machine learning for a while, right? For many years, you know, we handle people's money. So, obviously, we have had these trust models and account takeover models and so on to protect. And, you know, that's pretty standard practice for all financial services, right? So, yes. But what we've been doing in the last couple of years, as Rohit mentioned, is really bring a conversational interface to everything that we do. So, since last June, we have launched and are now supporting, I don't know, 20, 40 million customers on their help, their search, and their chat interfaces. So, everything is powered by our underlying Gen.AI platform, which I'm supposed to say that it is running on Gemini, on Vertex. Thank you. So, we are doing that. So, every time you have an interaction with us, you want to find out what's going on in crypto or you talk to us, it is you are talking to an NLM agent. Now, the interesting question that I want to address to you is that this is something, you know, many people talk about the fact that this, by doing automation, you are cutting costs by X percent, right? Sure. But I think what I want to focus on is the fact that how the customer experience for people is actually getting improved by that. So, forget the part that, yes, it is saving a bunch of costs. But what happens is that normally, I mean, think of your own, I think, like, let's say you're talking to a customer agent over chat trying to change your ticket, right? The normal experience is you type something and then you wait three minutes before that person comes back. You type something else and the whole interaction takes 30 minutes. Now, imagine having the same interaction, but everything gets done in three minutes. So, that is a huge amount of customer improvement that we are seeing. And we are now, that's on the customer side. Now, in terms of accuracy, in many cases, these agents don't have, I mean, if you think of the life of an agent, you know, they are trying to look at 40 different things on a screen with many stuff. They're cutting and pasting. We are able to automate all of that. We're able to bring everything together, pull the insights such that they can do this. I'll wait. I'll hold off. And this is our customer-facing journey that we are seeing. And there's also another aspect of our internal-facing journey, which I'll hold off for another question. Beautiful. Beautiful. Beautiful. The thing that always kind of surprises me is the size and scale at which you guys have deployed these type of technologies. Ramnik, over to you. I know that you've been very focused around customer journeys and understanding how to interact with them in your particular space with these technologies. Can you share a little bit about what has USAID been up to and how have you seen some of these outcomes manifest themselves? Happy to. And first off, we are a 103-year-old company. We are in fairly commoditized products, but we are highly differentiated. We are highly differentiated because of how we serve our customers, our members. We have consistently had the highest NPS in the industry year over year. And all of that is because of how we serve our customers with empathy, with care, with helping them in their time of need. And not just being the financial services company providing an insurance policy and a claim, but actually being there for the members when they need us the most. So similar to Rajesh's point about it's not for us AI is how can we enhance our member service? How can we enhance our member experience so that each interaction with us is even more delightful than it is today? And so a lot of our focus has been in that domain with the generative AIs. Of course, much like the others prior to generative AIs, we had hundreds of AI solutions that were already in use doing things like image processing and also natural language processing. But now we are very focused on this aspect of improving our member experience through generative AIs. And I would say a second category that has been incredibly valuable for us is text analytics, getting true insightful analytics out of textual data. We transcribe 100% of the interactions we have with our customers. And that's a very rich data set for us to glean insights, not just cross-sell insights. Those are important, of course, and we definitely are proud of all of our products and we want our members to have all of them. But it's equally about how well are we serving the customer. Were there action items that we left unsolved? Are we doing all of the things that we need to do compliantly? The quality assurance reviews of member or customer calls, at most you can do a single-digit percentage review, right? With generative AIs, you can be reviewing 100% of the calls. Did we put all the disclosures out that we should have? And then equally, was there any unmet need for our member that we would want to go back and serve them with? So I think those categories of customer service and then doing the text analytics, we have armed our frontline. We call them MSRs, people who pick up the phone every time someone calls, and we get 200,000 calls a day. Every time someone calls, we want to arm our MSRs with all of the knowledge that we have without them having to read documents while the member is waiting on the phone. And so to be able to get that corpus of knowledge and put it through, we have used Vertex AI search as well for that, and make that accessible to the MSR with natural language search, that's a huge lift for us. And our vision, of course, is much further than just that. We want to get to a point, we call it unplug the keyboard, right? So the customer service rep doesn't have a keyboard, the AI is listening and doing everything that needs to be done while our customer service rep is there as the human being on the other end of the phone, empathizing, being there with our members in their time of need. Incredible. I think what's interesting as I kind of listen to the three of you talk about this, it feels like we've graduated from tools that might be piecemealed approach to go and drive either efficiency or delightful experience. You know, I think for the last probably three or four years, we've been very focused on things like document ingestion, contact extraction. These are technologies that have generally led the way and have produced tangible results. As I hear you talk about this, it feels like we're kind of now entering an arena where this is really about system design and rethinking the operating environment in which you will build these capabilities and these experiences. As you said, it's almost a vision of no more keyboard needed or perhaps just get it done. I don't really want the insight, actually want the outcome to be achieved. Or I want to be able to scale to a degree to handle 30 million plus customers interacting with me with the complex interactions and questions. One of the words that comes to my mind is trust. And, you know, you represent a non-trivial part of the financial services community but also the consumer and customer base that that follows from there. And I have to believe that trust is something we all know takes years to earn and one click away from losing. How do you think about these capabilities and the operating environments that you've been building moving forward with the idea of trust at the center? How do you think about guardrails? How do you think about security and accuracy in the context? Because it feels like you're really pushing the bar here on how these technologies come to fruition. So maybe, Rajesh. Sure. I think trust is very important. In fact, if you look at Coinbase's marketing, the first word that comes is that it's the most trusted brand in crypto. That is literally what the brand prides itself in. So, yes. I mean, you know, we were in the industry, especially in the financial services industry, we were fairly early in rolling out Gen AI. We rolled it out in June of 2024 to customer facing. And at that time, you know, when we were looking at it, I would say during the first six months of the year, 60, 65% of the work was on guardrails. The models already were good enough that it could answer customer interactions. Much of the work was around figuring out the corner cases and how do you do it. So what we ended up doing is that we ended up building a custom guardrails model in collaboration with one of the major providers. And worked together to build the guardrails because we were naturally worried about this exact case. We would call it the New York Times use case, right? It's not that you give it a wrong answer, but you give such a wrong answer that gets copied by the press. Yes. So what was the trick and what is the trick today? So what was the trick about a year ago was to basically put guardrails and make it a very constrained problem. So, you know, in the industry, I mean, compared to like let's take ChatGPT as an example, right? There are 100 million users using it and they're asking all sorts of questions, but their threshold for making a mistake is pretty high. I mean, it's okay to make a mistake, right? But in the case of an enterprise, when you're answering questions as the mouth of the company, you need to be much more careful. On the other hand, the advantage you have is that you can really limit the topics that you want to talk about. If somebody is asking about which candidate to vote for, it's okay for you to say, I don't want to give this suggestion. This is outside my domain. If you want to compare between Ronaldo and Messi, you can ignore it. So I think the building the guardrails ended up being a completely new arena that we've done it. Now, fast forward nine months. Now there's a ton more work, especially with the agentic framework. You have agents that are specialized in doing the guardrails. And I'm very happy. I mean, we had to hand code all these things nine months ago, but now it's much easier. And, you know, people are the whole area that all these major providers like Google and Anthropic and OpenAI are doing makes it much easier for us to deploy these things. Amazing. You know, in the industry, we've kind of seen this as well now. You've seen some of the announcements we've made over here. We're trying to create developer kits to provide some frameworks on how you might think about building agentic experiences, all the way up to even talking about agent-to-agent communication and MCP kind of being the foundation layer of how companies and interactions can occur in an ecosystem. Alex, I was particularly amazed and genuinely learning quite a bit from the work over at Intuit. I believe you branded it GenOS. Can you talk a little bit about what that means to the company and how that is actually instilling the trust in the system as you build these capabilities out? Yeah, absolutely. I love the question. One of my favorite concepts in leadership is called ambidextrous leadership. So with ambidextrous leadership, you have two competing ideas in your mind at the same time, and you lead anyway. Right? So in this specific case, breakneck innovation, allow your engineers to just build and build and experiment, but it's financial data. How do you keep your customers safe? Like, which of those do you choose? And the answer is yes. It's both of those things. So how do you do that? So we decided very early on, one of the best decisions we made about two years ago was to create GenOS. So GenOS is our generative AI operating system, and it has very clear elements in the system architecture that allow the space for rapid, rapid innovation, but also inspection and enforcement of trust when necessary. So some of those things, for example, is that we have a component called GenSRF, which is security risk and fraud. So it has a filtering mechanism built in automatically to scan content, to look for data exfiltration, to look for prompts that shouldn't be returned, things like that. And the great news is that as we built this component, it is used everywhere across every single prompt, every single request. And so as we learn more things about how we want to provide trust and safety to our customers, we put it in one place and it affects every single implementation of GenAI across the entire company. We also built something called GenEval. So GenEval is where we use AI to test the AI. So the days of hand-coded unit tests, which not so long ago was commonplace, you can't do that, obviously, in the age of AI. So at the speed at which you innovate with AI, you need the AI to test the AI, obviously with human oversight. But I will tell you that trust also means you're there for your customers when they need you the most. Once again, especially since we're in the fintech world, which means if a certain model, a certain LLM goes down, you can't just be down. And so we actually have a GenRuntime that fronts the LLM. And every single request that we have has a primary and a secondary. So if the request, the service that we're dependent on, whether it's one of the own LLMs that we trained or a vendor-provided solution, if it's not available, we can automatically fail over to the other LLM. We also do this during testing so that we can evaluate if you're doing this type of prompt to solve this kind of problem, which of these LLMs actually solve the problem best for you. So by putting GenOS in place, it has really allowed us to unleash our engineers, get them to just innovate, innovate. And then the process by which we can inspect is like a fast follow. So what we didn't want to do was to make sure that we had kind of a preemptive review of every single work that's going on. We wanted it to be a very fast follow. So I'm really excited about the opportunity that we have with GenOS to continue to push that fast innovation. What an amazing journey over there. I think the DNA of the company kind of changed once you had that mindset of a generative OS operating environment. We've gone through a similar journey at Google as well. I think this notion of let's have agents review agents to ensure that there's viability there. What I really particularly like what you just said there is there's this notion of resiliency and redundancy. The outcome can't be the model is down. The outcome can't be the model is having issues. The outcome has to be that customers is taken care of and the service that's being provided is up and running. Ramnik, you mentioned a couple of really important words. So there are disclosures, for example, that matter in your particular space. They are very, very tight guidelines on how communication needs to occur. And so injecting these capabilities in that work stream, I can't imagine that to be trivial in how you've built out the systems. Can you talk a little bit about how you think about trust and resiliency and security in these concepts? Yeah, 100%. The only thing that we do is make promises and keep them, right? So there's nothing we manufacture. There's nothing we go out and do other than make those promises. And we have to keep them. And every interaction for us can't be at an 80% accuracy level, can't be at a 90% accuracy level. So really, if you look at a financial services company and mission-critical processes, that's where a lot of the trust framework, the guardrails, the observability of what the models are doing, and the human in the loop when needed, all of that comes into the picture. And we are tackling head-on many of those use cases. But I don't want us to think about just those because those are the harder ones to track, right? And we will get to them. But in any financial services company outside of that core, mission-critical, conservative, regulated process, there's a lot else that happens, right? There's a lot else that happens to customers inquiring about the status of a claim. That's a relatively trivial task for us to answer. There's all kinds of knowledge work that's going on by the employees that can be sped up with Gen.AI. So we are tackling a lot of those use cases because we've created the horizontal capabilities now. I mentioned any corpus of documents and any set of questions you want to ask against it, it's a horizontal capability. Any unstructured textual data and drawing insights from it, today it might be marketing insights, tomorrow it might be a different set of insights. But it's the same horizontal capability. So we've created those horizontal capabilities. We didn't brand it the way you did with Gen.OS. It's pretty good. It's pretty good. It is. If it's not trademarked, you know. But those horizontal capabilities, we are stitching them together for new use cases. And then in the main, when we are tackling those mission-critical processes, that's where we are looking at observability, identifying outliers, knowing when the model has hit its limitations. We are very particular about constraining those models which are in the mission-critical tasks to only have access to the tools, the APIs, the data, the domains that we want them to have access to. So we don't think we are at the stage yet where we can have agents that have access to all of our APIs and all of our tools, and they can interpret customer intent and decide what to do. We are not there yet. I think we are trying to create much smaller solutions that can be stringed together then to provide a good experience to the customer. But with each particular component of that solution being sufficiently constrained that it can't make too many mistakes. Yeah. Yeah. So I want to add to what Ramneek said. And we did something very similar. And, you know, I am terrible at naming. So we have a very similar platform, but it's called Coinbase GPT. So not very imaginative here. So we built a similar platform. We have Eagle GPT. That's how Eagle is our symbol. So I think we built Coinbase GPT as a platform. But I think what's really interesting is that the appetite for this kind of technology is just mushrooming very, very fast within the company. So when we say we built it as a platform, what it actually means is that we've created a whole set of APIs that everyone in the company can build upon. So, you know, my team, which is the AI team, has built, I don't know, 20, 30 different use cases within our platform. But we've had another 20, 30 use cases built by other people in the team. Like one of our developer teams built an automated PR reviewer, PR reviewer using the APIs. And then the other interesting point, as Ramneek was saying, is the fact that you can test some fairly advanced capabilities on your own internal workforce, right? So one of the things that we have, and I've had fun showing it to a lot of people on the phone, is that every employee in Coinbase has their own personalized GPT helper. Amazing. So it's on Slack. So we are a Slack-based company. So if you go to your Slack, you have a little thing that says Coinbase GPT, and you can interact with it. It has access to all of your documentation. It's an agentic rag. So it has access to all of your documentation and your knowledge base, plus the company knowledge base. And you can interact with it, ask questions. One of the funnest things we did, actually, we did this December of 2023, was to build a performance review assistant. So, you know, that's the time when we all do performance reviews, super critical, and everybody hates it. So we built a performance review assistant, which would take some, we'll have an interactive conversation with you, and help you write your performance review in a Coinbase format, highlighting the things. They would even ask questions around, you know, are you forgetting this, or you need to put more quantitative numbers in there, and so on. And it was, I mean, it got absolutely, with all the way to the C-suite, everybody was using it. So these kinds of things that you don't think of early, and when you make it, expose it to the employee population, there are all sorts of new ideas that come in, and we start using it for design, for marketing, for talent, HR, and so on. Were the employees that were getting the performance reviews summarizing it with an AI as well? Oh, so, okay, hold on. So we first built one for the employees to write their own reviews. Then we built one for the managers to write the employee review. So the one thing we didn't do, just to be clear, was for the AI to assess your review and give you a rating. We didn't do that. It's coming soon. It's coming soon. Exactly. Exactly. What an incredible journey. Like, I just kind of take a step back and think about what we just said here. So we went from point solutions and tools to very quickly this word of horizontal platform as a mentality. We went very quickly from, I mean, just consider a year ago at actually this very same venue, the conversation was, can we ever use this in a regulated environment? Can we ever use this when the nature of the data that we're talking about is financial services information that represents either a business or a person and a journey that's related to that? Are these technologies ever really going to get there? And here we are nine months later, I think I heard, or less than a year for sure, and we're talking about not just solving those type of problems but doing that at scale with a platform-based view. One of the other concerns that I think people were worried about in the early days, and I'm genuinely curious as to the answer on this, was, you know, these technologies, while fantastic, might represent a significant economic consideration in terms of cost to investment, cost to run. How has that kind of manifested itself in your businesses at the scale that you're running these things set now? I can start. I think the economics, for the most part, have been very straightforward to make. The development time for these solutions is low. We've been able to roll out solutions within four weeks. Maybe the longest was six months, but that was mostly a change management topic, right? It was to roll it out to 13,000 employees. You kind of have to work through on the front lines. Was that true a few years ago? Would you ever have been able to roll out services measured in weeks? Absolutely not. I think the speed to market has really improved, and so the cost of development comes down. The runtime costs have been plummeting, and the comparison point is really for a human to spend time to do that task, right? And obviously the cost of that is extremely high. Now, the challenge we all still have is if you take away 30 minutes of somebody's workday or if you take away an hour a week from somebody, dropping that saving into the bottom line is still a challenge. Sure. Now, at scale, for things that you do 100,000 times a day, yes, you can effectively drop that into the bottom line, and I'm sure as the solutions get more reliable, that we will feel more comfortable in dropping some of those savings to the bottom line. But the cost-benefit analysis on these things from a point of view of saving human productive time to take that away from the task that can be reasonably automated at this point, I think that's been incredibly easy. I completely agree. Great points. In fact, because they are these end-to-end solutions with AI, doing that cost-benefit analysis is actually easier. When you're saying, okay, I'm investing this to build this feature in the product, doing a cost-benefit or what is the benefit to the customer for that feature is a little bit harder. When it's an end-to-end workflow, measuring the actual benefit is actually pretty easy. So, for example, the agentic-based invoicing and invoice reminders that we built into QuickBooks, we know that on average, those that use it get paid five days faster than the ones that don't. Wow. We know that those who have overdue invoices, 11% more of them get paid in full because of the invoice automation. Wow. So, the investment that we made in that, and we can actually obviously look at the cost with a value to the customer, is astronomical. And then when we use that value to the customer and we make claims, obviously, it can lead to growth for us as a company. We can say, hey, look, you don't have to do your invoicing anymore. It's just done for you automatically. And not only is it done for you, five days faster, you get paid on average, and 11% of the overdue invoices get paid in full. So, that cost-benefit analysis, which used to be much more difficult and involve a lot of complicated math, now actually is much simpler. Say, because we automated this entire end-to-end workflow, it is absolutely worth us to make this investment. And then definitely, you know, the infrastructure costs obviously have plummeted as well. Those are excellent examples. And in our situation, some of you might have heard this yesterday from me, but after a wildfire or a hurricane, to be able to take aerial images and automatically assess all of our insured homes that are a total loss within a day. Wow. That means we are getting checks out to our members that much faster. That's amazing. They're in front of the line to get their home rebuilt because they're with the contractor with their check in their hand or they're looking for temporary housing and they have the money in their pocket. And after the LA wildfires, we were able to get the claims, 86% of the claims paid out by Feb 5th, and the fires ended on Jan 31st, right? Wow. That's the power of these tools. You know, when you deploy them out into a specific use case that takes it all the way to the end, you can delight the customer with that. I just love how trivially you both said that impact, but it's not trivial. That is incredible progress and journey. You know, it's fascinating to me because I think the conversation almost always was about cost takeout and efficiency gains. And what I'm hearing now is that it's really more about there are things that were impossible to do without these technologies and capabilities and now are actually a growth function or, at minimum, a pure benefit to the end user community and the constituencies that you represent. So that's really fascinating. Rajashi, I wonder how do you see the future of this evolving, especially in the space you operate in right now? So you mentioned kind of a bloom of use cases and capabilities and in a very measured way for the development community. What gets you excited, kind of forward looking? And if we're here nine months from now, 12 months from now, what do you imagine we're talking about? Yeah, it's very funny. And you can just tell how fast the space moves because Rohit asks, what do you see the future nine months and 12 months from now? Right. It's no longer five, six years. In most other topics, the question is, what do you see five years and 10 years from now? But yes, in this space of Gen AI, the times are really measured in months and not years. So I think we are super excited. You're seeing all these claims that are coming out that we are going to see a vast majority of software written by AI in a short order, right? But I think what I'm most excited is about the potential of AI taking on these complete tasks and doing it at a rate and at a level of accuracy and reliability better than humans. So I think that threshold is the part that is important to understand, right? That in the world and even in the financial world, even in the tax preparation world, even in the insurance world, there are mistakes made. Banks make mistakes. Every so often you read, banks sent you an extra money or something, right? Mistakes do happen. And every system has the checks and balances around it to deal with the mistakes. So as we rely more and more on AI, we need to have the checks and balances to make sure that the mistakes don't become super critical. The self-driving car is a great example, right? I mean, I have a self-driving car and I drive it and I let it self-drive all the time. And I'm not going to say that it never makes a mistake. But even when it's making a small mistake, there's the mechanism in place to catch it. And sometimes the mechanism is a human. And that's okay, too. That's okay, too. But I think we all want to get to a situation, and that's what I'm most excited about, is to be able to see these kinds of technologies and these architectures take on these end-to-end roles because they are faster. They don't rest. They are cheaper. And we can totally get to a point where they are more reliable. Amazing. Alex, any comments on that? Yeah. So there's so much to be excited about. I think that the thing that I would call out is that for so long in traditional software development, you figure out some problem to solve. You solve it. You deliver it to the customer. Then you figure out another problem to solve. You solve it. You deliver it to the customer. And then what ends up happening is that there are edges in between the things that you solved. And most of the time, you don't even realize that the thing that you solve may actually not be the most important thing to the customer. It's actually the thing that's on the edge in between those two things. And because of what we are doing now about the access to the tools, the access to the data, the agentic workflows, we can now discover those edges. Our customers can discover those edges. And we've already begun to see that where we think that what we're solving is problem A or problem B, and it's actually right in between A and B. And what will end up happening is that our customers will discover their own use cases. They'll discover their own solutions because the technology allows us to not just solve at the edge, but it basically erases the edge. And so you can imagine one of our customers who's moving from Credit Karma to TurboTax, and maybe they're a business owner. In addition to that, they do email marketing with MailChimp. So these historically are separate products, separate kind of delineation of what problems they're solving. And now those seams are going away. And so I think step one will be the seams go away within the context of one of our organizations. But over time, the seams will go away probably across our organizations and actually create unbelievable end-to-end solutions for customers where they will get to benefit from the prosperity and the success of others. Because it's all in the data, right? Inside of the data, we know why do some people get richer and why do some people get poorer? And if we can now enable that by eliminating the seams in between our own experiences and our cross-experiences, I'm so excited about what we can actually do to power prosperity for everyone. Incredible. Ramneek? Look, I think all of us technologists, we have a sparkle in our eyes when we sit down with our business stakeholders and think about an idea. And it sounds like a wonderful thing to run out and go do. And then traditionally, there's been a lag between that and the product coming out and we actually testing it out in the market and figuring out what we got right, what we didn't. I think it's incredible that we can now bring that time to such a small scale that we can start to do that much more innovation at a pace that we couldn't do before. I do think that English may not be well suited to create enterprise-grade applications. It may end up being a combination of English and some traditional coding structure. Sure. But at least we are getting to the point where you can sit down with your computer and express to it what all you need done and in the order of weeks, create an enterprise-grade application that can do it. And I think that's incredibly exciting for all of us as technologists. And I think for the world, it will really take the pace of innovation to a different level altogether. And I'm excited about that opportunity. Of course, being a data geek, just the opportunity to do analytics on unstructured data and automate all of the human toil that goes into handling unstructured data, whether it's images or video files or people's verbatim comments or first notice of loss, police reports, and all of the things that we have to deal with in our industry and in every industry, bulk of 100-page regulatory documents coming out, being able to have PhD-level IQ kind of pinned against all of those tasks and then get it in an instant, I think that's incredible and it will transform all of our businesses. Well, it's certainly humbling to be part of that journey with the three of you. I would tell you, you know, our focus in this particular space also very much aligns with what you're describing with some of these seams coming apart. One of the craziest things I heard yesterday is, you know, would the org chart of a company maybe morph a little bit over time and perhaps would AI agents be an actual named entity on the org chart? Boy, that scares me, but at the same time, it might be something that comes sooner than not. Look, I just want to say thank you so much for sharing these journeys and stories with us. We see an extremely bright future with these technologies and capabilities. Any closing remarks that you'd like to leave the audience with who might be thinking about either trying these technologies or trying to think about where to start with these things? Any advice that you might want to share with the audience? So I can start. I think the way forward for all of us is to rethink the entire application stack, starting from the data layer. I don't think the data layer looks like the databases of today. It's a combination of databases of today with a lot of unstructured data constructs, a lot of graph data, a lot of vector databases, and we need to be thinking about how to evolve to that layer on the database side. In the application layer, I think logic will be written very differently. We do want to have deterministic logic where we can deal with the problem with deterministic logic. Of course, we can generate it versus having to write it in what now looks like assembly language relative to English, but we can certainly imagine the application layer changes into orchestration of logic coded into either agents with reasoning or deterministic logic or combination of those and those strung together. And I think the UI will entirely change as well, right? The UIs, after all, were all structured into menus and submenus and pages and forms because that was the only way we could interact with the machine. And now that we can interact with applications much more fluidly with our thoughts, our language, our expressions, our facial expressions, all of that, I think all of that gets woven into the UI of the future where you don't really have to navigate even an app on your mobile. Amazing. Alex, any closing remarks? Yeah, so what I would say is whether you're a frontline employee or a leader of an organization, you have to use AI. Use AI. Every single place you can, just use AI. My team knows I've become a notebook LM junkie. Thank you. I use it nonstop. I'm in a meeting. I've got a notebook LM open. I'm collecting documents. I'm putting them in. I'm using it. I'm running prompts. I'm generating summaries. The more you use AI, the more you will think about the kinds of problems you can solve for your customers with AI. So use AI wherever you can. Yeah. And I want to, I mean, I want to make it even more real. So that, yes, you should, every one of you, your team, yourself. This is such a powerful tool that fast forward one year is going to just become that the world is going to not get divided between level three, four, five, six. It's going to get level differentiated between L3 with AI and L3 without AI. L4 with AI and L4 without AI. And honestly speaking, the people like, I mean, clearly you folks are interested in it and engaged in it to be here. But honestly, the people who use it are going to get ahead. The people who don't use it are, that is going to become the differentiator. So every one of us should be using it and encouraging our teams to use it. And new and more exciting use cases will pop up as they use it. Amazing. Look, again, thank you so much for the time. I leave you with this. It becomes easier and easier as I reflect on these technologies to not only deploy these things at scale but also drive value for them very quickly. If you haven't taken a look at some of the demos that we have out in the conference, I would pay special attention to some of the areas that we're investing in making it easier. So we talked about unlocking value from the data state, for example. We just announced agents for data science and data analysis. This is incredible stuff. I have to tell you, it's almost like magic. I've been in the business for some time, and I don't believe these things until you use them. But the fact that you can very quickly have an SAP system that has, you know, say, supply chain information linked up with your CRM system and Salesforce all the way out to ticket management with Jira and your ads platform and have an agent within minutes people traverse that estate and interact with that data, that is something that I don't think I could have made that statement even three months ago. So the fact that we're live and at scale deploying these things is truly remarkable. And if you haven't tried out agent space, shameless plug, you really should. Notebook LM, enterprise search capabilities, and the agents to your heart's desire are going to be surfaced in that particular environment. And it is so easy to use. It is part of my daily routine. So I thank you all very much for making the time to be over here, especially so early on a Thursday. I know how the days go at these conferences, so I deeply appreciate everyone here making that time. And to our esteemed guests over here, thank you for really sharing the stories and the journeys. Thank you. Thank you. Thank you.