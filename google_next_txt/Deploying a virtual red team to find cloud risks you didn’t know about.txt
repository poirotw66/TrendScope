 Hello, welcome to this session. We called it Deploying a Virtual Red Team to Find Cloud Risks You Didn't Know About. My name is Robert Lagerstrom. I'm a senior staff software engineer in Security Command Center. With me I have... And I'm Knox Anderson. I'm a product manager within the SEC team. My team covers vulnerability management, the security graph, and cloud security. My first boss told me all conferences are one day too long, so thanks for everyone for showing up on a Friday and bringing in this turnout. So today we'll be focusing on a few main topics. How customers address risk, how Google models risk and threats in our security graph, how we validate and uncover unknown risk with continuous virtual red teaming, and then we'll close out with a live demo and a risk report. So first what we hear from you, when we talk to Google Cloud customers, the conversation quickly moves to visibility and risk. How do I discover vulnerabilities agentlessly? Where can I see the activity that's going on in my environment? Are there compute instances that are publicly exposed? Who's exact into my Kubernetes cluster within the last hour? Then some of the what-if scenarios start. If a key or workload is compromised, what can the attacker actually do? What resources or data will be effective? Once teams have visibility, it's still sometimes unclear what needs to get fixed first and which resource is more important to the other. Each team is kind of building their own prioritization vehicles, and customers are stuck on what they want to address in their environments. But as we all know, managing risk is complex. It's a challenge to know what resources are exposed, how much they're exposed, what is the likely damage from an exploit. Do I have a compensating control like a firewall that's in front of my service? Looking at this slide, the implementation best practices are what people always try to follow. Principles of least privilege, network segmentation, vulnerability management programs, and penetration testing, but following best practices is something that becomes difficult, especially at scale and then with dynamic ephemeral cloud environments. So for us, managing risk is about understanding the exposure, measuring likelihood and impact, and focusing our efforts on the elements of those general ideas that are most important to implement today. And in order to do proper prioritization, we believe that context is king. It allows us to focus our defenses rather than apply general broad best practices. So starting with something like assets, it's important to understand, is that asset in production? Is it in a namespace that has a network policy? With data context, does this bucket or resource have sensitive data? Vulnerability context, is that vuln in a package that's actually loaded? Is it in a function that's executing? Having other ways to understand the activity of whether or not you want to prioritize that. Is that vuln part of the CSEC-EV database? Activity context. If I'm looking at my environment, has someone spawned a shell into that workload? And that can represent another risk if that workload is exposed and it has a remote code execution vulnerability. And then permission context. Permissions are granted everywhere in your environment. DevOps teams ask for a new tool. You grant permissions. It doesn't work. You grant more permissions. Are those permissions ever actually used? All of these are pieces of information that are critical to bring in, but you want to go and take and enrich any finding or any asset with this context. So, to help our users with this, we've introduced the new concept into SEC called Issues. You may have seen this in the keynote and in other SEC sessions. And so, this is something that's in both an SEC and Google Unified Security. Issues are a new way to detect, triage, and remediate your riskiest cloud assets. And they represent the most important thing that a user should work on and apply to all domains of security. So, there's three main issue types that we're introducing as part of this. The first is security graph rules. These are rules that execute against the graph to detect a correlation of many findings against a common resource. So, this could be something like you have an ingress controller that's exposed with the vulnerability that came out two weeks ago. Or something more complex like there's a Kubernetes workload. It has a critical vulnerability with an exploit. That pod is running as privileged. And that workload has access to a bucket with sensitive data. The nice thing here is all of these rules are managed by Google. And so, we go in and put best practices that we see across our customer base as well as emerging threats that are coming into your environment. The next two types of issues are powered by our virtual red teaming. And Robert will get into this deeper into the session. The first are toxic combinations, which represent the most likely path to a high-value resource. And then choke points help prioritize the cloud resources or resource group to fix. Because many toxic combinations go through that common attack path. If you're going to spend time on one thing in your environment, the choke points give you the biggest bang for your buck. And so, that's where I would start first when looking at the issues that I need to address. So, a lot of this has been around, hey, we need to generate issues. We need new product experiences. But to really deliver this kind of capability, we needed to bring new technology into the SEC platform. So, we spent the last year replatforming parts of SEC. And so, we're happy to introduce these capabilities that are all powered by our security graph. The first question is, why do you need a graph? There's many different ways that people have dealt with findings over the years. And so, the first is cloud attacks move laterally. Having a firewall isn't something that you can do for everything in your cloud environments. And so, identity and permissions are the way that you have to address firewalls in the cloud. When also trying to understand how you have access, there's many different ways a user can get access or a workload can have access to other services. Is it granted through the project? Does the workload have access directly? Are you using a Kubernetes service account? Are you using workload identity federation? It's really complicated to understand who can talk to what in an environment and what permissions granted overlap with each other. And so, by having a graph where you can have any node that represents a resource and then relationships, it's much easier to model access across different environments. Then, risks are multidimensional. You can have vulnerabilities, misconfigurations, threats, data security findings. And so, by having a common asset model that you can enrich all of those different findings against, it allows you to then correlate many findings against a common resource model. And then, one of the things with cloud security is each week some new use case comes up. I'm sure everyone's heard enough about AI this week. And so, when you have a graph and you're building packages or secrets or credentials into that graph, addressing AI use cases gets much easier. For example, you can say, all right, I have an open AI package that's running in this Kubernetes workload. Maybe this is an AI application. I might need to treat it differently. Or there's a Databricks credential that I see on this instance. It could be tied to more of a sensitive application. When you have all of that raw data in the graph, it makes it easier to then deliver new security use cases quickly and build new correlations. The other major change is kind of how people build their security programs and how that's changed as cloud adoption has grown. So, traditionally, you might have a vulnerability management team, an ops team that's working with your cloud security team that's handling misconfigurations, a threat detection team that's going in and making sure agents are installed across all of your infrastructure. You're pulling in findings across all of these different surfaces. Each of these teams was in their own silo, and that's something where each team was understanding their coverage, their findings, building their own prioritization mechanisms. That's something that's not going to work as you move to cloud environments. And so, by going in and having a common resource model and a common findings model, it's easier to go in and prioritize what you need to fix because every team is going in and understanding what is their exposure, what are their critical findings. And so, it's much more impactful to go a step further and say something like, you have a critical vulnerability that's on a privileged workload that is externally exposed and has access to a bucket with sensitive data. This is a vulnerability, a misconfiguration, exposure, and then sensitive data scanning where all of these used to be maybe different teams or different groups. Then you can go a step further and bring in real-time context. So, then if you see an unknown user that has kubexact into that workload in the last hour, that's something that you'll need to treat with a much higher responsibility and access into your environment. So, with that, next I'll pass off to Robert, who will go into virtual redteaming and how we use that to discover unknown issues in your environment. Perfect. Thank you, Knox. Thanks. Okay. So, now it's time to dive into the part of continuous virtual redteaming. If you heard some of the other talks, I think this was mentioned both in the keynote, the security spotlight, other SEC sessions. Also, if you were here last year, you might have heard of attack path simulations or the risk engine. So, these are all working together. So, basically, the continuous virtual redteaming is the center of the risk engine. It works on the security graph that Knox talked about, basically like a digital twin model. And what we feed this with is information like in-depth data about your resources, threats, vulnerabilities, identities, and other things. Also, threat intelligence from the Google Threat Intel team and Mandiant. We use this for Google Cloud, but also for AWS and Azure. And with the risk engine and continuous virtual redteaming, we discover attack paths. That's the core outcome of the redteaming that we do. We use these attack paths to derive toxic combinations. I will show you some examples soon. And also choke points like Knox introduced to you. This is good because then we can actually measure which resources in your cloud environment are at high risk. Which are your high-risk findings? Like, most of you know that you have thousands, maybe 10,000 findings you need to fix. So, in what order should I do it? What should I prioritize first? This is what the redteaming is really good at. Discovering which findings you should prioritize first and which resources are at most risk. Yes. So, the digital twin model. That's the core of continuous virtual redteaming. So, this is not redteaming as you might know it, where you have a set of people actually trying to break in to an environment. So, what we mean when we say virtual redteaming is that we don't do it on your actual environment. What we do is we take metadata about your environment and we build like a replica, a digital twin model. So, we don't spin up like a VM. We don't actually replicate the environment and do redteaming on it, but we create a model. Think of it as like a huge attack graph where the nodes are your resources and your vulnerabilities and misconfigurations. And IAM permissions and where you have sensitive data and things like that. So, we don't actually use your actual applications or your actual data. It's just metadata. So, this is not intrusive in any way. So, you don't risk of your production environment going down when we do the virtual redteaming. So, it's completely safe. And basically, this big model contains everything we need to know to do a security assessment. What we then do when we have this graph, this digital twin, is that we simulate an external attacker. We're basically saying that if an attacker starts from the public internet, which paths can that attacker take to reach your high-value resources? This attacker that we define is armed with Mandiant frontline threat intelligence. So, we keep it up to date. We know which of the vulnerabilities you have in your environment are actually exploited in the wild. So, these are much more likely that the simulated attacker will actually use. The attacker works in a way based on probabilistic reasoning. So, basically, the attacker, when it starts an attack, add a node. It looks at, okay, if I'm here with this information, like I have this service account key, where can I go next? What's the best likely step to take? And that's the way the attacker moves forward in this digital twin graph to reach the high-value resources. So, think of it as a huge graph where we're trying to find the most critical paths, the shortest paths, between the public internet and your high-value resources. And one of the really good things with virtual red teaming is that we don't only look at, like, one path. We look at millions of attack paths at the same time. So, the attacker here tries to do everything in your environment. It tries any combination of things to find out, okay, which are the critical paths that I can take. So, it's completely like machine-scale simulations. So, nothing gets kind of lost. Okay. So, based on those simulations, the key discovery are high-risk attack paths. So, usually, these graphs are, like, there's millions of nodes. And we're trying to find the most critical attack paths. So, for instance, in the big cloud, we can see here some key attack paths that the simulated attacker can take to reach high-value cloud resources. Based on these attack paths, we then derive toxic combinations. So, we basically look at each attack path and see if there are patterns within these attack paths that are common across all the attack paths. And we report that as a security issue called a toxic combination. So, it could be, for instance, first exploiting a vulnerability, then doing lateral movement by giving the attacker gives itself new permissions or creates a new key to a service account that it can assume. So, combinations of different vulnerabilities and misconfigurations. So, here's one example of an attack path or a toxic combination. Basically, the attacker identifies and connects to a publicly accessible VM and exploits a widely exploited vulnerability. That's the start of the attack path. With this, the attacker can gain administrator privileges, use these privileges to resume operations on other VM, another VM that was previously suspended. So, you might think that you're safe because you turn it off. But the attacker has the possibility to actually turn it back on again. Then logs into this resumed VM, gaining access to a critical business application that you thought was safe. Another example could be that the attacker gains a foothold in the compute instance and then abuses permissions in the service account to move laterally. Uses these service account permissions assigned to gain admin privileges. Then uses these admin privileges to set an IAM policy allowing read, write, delete access to BigQuery data sets. With these permissions, the attacker can then exfiltrate BigQuery data, which was discovered by the integrated sensitive data protection service. So, with SDP, we know which of your resources contain sensitive data. And with this toxic combination, we know how the attacker can actually access that data. A third example, an attacker phishes an innocent user. Gains access to an associated service account. Uses the service account privileges to create new keys for other service accounts. With these, the attacker can access sensitive resources. So, the simulated attacker not only uses permissions that are kind of, that exist. The simulated attacker also knows which permissions can I give myself to go further. So, those were some examples of attack paths and toxic combinations. The other security issue that Knox mentioned that is completely brand new, I think this is the first time you hear about it, is something we call choke points. So, within these critical attack paths that we find with the simulated attacker, we can also derive which cloud resources are common in these critical attack paths. So, it could be that there are several toxic combinations that all go through one in the same VM or one in the same service account. This is what we would call a toxic combination. So, an example could look like this. There are actually three basically completely different attack paths, one starting with phishing a user, like we heard with the toxic combination, or exploiting a vulnerability. Or stealing a service account key. Then the attacker moves laterally. And one of the things in all these attack paths that are common is a VM with a widely exploitable vulnerability. And then the attack paths spread out again to reach different high value resources. But focusing on this VM with this exploitable vulnerability can help you close not one, not two, but several attack paths. Okay. It's time to look at what this actually looks like in the product. So, Knox will start with showing you security issues. Thanks, Robert. And can we see my screen? Cool. Resolution looks good. So, if you go into SEC now, there's a new section of the app called Issues. And so, when I click on this, the first thing that I want to show is we've detected 18 issues. So, rather than dealing with tens or hundreds of thousands of findings, these are just the most important things that you need to address in your environment across the toxic combinations, choke points, or rules that we've run against the graph. Each issue here is its own unique detection that I mentioned before. And then when I click on an individual issue, I'm able to see any specific resource that has that issue. So, looking at this service account that exposed many valuable resources, we have six different service accounts that are that type of choke point that we've detected in our environment. Once I click on an issue, I'll be able to get a pretty deep view into the evidence. So, visualization of that specific choke point, the attack exposure score, details about how many exposed resources there are, and all of those types of things. Moving further, different personas might come into the app for different reasons. And so, if I want to look at any issue that involves a vulnerability, I can filter that individually, click into that specific issue, see that individual workload here, which is a GC instance with a high-risk CVE that's using a default service account and has full API access. And then all of the vulnerabilities that are on that specific instance that have generated that issue. So, within these vulns, I can see which ones have a fix available. We're bringing in the Mandiant intel on whether or not the impact is low, is there a known exploit, all of that type of information. The nice thing here is you might have org-wide deployments or different teams that are going in and interacting with the system. All of this can be filtered by information from your cloud hierarchies. So, if there's individual teams that own accounts or projects, they can see the issues that are related to their specific environment and only focus on what's important to them. Each issue that we detect then has detailed information on how to fix it, the different steps that you can take in that environment. And then if we're looking at something like the exposed valued resources, we're able to see any high-priority resources, medium-priority resources, and we're bringing as much context into this issue as possible. So, previously, you might be jumping between many different findings across the app, and this is a consolidated view for teams on what they need to fix and what's most important. Now, Robert's going to come and get a little bit deeper into specifically toxic combinations and choke points and the details that we have there. Can we go back to the presentation? Presentation. Presentation. Presentation. Presentation. So, I did a recording of my part of the demo, mostly because I wanted to show you two specific toxic combinations and choke points, similar to the examples I gave you. so now I click on an instance that exposes many valued resources so that was the show point I showed you in the slides so this is what it would look like in the product and what we can do is explore the full attack path so on the high level view that you that you just saw and that not presented you get some some high level data but if we explore the full attack path we can see all the steps that the attacker actually takes from the public internet to the high value resources so if we choose one of the attack paths leading to a high value resource a compute instance we can see that the attacker uses an open ssh port on a firewall moves to the compute instance that has an exploitable software vulnerability and a default service account and then uses permissions to resume another VM a VM that was considered a high value resource and with that full access that VM is compromised so you can basically see all the steps that the attacker takes and with this kind of in depth information you can choose how you want to mitigate that attack path and that choke point so if we go back and look at a toxic combination so this is a user managed key to service account with permissions to assume other service accounts leading to vertex AI data sets compromise so we're back at the AI thing again if we zoom in we can see that we have a user managed service account key that hasn't been rotated which then makes it more likely to be stolen with that one the attacker can assume a service account and with those permissions create new keys to another service account and that service account can actually perform actions related to the vertex AI data set both doing update and delete which would be then a compromise of that data set so those are two examples of what it would look like in the product and that was not mocks or anything that was a real environment that we were using where the virtual red teaming attacker actually found these attack paths let's see if we can move on not really okay okay so i wanted also to talk a little bit about the risk report maybe you've seen it on some of the like screens in the hallway and in the lunchroom that we have this thing called the risk report and you can all get a copy of it for your organization for free right now so you can sign up and get basically information about choke points and toxic combinations for your organization just to try it out and see what it looks like the risk report is basically an executive summary of your most critical issues so similar to what you have in the product but put in a condensed form a pdf the risk report includes like an introduction to continuous virtual red teaming so there's a page kind of introducing the concepts and everything if you want to learn more and also it contains the key capabilities that we have in the product like choke points and toxic combinations but we also use it to showcase new features things that we don't have in the product yet but that is about to come the flow of the risk report is structured to be like pedagogic for you so that you can read and understand and kind of move forward in the report i'm going to show some example pages which contains both things that we have in the product but also not in the product yet so for instance entry points entry points is almost like a toxic combination but it's resources that is on the perimeter things that the attacker would use first to move into your environment and one of the nice things i don't we can't really see it but almost you can see the colors at least that there are some entry points that are widely used like i think this is what user managed keys that's the main thing that the attacker uses to get into this environment a good thing here is also you get information on things you're doing well so here we can see that with mfa enabled across your org it's less likely that users will successfully be phished so that is not an entry point that our simulated attacker has been able to use so you get information on both things you can fix but also showcase things you're doing well in your organization then we have choke points like i presented here you see like an overview of from the public internet where the attacker is which choke points the attacker uses and which high value resources the attacker succeeds to compromise and a top list of which these choke points are and suggested mitigations how to take action then of course we have information about your toxic combinations with some examples some high level stats on your toxic combinations like which are the most uh frequent toxic combinations you have and so on we also have some information that we don't compile yet in the product that you can dig up yourself but that we put together here for instance a breakdown on which micro attack tactics the virtual red teaming attacker uses so if that's something you need for for reporting or something uh this is something you get with the risk report so we can see here in this example that one of the most frequent mitra attack tactics used in the simulations is tactic number two execution and then we can see that there are some that are less frequent like lateral movement through network connect as i mentioned there are some things in the risk report that are not in the product and here are two things that is not yet in the product that you might not get with the first try of the free risk report but that you can get if you talk to your i don't know your sales rep or your ce or someone and that is uh we call it vertical views so there's different ways to slice information about your organization here i am showing you two examples one focusing on identity and here what's interesting about this one is that we did a what if analysis is saying that if you use context aware access as a feature how much will that improve your environment and what we can see up here is that for instance there were 854 exposed resources before using context aware access and then after context aware access was deployed the number of exposed resources were almost cut in half to 475 so the attacker could still reach 475 exposed resources but much fewer than before and if we look at the percentage of expo exposed resource value it went down from almost 100 percent to only eight percent meaning that the most critical high value resources the ones that were the actual high value resources those are not reached anymore so even though there are 475 exposed resources it's the ones that are less critical that we would say low value to basically so this is a way to see should i actually use context aware access or not and in this specific organization it would make a huge difference and this can be tried with with other features as well to see how much a a like a policy or a control can actually reduce your attack surface then of course we we have a section on securing ai so here we specifically look for choke points and toxic combinations related to your ai resources so we can derive information specifically for that um so if you have a team that works on securing ai you can get which attack paths which toxic combinations and show points they should focus on yeah and as i mentioned uh you can all get a free security risk assessment uh scan this qr code and it will take you to a a sign up page basically and we will get back to you uh after that uh we will hang out here for a bit so if you do have questions or you want to chat with us feel free to do so otherwise thank you for for coming and joining us on this friday thank you thank you