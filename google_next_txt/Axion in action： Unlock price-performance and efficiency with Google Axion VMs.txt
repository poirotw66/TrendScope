 Welcome, everybody. Welcome to the Axion in Action session. We're going to be talking about Axion today. My name is Mo Farhat. I'm a group product manager in Google Compute Engine. And I'm privileged today to be joined by Abhishek Rai and Adam Steele from our partners and customers at Databricks and Spotify. Let's get started. First, while Axion is Google's first custom server processor, it is not our first custom processor and certainly not our first silicon innovation. Google's been building incredible custom silicon products from TPUs dating back more than a decade now with TPU1 all the way to the incredibly exciting announcement of Ironwood at Google Next this year. And, of course, our Titan Security ASICs, YouTube VCUs, and the series of Tensor G1, G2, and G3 Pixel phones. And, of course, Axion announced at Google Next last year. So why did we build Axion, and why should you build on Axion? Axion gets you the best price performance for ARM-compatible workloads, an incredible performance per vCPU for very common database and web-serving workloads. And it does all of this at an incredible performance per watt that helps you lower your carbon footprint. Axion gets you up to 10% better price performance and performance than the leading current generation ARM-based processors anywhere in the cloud today. And up to 65% better price performance and up to 60% better power efficiency than comparable current generation instances on Google Cloud. And it's important to note that it does this in a standards-based approach built on standard ARM-neoverse v2 compute cores to help you move your workloads easily with little to no application code changes. Now, the virtual machines running on Axion are in the C4A instance family. This instance family covers a broad range of general-purpose machine sizes and shapes, up to 72 vCPUs with 2, 4, and 8 gigabytes of DDR5 per vCPU, support for 100 gigabits, up to 100 gigabits per second of Tier 1 networking, all our latest generation HyperDisk remote storage options, and of course, in January, we announced support for Google's first titanium SSDs. Incredible performance, latency improvements over prior generation SSDs. We now have Axion in more than 10 regions and up to 15 regions coming in just in a few months and expanding from there. And you can use Axion-based VMs just like you use any other virtual machines in Google Compute Engine with the same rich management and features and functionality. And we've been building on Axion ourselves. This is just a subset of the Google applications that are currently running on Axion. We have thousands of internal Google applications that are running on Axion today, including some of these incredible names from GKE, Dataproc, Dataflow, Batch, BigQuery, Spanner, incredible performance improvements on Spanner. If Axion will run Spanner this well, it'll run your workload incredibly well as well. And at Next this year, we announced support for Axion in Cloud SQL and AlloyDB. And we're going to grow from there to make these machines as easy to consume and use for you as possible. And look at these impressive numbers. Up to 2x more throughput and 65% better price performance than Amazon RDS running on the latest generation Graviton 4 machines. Truly remarkable. And in AlloyDB, up to 3 million transactions per minute and up to three times the price performance of Aurora Postgres, again running on Graviton 4. This is a truly remarkable achievement coming in on our first generation Axion machine. We can't wait for you to try out these machines and these services. And we've seen incredible customer traction. More than 40% of the top 100 Google Compute Engine customers are running on Axion today. Encourage you to give them a try. Here are some just incredible anecdotes and points from our partners at Palo Alto, Elastic, Viant. But you don't have to hear it from me. Please welcome Adam Steele to the stage. Adam, welcome. Hi, everybody. I'm Adam Steele. And I'm here to share Spotify's journey to Google's Axion processor. I'm a product manager in the core infrastructure organization in Spotify inside of Platform Engineering. And one of the teams that I work with is our compute team. So I'm excited to share our compute team's experience using Axion. So who is Spotify? Hopefully you all already have this on your phones. Spotify is the world's most popular audio streaming service. We have over 675 million users in more than 180 markets. So truly a global product and a global infrastructure that we have to operate to support the product. Spotify primarily uses Backstage to interface with its cloud resources. Backstage is an open source framework for making developer portals. I highly recommend check out Backstage. As a platform engineering team for us making sweeping changes, such as to the processors, Backstage gives my platform engineering team an opportunity to make changes across 600 different autonomous engineering teams. Some more stats on Spotify. We have over 100 million tracks. We have 6.5 million podcast titles. 350,000 audiobooks. And we've been on GCP as a single cloud partnership for over 10 years. We do about 10 million client requests per second. And last year we had a peak of 1.5 million cores on GKE. So a little bit of scale and in quite a few places. There's some priorities that I'm thinking about as a product manager at Spotify. One of the main company priorities right now is cost and carbon reduction. So for one, Spotify has a commitment to be net zero greenhouse gas emissions by 2030, and I'm looking for ways to help make that happen. Number two, Spotify was profitable last year, and I want to do what I can to help keep that going. There's also the performance. As an infrastructure team, I'm often so far away from what's actually happening on the mobile app, you know, from the PMs who work on playlists or on podcasts. But one thing I know is that as an infrastructure PM, I can help reduce latency, deliver better performance, deliver better availability, and that leads directly to a better user experience and meeting the business metrics. And then one of our priorities is to keep close with Google Cloud and to make sure that we're keeping track of what the newest things are on GCP. Looking at Axion, there were some challenges that we had to worry about. Spotify has always run on x86. I assume most everyone here has mostly run on x86. And there's some unknowns when it comes to thinking about switching to Axion or switching to an ARM processor. You know, is that actually going to help the business goals that we talked about? How hard would it be to move from what we are today onto Axion and ARM? And then there's some complexity there too, right? Like, would moving from x86 only create different problems as we handle multiple architectures or switch architectures? And then what about looking at a specific machine type? Is that a challenge? And then finally, the prioritization, right? Is it's not zero effort, right? So is the effort of moving our processing worth the impact that we get from it, right? Like, does this actually make sense from a cost-benefit perspective? When we were looking at Axion, there were a few things that we were especially excited for. Number one, on the modernization side, Spotify has been using some older machine types for quite some time. And we ended up getting heavily committed onto older machine types. and we knew that regardless of which processors are out today, we knew it was about time to start looking and making sure that we were evaluating the newest types. On the performance side, we realized there were a lot of benefits to be had by improving centralized services. I think of, like, perimeter. I think of, like, caching. Like, anything we can do to make those faster or more performant ends up having an outsized benefit for the rest of Spotify, right? If I can make the edge a lot faster, I might make playlists load faster, and that's great for us. And then there's the efficiency angle. If we can get better performance for the same money and we need fewer nodes, that's just generally less overhead that we have to deal with. So we did a little bit of testing, and the numbers are really exciting. On the performance side, we increased performance on average about 250%. This has a direct impact on, like, user experience and business metrics. The most common thing that we do at Spotify is a stateless backend service. When I think about my team managing our Kubernetes clusters, most of that is a stateless backend Java service. And those typical microservices are going to get two to three performance improvement on Axion. There's another product that I work on, which is a managed memcache solution. This is a caching layer that we put in front of a lot of our most important services. You can imagine Spotify's traffic in each region kind of has this follow-the-sun pattern, right, where people wake up, they listen to music, they go to work, they listen on their commute. And memcache is allowing us to, this managed memcache product allows us to handle those bursts and better handle that diurnal curve. So the managed memcache product, we have started moving almost all of it to Axion, and the results have been incredible. We have teams who used to need, you know, a memcache server with eight cores, and now today they just need two cores. So it's been really exciting to move those, see the changes, right-size them, and just enjoy better performance. We've saved up to 40% on compute costs. I mean, just generally, faster cores, more cores per node. You need fewer nodes. And we see about 2.5x performance benefit for 1.4x the cost. And then we saved hundreds of person hours a month. It's a fun metric, but generally, it's just less operational overhead to need less VMs, right? There's less toil managing GKE. There's fewer nodes and clusters to manage. There's fewer configurations and horizontal pod autoscalers to set up and networking things to set up. On the IP address space, I won't dive too deep on the networking, but we always, we could use some more IPv4 addresses. So anything to reduce how many IP addresses we need is great for us. And this is able to open up a lot of ranges. And then finally, on the operational side, there's just less things to upgrade. And then I think it's very interesting on the fewer metrics in the time series database. You can imagine people might be reporting like CPU utilization and then labeling VM on that. If you have fewer VMs, that's lower cardinality. And that makes your monitoring queries more performant, right? You avoid, it also makes them a little cheaper. And then further, if you're an engineer and you're trying to debug something, it's a lot easier to look at a graph of 10 VMs than it is to look at a graph of 50 VMs. So just having fewer things to look at makes it a lot easier for us to observe what's going on and just to manage the different resources that we have. So by the time we did the testing, we've kind of decided to move all compute to Axion. I'm really excited about this. Our backend services, of course, will move. The microservices, the perimeter, the caching. There's some data jobs, there's ML analytics, all of it. And then I'm really excited for the managed services from earlier, right? Like Cloud SQL on Axion is very exciting for us. Cloud Spanner on Axion is very exciting for us. Bigtable on Axion is very exciting for us. So we're very excited to be moving forward and we have a couple tips. I recommend experimenting with Axion and ARM. Different workloads are going to get different performance gains. If you have something that's like network constrained, it might be different than something where you're CPU constrained. The disks on Axion are actually really exciting and super performant. And we've noticed different backend services might have different sort of amounts of logic within them that'll change how the performance profile improves. We were usually wrong about what parts of experimentation would be the hardest. When it comes to actually building for ARM and working on Axion, we were able to find that just by swapping out base images, we could pretty much build multi-architecture with limited effort on our end. And then I do recommend to regularly re-evaluate instance families. Spotify kind of fell into a flywheel, we'll call it, where six years ago we start buying one family and then we get committed use discounts. So then when people spin up new things, they buy the same thing and then we buy more committed use discounts. And then one day we look down and realize that we're using a lot of old machines, right? So I recommend always keeping track of what you're using and just double check to see if there's new stuff out there that you should be looking at for processing. And then finally, engage with the GCP team. The Axion team has been incredibly helpful for us. I don't think we would have seen the gains that we did without them. There were some special instances where we had teams who were working with sort of low level, like they need specific x86 functions. And we were very happy to have Axion's support to be able to figure out how to transition those workloads and how to think about what we do with those in the future. So those are my tips. Thank you very much for your time and I'm going to invite Abhishek on to talk from Databricks. Thanks, Adam. Hey, everyone. This is Abhishek Rai from Databricks. I'm here to talk about Databricks' journey with Axion today. So Databricks is the data and AI company. Our data intelligence platform is used by over 12,000 customers. These customers are using our market-leading open source solutions such as Delta Lake, Unity Catalog, Apache Spark, MLflow, and DBRX. We are grateful to Google for the excellent partnership that we've enjoyed over the past several years. We first launched on Google back in 2021 and since then we've grown our user base on Google significantly. Today, we have more than 2,000 customer subscriptions for Databricks on Google. and if you think about it, Databricks' fundamental goal is to provide a single consistent data platform across all cloud platforms. And towards this, we support our entire data platform today on Google Cloud. Unity Catalog, our data governance solution, is GA. are serverless products, DB SQL, jobs, notebooks, Delta Live tables, they are all GA on Google Cloud. Gen AI is in preview. And we are able to make these strides over the past few years, of course, because of the strength of the partnership with Google, but also because internally, Google Cloud is a top company priority for us. In fact, Google Cloud availability is a mandatory requirement for all GA releases of Databricks products. We are committed to open source innovation and partner collaboration. In fact, it's the strength of this partnership that Google Cloud has recognized us as the partner of the year last year and this year, and this is a really big deal for us. Next, let me go over the primary use cases that Databricks is used for across our user community. So we are primarily used for three use cases, data analytics, for data analysts, data engineers, data scientists, AI ML engineers, SQL warehousing. Databricks SQL or DB SQL is a 500 million business. It's our fastest growing product. Gen AI, we are rapidly growing our user base in Gen AI. In fact, it's our point of view that Gen AI will not succeed without data governance. Data governance is a unifying theme across all of these use cases, which is where Unity catalog from Databricks comes in. The other unifying theme across these use cases is performance and that's what brings us to Exion today. Before I proceed further, let me give a quick deep dive on our tech stack. So Databricks on Google Cloud is deeply integrated into Google Cloud's native offerings. We use the full range of Google Cloud services. We run our compute on GCE. We use Google Cloud storage buckets, block storage. We are integrated into Cloud Identity, Cloud Marketplace, and so on. Ultimately, not only do we have deep integrations with Google Cloud, but we also complement the native offerings of Google Cloud, such as Looker and BigQuery. With that context, let me give you a quick under-the-hood peak of Databricks architecture. So the system architecture slide is showing to the left Databricks tenant in Google Cloud and to the right is the customer tenant in Google Cloud. The Databricks tenant to the left at the top shows the control plane, which is hosting our services such as the data intelligence platform, the Unity Catalog governance solution, and other platform services. The control plane is what our users access. The control plane uses compute plane for running customer workloads. I have shown the serverless compute plane to the left here in the Databricks tenant. This is used by all of our serverless product lines. And the compute plane to the right is the classic compute plane which runs in customer tenant, and this is used by our classic product lines. The compute layer uses storage underneath GCS, block storage devices, and local disk. Next, I'll give a little bit under the hood peak of the compute plane itself. The compute plane ultimately is where our customer workloads are running. Each workload runs in an independent cluster of virtual machines. These workloads use Apache Spark and Databricks Photon engine. Photon is Databricks native execution backend. It significantly accelerates Spark-based workloads and is heavily utilized by our customer base. It's also a very important part of our Exion story as you'll see in a moment. Now, with that context, let's move on to the factors for us to choose Exion. First of all, Exion offers up to 40% better performance per dollar. The ARM cores in Exion, they are ideal for data-intensive workloads like Databricks. Exion also includes several optimizations that help these workloads tremendously. We're also very excited about Hyperdisk block storage, which gives you the ability to independently scale performance and size. Hyperdisk storage combined with titanium local SSDs can provide a significant boost to IO-bound workloads and I'll share more details on that in a moment. Exion networking stack is able to sustain encryption at full line rate, which fits in very well with our data security story for Databricks. ultimately, the strength of the Exion platform and what we are seeing for our internal workloads and what we are hearing from our customers has, with that we've decided to go big on Exion with our serverless offering. Databricks serverless significantly improves customer experience and reduces total cost of ownership through cutting edge intelligence and other optimizations built across the whole range of Databricks products. With that, let me go over some actual results of what we are seeing across our customer base. First of all, if there's one message to take from today, Exion really lives up to its promise. We are seeing significant performance gains across a whole range of workloads. We are seeing up to 50% performance gain compared to second generation instances and up to 40% compared to third generation instances. What's more, these gains are pretty consistent. As I noted earlier, Hyperdisk and Titanium local SSDs, they come with a lot of promise and what we are seeing in production is that they actually provide a significant performance boost for IO-bound workloads. I want to double-click on that point because IO-bound workloads can really increase your TCO if you're not careful because ultimately they end up in idling compute. With Exion, by speeding up these IO, sorry, with the Titanium local SSDs and Hyperdisk, by speeding up these IO-bound workloads, we are able to actually bring down the compute cost as well, which is a big win. In fact, we are very impressed with the Hyperdisk platform in general that we've decided to use Hyperdisk for our third-gen instances as well. We were not using Hyperdisk there before. The most important learning that we had was that it's really the hardware and software together that make for a strong story. Again, reinforcing the point Adam made earlier, Databricks Photon Engine along with Exion is where we see the biggest wins. The chart here shows, for example, that switching from Photon on N2 to Photon on C4A gives immediately a 50% performance boost across the broad range of workloads. And switching from Apache Spark on N2 to Exion gives a 10x performance boost, which is truly mind-blowing. In hindsight, though, that is not surprising. Exion is a great platform. Photon is an excellent execution backend, and it really shines on Exion. One other important call-out that we ran into is, again, use newer versions of the software stack. That is what will help you unlock greater value with Exion. For example, Java has gone through pretty significant optimizations for ARM between earlier LTS versions and JDK 17 and onwards. And that's where we saw the biggest wins as well. Finally, I'll leave you with a few tips. embrace Exion. As I noted earlier, it truly lives up to its promise. One thing that we found useful is to build for both ARM and x86. This will help optimize for availability and spot usage. And like I said before, don't ignore the software. The JDK 17 is one really stark example there. And there will be many others. if you are using Databricks, use a newer version of Databricks runtime with Photon Engine. Finally, embrace Hyperdisk. It's truly a big step function. Like I noted earlier, it really gives you the opportunity to bring down your TCO by helping boost performance for your I-O-bound workloads. That's all I had to share. Thank you for listening. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Take care. Thank you. Thank you. totalmente To be continued... Thank you. Thank you.