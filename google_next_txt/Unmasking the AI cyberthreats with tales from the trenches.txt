 Thank you, folks. I know it's one of the last sessions of the day. Thank you for coming and listening to our session. We have an esteemed panel today, experts from the cybersecurity industry as well as from Google, coming together to share tales from the trenches to tell you stories about how Gen.AI security is evolving how companies are using Gen.AI security, what tools they are using, along with how bad actors are using AI to make their attacks better. And we'll also discuss how future would look in a couple of years, where is the industry headed and how Gen.AI is going to revolutionize the industry. First, we'll start with a quick round of introductions. I'll start with myself. My name is Vineet Ban. I lead security and identity partnerships for Google Cloud. I've been in the role for the last seven years, came in early days of Google Cloud, trying to get the first firewall and the first product to run on Google Cloud. So it has been a long, great journey of having a lot of security vendors working with Google with a vision of making it easier for customers. So how do we make security easy for Google Cloud customers? So all the different vendors out there, their products are well integrated into Google and it's easier to use cloud because security is easy as well. Before Google, I was at Imperva, an application security company for three years. I did a lot of work on early application security in different clouds and a lot of work on the DDoS side of things as well. The attacks were getting much bigger those days as well. Before that was at Cisco for close to 10 years in the cybersecurity side of Cisco, building new products. Those days, virtual machines were coming up. So the first virtual firewall, email security appliances and so on. So I had good experience building products there. Before that was in voice or IP and the telecom side of things as an engineer network, engineer building wipe and stuff. So 15 or so years in cybersecurity in different companies has been amazing to see how the industry has evolved and where this Gen AI is going to fundamentally change everything again. I'll start with you, Jack, if you could introduce yourself. Sure. I'm Jack Satterfield. I'm the chief technology officer for Pima Community College. We're located in Tucson, Arizona. We're a two-year degree granting institution. We also have workforce development. We have what are called centers of excellence for the workforce development and basically reskilling. Those specialize, they're high-tech centers. They specialize in everything from aviation, cyber, healthcare, automotive. So we're located, like I said, in the general Tucson metro area, 10 different campuses. We usually have an active student load of about 35,000 students, about 2,500 employees, but at any one time, we're protecting well over 150,000 accounts. So a lot of those students are still there. So a little background on me. I was in the military for 25 years. So I was a senior warrant officer, signal warrant officer. So I've done everything in deployments from satellite communications, encryption, security, infrastructure, kind of everything. So retired in 2015, worked for a large behavioral health organization throughout the country, and then started the college in 2020. Amazing to hear the scale that you guys are dealing with and the number of employees. Bryce, if you could introduce yourself as well. Yeah, so my name is Bryce Daniels. I am on the Manient Consulting team, and I lead our Northeast Offensive Security team. So we're primarily focused on penetration testing, red team assessments, and that kind of thing. I've been at Manient for about 15 years, and in that time period, I've done incident response, some of our strategic offerings as well. So just kind of a wealth of experience of working with lots of different clients across many different industries, both those getting attacked as well as those planning for how best to protect themselves in the event of an attack. Prior to that, I worked for Ernst & Young, and before that, I was in the Air Force. Thank you. Mike? Mike Bertelski, Senior Director of Security Operations at Home Depot. Mind you, I'm wearing a blue shirt that is not an endorsement of the other company, so I should be wearing an orange shirt. My apologies for that. But basically, it's my organization. It's easier to say what we don't do in security. So we're not in, my team doesn't do IAM, we don't do governance, risk, and compliance, and we don't do business and strategy piece. So everything, we cover everything from the SOC, threat exposure management, which cloud security falls into, as well as application security, network security operations, and then data protection. And I've been with Home Depot for about three years. It's actually a little over three years. It's been a spectacular ride here, and it's gone by blindingly fast. The path to get here was more bizarre than I care to remit to you, but I actually thought I was going to be a high school band teacher when I went to college. So being the number two cyber person at Home Depot is kind of weird, but it's been a fun journey. I was a police officer in Montgomery County, Maryland. If anybody remembers the Beltway Sniper, that was my police department that handled that. After that, I spent a decade at the Department of Defense's computer forensics lab as a forensic examiner. Eventually got the management lobotomy and went into program management and whatnot. Also then went to US CERT, ran that for a couple of years for General Dynamics. Then moved out into the product world where I ran services for Fidelis Cyber Security, then spent four years at EY and then ended up here at Home Depot. So it's been a blast of a ride, but it wouldn't change it, and it continues to be exciting. There's always something new. It's an amazing story. Mustafa? Well, I think I made a mistake. I should have worn the UKG shirt. See? There you go. Everybody knows you and not me. All right. Thank you. My name is Mustafa. I'm the chief security officer at UKG, and I've been there for about 20 and a half years. Prior to that, I was the chief security officer for Brinks, where it's been about seven years. Super interested about the topic that we're talking about today because I think it's near and dear to my heart. From a background perspective, we've done a lot of working in tech or innovation and things that are coming, and I'm super excited to talk about this. But if you think about how this really connects to where I'm today, UKG as a company, and many of you may not know what UKG is or what we do, we're HCM space. We're HR tech. We connect the people to technology and technology as well, our customers to the people, so payroll, culture, as well as things like really driving value for human capital in terms of how you get funds and how do you really understand your background to your customers as well. So that's who we are as a company. Perfect. Thank you. So I think first we'll start just kind of understanding where different companies are in terms of their Gen AI adoption journey and how security is being baked into the equation. So starting with Mustafa, if you could tell us in your company, how is Gen AI getting adopted? You were telling us amazing stories about how everybody's doing AI, and our security team is doing amazing things, so we'd love to hear those stories. Yeah, I think every organization is doing some sort of AI or has a mandate to really look into the AI journey before you really lose, right, get on the bus or you're going to be behind. I think about a year and a half ago when UKG is really looking at how do we really bring in AI into our environment? How do we really make sure that this is also something that our customers are using? I have a big customer who's sitting right next to me, Home Depot here, so he can attest to some of those things. How do we bring these technologies to drive innovation, not only just based on the software we're building, but how do we make sure that customers are actually leveraging those things into the tech stack? Yep. So this is one of the things that we started the journey in terms of really looking at the opportunities and the opportunities. I started with Gemini, I started with a technology that we've launched a long time ago, UKG Bird, which really helps really the workforce management and workforce out there to really drive, understand their tech, understand their data inside of our products. That's how the journey started. From a security standpoint, we're thinking about how do we also make sure that we have a way to defend against this thing? Because it's a speed of software. I typically would say all of those technologies come into just pure supply chain security management. How am I thinking about it? And this is what we started on really thinking about security, Gen.AI, and some of those capabilities. Perfect. Thank you for kind of trying out all the technologies. I think UKG has been one of the early adopters of many of those. So we'll get into a little bit more discussion around how they're innovating in many different ways in security. Mike, if you could kind of tell us your journey, how Gen.AI is getting adopted, how security is getting baked into it as well. Yeah, so there's a couple of aspects to that. So from an internal perspective, certainly cybersecurity, but of all of IT, we've been going down the road pretty aggressively and leveraging it very similar to you, Mustafa. Internally for us, it's all about efficiency. You know, just from a security perspective, you think about the amount of data that we're pulling in. We ingest 70 terabytes a day into our sock. You can't throw enough people at that sort of thing. Yeah. So we have to leverage it to work smarter. From a customer-focused experience, we actually just launched Magic Apron in our app and whatnot, and I have to tell you, it's pretty astonishing what it's doing. You know, for our customer base, we're always looking for, we call it frictionless, right? You want them to have an absolutely frictionless experience in what they do. So what Magic Apron does is say, okay, I want to change my water here. I don't know about you, but normally I'd have to go like, all right, let me go look on YouTube, figure out how to do it. Okay, that's going to cause whatever injury to me and, you know, figure out then what product. Well, now it's all actually built into the application. So you can put in a query of, hey, I want to build a 10 by 20 deck for my backyard and it's going to be elevated by whatever. It will actually generate a product listing for you. It'll generate instructions on how to do things. It'll provide you videos for it. And then it'll actually pull in all the product reviews so you can make a determination. And again, it's all about that efficiency and frictionless experience for our customers. Wow. It's amazing to see how much innovation is happening and it was great to see magic happen even on the keynote today. So amazing work. I think, Bryce, you have a very unique spot. You kind of work with kind of a lot of different industries, a lot of different customers, seeing Gen.AI being rolled out and security being tested. So what are some interesting things you are seeing? Well, I think that a lot of our customers are perhaps not quite as, you know, aggressive as Home Depot in rolling out some of the different uses of Gen.AI. So it's many are concerned about, say, privacy and how their data is actually being properly handled. Because while some of them may be building complex applications that maybe leverage PHI to train a custom model that does something super interesting, like that's a really significant investment and risk that that organization has to think about. But many of them are just thinking about it in terms of, what are my employees doing with my company's data that may not be properly going through the right authorized Gen.AI models, et cetera? And so we are often helping our customers think through even just how is that governance happening and what is the, you know, how do they continue to progress down that path? And then I think that more and more of them will, you know, kind of get to that point where they're actually building an application. And now, now that you have an application, what are the risks that that does? What happens if, you know, you know, do you need to worry about what the model is capable of doing and whether or not it's going to risk exposure or something else like that? So, you know, how do you get into the testing phase and sort of build out on that side of things? So, you know, I think there's a maturity, you know, of some to another. And, you know, it's super interesting to see our clients move along that path. And are there any interesting trends where any industries that are more keen or more worried about the vulnerabilities or risks they may have? You know, I think the financial services industry is always one of the ones that is most concerned. They've got both some of the biggest motivations to do it. Yeah. And then they've got some of the biggest risks that might come if and how they implement that kind of stuff. But otherwise, I mean, I think everybody is really concerned about their employees' use of the models. And it really does span all industries. All right. Perfect. And Jack, tell us about your experiences. How are you guys kind of thinking about Gen AI rollout and security? Sure. So I'm in a unique circumstance where I'd be in higher education. So we have the student side and then we have our staff and faculty side. We actually have faculty that cross over both staff and student side. So you can see right there privacy issues, potential leakage of data. Those possibilities are very high. So what we've spent in our journey right now is a lot of it has been the governance piece, right? How we're going to control it. We started allowing Gemini recently with both our students and our staff in a small group and then looking at different controls on how we can control our personal data, you know, the privacy, all that data and not being sent out, right? So whether it's a firewall, whether it's a secure browser, those types of situations, looking at how we're going to control that data. The other piece of this too is the reliability. It's a big concern in higher education, right? Not only talked about the privacy, but the reliability of the model, whether or not those models are biased and how we integrate those models in with the teaching, right? Do we use something like Gemini or Grammarly to help teach the student to write a better letter, to be more concise, you know, fix the grammar? Or do we keep away from that and, you know, don't let them use any of those types of things? So it's quite an interesting role in higher education where we have both, like I said, the student side and our staff side and controlling that data that it doesn't shift. I can imagine. It's a big population that you have to work with. So I think the other interesting thing that's happening in security, there are obviously a lot of vendors in security. They're building co-pilots. They're trying to innovate and embed Gen AI into security products. So we'd love to kind of hear from the panel how this is kind of evolving. So Mustafa, starting from you, as we are building this security vendors that you're working with and how you're seeing Gen AI capabilities that are available to you that you can build some tools in security yourself as well. How are you guys thinking about what is the state of the industry now in terms of the co-pilots or the agents that are coming up from different angles? So I think I have a different view on the vendors and what they're using. For us right now, specifically on the security side, is really looking at some of the capabilities that we're building and how that could actually connect with anything outside. I mean, nothing new. We have APIs and other things in the past. I think it's a matter of understanding how they're using their technology behind the scenes to make sure that as it connects to our environment, as it connects to the things that we're doing that is done securely. So it goes back to data and privacy around the vendors behind the scenes running these agents. What is it really doing? If I take it to another lens in my product, my customers would ask the same thing. How are you using the agents or AI capability in your product and how has that been managed internally? So that's the top of mind how I think about it. All right. All right. And Bryce, from all the work that you have done with customers, are kind of co-pilots, people thinking about using co-pilots in security or generally, how do you see that adoption happening and the security challenges? I think that, Mustafa, as you were just saying, we tend to see each tool having their own sort of capability capability that maybe is going to help, you know, particularly a junior SOC analyst, et cetera, to write the correct query or to, you know, sort of as an advanced autocomplete almost. And some of them are growing more mature and more capable. I think, Mustafa, you were starting to say earlier to us that you and your team have started to just try to build kind of a more capable sort of agent. And kind of, that's been one of the things that we've talked a little bit to our clients about. But I think, to be honest, perhaps if you want to share a little bit, because you guys, I think, are even more mature than a few of the customers that I've been familiar with. So one of the things that we're doing is experimenting in a lot of this agent or agentic framework. And in the area in the SOC is, can we leverage agents where it becomes more of, just more of an augmentation and here's a problem and solve it, but take away 60% to 70% of the work of an analyst. Yep. Remove it entirely. And one of the experimentation is really driving or leveraging agents or multi-agents as well and making rationales based on what you know in your environment, your response capability, and your technology, the stack that you have to be able to do that. And this is one of the things that we've been working on and I'm super excited about the work and some of the members that are building that are actually in this room here. So that's, I see some of them sitting in the back end. But we, you know, as of yesterday morning, I was just looking at the tech and looking at some of the capabilities it's doing in terms of looking at an issue and taking about less than a minute or two to actually determine what to do or do I have to contain this or not. From a human perspective, that takes time to do in many cases, 30 to 15 minutes to 30 minutes to actually get there, given you have all the context and the knowledge to do that. And I think that's one of the amazing things that we've seen. Agent and agent framework can actually bring into your SOC so you can start to leverage the other people to do all the things that are necessary. It's amazing, I think Mustafa, that you mentioned about multiple models being used and companies kind of experimenting what the right agent model would be. But another interesting thing that you mentioned, there's a mandate now in many companies where the security team has to work with agents and build agents. So it's kind of fundamentally transforming what the roles are. You were mentioning folks who were more on the detection side of the house are also now building agents on their own. So a lot of the work, the roles are changing, what people are doing, how they're thinking about security is kind of fundamentally changing now. You know, I see that we are all going to defend against agents at some point. So you need to have agents to be able to detect against those attackers. Yeah. I think attackers are not going to stop because they use the same agents to automate their tasks, to speed up their work. Without agents, you're behind. It's just technically good. Yeah. And Mike, your experiences on different security products as you were rolling out Gen AI, there were products that had co-pilots or some kind of these things coming in or the SOC analyst automation use case was fairly common. What's your experience in terms of the maturity of those things or what are you guys using? So we actually just moved over to the XIM platform as our sim and, you know, there's a word that people have been using. It's context, right? And that's what's been pretty amazing with leveraging that because we're able to leverage the agents to essentially do the analysis, wrap up, hey, this is what we think it is, this is what we think the action should be able to take, and then the human being actually gets to decide whether or not to go forward. Now, there's other organizations that would be willing to let the agents, you know, take the action from soup to nuts. We still like having the ability before we pull the trigger on an action. but I think, you know, I think similar to Mustafa is the tool sets are very focused on their solution set and what they think the problem is. So we have also started building our own agents, specifically, an example that comes to mind from a data protection standpoint. You know, there's lots of tools that are out there that are great at scanning large amounts of data, but you're still leveraging, you know, strings and whatnot to figure out, like, okay, is this, you know, something I need to be looking at? Well, that generates a lot of false positives. So it's a lot of work that's spent doing not really something that's of value. So we build out models that very much puts context around all the alerts that our tools are doing. Yeah. So it actually increases the true positive rate that you're getting and you're, in turn, you end up having your folks who are hands-on keyboards actually being more efficient because they're not spinning their wheels on wasted alerts. Absolutely. And it's like a, the classic kind of says the security problem of how do we put all these tools, all the signals together? And one of the jokes I heard from a CISO was I have so many co-pilots, I need a co-pilot to control all the co-pilots. So there is an interesting problem coming up. And so real quick on that, though, that's where you also run into a challenge of you have these agents and, you know, so you build, you have a security product and then somebody, some other provider builds an agent that goes on top of it. Yeah. So you essentially potentially run into agents self-validating or corrupting the data set to deal with it. And there were like agents talking to each other. There were some reports that for every human worker you may have six or ten agents. So just keeping the identities in track of what are those agents will be very interesting. Jack, your experiences of what you guys have seen, any products you're using, any innovations? Yeah, so for our automation, we started on that road and they have co-pilots built into them and some are better than others. Some is a mixture of the product and the internet, which can be a bad thing. And really, we've started looking at XIM and some of the simplifications of bringing that all into one spot and then having the built-in agents understand all the data coming in from the products. Got it. Got it. Makes sense. Other interesting area is like, kind of Mustafa, you briefly mentioned, but Bryce, starting with you in terms of we have bad actors. They're also looking at all the innovation. They're trying to figure out how do I use all this technology. We're starting seeing reports and signals that the attacks are getting sophisticated. What's your read and what are some examples you have seen of things that are evolving? Yeah, so one of the reports that was released recently actually did come from Google from its threat intelligence team on how attackers, specifically nation-state attackers, happen to be using Gemini in a malicious way. Interestingly, though, the, perhaps somewhat, in a way you might anticipate, they're using it to better write their social engineering emails so that their grammar, their translation, et cetera, actually comes out with something that sounds real, even though these are, you know, foreign actors that may not have nearly the grasp of the English language or other languages depending on their targets. But they're also using Gemini to help them write code because they need to have malicious code that performs, you know, that helps them to attack the systems that they're trying to target. And then they might also use something like Gemini as well for reconnaissance. I want to learn about a public figure or learn about a company and what might be some information that might help them out there. So a variety of different things but it's mostly in that sort of, you know, what's going to help them to be more effective in a traditional sense but to a point about, like, where might things be going. Yep. So Google also recently did some research. They were able to use an LLM to identify a vulnerability within SQLite which is an open source SQL library used all over the place. Now, there are some caveats with the whole vulnerability but what's super interesting might be where that shows that this is going to go because if attackers as this is maybe democratized can the LLM, you know, can the attackers make their own LLMs that are good at finding vulnerabilities? You know, we already see attackers attacking, you know, edge devices like a VPN and stuff like that. You know, are they going to get better at finding vulnerabilities in those systems? And then are they going to, you know, once they get access to the networks are they going to have an LLM that helps them to attack and move laterally and do stuff like that and kind of, you know, as you guys were just, you know, talking about the attacker moving faster and what does that mean? Yeah. It's kind of very interesting to think about like everything from the kind of research that attacker needs to do. It's getting automated. They can find your digital surface, your digital kind of border through LLM models. They can, the toolkits can be automated and now if one toolkit doesn't work, the LLM could learn and modify the toolkit automatically to keep attacking until they get in. So, it's a whole different world that's coming up. Mustafa, how are you guys thinking about it? How do you think security is going to change with the attackers getting very good at what they're doing? I think we're getting educated the same way as the attackers are. And I think the LLMs and all of this capability is going to be the best attacker toolkit out there, in my mind. As an attacker, the first thing I'll do is spend a lot of time with these toolkits to really understand my target vulnerabilities and how to exploit them or step up my game in that manner. So, those are the kind of things that you know all the attackers are using today. Now, what are you doing for yourself, I think, from a defensive standpoint is can you rely on the same tools that you used to have to actually defend against this or should you actually incorporate some of the same toolkits that they're using? One, to identify their footprint, you know. Secondly, is to defend against those because that's to be speed. And the last thing we'll talk about is the context around it because it's not every organization is going to be different. So, how you actually leverage those and then tie it back to your detection and then even validating these things using the same models and validating doing reconnaissance for your own environment is necessary so you know what's out there. Absolutely. And Mike, have you seen any kind of attack patterns changing, velocities, what are you guys seeing? Yeah, it's, you know, when Mustafa answers, I just want to go, yeah, what he said. But no, I mean, we're seeing exactly that. It's the speed in which the actors can move. So, exactly as Bryce was saying, they're still going after a lot of the weak points of the people, right? so the smishing, et cetera, it's becoming so much better that it's increasing the probability that somebody's going to click on something or do something bad with that. You know, what, we actually had an event that we were working on from a fraud perspective. The malicious actor, anytime we, they were leveraging AI to stand up instances to be able to collect information and conduct the fraudulent activity. And as fast as we could, we got it down to about seven minutes from the time it got stood up on their end and the time they sent a smishing message to one of our associates for us to actually discover it and try to take it down. So in that case, you know, we were really kind of looking at it as how can we make it difficult and painful for them so that they had to, you know, had to keep switching their essentially infrastructure as a service behind the scenes to get it done. But I don't think it can be overstated the fact that leveraging AI, they can, the malicious actors can user profile to such an unbelievable level now that they can go out and figure out, you know, okay, this is the person, you know, I think about Home Depot where 500,000 employees, they can leverage AI and go, okay, you know what, this person's a gift card manager, I'm going to target them. How do you, the speed in which they can move is unbelievable and to Mustafa's point is, is we've got to be able to move just as, detect and defend just as fast and you almost have to leverage the AI piece of it to correlate everything in real time. Wow, it's going to be interesting. Will, Jack, any interesting attacks? Yes, with the generative AI, I mean, like we were joking earlier, you know, they fixed the grammar, that was the first thing, right, and then that made it through everything. So we took a little bit of a different approach too because, you know, a public institution, don't have a lot of money, can't really build stuff, I'm kind of relying on vendors to come out with certain products, right, to protect me. So actually, just recently, we went with Menlo, so a secure enterprise browser with RBI, so giving my protection to my users is the best I can do on some of these, right, some of this stuff's going to get through, you know, whatever you're using AI-based, I mean, we use other things for email protection, but it's a second layer of protection, and the great thing about it is it's not just while they're on premise, when I got faculty, I got staff to take all their laptops home, that protection goes with them everywhere they go, so it's another line, right, the email should pick it up, but if it doesn't, it goes through Menlo, which actually, like I said, has RBI involved too, so it isolates that user from directly interacting with the code, so it's been great, but once again, I'm having to rely on vendors, right, I can't go too far out there with certain solutions, so. Yeah, it's going to be a very interesting world, there are some kind of tech forward companies, people who have resources that may build some in-house solutions, there'll be. It's going to be agent against agent, is what's going to be. Agent against agent is either built by the company or built by somebody else for the company, but very interesting world. Another kind of interesting topic, there's so much technology coming into Gen AI, there are so many security solutions coming in. Any kind of feedback or thoughts you guys have on in terms of what would Nirvana State look like? we know the challenges are getting pretty significant. Any given company would have dozens or hundreds of different vendors of products they are using. How would all of this evolve if you were to suggest to the vendors and to the industry that this is where we should all go together? What would that look like starting with you, Mustafa? That's a tough one. I think this keynote this morning said Google is having a framework where the agents now can easily talk to each other from a protocol standpoint. I think that's a really interesting aspect of how do you really think about the future. Now, every product is going to have some sort of a Gen AI. If data on, it's a different story. So I think what problems are they solving? I think right now, everyone wants some sort of agent or say they have an agent, even if it's just there and not solving the problem. So if I'm asking the vendor, so anyone that has a security product, solve a problem, reduce the friction, and provide us with the right context so we can make decisions. Because showing me I have a problem all the time and not doing anything about it, it's not going to help me in many ways. Allowing me to extract that data. If I have to, because then the product itself could be really good, but context of how do I use the product, it's going to differ based on where I put it in my environment or the type of environment I am. So that's how I see it in that manner. The other thing is there's a lot of things that companies would do internally that the products themselves could do as well. Imagine the biggest space I think will transform its identity and I haven't seen a lot of work being done there, so I think that would be nice to know everything I have in my environment running with an agent, things like that could change the game for us. Absolutely. And Mike, your thoughts in terms of what would the ideal state and Nirvana state look like, even what should Google Cloud do, how should we work with the vendors, or how should everybody come together? I think every SaaS product, literally every piece of software out there is trying to build in AI capability. So when you think about most organizations already have a challenge around third-party management when it comes to dealing with their data, having vendor partners who understand the concerns that we have and having a bit more transparency about, okay, Home Depot, we've got some first-world problems. We're big enough, we can go, okay, you know what, you're not allowed to use our data to train your models, right? But most organizations don't have that. So there does need to be that level of transparency, transparency to still maintain some governance or control around that. And I think that's one I think that we're having the biggest challenge at Home Depot is everything is moving so fast, well, the toothpaste is already out of the tube, and how do we provide some responsible Gen AI governance around what we're letting our associates do, what we're agreeing to let our partners to do, because they're going to, you give them the inch, they're going to use it for every possible thing they can to monetize it, which you can't fault them for it, but there's got to be that business partnership because you really are allowing them to have such a level of access in most cases that it's got to be a symbiotic relationship. There's got to be gives and takes there. Makes sense. Makes sense. And Bryce, based on your experiences helping companies harden their Gen AI security side of the house, what are things that will really help those companies to do things more easily? Yeah, I did kind of want to also answer that question. I'm glad you sort of tweaked it a little bit. From the application security perspective, and it builds a little bit on what you were just saying there, Mike, about how companies need to have a governance thought process. They need to have thought through what is the threat model for the things that you're building or doing because in theory we're kind of at a point where e-commerce was a couple decades ago with Gen AI and it is moving so fast. So you kind of almost need to see a collapse in maturity so that we get to a more mature state and we're building things that have been designed with security in mind and obviously from selfishly from my perspective, somebody has also tried to come in and break them and just to check to see are the theories about how this works. Did we take into account the right things? is there are things beyond a prompt injunction that a Gen AI model needs to be concerned about. The entire application has to still be secure. If there's a remote code execution in the application, it doesn't necessarily matter whether or not that came through the LLM itself. So these types of designs are still things that have to be considered. So I think if I was looking at how should a company think about this, that company should think about it from the governance and all the way down to testing what they actually put into production. Makes sense. And Jack, your perspective, you said you're using a lot of vendors. How should they all work together or what would Nirvana look for you? Yeah, that would be it, that everything works together, but I know profits dictate things, so there's not going to be certain relationships out there that I think should be. But maybe more of a common framework. So stuff could indirectly work nicely with each other. You know, maybe a common framework or security framework. I mean, because this makes me laugh I've been in IT long enough. It's like we're human, right? We reproduce the same thing. We do the same thing over. We build out this whole AI thing, right? It's already out of the bag with no security really built into it to begin with. And here we go again building software without security. And we have to relearn how to do this every so many years, right? It doesn't cease to amaze me. And then we build products, right, to secure that product until it can protect itself again. Yes. If we could get out of that vicious cycle, that'd be awesome. Maybe it's an education thing. Maybe we're not teaching it. I don't know. Jack, AI is nothing but another software. That's right. You're going to have to treat it like a software, supply chain security. Yep. It's a software that has more problems because, well, it has access to more information like data as well as can actually shed information fast enough. So you need to make sure that from a privacy perspective and data perspective, you're actually tracking that really well. Yep. Because it tends to have loft the data and it tends to be privacy. Yep. So those, I mean, it's nothing but standard software security. Absolutely. So I think one last question. We have a few minutes left. I thought it'll be interesting for folks who are security practitioners, maybe early in their career, as the whole kind of industry is evolving, most of us starting with you, if you have to advise them on, hey, you're starting your cybersecurity journey or you're in early days of cybersecurity journey, what skills should they learn or what tools they should be working with so they become very efficient in their craft. You know, use one of the LLMs and create an agent, figure out a way. I mean, it's a way in the AI. And I think, you know, security, it's very different. And I always say, many people can get into security depending on how they think, the diversity of that process, depending on who you are and the background you have. Like, a detective working in forensic gives you a different perspective. A lawyer thinks differently. You know, an English teacher is a good writer. It changes the game in terms of how you think about it. But, you know, practice, there's a lot of labs out there, you know, specifically agents. Build an agent and learn from it. And I think it will give you more real-world experience than you think. Absolutely. Absolutely. Mike, your advice to kind of a relatively newer practitioner in security, what should they be building their skills on? You know, I have to say it really is an unbelievable opportunity for folks to leverage what's out there. right? I mean, you can't always believe everything on the internet, right? I get that. But at the same time, you have an opportunity to learn stuff faster and have it presented to you in such a concise manner. So learning how to appropriately put in queries and know what to ask the AI to be able to provide you. But it's also an opportunity, you know, if you do need to learn how to, you know, script in Python, okay, well, here, practice scripting and then actually run it through AI. Hey, what am I missing? You know, do a syntax check on this. And it's just, it allows them to get up to speed so much more efficiently. So that's what I would tell them to leverage. Perfect, perfect. Bryce, closing thoughts? I think I'll maybe sing the praises of consulting for just a moment and just say that one of the really cool things about being a consultant is getting thrown into an environment that is different every couple weeks and being able to see, you know, maybe you're working with Mustafa and you see how he and his team are able to solve things and that can spark something. And then you might, you know, be working with Jack and that can be, you know, just a completely different set of circumstances and building on that can just get creative, you know, cause some creativity and hopefully give somebody a good jumping point. Absolutely. Jack, closing thoughts? Maybe your student in the college? Sure, I mean, it's always good, good at school, right? But, I mean, you can get your start there just taking some classes, right? If you have the drive and the desire, it doesn't necessarily mean, I mean, IT's, especially in security, is one of the few areas right now. You can still get a job without having a bachelor's or master's degree. I mean, you can, if you've got the drive and you've got a base level experience, I'm a network guy at heart, I would say know the network a little bit and at least study that before you start getting into security and stuff. But all the steps are there and like Mike was talking about, on the internet, I mean, gosh, there's so many resources right now for free. So you probably didn't even have to go to a college. You could do a lot of that, find an internship or something. We were talking about earlier where, you know, the diversity of people that have desire and drive, I would rather have somebody like that than somebody all sorted up and has a bunch of degrees because that person I can train with the newest technologies that are out there and they're going to take it to the next level. So that's my suggestion. Absolutely. Thank you, panel. This was a very interesting discussion. I think folks in the audience, thank you for taking the time and listening to us. Hopefully it was helpful to folks. And thanks for folks who will watch this on YouTube later. Thank you.