 Welcome to our session for building multi-region high ability services on Cloud Run. So a quick intro to my co-speakers. First, we have Taylor, who is a software engineer and Uber tech lead for the serverless networking team. One of our customers, Sino, who is a senior solutions architect and head of use cases at a large financial services company, Commerce Bank. And myself, Shane, I'm a product manager on Cloud Run. So first, I'll briefly touch upon fault tolerant design and what are some common patterns for designing resilient services on Cloud Run. Next, Sino will talk about how they leverage Cloud Run for high availability and reliable banking. And finally, Taylor will come up to demo how multi-region deploy and a really cool upcoming feature called Service Health can automate cross-region failover to ensure high availability multi-region setups for your business critical services on Cloud Run. Now, a quick recap on Cloud Run. Cloud Run is a fully managed platform to run your code, function, or container on top of Google's scalable infrastructure. So some of the differentiating benefits on Cloud Run include hyper-elastic compute, scales up to zero, scales down to zero in seconds. Greater velocity for a better developer experience. Deploy code faster. Spend more time on your app logic. And really less time debugging infrastructure. And finally, high reliability out of the box. Cloud Run is zonally redundant by default, which means you can offload your SRE burden to Google. Now, we really can't talk about high availability without starting with reliability. Reliability is really about a system's ability to consistently perform its intended functions while maintaining uninterrupted services. It's about building trust that your service will be up and running for your end users wherever the traffic is coming from. It's also about building resilience that your service can recover in a timely manner from marquee disruptions. And in the event of an outage or disruption, you should have service-level objectives that tune your recovery time in hours, minutes, or even seconds, while also establishing recovery point objections to really minimize the risk of data loss. So when we talk about high availability, it usually revolves around fault-tolerant design. For Cloud Run, we provide a reliable, hyper-scalable platform out-of-box that, with minimal configuration, can operate business-critical services that are highly available across multiple regions. Now, this includes fault isolation. It all starts with architecting tiered apps and modular services on Cloud Run that really separate hot and cold traffic and ensure that faults in one service are really isolated from another. Auto-scaling. So if a few instances are bad, Cloud Run will scale up new instances for you in seconds. Critical redundancies. As mentioned, Cloud Run actually has zonal redundancies out of the box, and those zonal redundancies are N plus 1. Global load balancing. So we'll show you later how service health will allow you to fail over across regions with minimal setup to meet recovery time objectives. And finally, what are the other recovery mechanisms that are needed? So you can also add scalable multi-region databases like Spanner to really ensure that you meet other recovery point objectives. So let's go through a few scenarios. Scenario one. I have a control plane outage. Well, in this case, maybe you're trying to deploy a Cloud Run service, and it's returning an error due to the Cloud Run admin API is having some kind of temporary issue. Well, the benefits of Cloud Run are really the hyper-elasticity. So first off, control plane and data plane are decoupled. And so in this case, even though the control plane is out, the data plane is not affected. So your income coming requests scale up and down as needed, jobs continue to get served, and logging and monitoring operates normally. Maybe the second scenario now. I have a zonal outage. In this case, my service is returning some HTTP error in maybe West 4A. Okay. Well, the benefits of Cloud Run are kind of twofold. So first off, as mentioned, Cloud Run has N plus 1 redundancies out of the box, which means that right now we have N plus 1 zones ready in each one of your regions. And so traffic will automatically route to fail away from unhealthy zones. Additionally, Cloud Run supports zonal separation, which means that data centers within these areas are actually physically decoupled. And the second thing is hyper-elasticity. So in this case, once that failaway happens, Cloud Run will actually handle the restarting and auto-scaling instances in your new zone for you. And as mentioned before, because the data plane and control plane are separated, in this case, Cloud Run's admin APIs are not affected by that zonal outage. The third scenario is I have a regional outage. Well, in this case, maybe my entire service is returning an error in a particular US-West 4. So in this case, the benefits are recovery mechanisms in first, right? So the first thing you want to consider is how do I set up my backup and replication with services like Spanner? The second thing is critical redundancies. So we'll really show you how you can deploy your same service across multiple regions with a single command. Third is then global load balancing. Again, we'll show you later how we now have service health, which can actually automate cross-region failover for both external traffic coming from the Internet or internal traffic that's coming between private services. And finally, hyper-elasticity. And again, once your failover happens, your instances will scale up for you automatically in the new region. Now, I'm going to hand this over to Sinu, who's going to tell you how Commerce Bank is leveraging Cloud Run for higher availability. Thank you, Shane, for sharing interesting stuff from Cloud Run, which we are really looking for. Good morning, everyone. Imagine you have the business-critical application running in a cloud having downtime of two hours, and what would be the potential impact of your business? And what about the loss associated with that? Let's explore how Commerce Bank achieved reliable banking and leveraging high availability in cloud with one of the success stories with our use cases. Myself is Sinu, a senior solution architect, and a lot of use cases from Commerce Bank. Let's talk a little bit about Commerce Bank and who we are. Commerce Bank, based on Germany, has a history of more than 150 years. So strength of our business model provides an excellent baseline for future growth. Our business portfolio contains corporate and private customers. We are number one German middle stand, which is in German, which is a medium-sized company in Germany. We are supporting approximately one-third of German trade activities through our Comdirect services. So we have a global presence of 40 countries across the world. So we provide first-class advice for private and small business customers in Germany. Also, we have M-Bank in Poland. It's the most attractive bank for private customers in Poland. Now you know about Commerce Bank. So we are from BDA, which is for big data and advanced analytics. It's our key area, also our department. So we have roughly around 500-plus colleagues from four different countries. So we love being pioneers for others, and we were the first use case into public cloud across our bank. And we are also proud that Google has picked out code into their repository for the reference in terms of whenever you see some containers code or something from infrastructure code, maybe we contributed something for Google there. And our team is Cyber Center of Excellence. So we are the center of excellence team in Commerce Bank in BDA. So our mission is to have a foster, a secure, scalable, and standardized cloud environments and enable the use cases towards their cloud journey. How do we do that? So we care about cloud, information security, and data protection. So our four pillars are, these are the main pillars for us. So we support use cases, how to get their journey to the cloud, yeah? By doing their architecture and architectural support and setting up their standards and creating their infrastructure and guidelines in the cloud. So we define the standards for them, and they know what they have to do in case of they are new to the cloud. By doing that, so we are encouraging the more on-prem use cases moving towards the Google cloud. And we also write some concepts by standardizing what is good or good to do in a Google cloud and what is relevant for the financial sectors, what needs to be done, and the regulations, and so on. And we also create a product, which is really interesting for, might be for everyone. So we collect requirements from the multiple use cases, and we develop our internal products like a CS product from CCOE, which could be used by other use cases also. Like, you know, we are providing this as a self-service catalog solution, which is quite interesting for everyone. For example, we are providing the cloud-native-injection pipeline as a product for us. Yeah, and we are also providing a training for our colleagues to get into the cloud journey. So overall, we take the hot steps to make easy cakewalk for everyone in the bank. So let's talk about our use case, success story of MPS Falcon. So MPS stands for Matchpoint Services. So how will we achieve high availability and disaster recovery with our use case? So this Falcon use case is a primary search engine for our customer data within the bank, providing significant business benefits to branches and back offices operations on a daily basis, which is crucial for us. Yeah? It enhances efficiency by enabling quick and accurate identification of matching customer data by making searches faster and easier across the organization. And to be precise, the technical perspective, Falcon offers seamless accessibility through APIs. A foundation built on cloud-native and serverless technologies, which is ensuring scalability and modern infrastructure in our bank. So we launched this use case, MPS Falcon, in 2022. Since 2022, it's been in line. Falcon now handles over 700,000 plus searches daily in our bank and has been widely adapted by most of the source systems inside the bank. And also, it's providing high reliability and value in supporting operational excellence for the back offices to create a business inside in the bank. Now you know about the use case about the Falcon. Let's talk about the architecture. So how we really designed and what we did exactly during the decision of this use case. Let me start from the right side. As you can see, we have our on-premise. So the Commerce Bank system sitting in the back office, or you can imagine someone sitting in the branch. They are trying to search some customer data, which is being triggered as an API call to us as a REST API. We have an internal regional load balancer, which is associated with our proxy VMs, which is the API call. So we have a serverless connector. We catch those requests into our cloud run search engine, and we use Cloud SQL with the Postgres SQL in that, yeah? So this is overall how the search is getting from the back office to the cloud. Let's talk about how it is happening in the back end inside the bank. As you can see on the right side, we have the on-prem data lake. We are pushing the files, for example, the core customer data, which is being pushed every day around, you know, 5 o'clock in the morning. And we are taking those files as the pocket files, and we are using PubSub for event handling and so on. And we take those files using Cloud Run. We directly import them into BigQuery, and we are doing some business transformations within the BigQuery. And as soon as it is done, we are doing directly data transformation from BigQuery towards the Postgres SQL. Again, we would like to be precise on what we are sharing as a customer data during the search. We are also taking not only the data from the data lake, we are also taking the data from our event message queues. So this should be precisely like kind of a real-time data from our mainframe systems, which is being pulled using the same listener queue in the Cloud Run. We use the same PubSub for messaging the queue, and we are doing the data updated within the Cloud Run. This, the real-time data within during the day before the data lake loads the data into the system, it's also getting published into the Postgres. And the third one, we have the QNIC databases, which has the I-band, which is the account details of the customers. We also support in our search engine to provide all information about the code, information about the customer, also about the customer information about the account. So mainly, we distributed the queries here. How we do that? We distributed the queries, the write queries to the master instance in the Cloud SQL, and the read queries are distributed into the replication instances. Let's talk, even focus on the architecture here. When we are talking about the high availability, we need to be really sure that each and every request that's coming over here is getting distributed through an internal cloud load balance over here. So we have our proxy VMs, and the traffic from our on-prem systems are getting handled through this load balancer, and the Cloud Run is handling efficiently all the requests. So far, as I already mentioned, we are getting more than 700,000-plus searches per every day in the bank. Yeah? So this is all about the architecture. Now you know the falcon, how we are handling the search and providing efficient search engine into the bank. Let's talk a little bit even deeper into the high availability options. So when we design the solution for this falcon, so we had a lot of discussions internally because, you know, this is a core search engine for us to serve the entire bank for the back office and the front desk for the customers. So we had option one. How do we do that? So, you know, from Commerce Bank, our preferred region is Europe S3. As you have seen in the BigQuery, we have the transform data, which is getting imported into the Postgres afterwards, and we have evaluated, okay, we have the read replica instances from Cloud SQL from Europe S3, and the read replica, again, the standby would be the Europe S4. Yeah? So the search engine, whenever there is something happening within the S3, then it will be automatically switched to S4 from the Cloud SQL instance through load balancer. Then we had option two, which is like the same. We compared this with the Europe S4 and S3. Yeah? So whenever something happening when we are running our systems in the Europe S4, then we wanted to route our traffic into S3. So the same thing will happen with the search engine in the Cloud Run. So we wanted to have the replication, which is in the Europe S3A. And finally, we had a conclusion like, okay, we are going to check with the other regions within Europe. For example, Europe S1 in Belgium. For example, we have the replication in Europe S3A and 4A, and we have the script running in our on-prem load balancer, which is triggered like probably every 10 seconds checking the health checks. Yeah? So we are checking the health check of the systems, and if everything should be ready, then it is automatically switching each month. For example, if there is an issue happening in the one region, we are switching automatically to the another region during the replication. Now you all know the high availability options, what we have evaluated internally, and let's talk about the disaster recovery options. Let me start from the API gateway. So, you know, we have our front office sitting on the bank, and they are triggering the rest API to us. And the load balancer in the middle handling all the requests and sending towards the load balancer in the Google single-region load balancer. As you can see, the Europe S3 is really green for us and every time, and we have our primary master instance from Cloud SQL, which is being replicated. We use a cascading replica from Cloud SQL, which is automatically replicating the data to Europe S4, which is Netherlands. And these are the active instances from our side. So whenever there is something happens, the data is already being replicated to Europe S4. This ensures whenever there is something happening with Europe S3 for a couple of hours, we are immediately switching back to Europe S4. We have another, as you can see on the right side, we have the load balancer set up in Europe S4. Yeah, so we have two load balancers, which is on Europe S3, which is on Europe S4. And the same Cloud Run engine sitting over there. Then what happens in case of there is a disaster recovery? This is a disaster recovery mode. As you can see, the API gateway already pushing. The request is going to the load balancer, which is in Europe S3, and there is no response. Then immediately, our load balancer script, which is running for every 10 seconds, switching our regions to Europe S4. As you can see, we have the primary master instance from Cloud SQL being replicated in S4. We have all the data already available in Europe S4. Then by doing this, we are handling all the requests without any issues, without impacting our business for the bank. This is about the disaster mode. We are really proud that since 2022, we never had any issues with the Cloud Run. Everything is running smoothly in our bank. But we have the disaster mode enabled, and we are setting up everything ready for us in case of something happening. Yeah. So now you understand how we are doing the high availability and how we are setting up our disaster mode within the Cloud Run using the load balancer or region load balancer. I would like to give you two achievements here for you to take away. The Falcon delivers fast response times with 95% of the queries answered within 0.19 seconds, which is really great. Yeah? Or even less, even we are having less than 0.19 seconds. It handles over 700,000 responses daily and showcasing its high volume of capacity handling within the Google Cloud Run. The system's scalable and resilient architecture includes disaster recovery capabilities. Falcon is designed to meet all customers' search needs with room of additional features. For example, you are having one place. You can also, you don't have to be every time right with the customer name. I can also have some t-posts in the names. It also, I have the fuzzy search included mechanism within the Falcon. Cloud Run plays a key role in modernizing our cloud use cases and providing simplicity and scalability. This positions us well for future growth and innovation for our bank. I hope now you understand the importance of high availability and disaster recovery for business critical applications and thanks for your patience. With that, I hand over to Taylor. Hello, everyone. I'm Taylor. I'm an engineer on Cloud Run focusing on networking. Thank you, Sinu, for showing us how great Cloud Run is within the region for your high reliability use cases. Now I'm going to talk about how you can get beyond that with multi-region services and service health. As you may or may not already know, we have a public preview right now for multi-region deploy, which lets you just specify multiple regions right there when you're deploying and get the same config in all of the regions so you can, you know, reduce your management and focus on having high availability applications. Otherwise, it's the same commands and the same config you used today. We're also really excited to talk today about service health. It goes really well with multi-region deploy and it helps you scale globally and to have higher availability. So first, we're going to focus on container readiness. This is a new type of probe that you can add to your container so that we can understand whether your container is healthy, looking at all of the instances that are running in the region. To ensure that we always know the signal, we simply ask that you set a min instance to one so we always have something that we can probe. Otherwise, it's the magic you expect from Cloud Run. This can help you get a better time to recovery because we can help propagate that signal to places so that you can fail away from that region faster. And with that, you can get your full three and a half nines that Cloud Run provides. Don't let your downtime take away from the uptime you could be having. Here's a simple setup. Some of you may use this. Maybe you have more. Things on the load balancer there. US West 4. That's where we are today, Las Vegas. Asia East 1, very far away. If you send a request to this right now, it's going to US West 4 unless you have a very complicated VPN. What you want is if US West 4 becomes unhealthy for the traffic to fail away to Asia East 1, which even though it's far away, it's the healthy region. So let's see how we can set that up. Not quite yet. We can switch back to the slides. Okay. So first, you add a readiness probe. This one is an HTTP probe. It pings slash readiness every 10 seconds. And it's just looking for, let's see, three failures in a row. Very easy. You can copy-paste the startup probe and just change the path. Second, use your serverless snake exactly as you use it today. There's no additional setup needed on the load balancer. If you add this to a container and it's being used in a load balancer today, you will have this feature. As I mentioned, we're sitting in Las Vegas. That's where we're going to be seeing the traffic in a minute. And here you're going to see, it should autoplay. Here you're going to see how simple it is to deploy with multi-region deploy. I'm deploying a container that automatically switches the health status of the container every 30 seconds. So it's healthy for 30 seconds, unhealthy for 30 seconds. And I've also set an environment variable telling it that Asia East 1 is always healthy. Don't switch it. You see how quickly we were able to deploy that? And now, I'm going to go ahead and edit to add the readiness check and set the min instances to 1. Very easy, especially in Vim. just copy the startup probe. And then, you just apply it. And in no time at all, you have health checks ready to go. You'll see... Let's see. Do that. There we go. Here you can see I'm just going to quickly curl the two services. They're going to tell me their health. It's a little raw HTML, but that's okay. Just so we can see it's working. And now, I'm going to skip the load balancer setup. It's a couple commands, but now you can see me... Oh, that is the load balancer setup. One more. All right, I'm going to skip that one. Here I am curling my, you know, domain I have on my load balancer. And you can see every one second is just going to keep pinging. Eventually, US West 4 says it's unhealthy. It's telling me that, and it will switch away. There we go. So now Asia East 1 is handling the requests. Now, curl is one thing, but let's see it live. Any of you are welcome to type this URL in if you'd like. And then in a moment, we can switch now to the demo on the laptop. And here you can see that in 10 seconds, this container that's running in US West 4 is going to switch itself to unhealthy, and we'll watch it. switch over to Asia East 1. There it is. It's unhappy and unhealthy. And in a matter of seconds, it switches over to Asia East 1. When US West 4 becomes healthy again, you'll see it switch back. So we're really happy about this feature. It's really simple. It brings the magic of Cloud Run to multi-region availability, high availability. It helps you focus more on writing your business logic and deploying to the regions where you want to be, and less on thinking about how you're going to keep that uptime. In just a few seconds, it should switch back. And then... There we go. Now that US West 4... Oh, that's okay. There we go. US West 4 is very healthy now, so it'll sit there. Perfect. So I'm going to invite Shane and Sinu up for any questions anyone may have. And we'll just leave this running in the background for a bit so you can enjoy. Thank you. Thank you. Thank you. Thanks. Sure. Thank you. Thank you. Thank you. Here we go. We haveido Uぉ. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you.