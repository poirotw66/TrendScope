 . Hi, everyone. Wow, we're filling up. So this will be one of the most action-packed, jam-packed sessions today because we're talking about quite a few new innovations that are coming up in BigQuery. And we have a lot to cover today. I have some of the amazing product leaders joining me on stage this afternoon. And I also have one of our fantastic customers, Mattel, also coming on stage to talk about how they've implemented BigQuery in their organization. Let's get started. I'm Geeta Banda. I'm the head of Outbound Product Management for Data and Analytics here at Google Cloud. So the first one, as you've heard quite a bit this morning and also continue to hear over the next few days, is your AI needs to be fueled by your business data. So we all understand that AI is super important, and it is taking over what we are doing at an organization. But your data, your organization's data, is your moat to build that differentiated customer value propositions. So just to talk a little bit about where we've come from and where we are going. So we've started in the late 80s to about early 2000s about data warehousing, structured data. We're talking about high cost of ownership and also limited scalability. We moved on in the early 2000s and to 2020s into all data types, diverse data types, and then moved on to the lake houses of the, you know, until early 2020s as well, which is where we are unifying the data platform, open data formats, and also unified governance. But today, the modern organizations are looking for AI native, multi-model, agentic capabilities. This is where the data to AI platforms are actually taking over and starting this era or this decade. This is where we are introducing BigQuery as the autonomous data to AI platform. When we say autonomous, it is managing itself. It's assisting the entire life cycle. It's agentic, so we are accelerating the data work that is done by data engineers, data scientists, data analysts throughout their life cycle. And we are rapidly accelerating ML and AI models with seamless integration to vertex AI and also using BigQuery machine learning, a true end-to-end data platform. And this is where you see what BigQuery combines the best of data and AI capabilities into one platform. It is where we are unifying data, governance, processing engines, AI and BI, to deliver seamless business outcomes with simplicity and scale. So integrating AI at its core, BigQuery enables enterprises to move beyond traditional analytics into real-time AI-powered decision-making. Today, we'll talk about our innovations in these three big pillars. The first one is more our AI-assisted and agentic experiences with Gemini, the new-gen AI-driven experiences to boost productivity, as I mentioned, to all data specialists. So data engineers, data analysts, data scientists, and also where we are managing governance. And the second one we're talking about is a unified data and AI foundation. This is where we'll spend a lot of time talking about our multi-model data foundations with streamlined analytics across multiple engines, built-in unified governance. And I think this is where we are heavily focusing on making governance invisible. The third one we are going to spend some time on is being flexible and future-proof. So embracing open standards and robust partner ecosystem to enable customers the options and flexibility. But before we jump into all of that, I would love to welcome our TJ and Tom from Mattel to talk about how they're using BigQuery to build their data to AI platforms. All right. Let's get started. My name is TJ Allard. I'm a lead data scientist at Mattel. I'm Tom Varko. I'm a lead analytics engineer at Mattel. We're part of Mattel's product quality analytics team. And this is from data to insights, transforming consumer thoughts to KPIs with AI, turning work from one month into one minute using BigQuery and Google Cloud Platform. So I'm going to start off with a show of hands. How many of you were around during the dot-com days? Let me see. I know some hesitancy. Yes. Yes, exactly. So I'm sure you feel this, right? We're here again. Back then, if you, let me kind of set the stage here. So back in those days, every night of the week, you could go out to a launch party. And it was free food, free drink. And you would talk with these, you know, these startups and say, hey, what's your business model? They'd all say the same thing. Well, we're going to use advertising and we're going to generate traffic and that's how we're going to monetize. It's like, great. But what's your business model? And most of those companies didn't have an answer. And that's why a lot of them aren't around anymore. And so there's a lot of similarities in the AI world right now where AI is touted as world-changing technology. And it very well may be. But right now, we're getting weekly announcements, new advancements. Every week, it's something new, a magic trick, so to speak. But how do you generate revenue? How are you going to monetize this and what is that business use case to monetize? We're going to go over how we did that. We found a solution. And so for those who don't know who Mattel is, we're one of the largest toy companies in the world. We make brands like Hot Wheels, Uno, Barbie. And we have thousands of products sold worldwide. Online retailers, brick and mortar stores. And so this part of it here, the data to insights, this is like the real secret sauce for us. We have a world of consumer feedback. All these voices from product review sites, social media sites, websites, and our consumer services department. And so what we found is how do we turn that volume of insights into value? So turning that volume into value really started with the people. And the people is the biggest challenge. And when I say people, that's the people you work with. Understanding what's most important to them, those stakeholders. And then flushing that out to really say, okay, is this an AI solution? And in this case, we went a different path first. But this is what it used to look like. And this is why this is a perfect AI solution. This is real. This is literally how we were handling consumer feedback with tally sheets on a spreadsheet. Or on graph paper. I haven't seen graph paper in a long time. So this is kind of like, wow, here we go. Some of these challenges were there were multiple brands. And all these brands have different needs. And so these reports varied by team and analyst. There was no true taxonomy or structure across brands. So you couldn't do that apples to apples comparison. So different brands told different stories with different data. Well, actually, with the same data, just using different words. And that was a challenge. So the frequency of these reports was only quarterly because they were so long. It was very difficult to do. Super time consuming. And so what we developed in order to handle this was the Mattel Consumer Feedback Classification System. It sounds like a mouthful. And it's really not what it's called. It's just kind of our PQA model is our short term for it. And it's primarily a three-level classification system. Classifies things into a topic, subtopic, and attribute. Example for that, just to kind of wrap your head around it. If someone says, I love the toy, but the battery dies quickly. That's two separate classifications. A topic, a subtopic, and attribute. And has a sentiment attached. So one's positive. One's negative. So we went, this is, traditionally, this is a machine learning solve. Right? A machine learning problem. And we tried that route using, you know, things like text blob, data. We tried. Problem was, you want to meet your teams where they work. Right? So where do they live? What software do they work in? And this, in order to go this way, it was just too much expertise required. High time, high cost. And we tried to look outside for third parties, but the costs were, one, you're looking at a million dollars a year. And then two, you don't know their modeling. And so there's a term we use a lot. It's ontology. And that's really your intellectual property. And we'll talk more about that in a bit. But we built that whole system as a template. This was our initial approach that we used. And we were calling these prompt models. The idea was, it was great, but it didn't always work in the beginning. Because last year at Next, I was here. Just like you guys saw me sit in the audience. And I said, hey, we were having trouble with one of our brands called Little People. And this story is a testament not only to, you know, function of BigQuery, but also it really shows you why we chose Google as a partner. Because it was one vendor for the entire solution. And so what happened is with Little People, Gemini was not processing those because it was considered derogatory. And so we really dead in the water with it. And at an event just like this, I walked up and said, hey, we're having this issue. And within, I'm going to say two months, not even, less than two months, it was fixed. Now, I'm not going to say it was because of what I did, but it may have been because of what I did. But I'm not going to really take credit. I don't know. Anyway, the idea here behind this is what we did, because we got stalled that way, I reached out to the Google partners. And I'm going to call these people out because some of you guys are here and really appreciate this because you truly helped make this happen. I had to add Sengupta, Christy Liu, Mike Limkako, John May Portnick, Casey Ayagari, Jay Schofield, and Marcus Amora. You can leave now, Marcus. This has been great. And they immediately, when we stalled, I contacted them and they put a Python solution in place immediately. And because of that, we didn't really waste any time. We would just continue up and running until it was put into BigQuery. So I'm going to pass this off to Tom and he's going to tell you a little bit about Under the Hood. And then I am going to come back and give you some of the value adds. Thanks, TJ. So like TJ mentioned, we tried a bunch of different methods to do this. We tried Python, Notebooks, Vertex AI Studio. Ultimately, we landed on BigQuery and BigQuery ML because it really provided a uniform platform that allowed us to meet our data where it's at. Our data was already living in BigQuery. There was no need or no cost or risk moving data onto personal workstations, other servers. There was no need to transform or adapt our data for another platform. And the best part is because we're using plain SQL to do this, it became part of our normal ETL pipeline. So I'm going to go into this code on the next slide a little more. But this is our high-level process. Our data is living in BigQuery. We're using BigQuery via a SQL prompt, which is a stored procedure. And the third bullet here is the key part. We're asking Gemini to give us output in JSON format. Once we have that JSON output, we can use BigQuery's JSON functions to parse it into tables. So let's jump into this code a little bit. The heart of this is the ml-generate-text function. At the upper left here, starting with a CTE, common table expression, essentially we're concatenating a prompt with our output instructions and our text, our input text. So going back to the classification model, we're asking it to identify the topic, subtopic, attribute and sentiment of this review and give us the result in JSON format. Once we have that prepared and set up, the ml-generate-text function is a table function, so we're using select star from it. And it takes three arguments. The first is the name of the model. I didn't go into it here, but this is a quick set-up, a couple lines of code that you just basically copy and paste from the documentation. The second argument is the table that we just created above, the CTE. You could also put a subquery here if you didn't want to do a CTE. And finally, any input parameters that we need to provide to the model. So once we run that, we're going to get a table where our rows look like this. Every row is an output or a JSON output object with the topic, subtopic, attribute and sentiment. Then, just using the basic JSON value functions, we can pivot this into a table that looks like this. And that feeds our downstream analytics and reporting tools. So we've been running this for a while, and someone gave us a data set with 20 million reviews. Way, way more than we already had in our database. So like us, you're probably wondering, how is this going to scale? The answer is it really scaled effortlessly. Because we had set this up as part of our ETL pipeline, we just had to dump the reviews into our fact table, and our normal ETL process took care of it. I will add that we did have to add some batching. You can't just dump 20 million reviews into a single process because it will time out. But we're at a point now where we can do about 7,000 reviews every five minutes. Before I pass it back to TJ, I just want to touch on a couple of the new use cases we're exploring or have implemented. So keeping on the topic of ratings and reviews, we can also run our competitors' reviews through the same process to get an apples-to-apples quantifiable comparison of our products versus theirs. We can also summarize all the reviews for a single product into a few sentences, kind of like you see on any retailer website nowadays. The benefit of doing it in-house, though, is that we're a quality team. We can make that summary focus on the quality issues. Language translation is something that we don't actually explicitly need to do. As long as Gemini understands the language that the review is in, it will interpret it and give us our output in English along with everything else. We're also using this in global consumer services organization. We're analyzing notes from our consumer services agents' interactions with customers. And getting into more multimodal areas, we're analyzing images for fraud and counterfeit products. Finally, I'm an analytics engineer, so I love using this to clean data and transform it. One of my favorite examples is we had a column in a table called piece count or part count, which had the number of parts in each product. Sometimes it was a number. Sometimes it was a bullet list. Sometimes it was just sentences, a block of text. I was able to use Gemini to run that column through and get clean numbers out. And the great thing is I'm not a data scientist. I was able to do this. BigQuery ML is very democratizing. As long as you know SQL, you can use these kind of data engineering tasks or anything. Now I'm going to pass back to TJ to talk about the impact it's had on this. All right. So let's get into the impact. So this is the after. So you saw the before, which was tally sheets. This is the after. Now what this allows us to do is first, it standardizes this across the org. So you can click in what you're looking at here. You can click in any of the topics, subtopic, or attributes, and then get it all the way down to the skew level to understand what people are saying. So we've truly standardized these insights. And we built this as a template so we can democratize this. And this can be used for any of the groups in the org. So the new value unlocks. Like I said, we standardized these insights across the entire organization, allowing that apples to apples comparison. So with that uniform brand comparisons, you're allowed to now say, hey, let's look at, pick a topic. How does Barbie perform against, say, Hot Wheels? And the new dimension of data, this is a great one, out of the box with Gemini. We decided to start looking at ESG, just to understand environmental impacts and what our consumers are saying about it. And so right out of the gate, Gemini understood this. And now we were looking at that data previously, but now we're seeing it at scale in a way that we weren't able to see before. So the competitive advantage over the third party here, when you talk to them, you have that knowledge transfer. And this goes back, again, to the idea of your modeling, your ontology, that really is your intellectual property. And so if you're going to do that knowledge transfer to a third party, you're essentially giving them your competitive advantage. And what I mean by that is if you have two different toy companies all collecting the same data, it's the way that those companies use the data that really gives them the competitive advantage. They can use it in two entirely different ways. The way we built it is each piece of data will flow through and there is an action taken based on that classification. So that ontology, remember that. I think that's going to be a, that is really where this is going. That ontology, the way you use data, it really is your intellectual property. And so what this allowed for us, this faster reporting process, truly reducing this from months of work to a minute of work, increased the scope and not only the scope, but also the volume. I mean, we're at well over 25 million reviews at this point. And it's a small team with a big impact. I mean, it's two of us. We were able to really stand this up. Obviously we had help from our GTO and this amazing Google team here, but truly we were able to do this on our own. And this is my favorite one, the mega updates, because we have a brand called Mega Blocks. Mega updates, minor change. So once it changed, once there's a model update or anything like that, it's literally three lines of SQL and the pipeline continues to work. Continues to work from ETL all the way to AI inferencing. So the keys to this, the key to our success here, identifying the use case. That really is, again, like data first, but AI, understanding what your use case is and if AI is the right tool for the job is truly at the core of this. We had our great collaboration with our teams. It was the right tool for the job. It had that immediate impact and a significant savings. Well over a million dollars now because that initial cost, that was only at 500,000 reviews. We're so far beyond that. And we're able to stand this up for tens of thousands of dollars a year. And so again, by doing this, we've created our own asset with our intellectual property. And so thank you all for your time. I hope you enjoyed this part of it. And I'm going to pass this off quickly to Abhi because there's a lot going on in BigQuery. And I know you're here to see what's new in BigQuery and that's not what we did at Mattel only. But thank you all for your time. Thank you. Thank you. Thank you for these amazing insights, TJ and Tom. I'm Abhishek Kashif. I lead product management in BigQuery. And I'll start by sharing our innovations first for our Gemini features and what we are building for agentic workflows within BigQuery. Last year, we launched a set of assistive features using Gemini in BigQuery. And these included data preparation, data exploration, analysis, as well as code assistance, completion, and summarization. We now have thousands of customers using these. We are seeing a 350% increase in usage year over year. And the code acceptance rate for both SQL and Python is above 60%. That is industry leading. And all this is enabled by our state of the art Gemini models. Today, we are announcing that these top Gemini features in BigQuery will be included in the current BigQuery pricing. And these include code generation, code completion for SQL and Python, data canvas for exploratory analysis, and data preparation. Now, data preparation, which we launched in preview last year, is now generally available. It leverages Gemini to find issues with your raw data files. As an example, if there is a schema mismatch, and it generates SQL code automatically for you to fix those issues. So if you have a use case where you have a standard schema, you just take that file into data preparation. It will generate code. You can edit that code. You can generate a pipeline. And that pipeline in BigQuery is also get integrated now. So you can go end to end with data prep for your data preparation use cases. And this is generally available. Our preview customers have seen significant improvement in productivity using data prep. Now, many of you have or will be or may be moving between platforms. With Gemini, code translation, which used to be a highly manual activity, can now be activated, automated. So BigQuery migration services supports Gemini-based SQL translation through a conversational interface, and it is generally available now. You can also use it as a batch service, as well as through an API. So our partners for migration tooling can also embed it in their own tooling. Let us now talk about where we are going in the future. We are building a family of data agents which work together to assist and automate tasks across users. These agents use a chain of thought reasoning from the latest Gemini models. So your users can build trust by looking at the plans, and they can also go ahead and modify those. Because a lot of this is going to be very context-specific for your organization. The key ones are data engineering agents, which will assist a data engineer in their journey all the way from data prep to observability. Data governance agents to assist with data modeling, metadata generation, as well as anomaly detection. Data science agents, which are already available in our CoLab notebooks. So a data scientist can express their intent, and it can help with a plan all the way from data exploration to model training and deployment. And finally, a conversational agent for a business user to ask questions against BigQuery data. The agent has been available through Looker, and today we are announcing a preview for an API. So as a BigQuery customer, you can embed it for a custom agent through your application or a chatbot. Now let's look at these agents one by one. Our data engineering agent experience is embedded into the BigQuery console in a single integrated experience with data preparation. So it starts with a chatbot. So it starts with a chatbot. You start a conversation to say you want to do, let's say you want to transform a file and write it into a table. The agent will create the code for it. You can visualize it. You can look at the pipeline, edit it in data preparation. And to integrate it with your existing data engineering tools, the same capabilities will be available through command line. So you can easily use RG Cloud commands to do that. Data science agents, which I mentioned is available in CoLab already. We'll bring it to CoLab Enterprise and to BigQuery Studio. Again, a data scientist coming to a notebook can just express their intent for what they are trying to do. And the agent will create a plan from data wrangling to exploration, data cleansing, all the way to model training for multiple types of models and deployment. And foundational models like TimeSFM for time series forecasting are also available out of the box. And the third one, which is conversational agents. So for business users who today work with BI reports, we now have a Gemini-powered conversational agent. The demo you see here is the GA agent working through Looker. And as I mentioned, we are launching a preview for an API so you can create a custom agent and embed it in your own application. And we do have an agent authoring experience so you can point it to the golden data sets you want it to work on. Let us now move on to our innovations that enable you to build AI-powered analytics and applications. The first one, as you might have heard in the keynote today, is AI-query engine. So we just heard TG and Tom mention analyzing customer reviews. And this is an analysis of unstructured data that is just a starting point. So imagine if you could do such analysis across structured and unstructured data through a simple SQL interface. And that's what AI-query engine enables. You can write a single query that can answer a question that needs both semantic understanding as well as analytics. Like, what were the top complaints from my top 100 customers? Now, this is something that needs sorting. This is something that needs to call an LLM. So what AI-query engine does is it's embedding LLM calls into the BQ query plan. So you can add BigQuery scale very, very efficiently, answer these questions, and all through a simple SQL statement. So you don't have to involve multiple teams and multiple pipelines to do the same thing. And this brings BigQuery scale and performance together with Gemini intelligence into a single SQL interface. And we leave this blending of LLMs into analytics is the future of data platforms. Second, we have been integrating Spark into the BigQuery experience. It is available in preview through BQ Studio. So in CoLab, you can use end-user credentials. You can write PySpark code using serverless Spark. You can schedule that through BigQuery pipelines, which are Git integrated. And for troubleshooting, which in Spark is actually a big time sink, we now have serverless Spark web UI available on demand. You don't have to set up a separate persistent history server to do that. Along with serverless Spark, we are also making significant improvements to CoLab in BigQuery Studio. We have Gemini assistance inbuilt for SQL, Python, PySpark, and BigQuery data frames. We, you can do single short time series forecasting. You can also benchmark the models within the notebook to evaluate them. Finally, we are bringing best in class visualizations within these CoLab notebooks. And the ability for users to share their data insights with other users. Now, along with our first party CoLab notebooks, we do know a lot of you and your users like other editors. VS Code and Jupyter are two of them. So we have now built plugins for both of these editors. So you can write against BigQuery for SQL Spark or BigQuery data frames through VS Code and Jupyter through these plugins. I just mentioned BigQuery data frames. These are a scalable alternative to Pandas. So for data exploration, if you use Pandas through notebooks, you have to work with a small sample of data. With BigQuery data frames, you can, you have a Pandas-like Python structure and it simply offloads all the compute back to BigQuery SQL. So you don't actually need to work with small sample sizes. You can work at BigQuery scale through a Pandas-like interface. These are offered as open source libraries, which are available, pre-built into BigQuery Studio. And you can also use them through Jupyter and VS Code. Today we are announcing two key new capabilities. One, preview support for multi-modal data frames. So you can work with a combination of structured and unstructured data. Built on the multi-modal storage foundation of BigQuery that Vinay will just mention. And second, many of you use DBTs. DBT has added support for BigQuery data frames. As a Python model, so staying within your DBT toolkit, you can build and deploy against BigQuery data frames as well. Now let's move on to BigQuery ML, which we just heard a lot about from Mattel. It has been a SQL interface for both predictive ML as well as generative AI use cases. And we are seeing a variety of use cases like classification, embedding generation, text generation being used extensively. BigQuery ML now supports, along with Gemini, Cloud, Llama, and Hugging Face models as well. All through SQL. From the syntax you just saw earlier, all you need to say is change the model name. And you can use that. We have also added support for multi-modal data. We have added support for row-wise functions. And for structured data output from text generation. So some of the work that we just saw for having to pass the JSON is not needed anymore. And finally, using provision throughput, we have industry-leading scalability through BigQuery ML. For time series forecasting, we are also announcing a preview of a foundation model called TimesFM. So rather than the traditional model of creating a time series model and using it for forecast, you can use it for a one-shot direct time series forecast on any data set. So imagine if you have millions of products and you have hundreds of use cases where you can forecast. All it takes is a single SQL statement in BigQuery to use TimesFM at BigQuery scale. And if you have business processes that rely on these forecasts, like for merchandising, for supply chain, or anything, all that becomes much, much easier. The second key capability in BigQuery ML is a general availability of contribution analysis. Many of you at times may get pulled into fire drills because some metric like sales on a given day went down. All that gets automated because in a single SQL statement in BigQuery, you can run a contribution analysis on hundreds of dimensions. And it will come back with the top contributors for whatever metric anomaly you saw along with the weights. So this gives you an excellent starting point for any metric change that you want to triage in your data. The next feature, which is coming soon, is BigQuery data quality feature for automated anomaly detection. So if you turn it on for incoming data into a BigQuery table, it will uncover errors, outliers, and inconsistencies automatically, which then you can set rules to fix. The next feature is that of vector search in BigQuery. Vector search has been generally available and used by customers for very large scale, highly accurate product recommendations, identity due duplication, as well as batch rack pipelines. The usage has nearly doubled in the past six months. And again, the primary use case here is for the most scalable vector search at the lowest cost possible. Today we are announcing three key features. First one is general availability of a new indexing technique called scan. This was built at Google, and it has been used in multiple billion user plus products across Google. So this is what gives an unprecedented scale at the lowest possible cost for vector search in BigQuery. Second, if you have embeddings in BigQuery, which you can import or you can create using BigQuery ML, you can sync these with Vertex AI search for any online use cases. And finally, in vector search, we are adding support in preview for partition tables. So you can create and update indexes on partitions. So it becomes much cheaper, as well as the lookup is faster because you only have to get the index for a particular partition. With that, I'll hand it off to Vinay. Thank you, everyone. Thanks, Abhi. I'm Vinay Balasubramaniam. I'm also the product lead on BigQuery. So as Abhi mentioned, one of the core foundation of a data and AI platform is the ability to analyze data in real time. So I'm excited to announce that BigQuery continuous query is generally available. And what is BigQuery continuous queries? They're essentially SQL statements that you can run as the data is being ingested and analyze them at BigQuery scale. You don't have to wait for any of your batch loads to finish or create these complex streaming pipelines. With continuous queries, you can analyze the data as it's being ingested, opening up new set of use cases, such as real time dashboards, doing anomaly detection with data. Not only that, it's also integrated with our machine learning and AI system. So imagine building a fraud detection system, analyzing the data transactions as it's being ingested, looking at those queries, and then triggering down spring system to take action to detect if there are any frauds. And it's not just about analyzing. You can also export the output of the continuous queries to a BigQuery table or to a PubSub topic or a Spanner table or a bunch of partner indications we have. The next is BigQuery pipelines. It's generally available. Essentially, you have taken data form and made that whole experience inside BigQuery Studio, which means you can create these rich pipelines visually without having to write any code. You can schedule your SQL scripts, your Python notebooks, or even build data prep workflows. And this is also integrated with BigQuery monitoring and observability, so you can have a consistent experience. What we've seen over the last one year, there's a tremendous growth of customers also looking at unstructured data. But today, organizations have lots of unstructured data sitting in documents, files, images, call transcripts. How do you analyze that? Today, organizations spend up a different pipeline to analyze unstructured data. With BigQuery, we make it simple. All of the unstructured data that is sitting in GCS just become object tables inside BigQuery, which means you can now use the AI query engine that Abhishek talked about or using data frames, analyze the structured data and join that with unstructured data. Imagine asking newer questions such as, what are the customers who will turn based on the sentiments of the customer call transcripts? That is possible. And because it's a BigQuery table, all of the local level access control and column level access control that you use on standard tables are also applicable for unstructured tables or multimodal tables. Even inside BigQuery or even if you use it inside Vertex AI, the same consistent security policies are applied. Now, with BigQuery integrated governance capability, we are making it easy for organizations to discover, understand and govern both data and AI assets. A critical component of BigQuery governance is catalog. In the past, we had multiple flavors of catalog, but we are unifying all of that under BigQuery universal catalog, so that you have one catalog for all your metadata. Whether it's your business metadata, which has your business rules or policies, or your technical metadata, which has your table and schema information, or your runtime metadata, which has file level partitioning. And the same universal catalog not only applies to your structured data, but it also applies to your multimodal tables and your semi-structured. Now, once you have all your data catalog, you need to search that. So with BigQuery universal search and preview, we make the search experience inside BigQuery Studio seamless. You can use search through natural language questions or keyword-based search. And once you have the results, you can easily create, modify and delete, and enrich that metadata to create your business glossaries. Now, we found that organizations who are truly data-driven are the ones who give access to the users for the right data at the right time with the right quality in the right format. That's exactly what data products, which is an experimental, helps you. With data products, you can package all of your data, metadata, business tools, all in one thing and share it with your team in a secure manner. This fosters collaboration between your data science team, your data engineering team, your data analyst team on a single copy of data. And all of your governance policies are applicable. It also allows you to think your data in terms of assets, in terms of product as opposed to rows and columns. Now, building on the theme of data products, I'm excited to share that Google Map Places data is also available in BigQuery and Preview. Now, Google Map Places essentially have taken over 250 million businesses, the information about their location, their reviews, their ratings, and made that available as a data set inside BigQuery, which means through a data product, you can take that, join that with your proprietary customer data, organization data, and make that available as a data that you can share within your team. You can use all of the BigQuery capabilities at scale to analyze this, use the BigQuery pipeline to also automate some of these use cases. One of the key asks that you had was, how do you make sure that disaster recovery in BigQuery is seamless? I'm excited to share that BigQuery disaster recovery went GA earlier this year. And with disaster recovery, as part of Enterprise Plus Edition, all of your compute that you need for your DR zone is already included. And all you have to do is set up your secondary location, and all of the storage, all your data starts seamlessly getting replicated in near real time to the second region. And in case of any disaster happens, with the flip of a switch, all of your compute and queries automatically fail over to your DR regions. And for certain regions, we provide set SLAs. We provide SLA guarantees of RPO recovery point objective of less than 15 minutes and recovery time objective of less than 5 minutes. Now, the third key pillar of our unified data to AI platform is flexibility. Flexibility for you to build your open data lake house. Optionality to use open source to do that. So building on this theme, we announced the BigQuery tables for Apache Iceberg last year in preview. And since we announced it, we have seen tremendous adoption of this by customers, and we continue to enhance that. So with the currently BigQuery managed tables, you get full managed table experience, you get metadata management, we take care of the price performance for you, we take care of table management such as file sizing, file pruning, garbage collection, but we continue, we have added enhancements to that. So for example, we support the Metastore. So you have BigQuery Metastores for your metadata management. We have added support for secure data sharing, row level, column level access control, time travel, etc. And over the course of next few months, we are continuing to enhance that, having support for disaster recovery, high throughput DML, streaming ingestion, all of these capabilities will be available inside our BigQuery managed iceberg tables. A key part of the iceberg experience is the Metastore. With BigQuery managed Metastore, the interoperability is key. So one thing, there are two ways to do interoperability. One is making sure that all of the metadata inside BigQuery is available for external engines. So we will have support for iceberg rest API catalog support so that other engines can read BigQuery metadata. In addition to that, if you have other catalog systems in the organization, we will federate with that to understand all the tables and columns and we'll use that as well. So this two-way federation is something that is in works and will be announced shortly. The second one is BigQuery engine for Apache Airflow. This was formerly called Composer 3. And Composer 3 is a big shift in the way you create DAGs over Composer 2. It comes with seamless interoperability, observability, and management. So with one-click setup, we take care of your VPC controls and external IP management. We make it easy to manage GKE clusters and compute VMs. It is done transparently. The DAGs that you build with this Composer 3 is much more reliable with deep embedded observability that you can troubleshoot as well. I'll say the last, best for the last. So we are excited to announce the BigQuery SpendCommit. It is going GA today. With SpendCommit, we provide the flex. So last year, we announced the unification of all the engines. Now we are also unifying the commercials. So you can buy one SpendCommit and apply it across different BigQuery systems, whether you're using for BigQuery SQL engine and governance. Soon we'll have it for Spark and BigQuery and Composer as well. So you don't have to manage different contracts or SKUs. With SpendCommit, we provide you the ultimate flexibility. So that was a pretty big tour of what we have announced in BigQuery. But just not that we had over 400 capabilities that we have added to BigQuery over the last one year, and it's going to continue to enhance. So it's all based on your feedback. And we have curated a set of sessions for you which will go deeper into each of these aspects for you to go and continue your learning journey. And we are a data team, and we love data. So your feedback is our data. So please use the app to give us the feedback about the session, about BigQuery. We're happy to do that. And with that, thank you so much. Thank you for being a great customer and partner. Have a great time. Have a great time.