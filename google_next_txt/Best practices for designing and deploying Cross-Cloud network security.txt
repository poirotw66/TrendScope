 Welcome to our breakout session. I really appreciate all of you showing up here. You did not let the concert, hangovers, nothing stop you. This is true dedication. I sincerely appreciate all of you showing up here. I'm Sid Shibiraj. I'm part of the product management team here at Google Cloud. And I am joined by my fellow colleagues and customer speakers. We have Prados who will be talking about best practices and deployment patterns. We have Mahin from Schwab and Abiram from DBS Bank who will be sharing their customer experiences and journey within Google Cloud. So let me kick it off. Let's take a peek at the cloud security threat landscape. First, LLMs, right? All of you are aware of it. LLMs are being used by defenders. There are clear security use cases like helping with secure coding. There are use cases to make your security operations smoother. It's also being leveraged to discover vulnerabilities and address them faster. But, and a big but, this is also being used for, by the attackers as well, throughout the attack lifecycle. Right? We've seen our Google threat intelligence group have noticed APTs using this for recon against target organizations. We've seen it being used for discovering zero-day vulnerabilities. And also we've seen them using it to assist in developing new malware and new evasion techniques. Secondly, we have seen that there is a significant uptake in organizations that are facing substantial fines due to noncompliance. Right? You have your senior executives that are being held responsible that need to show yearly compliance, auditing, and also provide details when there are cyber attacks. This is adding a lot of pressure on them. And then there is the cost of a data breach. Every year I see this report, it keeps increasing to new heights. Last year it was close to $5 million. Right? And the reasons are kind of very similar over the years. There has been misconfigurations that's persistent. There are things like complex cloud architectures. And also you have zero-day vulnerabilities and stolen identities and such. What this really means is cloud network security and cloud security as a whole plays a vital role in securing your applications and sensitive data that reside in this infrastructure. So now let's take a look at the current state of the product offerings from CSPs. You have first a lot of operational complexity. What does this mean? Day zero operations like installing. And also day one operations like managing and scaling. All of this is taking a lot of time. And it's making you reactive versus proactive. And then there is the issue of low threat efficacy. You usually get only signature-based protections that are only for known threats. So you are having to compromise between user experience versus security efficacy. With Google Cloud, these were kind of the challenges that we had in mind as we started designing our network security portfolio over the last few years. For example, to solve the operational challenge, cloud NGFW is fully distributed. It has transparent insertion mechanisms. Makes it super easy for you to insert a network security solution into your workload. And second, you have where we brought in best-of-breed threat protection technologies like PalAlto networks. And also we have ML-based capabilities within Cloud Armor to stop the biggest of DDoS attacks. So now we are taking it one step further. A new chapter, if you will, in cross-cloud network security. Our goal here is super simple. We want to provide you security that is seamlessly integrated, centrally controlled, and enforced everywhere across your cloud footprint. Now let's quickly dive into the key areas, and I'll talk about some latest announcements in these areas. First, we have advanced threat protection, under which we are announcing DNS armor. This is a capability to detect data exfiltration attacks at the DNS layer. This is coming soon, second half of 2025. We have NGFW web filtering. This is to granularly control your outbound web traffic using domains and wildcards and such. That's also coming later this year. We have inline network DLP to protect your sensitive data in transit. And moving on to robust posture management pillar, we have the hierarchical policies that are coming now to Cloud Armor. This is already in whitelist preview. So if you are interested, please reach out, and we can get you added to the preview. NGFW tag enhancements. There are basically two pieces here. One is now it's available with hierarchical policies. And two, it is also now org scope, meaning it can apply to every workload across your entire organization. And finally, we have end-to-end MTLS security. So think about now actually enabling zero-trust principles and complementing it with all the workload security constructs that I've been talking about. And finally, we want to give customers the full flexibility and choice when it comes to network security solutions. So we want to bring an open ecosystem, a comprehensive ecosystem, where you can easily insert third-party network security services into your workload security paths. And we are doing that with service extensions, which is now already GA last year, but is also available with secure web proxy and network security integrations that went generally available earlier this month. Let's take a slightly deeper look into some of the capabilities. DNS Armor. This is our protective DNS solution within Google Cloud. This is coming with partnership with Infoblox. We are now seamlessly integrating and giving you a cloud-native experience. Why is this important, right? We've seen sophisticated actors target cloud workloads where sensitive data resides. And because DNS is so foundational, not many people are monitoring it. Not many people pay attention to it. And threat actors know this, and they're leveraging it for exfiltrating the data. So attacks like command and control, data exfiltration, using newly registered domains, domain generation algorithms, all of these are new tactics and techniques within the DNS layer that now you can detect very early because DNS is literally step one for every cyber attack. This capability will come later this year. Next, you have inline network DLP. Data, as you know, is the crown jewel, the IP for your organization. You have good visibility when it comes to data at rest, but we have heard from many customers that for data in transit that is exiting your network or flowing in your network, you have very limited visibility today, and you're also not able to meet compliance use cases for that. So that is what we are addressing with inline network DLP. This is going to be available via network enforcement points. On the ingress, you'll have load balancers. On the egress, you'll have secure web proxy. These will now give you the visibility and the control that is needed through service extensions. This will also be enabled with our first-party offering in sensitive data protection, but also with a third-party in semantic DLP. This is already, again, in whitelist preview today, so if you want to try this out, please reach out to your account teams, and we can get you added. The next part is the security posture management, right? One of the things that we've heard again and again in a dynamic cloud environment, IP addresses and subnet constructs just don't work. You need to use more cloud-native constructs and make sure that your security policies is independent of the network architecture. So what does that mean? You already are aware of the firewall tag concept. Now we are also bringing in a new construct that we call network types, which will let you write distinct policies for different traffic paths. You can write now a security policy for internet traffic path. You can write a security policy for intra-VPC or inter-VPC traffic paths as well. So it becomes extremely easy to do this in a cloud-native fashion. And now when you combine this with hierarchical security policies, with firewall insights, it gives you the full security posture, and also you can continuously assess and monitor that there is no drift. Finally, network security integrations. This, again, like I said, we want to give you the flexibility, simplicity, and the choice when it comes to third-party network services. You can see a lot of the key launch partners listed here. The main important part here is you're actually using the inbuilt functionality of firewall policy rules to now do traffic steering and traffic selection. And you're also now able to use the distributed enforcement that we already, again, have with our firewall product to also enable these third-party specialized solutions. So there is no need to re-architect your network. That's the point. So let me now pass the mic to Prados to come on stage and talk about some best practices as well as key deployment patterns. Thank you. Thanks, Seth. Yesterday I was playing with Gemini and asked it to generate an image or a cartoon for cross-cloud network security. So not bad for start my presentation with this picture. But what I want to do is to follow up on Seth's presentation by setting the stage for how all of the products and features that we just heard, and you have heard over the last few days come together and how they fit into the network. Specifically, we'll go through a few illustrations of how this deployment handles various network flows in your network. And we'll just take an example of a streamlined cross-cloud or simple cross-cloud network and walk through that and walk through all of the products and features in that context. So what I want to start with is to talk about some of the foundational building blocks that we have been working on at Google to establish that solid network security framework. Starting at the bottom right, we believe that robust network architecture is a must, is an absolute bedrock for effective security. So that's why we continue to invest in and build out NCC as that primitive. With hybrid connectivity patterns like cloud interconnect and cross-cloud interconnect as first-class resources to NCC, it lets you deploy and manage network topologies at scale. And then private service connect adds a key layer on top to build out and construct easily composable service-centric architectures, and we'll see an example of that. Moving to the next layer, when you have different network segments that are joined together and you use constructs like load balancers, you would want to make sure that you're building security into those connection points as well. So we continue to integrate our security stack into those connection points and all of our network hops. The bottom two on the left talk about our approach to the classic debate of host-based versus network-based security layering, and I'll talk about that in the next slide. And then tying all of that together is the hierarchical policy engine that you just heard about that is context-aware and that ensures a consistent enforcement across your entire organization. Okay, so let's step through this a bit. The original notion of security by imitating the physical world, which is by deploying and managing virtual network appliances, was far too simplistic for the SDN scale that we were aiming for. You would quickly find that resource provisioning is hard. IP address management is a headache. And moreover, keeping the ever-growing network in sync with security is challenging. So we took a different approach. We built the fundamental security controls right at the hypervisor into Andromeda, which is our host networking layer. That gives us ubiquity and isolation while generally making all of the security controls far more effective and relevant without needing any extra entities. At the same time, we realized that the hypervisor security is necessary but not sufficient for advanced security functions like AIML-backed intrusion prevention or malware protection. So we extended the Andromeda pipeline stage to build a unique packet interception technology, which acts as a bump-in-the-wire extension, if you will, with endpoints that does not require any routing hops, and that stays close to the workloads to execute those advanced security functions, kind of like a Goldilocks zone of security. And continuing on the same theme, with network security integrations that you also heard about, we took or we used the same packet interception technology and extended it for third-party endpoints. The beauty of this model is you can now mix and match your advanced security approach while reusing your firewall policy rules for distributed enforcement and then selective granular control to either Google's first-party offering or the third-party endpoints. So now I'd like to switch gears a bit and talk about traffic flows. So this is a simple network, but it is an example of a cross-cloud network. And the traffic flows really talk about the traffic that moves in and out of your network and as well as within it. These six flows here are quite self-explanatory, so I'll just hit the highlights. Ingress traffic, typically your incoming requests from your users to your applications. That could be an entry point for external threads. Egress security or egress traffic, referring to flows that your applications might be interacting with external APIs or downloading libraries. That could pose significant risk for data exfiltration, unauthorized access, or violation of some compliance. The next three flow types, three, four, and five, are all related to each other and constitute your distributed workload traffic, whether it is within GCP, hybrid across your on-prem or cross-cloud locations that may be coming over interconnect or cross-cloud interconnect, as well as to services. Protecting that traffic is crucial to avoid any lateral movement of malicious actors once they have entered into your network perimeter or insider threats, either accidental or malicious. And finally, user traffic that constitutes all the traffic from your employees or organization's employees, as well as extended workforce that want to access applications that they need, services they need, or access Internet applications and SaaS applications, but they would want to do this without compromising security. Now, this table gives you a visual summary of the ecosystem of all of the products that you may have heard so far. These are all Google's cloud network security products and how they map to the traffic flows that we just talked about. I'll go through and we will walk through all of these in the next few slides. So let's start with ingress security. For ingress security that is traffic coming from the Internet, Cloud Armor provides the first level of defense against DDoS, against any type of web-based attacks for your globally load-balanced applications by attaching security policies to your backend services or through adaptive protection using our machine learning models. And then you have cloud NGFW once it enters into the VPCs or potentially your third-party endpoints that you may deploy to add that extra layer of security for advanced, deeper inspection. So this is an example of a layered security approach, and this theme we will continue to see in the next few slides as well. Now let's shift our focus to egress security. Here you see the cloud NGFW as the first layer to inspect and filter all of the outgoing traffic and to make sure that only authorized data leaves your network. And then secure web proxy adds that extra layer of protection for your web traffic through URL filtering or data loss prevention, DLP, that you just heard about as well. For better or optimal compliance, safety, as well as control, the recommendation here is to centralize and route all of the egress traffic through an Internet VPC enclosure that houses those proxies. Moving on now to talk about workload security, and I've combined the use cases three and four, the flow types three and four, because regardless of where your source and destinations reside in the distributed connection map, the security approach here is a straightforward application of NGFW and potentially the third-party endpoints to, one, implement the right segmentation strategy, and two, to augment that with your advanced L7 functions in the NGFW, like your intrusion protection or malware protection. The fifth traffic flow here is about services. So service security leverages PSC everywhere, and that's our canonical model of doing services and service security. inside of a service landing VPC enclosure that has a couple of things, all the PSC endpoints and a proxy ILB. Making that VPC a first-class resource within NCC ensures that all of the PSC endpoints get exchanged for global reachability, and proxy ILB provides traffic management, traffic steering, end-to-end mutual TLS, as well as identity-based authentication and authorization. And then, integrations with Cloud Armor and Cloud NGFW gives that extra layer of protection for your services, no matter where they're accessed from. And finally, let's talk about workforce security. As we said earlier, this is all about your employees and extended workforce securely accessing private applications as well as internet and SaaS apps. Modern SSC stacks are really great at this because they consolidate a whole bunch of security tools like ASPE, ZTNA, access control, threat protection, and so on. So what we are really focusing here is to make that connection between workforce connectivity, that is how the workforce comes in, and the SSC security layer, making that connection as seamless as possible. And that's where NCC Gateway that you see in this picture comes in. It bridges that gap between workforce connectivity, securely steering the traffic, all staying privately, to the SSC layer before forwarding it to the ultimate destination where that may be. So now this is bringing all of that together, and you will see that it's building out that slide. That really encapsulates the key deployment scenarios that we talked about and hopefully gives you a view into the comprehensive security approach that we are recommending. So TLDR, NCC, and NCC Gateway for underlying connectivity, reachability, as well as traffic steering, PSC to build out your services, and a combination of Cloud Armor, Cloud NGFW, SWIP, as well as the network security integrations to really build that, you know, layered defense in-depth architecture. But with that, I would like to invite Mahin from Charles Schwab on stage to talk about Schwab's network security evolution. Thank you. Thank you. Hi, everyone. Good morning. My name is Mahin Erasi. I am Cloud Engineering Lead at Charles Schwab's Cloud Services Organization. With the adoption of multi-cloud and hybrid cloud architectures, it is essential to ensure our networks remain resilient to attacks, comply with regulatory standards, and maintain seamless communication between environments. We implement security at all layers in each environment to mitigate the risk of single point of failure. We enforce zero-trust principles by isolating networks based on environments and reducing the risk of widespread network breaches. Fine-grained access controls are implemented to isolate critical workloads and prevent unauthorized access. Ensuring confidentiality, integrity, and availability of the data is essential. And we use encryption and secure communication protocols to protect data as it moves across networks. We leverage infrastructure as code to automate and streamline policy enforcement, reducing human error, and enhancing overall security. These principles form the foundation of a resilient cloud network security architecture for us. Our approach has evolved to adapt to the dynamic nature of threats. We began with a single VPC architecture, implementing VPC firewall rules and Cloud NAT, while partner interconnects provided communication between our data centers and Google Cloud. With critical workloads moving to cloud, we transitioned to segment-specific VPC architecture, which helped enforce macro segmentation, and we have adopted global external load balancers and Cloud Armor for our client-facing applications to enhance the security by supplementing our existing external WAF implementation. To meet growing bandwidth demands, we have migrated from partner interconnects to dedicated interconnects, which strengthened our segmentation, and then with this transition, we had to move our edge firewall controls closer to workloads by adopting Cloud NextGen firewalls and implementing R-level hierarchical firewall policies. To better control egress API traffic, we implemented secure web proxy, which helped with fine-grained access controls based on identity, destination, and request attributes. Cloud NextGen firewalls FQDN features enhanced domain-based traffic filtering, allowing precise control over egress traffic. Now, let's look at some of the learnings from our implementations of secure web proxy and Cloud NextGen firewalls. While the primary objective of implementing secure web proxy for us was to restrict applications' access to specific APIs and specific operations of each API, it also helped us realize capabilities like API inventory for visibility into third-party APIs as a measure of risk and also helped identify service dependencies and service architecture patterns. The two learnings from our SWEEP implementation are deploying dedicated SWEEP gateways to minimize the risk from shared infrastructure and potential policy misconfigurations. Second, defining SWEEP policy rule naming standards to provide better visibility into the source, destination, and the purpose of this, controls for audit purposes and also when triaging issues. Moving to Cloud NextGen firewalls, while the initial adoption helped us with required security posture uplift, it did introduce some operational overheads for us. We had to revisit our firewall policy enforcement strategy to simplify the management and also reduce change control bottlenecks for us. Some learnings from our Cloud NextGen firewalls include implement controls at our level hierarchical firewall policies sparingly, given the scope and impact, and also use all flavors of firewall policies as feasible and try to implement the controls at the lowest level of the hierarchy. The higher you implement the controls, it is going to have a wider impact. Lastly, have a predefined strategy for implementing controls in your firewall policies in order to avoid the need to move controls at a later point of time. While we continue our journey, observability remains a core component of our security approach. GCP Network Intelligence Center has been the primary monitoring and troubleshooting tool for us, providing real-time insights into network behavior. We are currently implementing firewall insights to help identify gaps such as shadow rules, overly permissive configurations, and stale rules, providing real-time insights into or rather actionable remediation recommendations. Also, we are extending VPC flow monitoring to VLAN attachments to provide better visibility into the communications between our data centers and GCP, ensuring better detection of anomalies and potential threats by utilizing flow analyzer. Here is a 10,000 foot view of our cloud network foundation. As you can see, cloud next gen firewalls are at the center of our implementation, facilitating controls for all traffic flows in GCP. We channel external traffic through cloud armor and cloud load balancing and use secure web proxy coupled with cloud net and cloud connection firewalls to control egress traffic. As discussed earlier, we have implemented dedicated interconnects to provide on-prem connectivity where we have dedicated pipes to separate production and non-production traffic. And to further separate traffic flows, we have deployed dedicated VLAN attachments for private Google access traffic. Now, as we advance our cloud network security framework, our key priorities include evaluating and implementing cloud ideas for enhanced threat detection in internet traffic flows, transitioning from VPC firewall rules to network firewall policies for more streamlined security posture, refining firewall policy management to allow same segment traffic between GCP and our data centers to avoid the need of frequent updates to the controls, transitioning from explicit proxy to transparent proxy for SWIP to eliminate workload configuration dependencies and simplify deployment, and automating SWIP policy management to seamlessly integrate with our on-prem service registry, enabling better policy enforcement and streamlined governance, adopting address groups and secure tracks to simplify firewall policy enforcement, making security rules more manageable and scalable. Lastly, implementing hierarchical cloud armor policies to establish an effective WAF framework with centralized and customizable controls that provide better visibility into application security. As we continue to evolve our cloud network security strategy, we see Google as a vital partner in fortifying our defenses. Thank you. Now we'll hand it over to Abiram to talk about DBS Bank's cloud network security transition. Hello, everyone. Good morning. I'm Abiram Subramanian. I lead the solution architecture and engineering team for driving cloud adoption within DBS Bank. Let me quickly set the stage by introducing DBS. DBS is a leading financial services group based in Asia, headquartered in Singapore and proudly be the largest bank in Southeast Asia with a growing presence in the region. As you can see, we are operating in a significant scale which is driven by a talented 41,000 future-ready employees. Our commitment to stability and excellence has been consistently recognized globally. We have been recognized as the world's best bank and the safest bank in Asia multiple times. The core part of DBS's identity is our mission to be a transformative digital-first bank which is embedded in our culture and strategy. As a part of our digital transformation, we run multiple workloads in cloud for our compute and storage requirements and to drive innovation for our customers. As the workloads grow in the cloud platform, it was critical for us to establish a clear security objective before we design our network architecture. So we needed a strategy that can scale securely and efficiently. Our approach was based on three fundamental objectives. First, external access control to define a perimeter control for distributed and hybrid environments. environments. We wanted a sophisticated control for not-sob traffic that's entering and leaving our cloud environments, which meant we needed to implement fine-grained ingress and egress policies based on context while blocking malicious traffic at edge. Secondly, effective micro-segmentation. We wanted to control the traffic within our network, which is essentially the east-west flow between our applications and VPCs. Our goal was to have a granular traffic control with least privilege, access privilege, and it was important for us to have security and agility at scale, which required automated policy enforcement for consistency in our dynamic cloud environment. Third, was to achieve operational efficacy. So, we aimed for a central configuration and deployment of security policies within our network estate, right? So, which, furthermore, required visibility on control on traffic for our operation teams such as NetOps, SecOps, and DevOps teams. So, with those objectives, we came up with these implementation options by leveraging the native Google capabilities. So, this slide highlights three key Google Cloud security services which formed central to our solution. First, it's hierarchical firewall. We use these to define the baseline security rules on the whole of Google Cloud organization or to a specific folder. It provided us an important central enforcement point for compliance and it also enabled us to have a simplified security posture which was easier for tracking the audits because now we can demonstrate consistent baseline protection. Second, for controlling the traffic between our network, we use Cloud NextGen firewall. It provided a powerful feature to enable least privileged access control between the workload VPCs using the firewall tags. It also provided us with a layer 7 inspection. Now we can create rules based on FQDNs and it integrates with Google's threat intelligence which automatically blocks traffic coming in from malicious known sources. Also, the ability to deploy these globally or with a regional scope provided us in valuable architectural flexibility. Third, for traffic that's outbound to internet, we looked at Secure Web Proxy which enabled us enforcing the policies to limit the egress web traffic where we can create rules based on approved FQDNs. This was critical for us because we wanted to prevent data exfiltration and this blocked the malicious traffic to potentially harmful sites. Secure Web Proxy can also identify your traffic source based on service accounts, IP addresses and tags. Now, let's put together all of these components into our deployment. As you can see in the diagram, for the hybrid connectivity from our on-premise data center to Google Cloud, we use cloud-dedicated interconnect. We use the dedicated VPCs for different workloads or application groups and the central services VPC for the common services. The VPCs are connected to each other using network connectivity center with a mesh topology. So we apply the hierarchical firewall rules on the folder level for compliance rules. So in mesh topology, you can achieve the address group or the application group isolation using network types. This is something Sid mentioned earlier about where you can have VPC level segregation. communication. We use the cloud next-gen firewall, which is associated with the workload VPCs. So here we can implement fine-grained rules based on secure tags, ensuring the workload isolation. So for example, the services from workload one VPC can only communicate with the specific services in workload two VPC. So this provided us a very important restriction for the lateral movement between the VPCs. You can migrate your existing VPC firewall rules to cloud next-gen firewall rules by using Google Cloud's migration tool. For traffic going out to internet, we mandate that the traffic has to flow through a dedicated egress VPC, and this is where we deploy our secure web proxy and cloud next-gen firewall where we can control the layer 7 traffic. To wrap up, here are the three key takeaways from our journey. Embrace automation. In dynamic cloud environments, manual security management just doesn't scale, and it introduces risk. So leverage features like security policies for threat prevention, irreversible address groups, and firewall tags for policy definition. Automation ensures consistency, reduces risk, and allows your security to keep pace with development. The second is prioritize observability. You can't secure what you can't see. So it's critical to have a clear visibility onto your network traffic and how your policies are performing. So fully utilize Google Cloud's logging capabilities and have a deeper understanding of how the firewall insights works to optimize the rules. And use tools like Network Intelligence Center to understand your connectivity paths. The third is integrate for compliance. Ensure your entire network security posture feeds into your compliance So integrating firewall logs and findings into security command center provides your unified visibility for misconfiguration or threats in your environment. You can use tools like Network and Flow Analyzer to help to validate your segmentation and compliance requirements. Next, I hand over to Sid for a quick demo on this. Thank you. Thanks, Mahan, and thanks, Abiram, for sharing your journey with Google Cloud. Let me quickly wrap this up with a demo. So let me paint the scenario first. I want to show a situation where you might want to combine a first-party security offering with a third-party security offering and use them seamlessly together and also connect them to your SecOps tooling that could be first-party like Security Command Center Chronicle or it could be your own SecOps tooling as well. So first, we have two VPCs, a consumer VPC and a producer VPC. In the consumer VPC, you will see that there is a client as well as a web server, and the client can talk to the web server as well as Internet. So you can see that the client now has a tag associated with it that we can use as part of the firewall rules to achieve this connectivity. Now, let's take a look at the firewall policies. You have two firewall policies that is of importance, firewall rules. One is the intra-VPC rule that allows connectivity between your client and the web server. For this, we are using the first-party NGFW solution and the associated security profile group to do threat inspection. Second, you have an Internet-based firewall rule. Again, both of these, remember, are using network types, so context, cloud-based context for the firewall ruling. For this Internet-based connectivity, you are using the third-party network security solution. In our case, it's actually an open-source Suricata engine in IPS mode. You can see that now with the Proceed to L7 action, you can have two purposes, one for the first-party and one for the third-party and apply the corresponding security profile groups for them. Now, next, I think we'll go into and take a look at the endpoints and the configuration for them. So let's take a look at first the first-party endpoint. These are zonal endpoints, so you'll see that it's active, deployed, and it is now connected to US Central 1A. This is the NGFW enterprise endpoint. Similarly, you can also see a third-party consumer endpoint group that is now connected to a deployment group as well. And all of this, again, remember, is down to a single workload. So moving to threats, initially we have not sent any sample attacks, so there will be no threat logs. We are using log4j as an example here. So we took a look at the first-party dashboard as well as the Sarikata dashboard. There are no threat alerts generated. We'll create a filter for log4j. Once we send the attacks, we should be able to see them. Now let's go ahead. First, check connectivity for the east-west traffic. You're doing a basic curl to your web server. It's connected. It's working. Now when we send sample attacks on the same path, you're going to see that it's going to get blocked. Next, you're going to do internet connectivity check. Let's do a curl to, let's say, google.com. You'll see that this is going to work because the connectivity is allowed. You'll see a 200 okay. And then now when we send sample attacks on the same path, that is going to get blocked as well. So awesome. Now let's go to the threat dashboard for both the products. When you do a filter, you're now going to see the threat alerts that are generated for Log4j. You can see the source and the destination information. You can see the timestamp. You can see the threat alert information. Everything that is needed for you to do threat investigation and response. You can also see that this is based on Geneve, the tunnel that was created to the third-party Suricata IPS engine. Similarly, on the NGFW Enterprise dashboard, you will see an alert as well for Log4j. You will see the CV information, the criticality, timestamp, everything that is needed for doing the incident response. Now we're moving to the connection to the SecOps tooling. So in this case, we're using Security Command Center. So you'll see the threat logs that were generated by these security solutions now have been sent to Security Command Center for further investigation and response. You can create a security case. You can look at IOCs that were generated as part of this threat alert. You can go take a look at is this a true positive or a false positive, the risk associated with that, and so on. But the key point that I want to highlight here is actually what's coming up next in the playbooks. You can now associate a playbook as part of this threat alert. For example, we are going to generate a firewall tag called quarantine and associate that with the compromised endpoint. So you will now be able to go to the compromised endpoint and see that there is a net new tag that is created pretty soon. So we are now here at the compromised endpoint. Initially, we had one tag to allow connectivity. Now we have two tags, one for quarantining as well. So when we now even try basic connectivity from this compromised endpoint to the web server, this also gets blocked. There you go. So this concludes the demo. It really showcases how we are able to seamlessly integrate the first-party and the third-party solutions without any networkry architecture. Thank you. I want to wrap this up as well. Special thanks to our customer speakers for sharing their time and their experiences with us. Really appreciate you all showing up here. And I know there were concerts. There was a lot of drinking yesterday. But you all are seriously dedicated. So I appreciate you showing up here. Thank you for your participation. Thank you.