 Everyone is discussing at the moment is the boom of artificial intelligence, but really for us to be able to do artificial intelligence and drive value from it, we need to focus on the data foundations and that's where partnering with Google comes into the forefront to help us support that journey. So BigQuery for us is positioned as the unified data platform. That's where all of our different data sets live. It really presents us with a platform where data scientists, data analysts, data engineers can go in and create a seamless data journey and unite BigQuery with Zlucca and Vertex AI to really drive insight in the hands of business stakeholders and provide them with real-time analytics and self-serving analytics as well. We define an open lake house platform as a platform which is built using loosely coupled, easy deployable components that interact through the open standards and interfaces. Google Cloud offers great flexibility and scalability. We can seamlessly run any kind of open source solutions and it works just well without needing things underneath. We can connect different components, different processing engines, depending on the workload type. If we need to have large data processing or run machine learning tasks, then we can run Spark on data proc. Pretty amazing nowadays. There is no need to do the heavy maintenance work of hardware and infrastructure. We decided to work with Google because of their ability to see the future and their forward thinking technology. It's been key for us to be able to understand that we could get our real-time analytics. If you think about 6400 restaurants, real-time sales analytics, that's a lot of data passing through there. And we have no problem doing that with BigQuery. We're doing all of our data analytics through Looker. All of our visualization of our data. So dashboarding as well as self-services is being done through Looker today. Previously, it was three days before we would see our sales data. Now we can understand what's happening with the customer in real time. Please welcome Google Cloud Managing Director for Data and Analytics, Yasmin Ahmad. Welcome. Thank you for being here. And how amazing were the main stage keynote. Having been at the center of Google's AI and data innovations for the better part of three years, even I am dazzled by the big leaps we have taken this year. I'm Yasmin Ahmad, and I have the pleasure of working with our talented engineering teams who are building the future of data and analytics at Google Cloud. And it's amazing to be here with you all. Last year, we spoke about a new era. The drawn of truly intelligent data. We envisioned a world where data and AI work together seamlessly, autonomously to drive real-time business outcomes. Well, that future is here, and it's even more transformative than we imagined. The best part of my job is working with customers, getting feedback, and learning alongside you all as we build a better, bigger future using data and AI. And if I think back over the past year across all of the industries that we have had the honor of serving, some fascinating commonalities emerge. First, intelligence is everywhere. There's an explosion of AI use cases now over multimodal data. Second, agents stole the show in 2024, and now agents and agentic platforms are unlocking complex productivity and workflows. And real-time? Well, it's the X factor of AI. It's putting advanced intelligence and agents to work. Over the past 12 months, many of our customers have adapted to these emerging trends. So let's celebrate just what a few of our amazing customers have achieved. Radisson Hotel Group personalized their advertising at scale, training Gemini models on BigQuery data. Teams saw productivity rise 50%, while revenue from AI-powered campaigns grew more than 20%. Gordon Food Service migrated to BigQuery, ensuring their data was AI-ready, allowing them to achieve near limitless scale, and increasing the adoption of their customer-facing apps by more than 96%. JB Hunt switched to BigQuery from their fragmented legacy systems, including Databricks, to transform their shipping and logistics experience. These successes and many others are built on Google's data and AI cloud platform. BigQuery, Looker, and Vertex AI continue to be the foundation for groundbreaking innovation. Customers are the best source of inspiration. So today, I would like to invite a phenomenal customer to the stage to share their experience with Google Cloud's data and AI. So please join me in welcoming Rich Rubenstein, VP of data and analytics, and Jason Stalloch, VP Digital Core at General Mills. Thank you, Yasmin. Good afternoon, everyone. Rich and I are happy to be here today to talk about General Mills' journey to Google Cloud and how it's fueling our data and AI initiatives. About five years ago, General Mills realized we needed a strong foundation for our future data and analytics needs. At the time, we were stretching our on-premise environments to their limits. This made data-driven decision-making more difficult, and scaling our operations, let alone connecting them to analytics and AI, was a major challenge. As we looked at options to address our evolving needs, we were struck by the synergies between our goals and the capability roadmap Google shared with us. After deep evaluation, we decided that Google Cloud was the right path forward for us, and we began an aggressive journey to migrate to the platform. Google Cloud provided us with a scalable and secure cloud environment, easily observable and constantly improving. This wasn't a simple lift and shift. It was a major transformation, migrating all of our on-premise data assets to the cloud. We focused this effort on areas where data could drive the most value for the business. We implemented highly-governed, standardized processes, which acted as a forcing function for us to clean our data as we moved it. Most importantly, we up-skilled our internal teams to effectively utilize the cloud environment. The result was a platform built for speed and future growth. Data and systems are only valuable if they drive measurable business impact, making or saving money. Our migration to Google Cloud wasn't just a technical exercise. It was specifically focused on driving business results. With our scale data foundation, we quickly received material data and analytics wins. Our MillsWorks Agile pods now leverage enterprise sales, supply chain, consumer, and finance data for reporting analytics and AI models. Our use of a modern tech stack has dramatically increased our delivery speed and our delivery scale. And given our business leaders the data they need to make better and more data-driven decisions at multiple levels of the organization. But we didn't stop with just data and reporting and analytics. The power of Google Cloud tools, particularly BigQuery, Looker, and Vertex AI, accelerated our progress further. We partnered with Google Cloud early to develop, deploy, and maintain AI ML models at scale. This has resulted in millions of models running monthly, driving over $100 million in cost savings and incremental sales across revenue management, supply chain, and other areas. The speed and security of the Google ecosystem also allowed us to rapidly adopt generative AI. We built and deployed MillsChat, our internal generative AI system, leveraging Google LLMs and other technologies. Launched over a year ago, MillsChat provides our employees secure access to LLMs and image generation powered by Gemini. Our strong AI governance and secure architecture have been key to our rapid and responsible adoption of these powerful technologies. Looking ahead, our focus now is on expanding generative AI capabilities into answering questions based on structured and unstructured data, building agentic workflows, and scaling AI even more broadly across general Mills, leveraging Vertex and other emerging tools. This means moving from AI that predicts and recommends to AI that acts, and automating workflows and processes we couldn't in the past. It's an ambitious goal, but the foundation we built on Google Cloud, BigQuery, Looker, and Vertex AI gives us the speed and agility to make it a reality. Thank you. Thank you. Thank you. Thank you, Rich and Jason. Seeing a consumer food powerhouse like General Mills leveraging Google technology so successfully is both exciting and gratifying. And it's not only General Mills. The momentum is undeniable, and the results speak for themselves. We launched nearly 400 new capabilities last year alone. Multimodal AI analysis is up 16-fold, and customers are streaming hundreds of petabytes into BigQuery every month. This kind of momentum is why BigQuery today has five times more customers than the other two enterprise data platforms in the market. And together, BigQuery and Vertex AI are eight to 16-fold more cost efficient compared to any other data warehouse or AI platform in the market. So why do many organizations still struggle to capitalize on their data? Well, achieving true synergy between data and AI requires more than just bolting capabilities together. We've observed three critical challenges that stand in your way. First is the data and AI silo. Many of you are trying to embrace Gen AI, and that's great. But you're grappling with a new kind of silo. Data platforms with bolted on AI connected by fragile, inefficient integrations. This fragmentation leads to data duplication, unnecessary data movement, complex security, and soaring cost. Beyond the silo, there's the critical complexity challenge. You're trapped. Current approaches to data are simply too limiting. Manual processes and linear data pipelines just don't adapt or scale. They overwhelm data teams. And finally, tying all of this together is the need for speed or the real-time imperative. The pressure is on. You need to operate in a real-time world, making decisions and taking action now. But traditional data platforms built for a slower world just can't keep up. Delayed insights aren't just inconvenient. They're costly because data has an expiration date. Think about these timelines. 12 months. Forget about it. Remember business cards? Well, a study found that over 70% of business cards have outdated information after just one year. Not very helpful if you're reaching out. Even three months can be stale. A report showed that customer phone numbers decay at about 18%. That means in just one quarter, your customer data is wrong. The value of a few minutes? Huge. In the fast-paced world of finance and trading algorithms, they grab opportunities that disappear in seconds or at most a few minutes. So, information that's even a few minutes old can be the difference between profit or loss. But real-time? Well, that's the gold standard. A major retailer found that if their website was just 0.1 seconds lower, they lost 1% in sales. That's how crucial it is to capture and use data as soon as it's generated. Basically, from a year down to milliseconds, the fresher your data, the more power it has. These insight challenges aren't just data or technical problems. They're business problems. They're holding you back from executing on big ideas, delighting your customers, and scaling your business with speed. You've likely experienced all or some of these challenges. But what if things were different? Imagine what could be possible if complexity was removed. It would require a platform where data and AI work together seamlessly, intelligently, and autonomously to activate your data in real time. Well, that's now possible. You can access and achieve a level of simplification and activation that wasn't even on your radar two to three years ago. Today, we're announcing the evolution of BigQuery to the autonomous data to AI platform. It's the gentic, accelerating data work. It's intelligent, leveraging real-world knowledge from AI. It's real-time, processing data instantly. And it's autonomous, activating data and insights automatically. Just amazing. With BigQuery, we now have a continuous feedback loop. Your data fuels powerful AI models. Those models, in turn, unlock deeper insights. Those insights are automated into intelligent actions, in turn creating new data to be analyzed. The relationship between data and AI and this flywheel of activation is the key. To enable business users and analysts, we have also redefined the BI landscape. Gone are the days of traditional BI and thousands of static reports and dashboards that are stale and unchanging. With Looker, we're taking BI into the AI era, evolving Looker to be a unified, trusted and conversational platform. Blending self-service with real-time and governed semantics and new conversational analytics capabilities. Meet the future of BI as you see the evolution of Looker. As we deliver innovation, there are three core areas we've focused on across our platforms to help you work with data and AI. First, we're introducing specialized agents, putting the transformative power of AI into the hands of every user. Second, powering these agents, we have developed advanced interoperable engines. Think of these as the powerhouse behind under the hood. A suite of cutting-edge engines that offer innovative new ways to analyze data with unmatched performance, scalability and flexibility. Third, underpinning everything is the autonomous data foundation. We're automating the entire data lifecycle from ingestion to insight generation and freeing your teams to focus on innovation. Let's go deeper. Let's see how these mechanics work and the groundbreaking innovations that are bringing them to life. So, first, we'll take a look at how we're putting the power of AI into everyone's hands. We believe AI shouldn't be a black box accessible only to the experts. It should be a tool that empowers everyone from data engineers to business leaders. That's the vision behind our specialized agents. AI assistants that are tailored to the unique needs of each user. Let's start with data engineers, the foundation of it all. They often spend up to 80% of their time on data preparation. Cleaning, transforming, validating. Well, we're flipping that script. Introducing our new data engineering agent capabilities embedded within big creators. And powered by Gemini. Imagine pipelines that practically build themselves. Our agent capabilities automate the tedious tasks around data preparation and standardization. They're able to proactively detect anomalies to ensure data quality and even automate governance with metadata generation. This isn't just about saving time. It's about elevating the data engineer's role from data wrangler to data strategist. Next, for data scientists, we are enabling a next-gen notebook experience. Including an embedded data science agent to deliver advanced analytics in real time. We're supercharging our BigQuery notebook experience with AI. We're introducing intelligent cells where you can use SQL, Python, Spark. And these cells understand your data's context and provide smart suggestions as you write code. We're adding native exploratory analysis and visualization capabilities. And we're making it easy to collaborate, comment, and even schedule your notebooks. And to share insights across the organization, we're now making it possible to build interactive data apps. Dynamic, user-friendly interfaces powered by your notebook. Think about a personalized sales forecast that you can now instantly make accessible to all of your sales team. But that's just the beginning. Our data science agent takes this intelligence even further. Our agent is designed to accelerate model development. Be it feature engineering, intelligent model selection, scalable training, or simplified inferencing. The data science agent empowers data scientists to tackle your most complex challenges with unprecedented speed and efficiency. Now, let's move to talking about how we're empowering everyone in your organization to make data insights as intuitive as a simple conversation. Last year, we introduced our conversational analytics agent. Well, this year, we've taken it to a whole new level with three major advancements. First, we're delivering unmatched reasoning power. Our agent is now powered by Gemini 2.0's advanced reasoning capabilities, allowing it to handle even the most sophisticated of questions. Want to forecast next month's revenue? Simply ask. Need to understand sales trends by segment? Just ask. To answer these questions, we've partnered with Google DeepMind to enable a new code interpreter flow, from generating code to natural language explanations and interactive visualizations. And second, we know trust is absolutely paramount. That's why we've built in trust and collaboration ground up. We now have our agent outline its thinking, including the data it's using and the definitions that it's leveraged as part of its plan. And because the plan is natural language, we can actually collaborate and improve it together with the agent. No more black boxes. You understand exactly how the agent arrived at its answer, and you can adjust its thinking. Third, we want to empower you to customize for every role in the organization. We believe you should be in control. You can now easily create custom agents tailored to specific roles and departments, with exact instructions, be it tone, specific data sets that agents should ground to, or style guidelines. For example, a marketing manager could have a marketing-specific agent to analyze campaign performance. And these custom agents can now be deployed anywhere, in your custom applications, chat interfaces, or dedicated workspaces. Our new conversational analytics API opens up a whole world of possibilities for developers. Developers can now create engaging and accessible data interactions for all of your business users, wherever they work. You've seen how these specialized agents empower individual users. But here's the thing. The real magic is the shared intelligence. Just think about the sheer scale of data in a modern organization. Thousands of users, millions of tables, billions of queries, and a mountain of metadata. How can an AI agent or an AI assistive capability possibly know what data is relevant to a specific task? Well, that's where our BigQuery knowledge engine comes in. It's the brain behind AI and agents in BigQuery, providing crucial context that they need to be effective. The knowledge engine continuously learns from your organization's data. It understands the relationships between your data. It knows the patterns in your query logs. And it knows the meaning of your business terms, thanks to our LookML technology. All of this allows our knowledge engine to provide just-in-time recommendations and context to each agent, boosting accuracy and relevance by up to 50%. This is AI that understands your business. By developing AI that deeply understands your business context, we are directly addressing and solving for trust. Now, to help me show these innovations in action, I would now like to welcome Peter Bayliss to the stage. Thanks so much, Yasmin. Today, we'll show you how Gemini is fundamentally transforming how teams work with data. Let's use an illustrative example, Global Pets Superstore, a major retailer with both a large physical footprint and a growing online store. Before Gemini, Global Pets had massive amounts of data, but using it effectively felt a bit like herding cats. Insights were hard to wrangle. And then came data agents. This is Global Pets data agent, powered by Gemini, BigQuery, and Looker. And before we get going, I want to be really clear. What you're seeing is not prerecorded. This is entirely live code from the UI down to the API calls that we're making, powered by our new conversational analytics API. So let's imagine I'm in supply chain operation at Global Pets. I'd like to get a quick pulse check on purchasing trends. Normally, this involves requests, waiting for analysts, delaying decisions. Not anymore. I can simply ask my data agent, compare monthly sales online versus offline for the past year. I'm running my query. I'm running my query. The online sales have been higher than offline sales for each month in the past year. Amazing. Literally seconds. No waiting. Just answers. But analysis rarely stops at one question, and we always want to dig deeper. We see that online sales are doing better, so I can follow up and ask Gemini. And with Gemini's multimodal streaming API, I can literally ask Gemini. What were the top 10 products driving that spike online? Defining the data, writing a query, pretty complicated query. The top products driving the spike online include AquaClear 50 Gallon Aquarium, Flea Fighter Plus for both dogs and cats, and several tail wager, canine cuisine, NutriBytes, and Prime Paws food products. All right. The AquaClear 50 Gallon Aquarium had the highest sales at $11,285,080. All right. Thanks, Gemini. Lots of fish, lots of pet food. So, I can go even deeper with this multi-turn analysis. And I know one of my boss's goals in supply chain is to improve our delivery time, and I'd like to get a geographic view for them. So, I can ask again. Create a map visual of average lead times by state for these products. One more time, Gemini. Create a map visual of average lead time by state for these products. Second time's the charm, just like with a normal analyst. So, this is a little more complicated, right? I got a visual. I need to figure out what average lead time is. I'm using these products from above. And it's actually thinking through what's the best way to answer this question. It's generating my query. Getting my results by state. Building that visualization. Here's a map showing the average delivery time by supplier state. The average delivery time ranges from 4.82 days in Virginia to 5.37 days in Connecticut. All right. Amazing. There it is. Clear map of lead time state by state for our products. I can take this to my boss. I can drill in further. This agent is handling my questions dynamically, drilling in, pivoting, visualizing. You can literally see the bidirectional streaming running in real time against the conversational analytics API. And this isn't just faster reporting. This is a fundamental shift in how we can interact with data for everyone. And again, this is real. Leaders like Paramount and Google Health are already building and deploying their own data agents. And the conversational analytics API makes this possible, letting you build these kinds of agents literally today. So we've seen what data agents can do. And now I want to look inside of BigQuery to see how AI and data work together and drill into these data agents in action. First, we know that great gen AI requires great data and clean structured data is the fuel. Our expanded collaboration with ServiceNow now offers seamless access to critical business data. When this data lands in BigQuery, regardless of the source, it's rarely clean. This kind of purchase history data needs some cleanup. It's representing dates as strings, probably something many of you have seen many times in your career. And it's all in different formats. BigQuery AI recognizes this and proactively suggests transformations for me so I can standardize the data with, you know, a single click. In this case, I've got my purchase date now as a date, cleaned up, ready to go. More suggestions that I can go and apply. Look at this parse time expression. This is not something I necessarily want to write myself. I can preview it or YOLO. One click, apply, get my data transformations all set. And customers like Virgin Media report up to 85% reduction in data engineering time using these exact AI capabilities. This is transformational in terms of making it easier to get more data and more data pipelines into our system so we can apply AI. With this data clean and ready, we can put it to work in Data Canvas, which is our collaborative workspace. I've gone ahead and added the relevant tables, orders, order items, and products. And I want to show how the agent handles a really complex open-ended request and see it thinking in real time. So I'm going to ask the agent to show us sales trends, performance by product category, and top five sellers. My agent's looking at the data it's got, and it's building a plan. So writing a query for monthly sales trend, doing a join across my tables, writing some SQL, running the query for me, getting my answer back, and creating a visualization. Got my monthly sales trend here. Writing another query, moving over to top five sellers, writing that query, running the query, getting a visualization back. Even doing, you know, advanced analysis on my behalf. Now, with this advanced analysis, it's actually quite amazing. In this case, I'm actually using Gemini's code interpreter in order to go and essentially do data science on my behalf, decomposing the time series based on seasonality, and actually showing me, using something that a data science would have to do otherwise, essentially what's going on with my data. Giving me a series of findings, well, one, series of plots around my, here, I'll make this bigger here. Series of plots showing how my different categories are performing. Giving the summary from my, just like a data scientist would. This is amazing. I didn't even ask it to do the data science, but it recognized that data science will be useful to go and answer this part of my question. And here it's literally writing Python code on my behalf without having to go and give it any more information. It just infers this is useful. And this type of integrated, automated analysis is what customers like Walmart are already leveraging in their core workflows. Now, I can go and expand upon the analysis that the agent is giving me. For example, for our top selling products, I know my boss really likes seeing graphs that go up and to the right. So I can work with Gemini to make this look a little better. Sort this chart from low sales to high sales. Voila. Boss will be happy now. Now, if you remember, my brand colors are green, so I can also color this dark green. This is the kind of interactive data analysis and exploration that makes Canvas and BigQuery so special. I have my agent building my draft, and I can go and iterate, generate more insights, run more analyses. That is amazing and is why data canvas and Gemini are such a powerful combination. But before we wrap, I want to call out this type of advanced analysis is not just something for data experts. We're bringing to the rest of the organization as well. And I can do this by enabling Code Interpreter and my data agent. I'll spare you some typing. What I'm going to ask Gemini to do is to segment my customer base. So look at historical patterns, historical purchasing behavior, and essentially build a model so I can go figure out where are my big spenders, where are the customers I want to go and activate more, and tailor my supply chain and my marketing operations based on that behavior. In this case, Gemini is writing a query to first pull in the data. This is already kind of fancy. It's a three-way join filtering based on Nevada. We're in Vegas after all. It's pulling in my data. What it's doing now is it's actually running this code interpreter on my behalf. I'm not writing any Python. This is running behind the scenes just like a data science would run. And it's telling what it's doing along the way. Lots of code if I want to go and read that, but no time for that. It's gone and clustered my customers into three distinct groups. And lo and behold, here is my segmentation of my customers based on their history, all from natural language, explained in natural language, within my data agent. I can take this output, go send it to my marketing team, go get happier customers and happier pets. This is the power of Gemini and Google Cloud data and analytics, fundamentally transforming how we're working with data, making data more powerful, more intuitive, and ultimately more accessible to the entire organization. Back to you, Yasmin. Thank you, Peter. What an exciting demo. You heard and saw our intelligent agents in action. So, let's now go under the hood and explore the advanced interoperable engines that power our agents and make all of this possible. This is one platform with many powerful engines. So, let's start with understanding your data better. We all ask questions about our data. But traditionally, the answers we get back are limited to exactly what we're doing. We've structured, stored, and organized. But now, Gen.E.I. is changing the game. Models like Gemini are trained on massive amounts of information, giving them a broad understanding of the world. Concepts, context, connections that your specific business data likely doesn't contain. So, the real magic happens when you combine this real-world knowledge with your business data. Suddenly, you can ask questions that were impossible to answer before. So, BigQuery is making this combination now easy with the introduction of our new AI query engine. We're taking a huge step forward by enabling this co-processing. Traditional SQL co-processing alongside AI. Think of questions like which products are manufactured in emerging economies. The AI knows exactly which countries fit that description. See the difference? We're not just retrieving data. We're using AI's understanding to get to deeper insights. And it doesn't stop there. This new AI query engine also makes it super simple to handle complex questions over messy, unstructured data. Imagine having call center recordings where you ask, in which calls do customers mention our competitor by name? The AI engine processes the voice, adds real-world context about competitors, and is able to answer that question. The BigQuery AI query engine is a groundbreaking capability, allowing you to mobilize real-world knowledge, linguistic understanding, and the reasoning capabilities of Gemini. This ability to understand context and connect the dots across all of your data naturally leads to another powerful capability. Finding similar items within your data sets. We're now bringing the power of Google search for multimodal business data to your data platform. Introducing BigQuery Vector Search. It's more than a simple search. It's built on Google's cutting-edge scan technology. BigQuery Vector Search unlocks a powerful new capability. Not just finding what's exact and identical, but finding what's similar in your massive data sets. For example, finding similar images, recommending related products, or identifying relevant documents. It's all done with SQL or Python right in BigQuery. No data duplication, no specialized database, and it scales to billions of records. Okay. So, let's shift gears now from search to speed. In today's fast-moving pace, you need insights instantly to act on opportunities and threats that arise in the moment. That's why we've now built powerful real-time capabilities directly within BigQuery. BigQuery Continuous Queries is an engine for not only ingesting data in real-time, but also processing it, analyzing it with machine learning or AI, and making decisions and triggering actions all within seconds of the data arriving. Imagine the possibilities. A new customer transaction triggers a real-time fraud detection model. Or a user's browsing behavior instantly drives a personalized recommendation. We're making real-time insights and automated, intelligent action accessible to everyone directly within BigQuery, so you can move from reacting to the past to shaping the future. And finally, given your data strategy is unique, we believe in giving you choice and flexibility, not constraints. So, the autonomous data to AI platform is now built on open standards, integrating seamlessly with the tools that you already use and trust. That's why we're now bringing your favorite processing engines directly within BigQuery. For example, you can run Apache Spark over your data in BigQuery. This means running Spark where your data lives, not having to move that data. We also handle all of the Spark infrastructure serverlessly, and you benefit from the almost three-fold performance improvements that we've made over the past year. And with Google Cloud for Apache Kafka, your data is now always up to date. We are delivering more than flexibility. We're future-proofing your data platform and empowering you to use the best tools for the job without being locked in. With the AI query engine for smarts, vector search for matching, continuous queries for speed, Spark engine for scale, and the Kafka engine for fresh data, we now have a unified real-time platform. But these aren't isolated engines. They are designed to work together seamlessly. And the key to this interoperability, it's our architecture and platform design. A shared catalog and governance layer ensures that all of these engines can access the same data, understand the same metadata, and operate under the same security principles. It's one data platform with many powerful engines. Okay. So, now, powerful engines and intelligent agents all need a foundation that thinks for itself. That's the autonomous data foundation. We're automating the entire data lifecycle. You can now focus on innovation and not data infrastructure. This foundation is secure, reliable, efficient, and above all, autonomous. First, we're eliminating data silos and making unstructured data a first-class citizen. The autonomous data to AI platform brings together all of your data, regardless of the type or format. With BigQuery multimodal tables, you can now store and query unstructured data, images, audio, voice, and text, alongside your structured data, all within the same table. In fact, running AI or machine learning inferencing over multiple pieces of unstructured and structured data is now simple. And for those of you working with open data lake formats, we also have you covered. You no longer need to choose between open formats and enterprise-grade. BigQuery delivers the best in-market support for Apache Iceberg, a fully managed and open format solution, giving you effortless table management, high-performance streaming, AI-powered insights, and near-infinite serverless scale. All of this without the operational overhead. By deeply integrating Iceberg with Google's data and AI stack, we let you build open lake houses with the enterprise features you need, with fine-grained governance, with top-tier security. It's the openness you want with the enterprise power you need without compromise. Speaking of governance, it shouldn't be an afterthought. It should be built in and intelligent. And that's what we're delivering. BigQuery now offers unified governance that is intelligent, pervasive, and invisible across all of your data and extending to BI and AI models. What you have is a platform that is able to discover and catalog data, generate metadata and business glossaries. It detects patterns, now uncovers lineage, and uncovers anomalies. Beyond compliance, we're enabling trust. We're empowering users to access and use data confidently, knowing it's accurate, secure, and compliant. And the platform itself, it's constantly optimizing, learning, and adapting. It automatically scales resources and manages workloads, ensuring cost effectiveness. All behind the scenes. And we're giving you even more control today with advanced workload management. This capability in BigQuery allows you to align resources with your business priorities. And finally, as we bring together more and more capabilities within our unified platform, we're now making it easy to consume and use the platform with unified commercials. Our new BigQuery spend commit brings unified spend across the BigQuery platform, providing you flexibility to move spend across data processing engines like SQL or Spark, streaming, governance, and more. This autonomous foundation is what makes everything else possible. It's what allows the specialized agents and advanced engines to operate seamlessly. We're making data and AI work for you. There isn't a customer scale we haven't been able to deliver on. And with AI now embedded at every layer, this fully integrated architecture accelerates AI adoption, empowers enterprises to move from data to AI-driven insights faster than ever before. Wow. That was a lot of innovation. So much has been said about the future of data and AI, when in reality, all of those big leaps and possibilities are unfolding today. At Google Cloud, our vision is clear. You need an agentic power in real time. So, we're building a platform that anticipates needs, automates actions, and acts proactively on your behalf. Intelligence must be activated instantly. We're helping you bridge the gap and transform data into tangible real-world outcomes. And we're amplifying human expertise, empowering your teams and helping them to amplify their expertise and intuition to achieve even more. I feel so fortunate to be with you at the center of one of the most important technology transformations of our careers. And now, please join our data and AI breakout sessions and learn more about the latest innovations and meet our data teams on the show floor. We can't wait to hear where you will take your data platform next, exploring these new capabilities, experimenting with AI-driven data solutions, and building the future of your business with Google Cloud. Enjoy the rest of Next. Enjoy the rest of Next. Enjoy the rest of Next.