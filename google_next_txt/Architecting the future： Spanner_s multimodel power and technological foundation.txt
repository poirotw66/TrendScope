 I hope you are having a great awesome first day at Next, exploring all the new exciting capabilities of Google Cloud. In this session, we're going to introduce the Spanner's multi-model capabilities and how you can transcend your future application in the Gen.AI era. My name is Wenzi Khao. I'm a group product manager for Spanner. We are very excited to have with us today two of our distinguished Spanner customers, Farhan Thawur, Vice President and Head of Engineering at Shopify, the powerful e-commerce platform that behind many online shopping experiences. Also with us today, Praveen Sinha, the distinguished engineer from Palo Alto Networks, the leading enterprise cybersecurity solution provider. Also joining me today from Google, Chris Taylor, Google Fellow and one of the founding engineers for Spanner. Spanner. Nearly 20 years at Google, Chris has been absolutely instrumental to Spanner and the broader Google databases portfolio. It is truly my privilege to share the stage with them. Over the next 45 minutes, I will give you an overview of Spanner's evolution from a scale-out database to multi-model platform. And Farhan will take you on Shopify's journey to Spanner from Shard and MySQL and Redis and tell you how they achieve a highly scalable, resilient and globally distributed applications that touches more than 800 million online shoppers. Chris will give you a deep dive of the power of combining all the multi-model capabilities together, such as full-text search, graph, vector search and closer integration with analytics. So you can fully unleash the potential of your data while simplifying your architecture and operation. Following that, you will hear a real-world example from Palo Alto Network on how they successfully harvest multi-model capabilities in their POC to achieve high-performance cybersecurity solution with a simple, elegant architecture. And we will leave time for Q&A in the end. So, let's dive in. At Google, AI is deeply embedded in all the data products we build. Google's AI-ready data cloud offers you an intelligent, unified and open platform with a comprehensive database services and analytic services. The seamless integration from infrastructure all the way to API frees you from the complexity of integration and accelerate your organization's business digital transformation. So, you can really be the innovator, not an integrator. Spanner is really a... Sorry. Spanner is a critical building block in the overall data cloud vision. And the very same intelligence, unification and openness also permeates in Spanner's continued development. Spanner is Google's always highly scalable and globally consistent database. It sits in a unique juncture in the Google cloud databases portfolio where relational databases meets NoSQL. Today, Spanner already offers you a relational data model with Postgres interface and the key value data model with Cassandra API. Moreover, Spanner also features a fully interoperable graph, full-text search, vector search, all built on the SQL semantics, which we'll discuss further in this talk. Today, Spanner is already widely adopted across different industries in different applications. Here are only some examples. Spanner uses Spanner's use cases. Spanner uses Spanner's use cases. Spanner uses Spanner's use cases. Number one, customer uses Spanner for their highly available needs for their mission-critical workloads. For example, payment platform, order processing, and player interaction. Any seconds of downtime means bad user experiences, data loss, and can generate very big business impact. Number two, customer needs transactional consistency whether that happens locally or across the globe. Again, financial transaction, inventory management, billing or insurance processing. Every dollar, every update, every second, that must be counted for, no matter where it happens or where the data sits. Last but not least, customer also looking for scale. To be more accurate, scale insurance. Your application can start small, but it can grow really rapidly. Spanner is building on this horizontally scale-out architecture that's extremely good at handling spec-y traffic with almost no scaling limitation. So that means like you can gracefully handle all the ups and downs in your application. Black Friday, Cyber Monday, Flash sale, launch events, or even like seasonalities. Spanner can manage all of this for you. So you do not have to worry about database crashes, rewrite your applications. Well, something good is going on. With the advent of AI technology, the application development also evolves. And your customer demands more from your application. They want it to be more intelligent and more personalized. For example, your customer may expect your search engine to understand them better. No matter how they type in the search request, they want the results or your recommendation to be highly relevant to meet their preference. Also, they probably expect your service chat bot to not be able to provide you the right information, but also help them to act on those information. Think about agentic AI. As models and tools become more and more accessible, the only differentiation is really about the knowledge, and that is your data. So a database is no longer just about storing, organizing, and acquiring your data. It is also about reason, analyze, and contextualize your data. In addition to the existing relational and key value data model, you need to be able to search for the right information with the help of a text search database. Not only via keyword, but also semantically. So you need a vector database. You want to reason about knowledge. Not only the data itself, but also the interconnection between data. So you need a graph database. You also want to connect your data to the insights that you draw from your analytics. So that means you want a better integration with your data warehouse. How many databases do you need to fulfill your AI initiatives? What if I'm telling you that I'm actually not describing many databases here? Because you can achieve all of this just in Spanner. From the get-go, in Spanner, we already recognize the power is not about each individual capabilities, but really about combining them all together. So, for example, hybrid search, right? You can put a full-text search and a vector search together to improve the search quality by, you know, increase the relevance results or using, you know, AI or ML-assisted ranking. Another example is you can actually use full-text search and graph together. That will significantly improve efficiency for you to uncover the deep insight in the intricate connection of your data. So the interoperable multi-model of Spanner can really open many possibilities for you while still let you maintain a simple operation and also optimizing your total cost of ownership. What's the best part of all this? Is that this is all building on this already highly scalable, available, and enterprise-grade database. So you do not have to worry about scalability, availability, inconsistency that those purpose-built database often have. Just to illustrate on the scale, today, Spanner process over 6 billion QPS at peak and have over 17 exabytes of data under management. And those numbers are just growing. This highly scalable and available database continues to be the backbone of Google's multi-billion user applications, including Google Cloud's control plane. Also, Spanner, you know, today also powers many of the leading enterprise, Cockroach industry. On that note, I would like to welcome Farhan. And he will share with you how Shopify using Spanner to build the core applications that enables hundreds of millions of merchants across the globe. Thanks, Wenzi. And welcome, everyone. So I want to talk a little bit about our journey in reimagining our persistent store at Shopify. And first, I want to give a little bit of a snapshot for those who don't know Shopify, because we're typically the brand behind the brand. We like to say if you have bought something online and it was a good experience, it likely was Shopify. We are a global company. We are in 175 countries where we serve merchants. We are at almost over a trillion dollars of GMB process to date. We have almost a billion users and buyers across all of our surfaces last year purchasing all over the world. And the amazing thing about Shopify is we are just trying to make entrepreneurship more common. The ability for folks to just have a dream, they can start a shop, and they can start selling right away. And as we think about the scale of Shopify, we need to be highly available, resilient, and available for buyers all over the world. And as well, merchants who may or may not be in the same locale as those buyers. And so we started thinking about how we should build our next generation database infrastructure. So we currently have, we believe, the second largest MySQL fleet in the world. And one interesting thing is that Spanner was actually developed as a way to actually progress past MySQL and Vitesse. And actually that's how Google invented Spanner because they weren't able to scale as much as they wanted to on that infrastructure. So Shopify today uses MySQL in what we call a sharded capability. It means that shops are, all of our shops are sharded by a database. It really means that everything that we do today, a one shop has to just hit one database. And it's very easy for us to scale because typically you have millions and millions of shops. And as they grow, we can grow with them. But as we think about the future, we want to make sure that we can do things where we have a buyer in France but a merchant in the USA. Or a buyer in Australia and a merchant in Asia. We want to make sure that all of these use cases are easy for us to develop without having to take the database and move it all over the world. So we do have current challenges where we want to make sure that we can think about the next generation. And we started thinking about Spanner. Now the cool thing is that Shopify in 2018 moved all of our infrastructure off-premises, we used to have our own data centers, into Google Cloud. So today we're 99% Google Cloud, which allows us again to take an advantage of all the offerings of Google Cloud, including Spanner. We started thinking about how we do this bake-off between where we want to move to. And you can see some of the benefits on the page there, where we know that it's very easy to scale. Spanner is already available for you to do testing on. It has a global namespace for carts. And I'll talk about some of the things that we're doing there. And, of course, it has a globally consistent nature. So we wanted to quickly figure out how we could test this. So the first thing, sessions. So at Shopify, once a buyer hits a storefront, we create a session. And we want to make sure that it's a very, very fast and easy replicable use case for folks, whether it's on desktop or mobile. Right now, our session infrastructure is actually stored in Redis, which, as folks who maybe know Redis, is not the most reliable or performant for this use case. Storefronts is really separated in Shopify. It's a read-only use case. So if you're a buyer, you can basically be able to see browse products, see inventory, be able to search, all of those things, without actually doing any sort of persistence. This means that we need to be able to be very, very quick to have that responsiveness that buyers expect. Right? They want to wait for information about products or wait for imagery. Right now, that shift is moving to Spanner. As you can see from the page, we're looking at many, many aspects of Spanner to make this experience great for users. Very, very fast, globally distributed. And don't forget the merchant side. Merchants might come in, update a product, include a new product, update product imagery. And that has to quickly scale across the fleet so that buyers have a consistent and great and up-to-date experience. Imagine a spelling mistake on a product page. We want that to be updating and not for users to see an old version of the page. We also have a very, very high throughput. You can imagine whether it's Black Friday, Cyber Monday, or even just a flash sale from an influencer. That traffic can scale up very, very quickly. And we needed something to be able to scale up with us. And so, again, we wanted to move that session infrastructure to something that would support that. The other interesting thing is that people do use Shopify and its sessions as sort of a way to start an experience and end it later. Meaning you might open a page today. You might not go to the checkout or add something to cart until tomorrow. You might open it on desktop and then continue on mobile. All of those things need to be supported by one piece of infrastructure. Over time, we believe that the session infrastructure itself will be almost two petabytes of data, which will be loaded all into Spanner. So, right now, we're actually in the prototype stage. But this is very, very quick for us to get going. Going through the stack of a Shopify buyer, once you actually click on add to cart, you are now moving to something that is much more persistent. And this is where we started thinking about how we move our carts infrastructure to Spanner as well. We also use other parts of Google Cloud, like GCLB, which is Google Cloud Load Balancer, to enable us to think about how do we get into Google's fiber as quickly as possible. Again, a user expects a consistent experience. So, what that means is, once you add to cart, whether it's on your phone or desktop or today or tomorrow, you expect that cart to still be available later. A lot of folks, like me, use the cart as a wish list, meaning I add something to the cart and then weeks later maybe I might actually check out. Or, in my case too, I might add something to cart and then wait for my wife to add her items to the cart before I check out. In which case, you want this session infrastructure and cart infrastructure to be persistent. So, again, I'm not going to a store and all of a sudden it's empty because I'm feeling like I've lost my experience, I've lost my personalization. There's going to be about 200 terabytes of cart infrastructure in Spanner when all of this is migrated. We currently are testing this today and, again, we want to make sure that this is a great experience for our buyers. The other thing that happens is, and Wendy mentioned this, is something called flash sales. Flash sales is when an influencer, a music artist, or a YouTube influencer might go online and say, I'm dropping a new product at 11 o'clock on a Thursday. What happens then is we get an immense amount of traffic during that time slot. The infrastructure has to ramp up, the persistent store has to ramp up in order to handle that. In our case with Spanner, we don't have to do anything. We literally just let that happen on its own and Spanner handles the increase in traffic. We also have to make sure that things can transition between regions. So, imagine a region becomes hot. Let's say there's an influencer in Singapore and all of a sudden where all the buyers are coming from Singapore and hitting our database infrastructure. Spanner allows that to happen seamlessly by having global replication and that data can easily be migrated to the region closest to the buyer without us having to think about anything. There's lots going on here. And, again, we were able to do this use case very, very quickly with Spanner because that Spanner architecture already exists and for us to spin up this use case quite quickly. And by quickly, in a Shopify sense, we tend to do things in weeks, not days. And so, very, very easy to get going. Another use case is around taxonomy and, again, AI. Taxonomy is the ability for merchants to upload products into our catalog and for us to automatically tag them with, like, the color, its crimson, or its address, and then to save toil for our merchants. We're in this interesting position where Shopify, we do not try to keep, you know, in many consumer products, you try to keep people in your product. We like to get merchants out of our product as quickly as possible. Our goal is for merchants to build the best products and to talk to their customers and not to be dealing with the toil of our admin interface. Instead, they should be, like, saying, hey, I've got new products, upload it, and we should be able to use AI to automatically categorize the products, including the imagery and the text, to make a compelling vision for the buyers. We have all of our products now moving into Spanner for us to do these AI workloads. So we can import all our products. We can automatically categorize them. When a new product comes along, we can easily tag it for the merchants so that they can get out of the admin and, again, focus on building great products. This also allows us to have multi-shop search. So for those of you who have ever used our shop app, which allows you to search across our storefronts and, of course, do package tracking, all of this now in the background is powered by Spanner because you can quickly search across the entire infrastructure. As you can see here and as Wenji mentioned, there are search capabilities in Spanner. But for us, right now, because our infrastructure is on Elasticsearch, we just integrate with Elastic. So that allows us, again, to use parts of our infra with Spanner. We don't have to move everything at once to the infrastructure, although in some cases it might be easier. You can see at the bottom there, we are using Spanner's change streams, though, to keep our infrastructure up to date. So, again, it's very important for us because our merchants are in the admin all the time updating new products, new imagery, changing descriptions. We want that to flow across the infra very, very quickly. And, again, Spanner allows us to do that without us having to do anything. And, again, lastly, on some stats, we're at about 2.1 billion products across Shopify. All of that is now inside of Spanner to allow us to do these operations very, very quickly. So, quick summary. One of the things that we've been focusing on is trying to get these things very close to buyers as quickly as possible. We like to build things in a way that allows us to take from an idea to a slice across the infrastructure in weeks. Because Spanner is already live and available, this is very easy for us to do. We've got our point of sale, our point of sale, our proof of concepts up very, very quickly in weeks. We have live traffic going to these from buyers and merchants within months. So, again, it doesn't take a long time to get these going. Very easy to do a bake-off. So, for example, as we start evaluating our next-generation persistence store, it's very easy to get Spanner and other database infrastructure without having to do a lot of work. Because, again, it's already live. All of these use cases are already seeing real traffic, which allows us to then see the latency and see the performance characteristics. And, again, the last thing for us is we want to simplify our infrastructure. So, in order for us to focus on performance, resiliency, reliability, we focus on one thing, which is simplicity. If we can use more of Google Cloud, in this case Spanner, it allows us to simplify our infrastructure so we don't have to think about it anymore. Next up, I'm going to call up Chris to talk about hybrid search and multi-model. Thank you. Thank you. Thank you, Farhan. And just to show you how fast Shopify is moving, Farhan and I had lunch together in October. And they had nothing on Spanner. Now they have three major use cases, more to come. It's really awesome to see the pace. So, a few months ago, I was talking to a colleague from YouTube about some of the things they're doing with Spanner and some of the opportunities we have to improve. And he said something that really stuck with me. He said, when we moved to Spanner, we stopped ever having to think about database scaling and database reliability. Before Spanner, we used to think about those all the time. Learning that kind of confidence is job number one for us. Great to hear a similar sentiment from Farhan and Shopify. The essential job of the database is to extract big problems from the application, solve them properly, and package the solutions so that they're easy for anyone to use. Spanner has done that for reliability and scaling. And today, I want to talk about a different big problem, which is search. And how Spanner is harnessing powerful search technology in an easy-to-use package. So, what do I mean by search? Modern applications have a lot of data and want to ask increasingly complex questions of it. And Gen.ai has only thrown fuel on the fire with remarkable opportunities in every industry to transform how we work and how users interact with our products. The key to these opportunities is ensuring that powerful models and agentic frameworks receive the right proprietary data at the right time. And that's a search problem. So, let's break it down a little further. There are lots of ways to think about search. SQL, if you squint at the filters a little bit, is search. Obviously, full-text search is the classic search and still has a lot to offer. More recently, vectors and semantic search are a new paradigm that improves quality by searching for concepts and ideas, rather than being completely focused on words and phrases. It's less likely than full-text search to find you precisely what you asked for, but much more likely to find important nearby ideas, like leather sandals or hiking boots. And finally, there's graph, which has a sort of intuitive appeal. Edges in a graph can model real-world relationships. Following some of those edges as part of a query can lead you to important insights that might be missed by other algorithms. In this case, a graph can tell you that people who bought natural brown shoes often also buy leather conditioner. So, four search technologies, all useful in their own way. What to pick? What is the best way to do search? I've been at Google 20 years. I've seen a lot of search. And the conclusion really writes itself. These are not competing search technologies. They are complementary. For Google's own search engine, we've been investing deeply in all of these areas for many, many years, and used them all together to power our first-party search and AI experiences. So, if you really want to maximize insights from data, empower an LLM to give you the highest quality results, you'll want to use two, three, or all four together at runtime. Now, appealing as that conclusion is, think about what it takes to turn that into a real solution. The standard ways to do this require deploying two, three, or even four different databases, probably from different vendors. Weaving them together is a tough job. In addition to an application, you find yourself writing most of a query planner, particularly if, as is common, you're trying to offer your application's users a rich and very customizable data exploration experience. Now, in Spanner, we have been hard at work on this big problem, and we have an approach we're excited about. Over the last year, we've leaned on Google's deep research background to embed vector, full-text, and graph capabilities in Spanner alongside our longtime SQL engine. So, let's take a peek at each of them. Let's start with full-text search. We've combined ML query understanding capabilities from Google search with a native, fully transactional text index, and made it available directly from SQL. When you write to Spanner, your text index is automatically kept completely up to date, and both writes and reads deliver the same five nines availability and extreme durability as the rest of Spanner. Of course, as we discussed, semantic search with vectors is a powerful way to find relevant results that full-text search systems miss. So, we've also added first-class distributed vector search to Spanner, based on Google's scan technology. Like full-text search, Spanner vector search is fully transactional, SQL integrated, and delivers the same availability and durability as the rest of Spanner. But, you can see on this slide, the power of having both these search modes together. Trivially, we can use vector distance as a higher quality ranking function than traditional ranking approaches like TF-IDF. And, in many search contexts, like product search, vectors' ability to find broad conceptual matches complements full-text's ability to find a needle in a haystack, say a specific model number, or a similarly highly selective phrase. Finally, earlier this year, we brought Spanner graph to GA. Graph's ability to model the interconnectedness of data allows searches to easily discover relevant context that doesn't precisely match the search terms. As you'd expect, Spanner graph provides the expressiveness and power of graph, combined with the scalability, durability, and availability of Spanner. Graph, like full-text search and vector, is designed to seamlessly blend into the rest of your query. On the slide, you can see a single-shot query that is able to not only find the product the customer is looking for, but also recommend other products, which may not be hiking boots, purchased by other similar customers. Graph brings me to the last impressive capability I want to highlight in Spanner. It's very common for search and graph use cases to combine online and analytical requirements. For example, discovering fraud patterns can be highly analytical, but operationalizing the pattern into real-time detection requires high throughput, high availability, and low latency. More generally, many search use cases combine an offline component to experiment with new data and new ways to combine it, and an online component that uses those insights to deliver low latency and high-quality results to live users. Today, we announced BigQuery graph, designed from the beginning to fit hand in glove with Spanner graph. Combined with BigQuery's existing support for SQL text and vector search, as well as Vertex AI, you have excellent options for both online and analytical workloads. And over the last year or so, we've been working to make data journeys seamless between them. Spanner and BigQuery share the same SQL dialect, Google SQL, which means that in many cases, queries can be moved seamlessly from one to the other. We've also been working to make the same data more easily accessible to both engines to empower the types of hybrid analytical and online use cases that are common in search. With external data set, your Spanner tables can automatically appear in BigQuery for ad hoc analytics with near-complete performance isolation, with no moving parts to maintain, and almost no setup. We also have reverse ETL and BigQuery continuous queries, which allow you to transparently mirror BigQuery data into Spanner for low latency serving. So let's briefly recap. We saw that search at its best is inherently multi-model, with SQL, full text, vector, and graph search complementing each other to find the most relevant information. We saw how Spanner allows you to bring these four modalities together into a single query and use them seamlessly together. And we saw how with Spanner and BigQuery together, you can build search-oriented products that include both analytical and operational components. On that note, I'd like to welcome to the stage Praveen Sinha from Palo Alto Networks. Praveen is joining us to talk about Cortex Cloud, an impressive new security offering that is building its next generation using BigQuery, Spanner Search, and Spanner Graph. Welcome, Praveen. Hi, good afternoon, and thanks, Chris. Thanks for the kind of things you are building that can power the use cases that we have been seeking out for a long time, I should say. So what I'm going to cover today is our journey towards finding the solution for our use cases. These use cases are pertaining to the cloud security domain per se. The problems that we are talking about is I need to have data fast enough, I need to be able to have fast searches on top, and I need to keep it fresh, as fresh as possible from the source of truth. Let's get along and see how it happens. First of all, a generic overview. What is, what am I representing? I'm representing Cortex Cloud from Palo Alto Networks. It's the next generation of our CNA platform called Prisma Cloud, built on top of Cortex, which is essentially bringing out the CDR, cloud detection and response, to a single platform. What a single platform means is a single unified data across the real-time events that are happening, the posture that I have understood by my scans on the cloud deployment, and on top of it, the ever-changing event that's there. With BigQuery, we get a rich, big unified data platform to power the end-to-end use cases. What end-to-end means here, whenever you have a risk or an incident, a security risk or security incident, the eventual goal that you want to achieve to reach at is how do I resolve it? How do I remediate it? And how soon can I do it? There are many ways to do it, but with this whole contextualized data plane, you get the path it takes from your code to deployment to runtime, and in your SOC, you can see what is the incident can be tracked down to, and where can I fix it. Okay, with that overview, a bit into the use cases, we have taken three use cases, three difficult use cases, to do POCs and to answer the needs using Spanner here. So, first one is search and investigate. We have a booth downstairs, so you can go and have a look at the product, but just a small overview here. This is how the cloud inventory looks like. In the cloud inventory, it gives you the image of your estate, a cloud estate, your VMs, your network, your permissions, everything, right? Along with that real estate, you also get to see aggregates and the ticker, I should say, of how good or how bad they are in terms of security posture. Problem statement here, fast searches across multiple dimensions, across multiple aggregates, and the need for immediate consistent reads on an N-way joint data set, meaning you have cloud state, you have scan findings, you have the vulnerability reports on top, and you have the existing issues on top, right? And these are all fast changing. Every second it might change. You have an automation setup across all of your CI, CD. Every second or every CI, CD deploy has a new picture altogether. Okay? Second use case. The posture, security posture. So, security posture is a real-time map of assets and the results of the scan. So, this gives you a view which is actually an aggregate on top of various dimensions. How good are you at this point of time? How much coverage do you have? Out of that coverage, how much is risky? What should you attempt to solve right now? What is your top five things before you can say, I'm done for a day, right? So, those kind of use cases, again, the technical aspect of it is real-time aggregates across multiple dimensions and consistent read views on top of N-way joints and aggregations. Something similar, technically, to the first one. The last one that we want to cover, this is the attack path scanner. So, none of your security risks should be treated in their silos. Okay? So, when I talk about, let's say, I have a VM and the VM has an overexposure, has a network exposure, by itself, it does sound like it's a bad thing to have. But if that VM is connected to a database which has your customer-sensitive data, it's really bad. So, this is what we call about attack path. You have an egress, you have an ingress, you have an exposure, and it is connected to sensitive data. This makes the problem really, really high. Okay? So, what, again, what do we need here? We need, as Chris was talking about, a graph DB here, which can be used to search across relationships, transitive relationships, with degrees that is spelled by the relationships itself. And the example I said, EC2 exposed, with sensitive data connected to it. Okay? Now, just to dumb down a bit, or to maybe take it to the technical level from the functional level, this is a representational-only slide, but it gives you a picture on what we are dealing with. We are dealing with three or four large data sets connected and related with each other. We are talking about a 90 percentile size of our customers. We would be having around 200 million assets that they are talking about every day, live assets, as we call. Scan findings, on average, we see that each asset has up to 15 findings, security findings on them. Max assets, 500. Max findings per asset, 500 to 1,000 range. Vulnerabilities can be huge, 100,000. For example, you deployed a VM using an old 2013 Linux VM. And relationships, though it is not really high in cardinality, but it is there because we are talking about n degrees of relationship here. Okay? Just to recap, typical problems that we have. Immediate availability of search indices on the data that should be fresh. Efficient and fast joins. Real-time aggregates. Large number of attributes and search space that we are talking about when we talk about the graph searches. Node sets. With and without edge type filters. So, you can do queries like, give me all the VMs which are connected to a sensitive data. How? I don't know, but find it out. Right? So, this is a subgraph versus subgraph relationship with n degrees. This is kind of a hard problem to solve computationally in real-time, with real-time queries. Okay. So, we did our POC. We fanned out the options. And maybe this can help some of the people who are trying to solve similar problems. So, as I said, to start with, we have a unified data plane that is served by BQ efficiently. And it's solving a large number of our problems there, or our customers' problems. So, let's look at, just option one is about BQ alone. So, we are looking at real-time aggregates in a matter of less than a second. Searches backed by BQ, Big Search, of around less than five seconds. Graph, till today, we, as Chris announced, we didn't have it. But, again, we can visit this back later. Data freshness. Data freshness, because of the joins and materialization of the views on top of the joins. We are paying a view on a materialized views of around four to five minutes. This is typical for our largest customers. Okay. So, this is where our numbers are as we speak right now. Now, how do we improve it? So, let's put Spanner in for our transactional queries. So, we do see a huge improvement in search using Spanner FTS right away, around 300 milliseconds. Graph, zero to five, this capability was not there earlier, but now with Spanner Graph, we are serving graph searches as well. But, the data freshness issue is still there, four to five minutes for the BQ stuff. But, this option was with the source of truth being in BQ and data being transmitted or streamed over to Spanner using reverse ETL. That process in itself implies a delay of about 15 minutes. So, data is stale when we do Spanner-based searches on top. So, that drives me to the option number three, and obviously, the last option is the best option in any slide deck. This one is the best one, again, with that regards. This is where we fork data up front, and with this fork data, we use Spanner for the best thing that Spanner can do, and we use BQ for the best thing that BQ will do with its columnar structures, with its nested columns, rich support for arrays and all. And, finally, we have latencies, all latencies under around a second, data freshness with Spanner side of the world. It's real-time. That's like, you know, a goldmine. So, we have improved this. I just wanted to give a pictorial map, a very simplified pictorial map to say how simple the solution is in terms of the lay of the land. So, we use a lot of PubSub. We are hydrating BigQuery using PubSub. We just fork it out to Spanner, and without much changes, we have the app there getting the best of both the worlds. Okay? Conclusion. BigQuery has been good for us. It has been good to prove a good point of source of data, unified data, for serving connected or data plane-based queries. Spanner, with interleaved tables, solves a lot of our joins use cases. Spanner, full-text search, and graph helps us in faster searches and graphs. So, with that, I'll hand it over to Wincy again. Thanks, guys. Thank you very much, Pravin. It's really great to see our customers using the technology we built to achieve their technology goals. So, we hope you find today's session helpful, and we truly believe that Spanner's multimodal capabilities, building on this highly available and scalable platform, will help you to accelerate innovation and open many possibilities. If you are interested in Spanner, I just want to let you know that there are more sessions coming up in the following days. We're going to doubling down on graph tomorrow. We're going to talk more about the multimodal that we introduced today. And also, we're going to show you, you know, more how, like, Spanner integrate with BigQuery and to drive more AI-empowered applications. Unfortunately, I don't think we'll have time for Q&A at this moment. However, me and my co-presenters, we can, you know, linger here a little bit if you have questions. And feel free to come up to us. Thank you very much for your time. Thank you.