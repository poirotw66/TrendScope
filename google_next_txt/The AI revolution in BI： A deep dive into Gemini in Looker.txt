 I think, yeah, my mic works. Welcome. You know, I'm so excited to see so many of you here. Thank you for taking the time to be here today. And I hope you're excited, as much as I am, to learn and talk more about AI revolution in BI. My name is Ani Jain. I'm in the product team at Looker, and I'll be joined by two of my colleagues, Vijay Venugopal and Mark Walnick. And we also have Ansi Roussi, the CEO of Supermetrics. So thank you, Ansi, for being here today. All right. So we have a really, really cool agenda for you today. We're going to start off with giving you a brief overview of Gemini and Looker and all the capabilities that come with it. Then we'll tell you all about Looker's AI agentic architecture. The foundation that powers these Gemini features. Then we're going to have a product demo. We have to show you all these features in a demo. Then we'll have our amazing customers showcasing their AI revolution with Looker. And last but not the least, we want you to leave here, but a little bit of our roadmap, our future. What are some of the things that we're bringing and working on in our AI and BI world? So hope you're excited. All right. So we're living in a Gen AI and an AI world. Even my 10-year-old knows what AI means now. But we're exploring the impact that Gen AI has and how it's transforming the way organizations interact with data. But as AI is transforming the way businesses operate, there's a key principle to keep in mind. AI is only as powerful as the governance that ties behind it. For AI to provide real value, it needs to be fueled by high-quality business data. But just as importantly, businesses need AI to help unlock the full potential of their data. There's so much data that most organizations have. And as organizations accelerate AI adoption, one thing is clear. AI innovation will hinge on strong governance. And it's not enough to just say, hey, LLMs will do enterprise data and they'll throw some data back. These models need to be properly grounded in high-quality, well-governed data, or else they risk hallucinations, producing lots of errors. Now, here's where Looker has an advantage. Looker is backed by a decade of Google's AI research and development, along with the expertise of Google's deep mind teams. We leverage Google's advancements in infrastructure, foundation models, and safety protocols to make AI accessible and beneficial for everyone. Now, Google has been an AI-first company since 2016, pioneering many of the breakthroughs that propel these AI progress for both us and the wider industry. Now, within Looker, we're coming up with this unified BI platform that's powered by Gemini and Looker. So, at its core, this approach combines advanced analytics. It combines embedded analytics. There's data modeling and self-service capabilities. But with Gemini and Looker, users can generate insights efficiently, trigger workflows, and leverage these AI-driven recommendations. Now, foundation of this system is Looker's semantic model, which ensures consistency. It ensures accuracy, while the direct connectors also give you the seamless integration with various data sources. So, this is something that we are really, really excited about, and we're going to continue to invest in throughout the course of the year. Now, let's talk about how Gemini and Looker is designed to enhance productivity, not just for analysts, but for business users as well. Now, for analysts, what does this mean? How is Gemini and Looker helping them? So, for analysts, it means reducing the effort that it requires to prepare data and create semantic models for BI. By automating some of the routine tasks, Gemini and Looker can help analysts focus on higher work value, right? Like refining these insights, building compelling visualizations, and building these reports more efficiently. Now, if you're a business user, AI enhances data literacy. So, with natural language capabilities, users can go beyond static dashboards. They can ask questions directly, get answers, you know, keep interacting with these conversations, and ultimately, the goal is to minimize the time analysts spend on repetitive tasks and empower these business users to get more insights that historically, they were dependent on other people for. Now, there are five features that make up Gemini and Looker, and all of them are available to you. All of them. You can try it, you can test it, and we're so excited to showcase these to you. So, what I'm going to do is go through one by one, and then we're going to show you all of these in a live demo. All right. I know we've all heard about conversations. We've heard about all these agents. So, Looker conversational analytics significantly reduces the analyst backlog by just empowering them to ask questions and get their answers. So, by enabling natural language, it allows users to have a chat with their data. How cool is that? You simply ask a question and get the answers in return. So, the self-service model increases productivity, efficiency, and it reduces the reliance on technical teams that business users have historically had. So, we're super excited about it. Now, the other thing, we all know eventually, everything just comes in slides, right? Now, what we are trying to do is help you bring that information in slides using natural language. So, automatic slide generation streamlines the process of creating presentations from data reports. So, it uses AI to generate these chart summaries that explain key takeaways, helping users quickly understand the visualizations they're looking for. So, imagine you don't just get slides, right? You actually have context. What are you actually looking at? What does the data actually mean? All coming automatically from the reports. The other one is formula assistant. Now, I know oftentimes I'm running a report, I'm running a visualization, and I just think of some metric or some measure that I want to create on the fly. But oftentimes, I either don't remember the syntax or I get it wrong. So, here, we have an agent to help you. Imagine you want to create a formula or you want to just concatenate last name and first name. Use this agent. Tell the agent that this is what you're trying to do and let the agent automatically create these measures for you. Again, making it simple, making it easy. Now, LookML Assistant. We all know that the power of Looker is its semantic model. LookML, the strength of LookML, is the biggest differentiator for Looker. It standardizes business metrics, it has robust data permissions, and it has row-level and column-level security. But what we're doing with LookML Assist is adding this natural language and AI agent to make these data models or give you a starting point. So, let's say you want to create a measure or you want to create a dimension. Chat with your data, and it'll go ahead and create that for you. Again, you can modify it, you can choose to keep it, or you can choose not to keep it. But it gives you that starting point and builds that model out for you. And last, but definitely not the least, everyone wants more visualizations. Everyone wants more and more ways to tell their stories. With visualization assistant, users can, again, ask questions in plain language and receive automatically these generated visualizations, and they can customize them using natural language via Genman and Looker. So, it removes the complexity of JSON parameter searches, it democratizes data access, and makes it easier for anyone to just build compelling charts. How do we do this? What powers all of these Gemini capability? It is Looker's agentic AI architecture, and we need to know, what is it? What is the magic behind this architecture? So, to talk about that, I want Vijay to come up and share that with you. Over to you. Thank you. Good morning, everyone. Wasn't that just awesome? It's now time to peek under the hood, right? What have we built in the technology stack to power all these features? Now, firstly, the thing with AI is, does everyone trust the answers that AI is giving, right? We have all heard about hallucinations. We've all heard about how the data analysis is not going to be, it may not be accurate. So, how do you trust the answer? So, we as product builders, our whole goal is, how do you build an AI architecture that gives you high quality, high accuracy, and reliability in the answers? So, when you ask questions and get answers, you can trust what the system is doing. And the key to that is the agentic AI architecture that we have developed in Looker. So, let me break this down into a few things, and I'm going to dive into detail on each and every one of these. So, firstly, hopefully you've heard a lot about agents, and Gemini's reasoning capability through this week. What has been incredible in the last 12 months or so is the advances that LLM models, especially Gemini 2.0 and now with 2.5, the ability for agents to think through problems, break down the problems like the way a human would, and just act on it the way a human would solve problems. So, this ability to use agentic reasoning and execute the action through a set of tools is really powerful, especially when it comes to data analytics. As a very simple example, a year ago, when we first started building these capabilities out, we would use single-shot LLM calls to generate the SQL required to answer the question. But our accuracy was probably in the low 40s, low 40s to 50s. Once we started implementing these semantic model-based agentic architectures, our accuracy numbers are 90%, close to 90% accuracy, and we're continuously improving. And the agentic architecture is a huge part of how we deliver that high accuracy. The second thing is when you're building these experiences that you want end users to interact with the data, it's extremely important to provide a human-like conversational experience. And what we leverage is we use a conversational history in the agent memory. So, the agent remembers the history of the conversation. And so, when you have a conversation, it remembers the past questions that were asked. And so, it is a very natural, human-like, multi-turn conversational experience which just makes it easy to use. Now, the semantic model is extremely important to the accuracy, and I'm going to spend a few more minutes just on the topic of semantic models. But with Looker and LookML, we have the world's leading semantic model for BI, and it's a huge advantage when you're trying to do generative AI capabilities, and you see what a massive difference it makes when you use a semantic model like LookML. And the last piece I'll cover in detail as well is what are we able to do with custom agents? And the semantic model is great, but it's not enough. There's more information that you need to provide for specific use cases providing reusable context that improves the accuracy. So, we're going to show that to you in a bit, and you'll see this, you know, why having some of these reusable context helps improve the instructions that further improves the accuracy. So, each of these are techniques that we've put together just to ensure that there's high quality when you ask the question, and even more importantly, there's complete transparency in how the agent arrived at the question, how the SQL was generated, or the looker queries were generated, and give you a full explanation for how it worked. So, all of these are critical to how you're going to generate a conversational AI experience that you can trust, and you can have confidence in the quality of the answers. So, the semantic model is a topic that's worth double-clicking because it is so important to generative AI accuracy. Any of you that have tried using either ChatGPT or even Gemini to generate SQL queries against a set of tables, you would have realized that without having some form of semantic context to the data, there's a lot of hallucination in how the model generates a SQL queries. A simple example is that if you've got, you know, let's say seven tables or ten tables, and you give that as input to the model and you ask it to generate the SQL, if your answer requires one join, it gets it reasonably accurate. If it requires two joins, the accuracy comes down by 50%. If you have three joins, it's close to zero, right? Literally, you cannot run a Gen AI-powered conversational experience even if it has three joins or more in the data. Now, this is where the power of LookML comes in because what LookML does is it flattens the schema out. It presents a logically flattened schema because the entity relationships between the tables are predefined in the semantic model. So now the agent doesn't have to try, you know, doesn't have to infer what the relationship between the tables and the columns are because it is already pre-encoded in the semantic model. It's a huge advantage and we have seen a two-third improvement in accuracy by using a semantic model to generate answers versus just using the raw tables at the back. The second piece which is equally important is the fact that you've got governed metrics in the data. That's, you can define your measures, right, whether you're using ACV or profit margin or any of these critical business metrics. You can define them in the LookML and so anyone who asks the question gets the exact same answer every time. So the ability to have these highly governed metrics that everyone can count on is extremely important to the entire experience of how you ask questions of your data. And just to see this live, let's take a look at a quick example, right? So what you see over here, you know, is an example for questions and forecast growth for our highest ACV customer segments last year. And what each of these do, what we do at the back end is we translate these intent that's expressed in language and translate that to the necessary fields, the measures, the dimensions, the time period in which it is, you know, in which it is asking the question. And we translate that to the Looker query and we directly execute a Looker query on the Looker explorer on which the question is running. And then for, and first we explain how we arrived at the answer. The agent breaks down its reasoning, explains what it did, explains what are the exact query that's generated. And you can even open the answer in the Explore and you can see the filters applied, the aggregations that are applied, and the answers and you can verify with it. So this is extremely powerful in its ability to ask questions, get answers, and trust the answer that the system is giving. Let's talk a little bit more about the agentic architecture. I'm just going to mention two points on this. So the way agentic technology works is it works on something called a React loop. So the React loop is an ability for an agent to reason and to act on the reasoning. And the way this React loop works is you give it a set of tools in order to answer the question. So in the previous example, when the question saying I want to forecast say ACV by product segment for the last year, what the agent does at the back end is it breaks it down into a set of actions. First it needs to detect the schema, fetch the data for the schema, pass that data to a forecasting model to execute the question on forecasting. And we build a set of tools that execute what the user is asking for. So you have tools for schema detection, tools for generating SQL or the local queries. We have tools that do automatic visualization generation. So the charts that you see, we have a tool at the back end that generates the charts. We generate the insight or the summiting. And most importantly, we've also built a brand new code interpreter tool. I'm going to spend a little bit more time on this as well because a code interpreter has the ability to build answer questions using Python and not just SQL alone. And the advantage of using Python is that you can do more advanced analytics than what you could do in the past with just SQL and traditional BI. So what does that mean for you? Just give me a second. I need some water. Am I using my water bottle? I've had a bath throat all week. Sorry. So what does that mean to you as a user? The main thing is that traditional BI and what you could do with dashboards were typically historical questions. What happened last year? Sales last year? Look at my growth by segment for quarter over quarter. But now with doing things like advanced Python-based analysis, you can go from asking historical questions on what happened to start asking questions like how do I compare between Q2 this year versus Q2 last year? Or what caused the change? You can do things like key driver analysis where you can find out what was the dependent metric that drove a particular metric to come down. So you can do root cause analysis. You can do correlations. You can do forecasting. So these capabilities were typically the realm of advanced data science. And what you can do now with building these tools into the conversational analytics is we're now able to democratize data science and bring data science to the realm of conversational analytics. So now any user can ask questions. I want to look at, I want to do clustering or segmentation. And it'll run a Python model at the back to do K-segment analysis and be able to do clustering of the data. And it does this automatically without requiring a data scientist to run these models for you. A data scientist to run these models for you. Or if you want to do forecasting, it automatically runs a forecasting model against the data and does that without requiring expensive data science investments. Now, this is really, really powerful. And this is going to be available extremely quickly, probably in the next few weeks. And there's a link at the bottom on how you can sign up for the preview and as soon as it's available, you can try it out. We showed a demo of this yesterday at the spotlight session. Extremely powerful capability that was never available in BI tools before. And we think that this is going to make a big difference to how users are able to consume insight and make decisions out of data. Two more points I want to make very quickly before we move on to the next section is that I mentioned that how providing additional LLM instructions further improves accuracy. And again, any of you who've used any of the LLM tools, you know how prompting is important, right? You give prompts and the more prompts you give, the richer prompts you get, you get better answers from the LLM. And this is where by providing these instructions as well-defined rules that are persisted in the agent configuration helps improve the overall accuracy. So in this example, there's an example of an orders agent for EMEA. So there's an analyst that will build an agent. Typically, these are created by an expert, like an analyst, who will create a custom agent for answering questions on orders in EMEA. So you pick the data set, you give it the instructions, these are the fields that I want you to use, here are some sample questions, here are the expected answers, and you give that as part of the agent instructions. And when the agent, and you share that with the EMEA order management team. And then the EMEA order management team, when they're running the questions on these agents, they get very high accuracy answers because it's built on a semantic model. And on top of that, you're giving all these instructions on how you get high accuracy. So the end user experience for someone who may not even know the data, they can ask questions and get answers in an extremely simple manner. And all of this has been packaged into a very simple user experience in this conversational analytics product, so it just becomes like a chatbot for your data. Literally, that's go to your data, ask questions, and anyone can ask questions on data and get high accuracy answers. And it is extremely transparent every single step of what it does. It explains how it arrived, you can see the code, and you can actually open the data in Looker to see the actual answers, so you can have complete trust in the quality of the answers that the system is providing. And now, to see this all come to life, I'm going to invite Mark Walnick to stage to do a full demo of all these capabilities we talked about. Thank you, Vijay. Now that we've already heard so much about AI and BI on slides, let's use the next few minutes in order to demo this stuff live. In our demo, we will talk about the precision, democratization, and efficiency in leveraging Looker's semantic model so that we have everything along the workflow available for everyone that uses it, and, yeah, make it available to everyone. All right. So, the entire demo is like, we want to look at the lifecycle of a measure. So, we'll start off in Looker's IDE. So, this is basically our one-stop shop where every developer will essentially create the semantic layer which powers the insights, and it powers also the agentics' ability to interpret the questions right, right? So, here we are in our symbol pads. You might have seen that in other sessions already. This is already preloaded, everything, but we want to create a new measure, and for that, we will be using, like, LookML Assistant already introduced previously. So, we create a measure, and what we want to do is we want to create total sales summing up price and then format it in U.S. dollars without decimals. So, we let this fire. So, while this loads, the entire demo is live, so it'll take a little bit of time, and also, what you can see here, it's saying line 62. This is where the cursor is. This is all contextual, so it takes whatever it has available in that specific view in order to come up with the measure that we are asking for us to generate. So, what we see here, it's done it right, so we are very happy of that, giving it a thumbs up, of course. Measure is total sales, it sums it up, SQL is price, exactly what we expected it to do. We'll insert this here into our code, save the changes, and then we go into the first layer, essentially, of the workflow. So, we go into the Explorer, and right here, this is our data exploration shop, basically. We see, we have a total sales measure here right now. We can run this. This is coming from CashNow, because it's very fast, because I executed it previously, of course, as well. And it's also generating the SQL that we thought and would have liked it to generate. It sums up the price as we asked it to. It's given us exactly what we wanted. The format is right, in line with what we asked it to do. Now, let's take this one step further. We can go into Looker Studio, which also leverages our LookML connector, which is also powered by the Looker semantic model. And we're using the same Explorer that we just altered, basically. And we add this to the Studio report here. And what we will see is then that we have the ability to use exactly that same measure, give it a second, in a chart that we're going to be creating. So let's do a time series chart. And we will use total sales here again. And that will give us a nice little time series. This is, by the way, powering already the new modern chart library, which is really nice. Definitely try it out. GA already since last week, I think. And what we can do now is go one step further in the AI and BI journey using our Gemini features here on the right. We'll generate the slides with it. So we select all visualizations. This is due to the simple use case we have here right now. But going further for everyone who uses that, you will have polished reports with a lot of visuals. You get to choose which kind of visuals you want on which slides. You can have multiple visuals on one slide or one slide per visual. And what this already does, also does, and what Ani showed before as well, is it adds a summary to the chart. So everyone didn't like that tedious exercise of adding the bullet points to it. It's already done for you, so this is a pretty cool addition to the slide generation. And last but not least, in our workflow, we can go back to the explore and essentially from here onwards start a conversation, go into conversational analytics. So once this loads, we see on the right-hand side, this is also powered by Lucas-Semantic model. And we want to use our newly created measure to show me total sales monthly in 2024, visualize on a time series chart. So what's happening now is exactly what VJ explained earlier. There's some reasoning happening in the background. It's identifying the fields from the Looker model. It's determining which are the best fields to use in order to answer the question that we asked for. It generates the data, and then it also generates the chart for us, including insights. The insights that we have here are also part of the reasoning engine, and once this loads, we can also see that it gives us a little bit of these insights. These are nice bullet points to be taken away for an executive summary, for example. Yeah. With that being said, wrapping up this really, really short demo, just showcasing a few of the highlights that we have, and I would wrap this up and hand it over to Ansi Rutsi. Thank you. Thank you. Thank you. Thanks, Mark. All right. Thank you, Mark. Okay. Good afternoon, everyone. I'm Ansi Rutsi's CEO of Supermetrics, and like every good CEO, I work with a presentation coach before getting up here, and she told me two things. Don't do a live demo. It will go terribly, and please use a teleprompter because that's how the professionals do it. So don't have a teleprompter, and we're definitely going to do a live demo. So anyway, greetings from Finland, the land of Santa Claus, reindeers, and northern lights, where our Supermetrics headquarters is based. I'm incredibly excited to be here with you at Google Cloud Next. Today, I'm not here just talking about data. I'm talking about the future of marketing, a future where chaos turns into clarity powered by AI, a future where every marketer can become a data strategist. For years, marketers have been drowning in data. We've all felt it. The endless spreadsheets, the disconnected platforms, those countless dashboards, and the constant struggle to extract insights and make confident decisions that drive growth. And at Supermetrics, we're on a mission to solve that, and our partnership with Google Cloud has been transformative. Our journey began with a simple idea, make marketing data easily accessible. But it's our partnership with Google that has really supercharged that vision. From the early days of integrating with Google Sheets and Looker Studio, and today, where we're working very deeply with BigQuery and AI tools across Google Cloud. So we are building the future of marketing intelligence together. And this goes beyond just technology. It's a shared commitment to empower the marketers with high-quality data and the right tools to drive growth. And we're solving this globally already today for 15,000 customers across Europe, the Americas, and Asia. But a little bit more. What does exactly Supermetrics do? We are a composable marketing intelligence platform. We help marketers connect, manage, analyze, and activate their data. On the left, you have that messy, scattered data. In the middle, our platform, making it easy to bring that data together and organize it. And on the right, we deliver clean, AI-ready data into marketers' destination of choice. We scale with our customers all the way from single user, powering the whole marketing organization, helping marketers turn raw data into real results. A challenge we've seen again and again, and also experienced ourselves, is data overload. At Supermetrics, we have an access to a lot of data. There is product usage data, customer behavior, business performance, and of course, our very own marketing data. But having all that data didn't automatically lead into better business decisions. In fact, it often made things harder. So we decided to do a research on marketing data, and it showed that this is a universal challenge. Our research of over 6,000 businesses shows that there is a 230% increase in marketing data and 100% increase in the amount of data being pulled since 2020. But at the same time, 56% of marketers, they don't say that they don't have the time to analyze their data thoroughly. So we are drowning in data, starving for insights to make better business decisions. And we at Supermetrics, we face this same challenge internally as well. The promise of AI in marketing is huge. We can all feel it, but here is the truth. AI is only as good as the data you feed it. And after 25 years, I've been in the industry, one thing hasn't changed. Garbage in, garbage out. If your data is fragmented, incomplete, or just wrong, your AI models will give you exactly that back. That's why quality data isn't an optional nice-to-have. It is the fuel, a must-to-have, that powers everything. The shift to AI-powered marketing is happening now. Our research shows that 57% of marketing leaders are turning to AI for advanced analytics. We built our own data foundation on Google Cloud with Supermetrics on the core to bring together all data straight into BigQuery. This gives us a single source of truth, eliminates all those data silos, and scales with our data needs. And on top of that, we use Looker and Gemini to improve efficiency, unlock insights, and drive decisions. Let's first talk about reporting. Our marketing team runs performance reviews and create reports for C-level, which took a lot of time. But now, with Gemini and Looker, our team generates Google Slides instantly. They can embed live charts into our reports. They can even create quick podcast versions using Notebook.lm. And now, let me show you live how this really happens. So, let's jump to the demo. Here we go. All right. We have Gemini in here. Let's put it right away to the action. So, what used to happen in the past, I have my report, and the marketing team, as you can imagine, they take screenshots, they copy-paste that to the Google Slides, they need to write their text, but, ta-da! Now, the slides are here. So, let's have a quick look. Okay. Yes, we have our marketing leads in here, and the text, weekly development, how it goes, leads by channel, looking very good, spend budget. Yeah, everything, everything is there, looking pretty good. Maybe a little bit of polish required from that side, but, very well. And the beauty is also, once this is done, and the data changes, all our team needs to do is select the slides in here, and click update, and the slides get immediately updated with the latest data. How cool is that? So, that's reporting, made simple. Let's go back to the slides. This is truly a game changer, like reporting done in minutes instead of hours. And the best thing, now my team can focus on more productive, higher value work. But, I have a confession to make. I rarely have time to go through all these slides, Dex. Just, don't tell our marketing team. Let this be our secret in here. So, but one evening, I was biking home, and I listened to that podcast they had created, and, let's see if we're able to listen a clip from that together. Let's see how, does this really work? Maybe not. But, anyway, what I'm hearing from the podcast is that the leads have increased. Okay, that's interesting, but I don't know why. I didn't know why. And, I have questions. Where did those leads come from? And, in the past, what did I have to do? I had to book a meeting, or I had to send a message to the team, and wait. But, like many CEOs, I'm a very impatient person. I want answers instantly. So, I got home, and, that's where Looker's conversational analytics comes in. Now, anyone on our team, even me, the CEO, can simply ask a question. I get instant answers, straight from our data. No bottlenecks, no waiting on our team, just fast insights for everyone. So, let me show you live how this happens. Let's jump to the demo. Let's go. Let's go. So, here we are in Looker. I have my marketing assistant agent waiting for me, 24-7. So, and, as already mentioned, like here's, there's a lot of, like, technical things. I'll hide that one. I don't really know what it's doing in there, but I have questions. So, my MQL, so my marketing qualified leads, have increased. The first question comes to my mind is that has my spend also increased recently? So, did the marketing team just spend more money? So, that's the first question where I want to have answers. Okay. It's doing its magic. Everything that Vijay and the team spoke about, which I didn't really understand at all. But, I do understand this. Okay, there's data coming in. Okay. Okay. Very good. Oh, more data coming in. And, and showing me charts about it. Okay, I can see. Spend hasn't really increased. All right. Well, that's great. So, they haven't spent more money. But, yes, there is clearly a spike in here on the marketing qualified leads. So, this is interesting. Where did this come from? Okay, my next question. So, could you show the marketing qualified leads by channel over time? All right. Writing a query. Doing its magic. Okay. Getting things. Hmm. showing me the different channels didn't quite do what I exactly. Okay, but once again, maybe it was a poor question. I need to be more specific in here. All right. So, can you show this stacked by channel? What else could I do to help it to do a little bit better? Okay, with date on the, okay, typos. with date on the x-axis. Hopefully, that's detailed enough. Okay. Whoa. Yes. Oh, this is cool. So, what did I discover in here? So, the marketing qualified leads had increased and they had increased because of the research paper that we have done. All right, this is cool. So, we didn't spend any more money but got more leads because of this research paper. Okay, that's great. So, what I should do now is go to our marketing team and say that you did an awesome, really great job and let's create more content for our customers for this one. That was amazing. All right, let's go back to the slides. So, things happen so fast. So, let me summarize. Marketers today, they really have three big challenges. There is too much data, too much granularity and not enough time. But everything starts with a strong foundation that brings structure, trust, and accessibility to your marketing data. And now, with Gemini and Looker, as we just saw, you can achieve the next level of efficiency in your organization as well. So, we believe the future of marketing is AI-powered. We're super excited to be at the forefront of this evolution together with Google Cloud. Thank you. Thanks. That was, wasn't that just incredible? What a demo. It worked. It was fantastic. I'm going to show you a roadmap in a minute, but I have one question for Nancy before you leave. It's great to see how you're applying AI to use. What advice, what is, what companies, especially marketing companies, what makes them, the companies that are successful with AI and the ones that are struggling, what differentiates them? Yeah. I think everything starts from that strong data foundation, so you really need to get that in place. That's where everything starts from. And I think the next thing is really important is this collaboration between different teams so that the marketing team collaborates with the data team, with the tech team, so you work together. And then, there should be a little bit of bias to action, so not seeking for performance, just get that first thing doing, solve that, and it also requires the organization to embrace a little bit of curiosity and just trying out things, getting those first quick wins, building the confidence, and then off you go. Fantastic. I mean, it's so incredible to see the technology we build come to life and solve real problems, so thank you so much, Nancy, for coming here. Thank you. Excited to have you. So, I'm going to wrap up now with a sneak peek to the future of Gemini and Looker. and a couple of very exciting announcements we want to make. So, we've showed you a lot of exciting conversational AI capabilities, but what we are really excited is that we are also going to bring this to you as an API. And what that allows you to do is that you can now take these experiences to users where they are instead of having the users always come to the BI tool, right? With analytics, users always have to come to the BI tool, but what if you can use the power of AI to take conversational AI to where the users are and meet them where they are? So, you can build custom data applications of your own and embed conversational AI right into your applications. So, this capability that we just showed you is going to be available very soon in a preview. You see a link over there if you want to sign up, register your interest, and as soon as it's available, we will give access for you to try this out. Now, what kind of experiences does this enable, right? First, we're going to expand conversational analytics to doing things like chatting with your dashboard, right? You can build a dashboard and you can now start chatting with your dashboard. You saw the example of Unseen where he picked an agent, there was an agent that was picked and he asked questions of an agent, but most people start their BI journey with a dashboard, right? Why start with the dashboard and start chatting with your dashboard? That's an example of using this AI to start, you know, building these experiences in other parts of the product as well. And this example, next example, is an example of a custom data application. This has been built by the Google Health team. So what you see on the left over here is a Looker embedded dashboard and on the right side, there's a conversational panel which is being built, powered by the conversational API that I just mentioned. And so they've built a custom chat interface into their data application using the power of these APIs. So this is an example and this is just one example. There are so many examples of how you can use these APIs to go and power different experiences in, you know, in other places. We can build Google chat applications. We don't have time to show that to you. We built a Google chat app where you can chat either in chat or Slack and so literally users can chat with your data wherever they are. The other one is agent space, right? You've probably heard a lot about agent space this week. We're also building an integration into agent space. So you can take these Looker agents and create those agents. You saw the whole agent building experience and then you publish that into, you see this here, you publish that into agent space. And then a user can go into agent space and go to the agent garden in agent space. Find all your agents, either the agents that you're building yourselves or other Google agents. See them all in one place and you can chat with your data right inside of agent space. Again, this is powered by that API experience at the backend. So extremely powerful in taking these AI capabilities and meeting users where they are. And the last piece on the roadmap that I wanted to cover is further advancements that we are making in our LookerMail authoring experience. Mark just showed you how you can use the LookerMail assistant to generate a metric or generate a measure and insert that into the LookerMail. But we are taking this to the next level now with the ability to author entire LookerMail models with Gemini assistants. So you can literally take a set of tables because LookerMail is extremely powerful, but it takes training and expertise to get it right. So what if we can use the power of AI to reduce the amount of time it takes you to author high-quality LookerMail models? You can use, if you could be new to LookerMail, just getting started with little training or you could be an experienced professional, just want to reduce the amount of time it takes you to do an important job. And what if you could use AI to do that for you? Just give it a set of tables, a few instructions, maybe even an ERD diagram drawn on a PDF document and say, here's my entity relationship that I want and ask Gemini to do the magic to auto-generate the entire LookerMail model for you. So you see, this time is back to the original vision that Ani started with, which is our vision for the use of AI is that we want to apply AI across the entire BI ecosystem, starting with analysts that are preparing the data for AI or for reports and using things like LookerMail Assistant and the semantic model generator or the formula assistant just to reduce the amount of time and effort to build high-quality data to have these AI experiences. And at the same time, build these agentic capabilities that can take the power of BI to the next level with doing things like code interpreter and forecasting and anomaly detection and just do that with the power of natural language search. So that's our vision and hopefully you saw it live, you know, seeing that example from Ansi and how Supermetrics is actually doing this live in the environment, you know, gives you a sense of how you can put this to practice in your own companies. So with that, thank you very much. Thank you for being here and attending this session. We have a few more deep dive sessions. You can go into more detail. We have more details on agents and the APIs. We've got sessions on conversation analytics. Please enjoy the rest of your time here at Google Next. Thank you. Thank you.