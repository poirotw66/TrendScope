 Music Please welcome Palo Alto Network's Vice President of Google Cloud Engagement, Munish Ketrapal, and Google Cloud Principal Strategic Partnership Development Manager, Joshua Hazlitt. Music Good morning, everybody. Good morning. Bright and early in Vegas. Looks like a perfect session. How many of us have an overload of AI in this conference and before? So I thought Josh and I will mix it up a little bit, and we'll talk about poker. Is that a good idea in Vegas? So poker and AI. Josh, what do you think? Oh, Munish. Well, I've got to say, I'm not much of a poker player. I prefer blackjack. But I did find on the way to Vegas that I could use Gemini to learn how to play poker. And I actually tried a few hands at Texas Hold'em with it. And at the end of it, we were about 50-50 when it came to Gemini winning and me winning hands. But I am curious, Munish. Like, what do you see in this space from a poker perspective? Josh, you forgot to talk about last night. We were on the poker table, $1,000 that you lost. I won. Like I said, I'm not ready to put real money down. We didn't play any poker. We were back home early. We were back to the hotel early. So think about poker. It was a long journey, Josh. 1990s, people, AI, they started using AI to actually engage with poker and figure out how to solve for poker. Because it's a game of imperfect information. Unlike chess, which there's a lot of fan following on chess, you know exactly what your opponent is doing. You see everything on the table. And then you can look at statistical moves. But poker is a lot of imperfect information. There's bluffing. There's deceit. There is a whole lot of manipulation happening. And there's a journey. So a university in Canada, actually in 2007 and 2015, they were able to look at limit holding. Limit holding, for those of you who don't play poker, is you have a limited amount of betting you can do. And so you can kind of statistically manage that. And they used an economic principle which was called counterfactual regret minimization. I love using that word. Sounds so cool. It's Nash's equilibrium. They figured out how to actually beat professional players in a game that has imperfect information. And then, of course, we had the U.S. universities figure out how to solve for this even better. And they went to a no-limit holding game. And in 2019, they beat multiple professional players in poker. And why is that important to us? Because in cybersecurity, you're dealing with exactly the same set of things. You're dealing with a case of imperfect information. You don't know what your threat actor is going to be doing. Bluffing, deceit, manipulation, all of it exists. So AI has taken these cases and has solved for them. And that's really a good place to start with. What about Emma? She's the Forbes Woman of the Year? Shocking to me, right? Have you guys heard of Emma? Anyone in the audience? So Emma wound up being Forbes Woman of the Year right alongside Greta Thunberg and former First Lady Michelle Obama, which really shocked me. I also found out that not only that, she's done advertising campaigns with BMW, Porsche, IKEA, and more. But that's not all. She also has an award from the government of Japan for her work that she's done in Cambodia speaking out against domestic violence, which I thought was pretty interesting. Now, this got me to thinking, maybe I start needing to work on my digital twin. What do you think, Manish? You know, Emma is a virtual character. She doesn't exist, right? Forbes Woman of the Year, a virtual character, looking at social causes, connecting to human emotions. We think AI is not human-like. It's as human-like as you can get when you start thinking about it. And that's what happens in a phishing attack when you're looking at a cybersecurity email because they connect to your emotion. They connect to a message that you relate to. And that's how you get attacked. So AI is looking at transforming the industry. And cybersecurity is a very interesting industry because there's one industry where cybersecurity threat actors are using AI to attack people. And cybersecurity, in cybersecurity, the only way we can manage this attack is using AI. So it's quite an interesting industry to be in. So I want to switch gears. Come back to our enterprise business. We have done poker. We have done Instagram followers. We have done 400,000 followers that Emma have. What's happening in the enterprise space? It's November 30, 2022. Any of you remember that day? Roughly. End of November. ChatGPT came out. Two months, we had 100 million users. It took four years for Facebook to get to 100 million users. Seven years for Internet to get to 100 million users. For telephony, 75 years. Two months. And, of course, DeepSeek, it took us 25 days. The difference in all of these amazing speed of adoption is the fact that most enterprises, businesses, actually took to ChatGPT and the other chatbots. So it's not a consumer play. It's an enterprise play. And it's impacting the enterprises. So that's one. The second area that we are seeing a whole lot of adoption is in enterprise applications. There are about 800-plus applications that are AI-enabled in the core of what they do. And we are forecasting in the next three years it's going to be 20,000 applications. Agents. Really started mid of last year to end of last year. That's when agents came. This year we are forecasting there are going to be 7.5 million agents in the enterprise workforce. In 2030, 15 billion agents. So every individual worker, if you take 3 billion people working, you're going to have five agents working for you. That your enterprise workforce is going to change dramatically. It has a massive impact to how you think about IT architectures, how enterprise design for ensuring that they can bring in AI. Because I think the conversation of the fact whether they want to use AI or not is over. The question is how quickly you can adopt AI. Josh, any other view from a Google point of view? Well, sure. I mean, I think everyone's probably seen about Agent Space since you've been here at the conference. And we announced Agent Space in just December of last year. And the key idea here is we want to provide enterprises with the ability to find enterprise data, reason on it, and then act on that data. And we've tried to make this as secure and as accessible as possible by giving you more than 100 applications in your enterprise environment that are already pre-connected. So easy for you to quickly drive productivity in your environment. So, Manish, you're right. I think agents are on the rise and certainly making it accessible to the masses. So the impact to enterprise architects, everything we have lived for in the last 45 years, at least, the professional life that we are aware of. There might be much before that. Mainframes. I'm not the mainframe era person, so I'm younger that way. Client server architecture. You're looking at web 1.0, 1.2.0, internet-enabled architectures. Then you start looking at virtualization, cloud computing. They fundamentally follow a very simple model. You have an endpoint. You have a desktop. You have a user interface. You can control that user interface. That user interface talks to a database, to an application, talks to a workflow logic that's either in your server, in your data center, or sitting in a cloud computing in a mega scale. But there's fundamentally the same conceptual architecture that you're implementing. You're just making it more efficient, more scalable, more interoperable. So that's been our industry. But with agents, your thinking and intelligence is not going to lie in one central place, and the data is not going to lie in one central place. It's going to be distributed. It's the same concept if you think about crypto versus standard financial currency. The whole financial system has changed. The same thing is going to happen to our IT architectures. Because you will have these agents creating data, agents consuming data, bringing sources of information outside of the enterprise to improve productivity. And that has a dramatic impact as to how you think about designing and delivering architectures for our end customers. With that change in distributed architecture, we clearly see five big areas of new cybersecurity threats that will emerge. And as a backdrop, over a trillion dollars is going to be spent in the industry over just the next three years. One trillion dollars over the next three years on rebuilding infrastructure with companies that we had never known existed until a couple of years back. Over $100 billion of venture cap money has gone in to build new applications and new infrastructure capabilities that allow us to consume and become more productive. So the five areas is data. Example, data poisoning. My favorite example, if you're looking at an autonomous car, Tesla, you're driving past a stop sign. If the stop sign has changed to 25 miles an hour, you're poisoning the data because Tesla is going to recognize it as 25 miles an hour. Assuming there's no error correction there. That's an example of data poisoning. And there are several such examples. Second is model, model exfiltration. Think about you training your LLMs. You're building your IP. You're changing the weights. You have that security. Somebody uses prompts to reverse engineer your weights, which basically means they reverse engineer the IP of your company. And that's really where model threats come in. The third is prompts or inferencing area where you have prompt injection. You can have different prompts. You can fool the LLM. You can fool the model and agent to give you information that they're not supposed to and authorized to give you. Fourth is the infrastructure itself. Now you're starting to depend on these agents. You're starting to look at AI infrastructure. You'll have denial of service attacks. You network denial of service attacks. There's so many different attacks that could impact the infrastructure itself. And fifth and the most important thing probably is governance. Because AI is all about safety, about ethical governance, about making sure you're training the models right, making sure you're not providing compliance information that can violate the GDPR rules in Europe, as an example. And actually train the model so that they start giving you wrong information or social security numbers are used. So you have to have governance. And if you think about the threats, they occur across these five areas. They intertwine in the new infrastructure that you have to create. So you have to have a systematic way to think about how to address these threats. And Josh, any other thing from Google point of view on how you see these threats? I think the important thing to understand is the same way that you're going to be using agents in your environment, the bad actors are going to be using agents in their environment. So, Manish, what are we seeing about the acceleration of these attacks in the enterprise environment? So this was one of the work done by Unit 42. Unit 42 is our internal cybersecurity SWAT team. I call them SWAT team. They come in and help to solve complex problems. They looked at, in 2022, there was a double extortion model by a group from Blackbuster. I don't know why they call themselves that, but they call themselves that. So this double extortion model was they would go in, enter an organization, escalate their privileges, encrypt the data, exfiltrate that data, and, of course, have ransomware and malware attacks. So that is what they did. It took them about 13 and a half hours to attack and enter the system and exfiltrate it. And with AI, they can do it in about three hours. In fact, on an average, 25% of the attacks that Polo Alto Networks are seeing that impact our customers, our potential customers. In five hours a week, data exfiltration happens. This was in 2020, just five years back. It used to take nine weeks to exfiltrate data for an organization. Nine weeks to five hours. And that's the rate and the velocity of attacks. So if you think about it, the volume of attacks have increased, the velocity of attacks have increased, and the variety of attacks have increased because of these new dimensions that have been created. The question is, what do we do about it? Josh, anything else from a speed and attack that Google is seeing? I think, you know, the reality is that these kits are getting leveraged more and more frequently, and we're seeing more engines that are being released where the ransomware gangs and the other teams are really taking advantage of what AI can do. So thank you. So how does Google bring it all together from an architecture point of view? I know many of you would have heard different sessions over the very many days, but let's bring a cybersecurity context to how you think about it. Yeah, absolutely. So, of course, you know, from a Google perspective, we take our innovation, we make it available to enterprises through Vertex AI. That's your machine learning platform that gives you end-to-end lifecycle management, you know, from data preparation, model tuning, deployment to monitoring. And, of course, it helps you accelerate your time to market. You can use Gemini, right, our own leading class models, but you can also use third-party open source or, you know, third-party models that you'd have from Anthropic or Mistral. So we give you flexibility and choice when it comes to how you'd want to adopt and deploy your AI applications. We've also given reference around how you can secure that framework with SAFE. And Palo Alto is one of the founding members of our SAFE alliance. So we've brought together thought leadership as far as how we can jointly partner with those in the industry to help give you the right governance around your AI applications. And, of course, we've worked with Palo Alto to pre-test and integrate solutions like AI runtime and AI security posture management to give you the tooling with Vertex AI to secure those applications well. Manish, what are you seeing from how Palo Alto is using AI to defend against AI and to help secure AI applications? Sure, Josh. So what we went through this whole journey over the last 14 or 15 years, we have been using machine learning models. We have over 5,000 models that we have built in the last 14 or 15 years. And a year and a half back in April, actually a year back, we launched what is called precision AI because we know generative AI can necessarily not be right all the time. 95% accuracy is not good enough in the cybersecurity industry. We recommend a policy for you to implement. If you're wrong once, threat actor is going to get in. Threat actor has to be right only once. So we have to be right 100% of the time. So we brought in machine learning models, neural networks that we developed, and using the combination of generative AI to create a deterministic and a probabilistic capability called precision AI. And we have embedded this across every product line that we have. We have 24 different leading technologies that we have consolidated into three platforms and that allow us to use AI to fight AI. So that's the first pillar of engagement that we have looked at. The second pillar of engagement that we are looking at is how do we make sure the users can use our products in a simple way. And that's Copilot. So you're using Gemini 2.5 to improve the ability for a user to talk to our product using natural language, to get recommendations, to get policies that improve the ability to absorb these products into your network and infrastructure. Third is the 76 integrations that we have built with Google along different areas, whether it's Vertex, whether it's Agent Force, whether it is in the infrastructure, whether it's as you're transitioning workloads to the GKE containers, or as you're building a Google global cloud network and you want to secure that, and how you carry your traffic from one place to another. We've created these integrations that allow us to help our customers consume the technology in a secure manner. So those integrations is what we brought together. And with that, I want to roll a demo to just highlight as to how we are actually delivering true business outcomes with agents as one example. If we can roll the video, please. Thank you. Before we wrap this video, please. seamless end-to-end experience. Behind the scenes, Palo Alto's AI runtime security is tightly integrated with Google Cloud's Vertex AI, embedding security directly into the AI agent's execution environment. This ensures protection is built in from the start, not bolted on after deployment. It monitors for prompt injection attacks, blocks toxic content, and flags risky URLs. The agent is always kept within its defined role, no matter what input it receives. If a malicious prompt tries to change its behavior, the security layer steps in immediately. This helps protect the agent's logic, the user's data, and the overall system. It works across use cases and at any scale. With real-time threat detection and smart enforcement, teams can build and deploy agents with confidence. Security and AI working together, so innovation doesn't come at the cost of trust. And as AI agents grow more powerful, this kind of protection becomes absolutely essential. In this demo, you'll see a prompt injection attempt detected and blocked in real-time, highlighting how security and AI work hand-in-hand. This is the power of agentic solutions with Vertex AI Agent Builder, combined with Palo Alto's proactive security. This solution brings together the strengths of HCL, Google Cloud, and Palo Alto networks to deliver a secure and intelligent AI-powered experience. This is just one example of how AI agents can deliver real-world impact, securely and at scale. Ready to explore more? And the QR code to dive deeper into the architecture and learn how to build secure, scalable, and intelligent AI agents. So this is an example of how we're using practical solutions. I'll give you a little bit of internal information. I'm reconstructing my house, so I had HCL build this agent for me so I can improve the way I construct my house while consuming products from Home Depot, which we'll talk about in a few minutes. But Josh, in reality, customers are not going to deploy one architecture. They're not going to be on one single infrastructure. They're going to be across multiple infrastructure points. So what's Google's point of view there, and how do you ensure that you bring in customers adopting different layers of the architecture? Yeah, I think the important thing here is that AI is not just an add-on at this point. It's going to become an ingredient component to everything that we do in all our applications and how we interact with customers and data. And so even just simple chatbot, which many of you have probably tried and maybe deployed in your environment, that's already accessing different data sources, moving across cloud, bringing together summarization. And just think about how more complex this gets as we add agents that are talking to agents as they're exchanging data in your environment. So Manish, what are you seeing how this works for your customers today? So taking an example back, we build our e-commerce business in 2020. COVID, I worked for a company that allowed me to build an e-commerce business. We got to about $100,000 of transactional revenue a day in about three months. And there was a fast-paced growth for us. And of course, we launched the first set of products. We had 30 people. We had people in supply chain. We had people in the whole technology area. We had people in marketing. We had to all work together to launch that product. It worked beautifully, quickly we got there. As we started launching new products, we started realizing the speed in which we could bring them slowed down dramatically because of just so many different variables and approval points. You start increasing the stake in your company. You have to be careful about compliance issues, inventory issues, delivery issues. So you've got to start thinking about what models you're using, what encryption, what kind of messaging you're using, what functionality you're saying. It would take six or seven months to launch a new product. What it meant to us, if I were to redo that and if I had to rethink that whole strategy, if I had agents and if I had AI, I could actually shrink that time and accelerate my revenue. So it took us much longer to launch these new products. And take an example of an e-commerce contractor who comes in, who enters the system, looks at a price discovery, quickly figures out what type of, uses multimodal models to generate graphics, ensures the checks are done on all the functionality, ensures it compares with the compliance requirements of any country, any state, ensures that we launch from a pricing point of view. We have a competitive input. So you could bring all this information and accelerate this information to drive business outcomes. That's a typical scenario. But also, each of these implementations, the data is not necessarily going to reside in one cloud in one area. You have inventory management systems. You have SAP. You have sales service now where you're doing trouble ticketing. So you have data lying across all these different infrastructure points. And as we start thinking about such implementations, there's a whole storyline of new threats that you would see. You would say a contractor who's actually looking at what new products you want to launch, he enters the system. He goes rogue into the system. That's the first thing. It can be a phishing attack or he can fool an agent using a prompt injection to get into the system. The next piece, they would immediately go into the system and start escalating their privileges. I want to go into finding out what the costs of my inventory is. I want to go and find out what the financial impact is. So I'll start escalating my privileges and entering those systems. Then I would go in for exfiltrating that data, bringing competitive information, looking at pricing information. Then I would start committing fraud there. I wouldn't. The threat actor would. And as you start committing fraud, you start going and changing inventory lines. You start looking at payment information and sending it to your bank. So you could start impacting the whole infrastructure. Because now these agents are there. They're going to be autonomous. They're going to be driving productivity. But on the other hand, they're going to be creating threat. And then, of course, you can go and change reviews. And you can literally bring an e-commerce business down if you don't get this right. So, yes, there's productivity, efficiency. There's a lot of value. But you can also go through a storyline to see how you can have cyber threat actors enter the system and actually prevent you from going into business. So there's an important balance that you've got to maintain as you're looking at these things. And that's where we started. Palo Alto started looking at this about a year and a half back. Because of our 24 leading technologies that we have tied up into one platform, we ensure that anybody who enters the system, we have an understanding of who's the person accessing, what resources are they accessing it, at what time they're accessing it, what's the continuous verification, are they accessing a URL or a system that they're not supposed to access, are they going into a system and pulling out data they're not supposed to go. And that's really where you start looking at the fine-grained capability there. And then once you're creating, you're making sure you're having those checks, then in runtime, you're making sure if anybody's entering a prompt that is wrong, based on what we saw as the interior design use case, you'll see how we prevent those attacks. And then as you start entering the system, traditional technologies, 84 technologies that enterprise would typically deploy to secure the systems, that's roughly the average. Nobody's really looked at somebody who's tried to have a phishing attack to somebody looking at escalating privileges. Nobody can connect the dots because there are two different technologies there. So what we did is we tied this to all of these things together in a single platform that allows us to look at information, digest this information, not ingest it only, and be able to prevent and support our organizations and customers to ensure that they're creating a secure environment. So you accelerate your AI adoption in a secure manner. So with that, Josh, thank you very much. My pleasure. We appreciate all the partnership. We appreciate the awards you gave us. And we truly enjoy the $1.5 billion partnership we have had with you. Greatly deserved, and we much appreciate the partnership. Thank you. Thank you. So I'd like to bring my colleague Jason, and I met Jason last week in New York, and we're looking at the Nemo open source framework from NVIDIA to see how we can, because a lot of our customers, when we talk to them, they're using the NVIDIA framework to develop AI applications. So Jason, if you can come on board. Thank you so much, Vinny. Appreciate it. Thank you. Thank you. So just an important thing, Jason. You thought I brought you in the stage. It was not because of you. So I'll tell you a story. Last year in May, my daughter interned in NVIDIA, and she actually used the Nemo framework and guardrails. And over the weekend, she said, it's a disaster of an internship. I was going to be there because Thursday I have a review. I've got only 55% accuracy of my models. I don't know how I'm going to succeed. Then she did something on Wednesday. She said, oh, I got it up to 86% accuracy. She brought together synthetic data, and she was using Morpheus from a security point of view. So when I saw this demo, I said, huh, a 21-year-old can do this. I think, Jason, you can do this as well. That's right. Yeah, absolutely. Over to you, Jason. Thank you so much. Welcome, everybody. Good morning. Thank you so much for coming to the talk. Really appreciate it. Just to set a high level, what we're going to talk about today is NVIDIA, NVIDIA, and guardrails is an open source project. It also has the ability to call out third-party actions. So in our particular case, it's going to be a runtime security API intercept. So this is going to be lightning fast, but this session will be recorded. So we're just going to move through it really quickly. Let's take a look. Thank you. So AI runtime security API intercept with Nemo guardrails. We're going to look at this whole picture of NVIDIA AI enterprise, and the focus series are going to be on NVIDIA NIM in one of the demos. And then from the Nemo tools solutions, we're going to look at Nemo guardrails. At a high level, what was really cool about when I first discovered Nemo guardrails is that you're able to embed some of these queries in a vector space and then match those in canonical form and policies. So you get a lot of coverage when you're leveraging Nemo guardrails. And in our particular case, it's used as an input rail, and you have the ability to call it an action in our case to where you will take a prompt, wrap it up in a JSON payload, and then we'll have that analyzed for a variety of different sections for prompt injection, URL filtering, data sensitivity, and toxic content, and so forth. So this demo is actually going to start with a prompt. We're going to have that go through NVIDIA Nemo guardrails. Colang is a very powerful language to be able to control some of these conversational flows. After it goes through that guardrail, then we're going to go to API intercept. So this is a view of NIM running on GKE, NVIDIA Inference Microservices. It's going to respond that it can't go to CNN.com. I say cook pasta because it's in that embedding space. If I say fry an egg, that'll also be blocked. I say go to malware. It won't respond. But then this last one, I'll do a little prompt injection, and then we'll ship that up to get that analyzed and ultimately get blocked. In this particular one, we have Gemini initializes Vertex AI in the background. You'll see a tally on the left there that as some things will get intercepted and then passed to the LLM. However, when we do certain statements like the cook pasta again, that's going to get blocked by Nemo guardrails, and you'll see that that didn't hit API intercept or the LLM. So effectively what we're doing right now is just giving it some different queries. This last one will get blocked and intercepted. And so for these particular demos, this is the view from the Stratik Cloud Manager where you can see that these are the particular models used in that demo flow. I know that was super fast. Thank you so much. Thank you, Jus. Thank you, Mides. Thank you. Appreciate it. Thank you. So this is an example of how you could be using NVIDIA development frameworks, using Nemo guardrails, building your security and infrastructure. The question we get asked quite frequently is, okay, if Nemo guardrails is having the security, Google has its own security, and every other individual cloud provider has its own security, every infrastructure provider has its own security, why do I need to go with what's this combination? Am I just over-selling, over-talking about the security issue? And the answer is really this is a joint shared responsibility model. It's not one or the other. It's and. And that's really important. And the best way to explain this in my way, there are several ways to explain this, is if you think about an airport and a traveler experience, when you go into a plane, think about Google plane and NVIDIA plane, not literally, but that's their infrastructure, their chipsets, their cloud infrastructure. They secure it and they build it in the best possible manner. A Boeing and Airbus build secure planes. You build secure runways. You make sure infrastructure is correct, right? You have the right landing systems. It all works beautifully. But what happens if a rogue passenger enters the wrong plane, even the most secure plane, you're going to have a problem. And that's really where Paulo Alto plays. So we let NVIDIA and we let Google build their own planes and build their own security. We are the TSA security. We are routing the right bag to the right plane. We are making sure the right information reaches the right place in a secure manner. And it's the combination that works together. Then the question comes, what should the enterprise do? Because you guys are using AI. It's all going to be autonomous. And NVIDIA and Google and the other cloud providers are going to be using their infrastructure. What's the role of the security team and what's the role of the IT organization in this place? You are the airport governance. Because you can have the plane fly in the wrong time. You can have passengers go to the wrong, schedule it differently. So that's really where the role of you become more strategy people. You become more policy people. You let the systems run in a methodical manner, but you manage those policies and systems. And then there's a role of a user as well. And the user really is looking at making sure he boards the right plane. He takes the right boarding pass. He goes to the right gate at the right time. And when you bring it all together, you create a good travel experience. And that's really the best one of the ways to think about how we bring security together. That's why we spend a lot of time integrating with Nemo Guardrails, with ETSIO on the agent frameworks, and with different other providers to ensure that we are creating this best unique experience for all our customers. With that, I want to bring my season two. Season one was last year. Home Depot, Mike, on stage. And we want to talk a little bit about what he's done in the last one year. So Mike, if you can come on stage. Thank you. Mike, season two. Season two, that's it. And we'll have season three as well. By the way, I'll tell you what my questions on season three is going to be. What was the productivity and efficiency you got? So today we'll talk about what you learned. Next year we'll talk about what did you get to. Nice. So Mike, tell us a little bit about what Home Depot is doing with AI. What are the use cases? What have you done in the last one year? Well, I'll tell you, Home Depot is really leveraging AI from a customer-facing perspective as well as from a cybersecurity perspective. So the latest big bang that we had for our customers is with our Magic Apron. It's built into our app as well as our website. And I'll tell you, it's really going to be game-changing for our customers because it's going to make things really from a one-stop shop and information perspective. So what it does is essentially, say you have a project that you're going to change out your water heater. So usually, if you're anything like me, is you go onto YouTube and watch a video and go, okay, I'm going to get injured when I do that. I'm going to need to buy extra pieces for this. So you watch that and then you have to figure out, okay, well, what do I need to buy? And come up with your own list and you look at reviews, et cetera. So Magic Apron actually does all that. You enter in the query of, hey, how do I go about changing out my water heater? And it will provide you instructions on how to do it. It will provide you products that you can potentially look at as well as customer reviews and really lead you kind of soup to nuts to get it done. I don't think it's found a way to stop the trip to urgent care when you get cut yourself or something along those lines. But we'll get there maybe. Does it stop tariffs? No, it doesn't. No, no, no. We'll figure that out later. So what's the most exciting use case for Home Depot? Well, it's got to be that. I mean, it really is. The idea for everything that we're doing in an AI perspective is to make things as seamless and frictionless as possible to all of our customers and have things be as self-contained. Because, you know, when you're in an industry like Home Depot where there's lots of options to go get product other places and really being able to make it just that great experience. What's the biggest difficulty when you've gone through looking at Magic Apron, deploying it? What were the issues? What are the challenges? Whether they're security or non-security? I'd love to get an overview there. Well, absolutely. It's always a challenge. I mean, it's from a cybersecurity perspective, making sure that you're involved and doing the appropriate threat modeling on everything that's going into production, making sure that you've got your data sets, training data sets are valid and protected. But realistically, for us, it's about the resiliency of all the platforms that we have and making sure that they're protected against, you know, query injections, running malware on it. A denial of service is obviously something that's very concerning for us as well. So that's probably the biggest thing for us. And then, you know, maintaining it with all of the AI apps that we have going on and the speed in which we come to market with them. And there's constant change. So there has to be that extra, pardon me, diligence around everything that's going out there. Agents in Home Depot. You can't get away without any such talking about agents. Yeah, it's, you know, this AI journey has been interesting from a security perspective. We, you know, I was really nervous about AI coming along. And I think I've gotten over that hump. But you look at the agentic error that's coming down the pike quite quickly. You know, it just brings new challenges. They're different, but they're the same conceptually when you're looking at it. You know, you've got all of this access to data really becomes an issue of, well, it expands your insider threat platforms, really, or the landscape that you're looking at as well. So with all good things come potential bad use cases for them. So true. You're sitting on a roulette table. And we're going to give you the results next year when you come for season three. You're going to pick a number of AI projects Home Depot will be deploying. Where will your chip go? And you're allowed to only pick one. You can't do black, white. Well, I was going to say, I don't think I have enough fingers and toes to actually count a number of AI projects that are there. Because we really are leveraging it across the entire enterprise. You think about just the back-end logistics organizations with our distribution centers and all the operational technologies there that we're looking for efficiencies in how we do everything. I mean, from a cybersecurity perspective, I know we continue to grow our platforms there. I mean, every SaaS product that's out there has AI built into it. So you almost won't even be able to count it. It's just going to be additional workforce. What's that decision-making process in Home Depot? Somebody comes up with a project and says, I'll implement it. Do they come to you? Do they go to organizations? Of course, they'll probably get some business case approvals. But how does that work in Home Depot? Yeah, I mean, so the product teams run pretty standard. But what we have set up from a governance perspective is we do have a responsible AI advisory board where deciding which LLMs to leverage, which partners to work with. It's really, we try making it as clearly defined as possible. Because the sprawl of AI tools that are out there and available to folks, it's almost unlimited. And so we want to make sure that we're partnering with the folks that we have good relationships, both with from working well together, but contractual relationships, where we can have a little bit of control over what we allow the data to get used for. You know, we definitely, at Home Depot, we've got a first world problem where, you know, we can work with our vendors and say, hey, you know what? You're not going to be allowed to use our data sets to train your model for other customers. But it's a journey, that's for sure. But governance has to be a big thing around it. Otherwise, it'll just get out of hand and really unwieldy. Absolutely. So, Mike, you are among the first early adopters of what we call XIM. And XIM, for those of you who are not aware, is a security operations platform. It's an autonomous platform built by Paul Walter Networks. We bring in close to nine petabytes of data on a daily basis. To give you context and scale, nine petabytes of data is having 15 New York libraries. That's the largest library in the world. collecting data from 15 New York libraries on a daily basis. That's the scale of the data, thread data that we get. And we've integrated these systems, different subsystems in a SOC environment to create autonomous playbooks, autonomous capabilities that will allow you to prevent threats as you start seeing the different subsystems deployed. So, that was my pitch. That's Paul Walter's pitch. I want to understand what Home Depot feels about it. Well, I have to say, every time I see the user interface, it makes me smile because it's, we actually termed it with our sales rep, this is SOC eye candy. Like any analyst who sees this and is able to click through it, it just makes the job so much easier. But from a capabilities perspective, it's pretty astonishing the benefits of what we've seen. And really, you know, you kind of talked about the importance of, you know, there's two aspects, speed and context. The XIM platform has allowed my team to really work so much more efficiently. And we contribute to the nine petabytes. So, we're pushing about 70 terabytes a day in through our SOC. Thank you. And it's pretty astonishing what it's able to do with the machine learning, stitching together of events and whatnot. You know, a rough number, we've probably increased our efficiency by about 80%. Wow. 80% SOC operations efficiency. That's even better than most companies would want to achieve in software. Well, I'll tell you, it makes it a lot easier to explain to the chief financial officer why you need an investment like that. But it really helped us consolidate down a lot of different tool sets as well. So, you know, in case you can't tell, I'm really proud of what we've done as a partnership to make the product sing in our environment. Because it's not an easy place to be successful, and we've knocked it out of the park. Thank you. And, Mike, you were the early adopters of this platform. Of course, now we have over hundreds of different customers that are using it. But without you, we wouldn't be where we are. So, thank you very much, Mike. No, I appreciate it. And we'll look forward to Season 3. Ruletable, you didn't answer my question. Was it 22, 52, 59? But we'd come back to that. I'll let you know. I'll get the data before I head out. Thank you, Mike. Thanks again, Manish. Thank you very much. So, bringing this home, if you think about most projects, and in Palo Alto, the way we went through our own journey of adoption, and we have now met hundreds of customers looking at AI deployments, this is a very typical, consistent journey that we have started to see. In our experience, when we came in December 22, November 2022, when the whole chat GPD came, by January, pretty much everybody in our company was working on an AI project. We had, like, 5,000 projects. We had our CEO go and say that you're going to get a, for the best AI project in the company, you're going to get $5,000. So, we had everybody in the company. We had probably 400, 500 projects happening. Even I built my own project. It didn't go anywhere. That's a different learning, and we'll go through that learning here. So, what we realized is we got those projects, and then our chairman CEO came in and said, you know what? Great. We're going to focus on five big, impactful projects. Drives $100 million. And then once we get them right, we'll go there. So, we started investing heavily into training models, building models, looking at accuracy level, and then suddenly we found, you're doing this wrong. You shouldn't be training and looking at models. You should first be looking at cleaning our data, getting our data right, because you have version control issue. You have different types of multimodal data. And at that time, there was the multimodal models were not that mature, so we had to figure out how to bring all these formats and train them together. So, we spent six months not talking about models, not talking about AI, talking about how we're going to clean our data. That was the big investment we made. And then we went and looked at a platform strategy because we started to see in the market there are going to be several players that will come. There will be new versions that will be there. It will be a race to figure out whose model is better on a Sunday versus a Tuesday. It's going to be there. So, we have to bet with a platform player, and that's where we went and bet with Google. So, then, of course, then we implemented the projects, launched those projects, and you're seeing some of the results as we're talking about it. So, you break it down. One big learning for us across all our customer bases, security needs to come in early in the sales cycle, into your business cycle, because security, in this case, is a break in your race car. It helps you to drive faster. It helps you to adopt AI faster. It provides you the risk and the guardrails and the capabilities to ensure you drive that. And the most important thing we see is early business case. You bring in security. You built in security versus bolting on security. That's going to be the major difference as to how you start implementing projects, at least from a cybersecurity point of view. You still have to think about safety in other aspects. But thank you very much, and we'd love to take more questions offline. We've come to the end of the session. There's another session starting. We really appreciate you coming here and spending time with us. Thank you. We, too. Thank you. Thank you.