 I hope you're all having a fantastic time at Google Cloud Next. I know I surely am. And I'm so excited that you're all joining me this afternoon to discuss how video game studios use Google Cloud to power generative AI in games. Now, we have some really cool content planned for you. But let's start with a show of hands. Ready for this? How many of you here love games? Ah, that's good. Good, good. You're in the right place. And how many of you here have used some form of generative AI? Fantastic. How many of you are game developers? All right. Sizable chunk. That's great. And how many of you, the game developers, have used generative AI in games? Fewer. Okay. And how many of you here who have used generative AI in games have done so on Google Cloud? All right. Well, I see you there. So, you know, next time I would love for you to give the talk. All right. So, I'm Ishan Sharma, a product manager in Google Cloud. I'm focused on driving accelerator infrastructure and platform innovation for running AI workloads on Google Kubernetes Engine. I also lead the games team building the technology that powers game servers on Google Cloud. And what excites me most about my job is the fact that I can integrate the two roles together, which is bring generative AI into games. I'll introduce my co-speaker a little later in the talk. Now, today, there are more people playing games than ever before. To keep players engaged, game developers need to constantly update and evolve the game with new content and experiences based on player behavior. This is what makes a game a live service game. In a recent survey of over 500 game studios, 95% said that they're working on a live service game. This means that in today's world of live games, the majority of the players are playing the same incredible games year after year. This behavior, however, creates an even harder ecosystem for new games to capitalize on new audiences and gain market share. With the majority of the game titles competing for just 39% of playtime. And this is why many of you are exploring ways that generative AI can create more engaging games. Generative AI really has the potential to transform games into a more lucrative, interactive experience with infinitely immersive player experiences. But first, let's take a journey back in time. Video games first started as a consumer packaged good. We remember those days, right? Video games would be developed and purchased in single instances without the constant demand for updates. As player behavior started to evolve, games became digital live services where players access games online, play across devices, and interact with the ever-changing world within the game. However, live games have created an environment where developers often struggle to keep up with the player demand. With large content pipelines, complex technical requirements, and a fast-paced competitive market, studios need to speed up development and provide new player experiences in order to remain at the top of the market. Generative AI is the next step for studios to move from just keeping up to truly innovating at speeds that take live games to the next level. Generative AI enables the game itself to dynamically evolve with player experience. We call these living games. Living games will transform the game's landscape, empowering creators, designers, developers, artists, and marketers to reimagine their workflows and craft new experiences that were previously unimaginable. In fact, 75% of game developers are anticipated to use generative AI in their work by 2025, end of this year. The question is, are you one of them? Whether you are just evaluating the idea of generative AI in games, knee-deep in development of generative AI, or about to launch an exciting new game title with generative AI, be rest assured that Google Cloud for Games has got your back and the platform to power it all. In fact, launching and operating a living game requires a whole new mindset and a robust technology stack. That's where Google Cloud comes to help. At Google, we have been building live services such as Search, YouTube, Gmail for years. And these are deeply embedded in our culture and technology. And with the experience and technology foundation we have built over the last couple of decades, we are helping game developers like you connect with players, deliver exceptional experiences, and really scale your business. The Google Cloud for Games technology stack consists of three pillars. Game servers on Google Cloud for Games. And these are the main services and applications you are providing so you can better engage your players. And these managed services listed here, Google Kubernetes Engine, Cloud Spanner, and BigQuery are the foundations to deliver exceptional experiences to your players. So that you can focus on building great games instead of worrying about the infrastructure. And combining these solutions with generative AI on Vertex AI and Google Kubernetes Engine can help you build living games. Now, at Google, AI has been long core to our live service technology. With groundbreaking papers on DeepQ, AlphaStar, AlphaGo, and recent research publications on Genie 2, SEMA, et cetera, we have led AI in games since the beginning. More recently, the Gemini era and our latest Flash 2.0 family of models are really poised to usher in the next generation of living games. And that's possible by generative AI. Google's state-of-the-art models, Gemma, and Gemini are available in Google Cloud through a single integrated development platform, Vertex AI. And I'll talk about that a little later. And Vertex AI runs on our performant-optimized infrastructure, the AI hypercomputer. The AI hypercomputer includes libraries and frameworks running on Google Kubernetes Engine that in turn runs on performant-optimized hardware, such as Google Cloud's TPUs and NVIDIA GPUs. With Google Kubernetes Engine, you can serve open models, such as Gemma, right alongside your game servers and your game backends. When it comes to games, we can classify generative AI into two categories. One, improving productivity during game development. And two, improving player experience during gameplay. In the first category, you can use generative AI to accelerate time to launch by creating content and simplifying development. This includes game assets, such as characters, props, audio, video, code generation, and AI-based game testing. With Google Cloud's Vertex AI platform, you can leverage generative AI to rapidly accelerate the creation of content and code and spin up AI-based game testing environments with ease. You may have seen this image banner before if you were at the Games Developers Conference, where the Android bot is part of our communications this year. The animated version of it that you see here was generated from the still image using VO2 with a simple prompt saying, turn the character forward and wave. And that's what you get. Pretty cool, huh? In fact, Vertex AI is a fully managed and secure platform for generative AI offering access to a model garden of over 200 of the latest models from Google and other parties, all of which can be securely tuned and customized for your specific needs and then deployed to your development team with ease. Vertex AI keeps your data secure and private as you customize these models so that you can have the confidence in both the quality and the safety while you add new capabilities to your development workflow. Vertex AI is also connected to Hugging Face, offering the same benefits for over 100,000 open source models. And all of this allows developers to radically improve content concepting and creation speed while maintaining quality and improving time to market. This brings us to the second category, where game developers use AI ML and generative AI to adapt the gameplay and empower players to generate content in real time. These include smart, non-playable characters, NPCs, dynamic in-game content, gameplay customized to players, and user-generated content leading to endless worlds. For gameplay experiences, developers are now leveraging the power of both Google Kubernetes Engine and Vertex AI to provide real-time, in-game generative AI at massive scale. What's up, guys? Check out this game! It's called Countdown Atalante City. It's so cool, you can talk directly to NPCs, and they talk back to you in real time. Alright, I've been looking for a new outfit to get out of this suit. Let's test it out. Oh, hey! Can you show me a few outfit options you have? Sure. Let me know if you like any of these. Hmm, let's try something different. Could you make a red jersey with a silver dragon on the back? I can do that. This will be a premium item, and I guarantee you'll love it. Here you go. Great! It's perfect. I'll buy it. Did you see how fast that was? Alright. So, I've been told my next mission is in this building, on the second floor, but I have no idea how to get up there. But maybe I can ask someone for advice. Hey, do you know how to get in that window up there? I don't know, but if it was me, I'd drag that dumpster over and climb on it. Nice! Thanks! Have a good one. I should have thought of that. Well, let's see if she's right. I'll just drag the dumpster to right underneath so I can climb up there. Whoops! Sorry, buddy. And I think this should work. And up we go! Look at that! Nice! Hey, thank you! Thank you! How cool is that! How cool is that! To understand how to integrate generative AI during gameplay, let's first explore how to run game servers on Google Cloud. We recommend running Agonis on GKE, which enables hosting, running, and scaling fleets of dedicated game servers for global-scale multiplayer games. Now, game servers are these environments where players share a simulation, which is the authoritative source of truth. And Agonis is an open source, dedicated game server hosting and scaling solution built on top of Kubernetes, which teaches Kubernetes how to run game servers. Running Agonis on GKE brings several benefits. One, you can pack game servers and reduce waste, which is a hallmark of Kubernetes. Two, you can easily deploy game servers in the right places at the right time. You can be engine agnostic, whether it is Unity, Unreal, or your custom engine. You can track the health of your fleet with integrating logging and monitoring. And you can let your staff innovate with Kubernetes, a technology that your staff is already familiar with. Agonis on GKE makes running game servers really easy. By using Agonis Fleet Autoscaler with GKE Autopilot mode of operation, your global game server fleets automatically and dynamically scale as players flow in and out of your game. Essentially, you can set it and forget it. Scaling game servers with GKE Autopilots makes sense because game servers are pods. And Autopilot speaks in units of pods. Autopilot ensures you pay only for your running game server pods, and you don't pay for system components, operating system overhead, or unallocated capacity. So it really just makes sense. Now, GKE Autopilot for game servers brings the best of managed Kubernetes to games, with 45% improvement to developer productivity, always-on reliability resulting in 55% fewer support tickets, 93% pod security standards covered by default, resulting in 36% fewer known container breakouts, and up to 85% reduction in operational costs. Pretty fantastic, right? Now, here is the high-level architecture of a live service game. A typical live service game starts with players in a lobby and a matchmaker which directs them to connect to a dedicated game server where they can connect in a shared experience with other players. The game frontend, the custom matchmaker, and player profiler service all run on GKE Autopilot clusters. The player profile metadata can write to a globally replicated database for access later or for analytics such as leaderboards. The game servers also run on Kubernetes on GKE Autopilot and are orchestrated by Agonis. A service mesh can be used for global deployments to connect all of these together to cater to a global player audience. So now we want to add generative AI inference servers with the game servers, right? And how do we do that? How do we create that generative AI in games? How do we deploy them? How do we manage them? How do we connect them all together? How do we manage them all together? How do we manage them all together? GKE extends your platform to run generative AI during gameplay by improving latency, cost, overhead, while giving you the flexibility and the performance that you need to run generative AI alongside game servers for your players. This helps you with cost, helps you with performance, and keeps you scaling up and down with your player traffic. And here is an example of how an inference model might be deployed on the cloud. The inference models could be any type of model you wish, and any number, for that matter. The generative AI middle layer shown here gives you more flexibility and control over how your inference models behave with your users. Now, this is a layer that can enforce things like content moderation, compliance, as well as narrative consistency for your players. It can reduce costs, increase performance, helps you with batching and caching, essentially acts as a conduit between your game servers and your inference stack. Now, this ubiquitous GKE middle layer can help you integrate with Google Cloud's Vertex AI for a fully managed experience, or lets you run your own models with GKE. You can also easily integrate with generative AI offerings from our partners on Google Cloud Marketplace. Now, to demonstrate this, of course, we built a demo game. The game is called Home Run Gemini Coach Edition. Of course, it's about baseball. We use Gemini 2.0, 2.0 Flash, and in this game, our Gemini-powered head coach gives us insights to make the right moves. The game shows real-time agentic AI running during gameplay. The agentic AI is built using Gemini 2.0 Flash for features like native tool use, a 1 million token context window, and multimodal input. The application and the API layer are built on GKE Autopilot, which gives portability, performance, and cost-effective scaling at a global scale. Prompt storage and prompt cache are on Cloud SQL and Memorystore, respectively. Let's take a look at the demo on the next slide to see how all of this comes together. You know, before we get to that, we built this demo really to highlight how advanced models can be used today for things like game tutorials and how helping customers. Here, we really focused on helping the player understand which of the tactics are best for them, which increases their probability or their chances of winning. But hopefully, what this demo highlights to you is how you can send your current game state to the model and get hints about what to do next. As you watch this video, notice the assets, the animation, and the gameplay itself. And then we'll talk about it. So here are our two sides. We're starting on the right side as the pitcher. Head coach has recommended a tactic for us for pitching. There are, however, a couple other tactics which we can browse through. And here's pitching tactic number three. Coach had recommended tactic number one. But in this case, we choose to ignore our coach. Now, head coach gives the opponent some advice. There are a couple of different batting tactics. Number two, this one, is recommended. And here's number three. And, of course, we choose to ignore our coach's advice. Well, that's what happens. Next round, head coach gives us some advice. This time, I think we should listen to coach. That's probably in our best interest. And once again, coach recommends. And so what's happening here is that Gemini is looking at the game state and giving, and based on the rules of the game, suggesting what the best tactic would be in this particular scenario. So, some interesting facts. The static game asset, the players, the baseball field, which is the diamond, right, are created using Imogen 3 with Google Cloud Vertex AI. The dynamic game assets, animations, or videos are generated using VO2 on Vertex AI. Head coach, of course, is powered by Gemini 2.0 Flash. And the gameplay itself giving all those different tactics is also powered by Gemini. So, this demo really highlights how we can start to integrate AI into our workflows and the game itself, bringing the idea of living games to life. Now, I love working at Google. And what excites me most about my job is seeing incredible experiences that our customers, all of you, build using our technology. And one such customer is Clang Games, who have built a groundbreaking and ambitious MMO simulation experience, Seed. To share more about the incredible work that they have done, I would like to welcome on stage the CTO and co-founder of Clang Games. He truly is an industry veteran. He has been working on building MMO games, game back-ins, and virtual worlds for over 20 years. And he has brought his dream and vision to reality with Google Cloud. So, without further ado, let's give a warm welcome to Adur Magnusson. Thank you, Ijan. Mic check, mic check. Can you hear me? All right. So, thank you, Ijan. Hi, everyone. I'm Adur Magnusson. I'm the CTO of Clang Games, and we are a Berlin-based game studio. And we're working on a game called Seed, a massively multiplayer society simulation. This is something that we truly believe represents a living game. So, today, I'll cover three main areas. I'll start with a quick project overview of Seed. Then I'll talk about how we have built the game's backends on Google Cloud. And to wrap it all up, I'll cover how we're using Gen.AI to really make the characters and the world come alive. Okay. But first, to kick things off, here's a short video to give you a first look into the world of Seed. The vision behind Seed is to create the most advanced simulation in human history. To try and simulate human society at a level of detail far beyond what has ever been done before. If that doesn't excite anyone who makes digital experiences, nothing else will. You control characters that we call Seedlings. And you basically help them live out their lives and fulfill these interesting fantasies with all of the life stories and the drama and the wins and the losses and the grievances. Very highly intelligent beings that evolve over time and we can observe really interesting behavior from them. Artificial intelligence of a scripted form has existed in games for as long as I've been playing games. It's just gotten more compelling and more advanced. When we started pitching this back in like 2011, 2012, people thought we were crazy because like AI running on these backends had never really been done or wasn't really even possible back then. So we had been doing a lot of pre-production. We had been building a lot of kind of restructural AI systems and right at the moment where we had a lot of that generative AI jumped onto the stage and we kind of just almost by accident had built like the perfect framework to actually work with that. Generative AI brings that more to life and so my seedling, my character, we could have made do cool things but now we can do cool things. At any given time your seedling can text you and say, oh my god, something happened and they can really understand contextually what it is that you're saying. So imagine you have like a seedling called Jake and they like another seedling called Emma and Emma walks into the room and you text your seedling, why don't you ask her out on a date? And then you can actually see your seedling get up, walk over to Emma, strike up a conversation and then you come back the next day and you ask your seedling, hey, how did the date go? And then Jake actually describes how the date went based on their own subjective opinion. It really creates this like dynamic, deeper interactions between the players and with the NPCs. It's going to really step away from what we see in other games with NPCs and like this. Imagine a city where you just like pan around the city and you can see seedlings kind of having conversations with each other or, you know, painting things that then they decorate their houses with. But more importantly, this is not a random painting that they did, but this painting is because of this is what they're going through or, you know, this is their worldview. It really grounds all that high fidelity in kind of reality and everything starts feeling real. It's really ambitious with going for a larger scale than anything that's currently out there. I think we severely underestimated how hard it would be to scale this thing. What we're doing is already hard. Creating a persistent, always-on, single-world game requires computational power. To then add generative AI on top of that, it's increasingly difficult to do at scale. The foundation of Seed is the storytelling simulation and that lives in the cloud. And Google is obviously at the forefront of running cloud infrastructure. Of course, Google was the perfect partner there because they've both been on the forefront of developing generative AI. We're also building the backend services that we've needed to really scale deep. And now we have Google coming online with these amazing generative AI offerings that we can fold into that. That builds on the same platform, allowing us to achieve a lot more. The players are creating the content, but then our own AI is creating the content and Gen AI is creating the content. And all of this, I think, just creates these absolutely unique experiences that we've never seen in games before. The self-organized fun in this all-connected, living, breathing world of Avesta is a game I've never been able to play before. So I'm excited as a gamer, not just as a member of the team. Sometimes it's harder to describe it as a computer game. It's beyond a computer game. It's beyond a TV show. It's beyond a virtual online society. I think it's a new form of entertainment. All right. So the world of Seed is inhabited by our in-game characters that we call Seedlings. We simulate each Seedling in detail, including their stats, needs, goals, relationships, aspiration, et cetera. And these details are then what drive their behavior. As the player, your role is to care for these Seedlings and guide them through their lives. And since no two Seedlings are ever the same, each one lives out a unique and dynamic life. You're not limited to just one Seedling. You can manage several at once. Maybe you want to really focus on an individual life story or you want to guide an entire family across generations. And these Seedlings, they live together in large multiplayer societies where each society is alive, filled with characters from thousands of different players. But what's unique about these Seedlings is that they are always on. They persist in the game 24-7 and live out their lives continuously, no matter if their owning players is online or not. So the world does not pass when you log off. Rather, it keeps evolving and the stories, they keep unfolding. As we zoom out even more, we see it's actually one single world. All these societies coexist together on the same planet. Ultimately, Seed is one massive living world where the combined actions and stories of all the Seedlings created single evolving history. Building a world this complex and at this scale requires some serious infrastructure. And that's where our partnership with Google Cloud comes in. They provide us with a platform to pull off this vision. So with that overview and understanding of the project's vision, ambition, and scale, let's get into some of the technical details. Because the world is persistent and continues evolving even when the players are offline, the entire game simulation must run server-side. This requires running our game servers reliably and cost-effectively, whilst ensuring that we can scale up as more players join and the world gets busier. Essentially, all our backend workloads run on GKE, ranging from the standard utility services like user management and payments to the core game servers running the simulation. And so inside each society, the simulation is not just running as a single process. Instead, it uses a bunch of specialized workloads that cooperate to drive the simulation. For instance, we have separate workloads for pathfinding and navigation versus the logic for seedling decision and the environment simulation. So let's quickly look at our overall setup. So we have traffic from PC and mobile clients that enters through these API gateways. And from those gateways, requests are sent internally either to the global services or to the services for each specific society. And to stay informed about everything that's happening in the world, we use a standard Google data pipeline consisting of PubSub, Dataflow, and BigQuery. For AI model hosting, we use Vertex AI. That way, we get access to Google's modules and the flexibility to use third-party and open modules. Seeds' continuous, always-on world bring some unique cost challenges. This meant we really had to optimize both for cost and efficiency. So to maximize our cost savings, we use Spot VMs pretty extensively. The key was designing many of our workloads, like the character simulation, which is the biggest one, to be able to handle VM preemptions gracefully. To optimize our node configurations, we use node auto-provisioning, or NAP, which automatically finds the best configuration for our node pools based on our current requirements. If you use GKE autopilot, you get all of that out of the box as well. Egress costs is another big one, especially with real-time game traffic. We cannot just throw all the assets on a CDN and serve it from there. So to reduce the egress costs, we use compression heavily, we offload slowly changing data, in-game data, to a CDN where we can serve it cheaply, and we take advantage of things like the bandwidth alliance. And finally, to validate all of this setup, we run simulated scale tests. Basically, we spin up a fleet of scripted clients that emulate real players and generate realistic load. This allows us to find any inefficiencies in our setup and to make sure that everything holds up. So, we actually started working on Seed long before the current wave of Gen AI. So our initial focus was purely on building robust backend infrastructure and the core gameplay systems. But then, as LLMs showed up, we immediately saw the potential to really make our seedlings come alive. With our backend already on Google Cloud, adding Google's AI offerings was a no-brainer. So now, let's take a sneak peek at how we're integrating Google's AI infrastructure and modules directly into the game. But first, let's take a look at kind of where we're coming from with our AI. Our seedlings have been using a classic sense, think, act loop, something that's very well-known in game development. that. The seedlings start by sensing the world around them, like nearby objects or characters. Then they think about their surroundings and compare that against their internal state and their goals. And finally, they decide what they want to do next, and then they act on that decision. This continuous loop is what allows these characters to respond dynamically to the game world. But this approach has its limitations. Everything the seedling can consider or do has to be explicitly scripted beforehand. When the world gets richer and more complex, manually creating every possibility quickly gets out of hand. It creates a massive bottleneck and limits any chance of truly emergent gameplay. So, how do we translate this sense, think, act to Gen AI? What was sensed before becomes dynamic prompt creation. The think step uses a Gen AI module, and the act step takes that model output back into the game for execution. Let's break it down a little bit. For sense, we now use a RAG-like process, Retrieval Augmented Generation, which means that we are dynamically generating rich, context-aware prompts from our existing game systems. And these prompts, they reflect each seedling's unique situation and perspective on the world. Then for the think step, a Gen AI module takes this detailed prompt and comes up with a plan. The module's ability to reason about multiple characters simultaneously and plan multiple steps ahead leads to far more meaningful and compelling outcomes than our previous approach. Then, for the final step, the act step, we take the plan as structured output and we validate it against the game world. And only after it passes validation do we turn it into actual in-game actions. This is to prevent hallucinations. Also, players need to be able to interact with the game in a meaningful way. They need to be able to effectively guide their seedlings through lives. Going beyond the traditional methods, Gen AI introduces a new way of interacting, including being able to actually talk to their in-game characters. Let's see if we can wake up Jake here maybe just by texting him. Okay, Jake, you're going to have a busy day. Wasn't really up for it. One of the things Gen AI modules and overall these conversational modules is conversations. And for a game like ours, which is focused on characters and stories, this is a perfect treat. We're already generating stories that involve involving the seedlings. So now, we're actually enabling them to talk to each other as these stories play out. But beyond the seedlings talking to each other, we also enable the players to talk to their seedlings. This opens up new interaction possibilities by allowing the players to guide them, guide their seedlings through conversations. So players can ask seedlings to perform any action in the game. However, whether the seedlings choose to listen to their owning player is up to them. The seedlings might just refuse based on their personality or state. Technically speaking, this makes the seedlings fully-fledged in-game AI agents. They can operate autonomously, they can perform their own actions, they can use all of the in-game systems, and they react dynamically to the world and to the players' commands. Let's look at an example here, showing how stories can emerge between seedlings. In this example, we tell Jake to go play a video game with Emma. The model takes this player input and the current in-game setup and generates a story out of it. Crucially, the generated story isn't just visuals and animation. It changes the game state because the seedlings actually perform the actions within it. These actions then ripple outwards with real consequences, impacting things like Jake and Emma's relationship. And because seed is a persistent game, they remember all of their previous interactions. So following up on that video game session, now Emma talks to Jake and builds on that history. Notice how they are talking and thinking in their own characteristic ways. Jake is insecure and Emma, she is direct. The narrative evolves over time, completely unscripted. The AI is generating these in the moment based on their history and the current in-game situation. All right. Now, whilst these possibilities are amazing, let's talk about some of the challenges of working with such new technology. There's not a lot of best practices and the landscape is constantly changing. A key challenge for us was grounding the modules in our fictional world, essentially getting to forget about our current world. We want fictional characters that are both unpredictable and lifelike with their unique personalities. With a lot of these instruction-tuned modules, getting the default assistant persona that really just wants to help you, we kind of had to train that out of the modules. We are simulating real characters and sometimes they're just in a bad mood and we kind of want them to be able to be rude to each other. Another challenge was the lack of mature tooling for developing and testing prompts. So we had to build our own tools that allow us to iterate safely, easily tweak prompts and test different models. Having these tools enabled the rapid experimentation that we needed to really find out what works. Also, we're not just building against one specific module since we know that the modules are going to keep evolving. Instead, we're building in the ability to be able to adopt new modules as they come out. And because Gen AI modules are non-deterministic, observability is key. So for that, we have to route all the LLM requests through our central LLM router microservice where we can monitor how they're behaving in the live game environment. Choosing the right AI module for each specific task is vital. Definitely avoid a one-size-fits-all approach to your modules. For instance, toxicity filtering works really well with a lightweight module, while a complex storage generation task might need a more capable one. Make sure that we are optimizing our tokens both for cost and latency, especially focusing on the output tokens. Also, since we are generating an output that we're feeding back into the game engine, we can keep the machine-tested output as short as possible and being mindful of all of those extra JSON tokens. Thinking about cost and hosting, Vertex AI is really giving us options. We can begin with a paper token approach and move to provision throughput once we have the sustained load. Or, we can move to open modules like Gemma 3 and go with hosting it on GKE. So, to wrap things up, bringing C to life has been an incredible journey. It's been an amazing experience to see the game come to life in front of us and even more so with Gen AI. Also, really understand your platform. For example, GKE works best when you really embrace the cloud-native principles and the overall Kubernetes ecosystem. Treat scalability and cost as core architectural inputs from the start, not as afterthoughts. And consider not only the new gameplay that Gen AI makes possible, but also reflect on how it could help elevate what you already have, like we did with the SenseThink Act. And finally, experiment. You gain crucial insights by trying things out. And in games, the only way to know if something really works is to experience it. With that, we are really excited for what's next for Seed and for the future of these truly interactive, emergent, living game worlds. You can find us online at seed.game where you can sign up to be notified about all future updates and playtests. And with that, I will head it back to Ishan. Ishan. Thank you so much, Odur. This was fantastic. Can't believe there's a real game coming to life with generative AI in games. So cool. Well, you know, the benefit of working with Google is that you don't have to do it alone. We have invested a lot of time and resources into selecting the best gaming partners for our customers, for all of you. And these partners will meet you where you are currently to really drive game development improvements forward and realize your full game's potential. Together with our own technology stack, our solutions, our partners, we provide you with an entire ecosystem for living games that can address just about any challenge or opportunity. and with that, I truly can't wait to see all the amazing experiences that all of you are going to build using Google Cloud. Thank you so much for joining us this afternoon.� cro Experian, huh, cheers & без надlement of monde放課 for coming to the world. Thank you for buying more things and the of the else you our çünkü