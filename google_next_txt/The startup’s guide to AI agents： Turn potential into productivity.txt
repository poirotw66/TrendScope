 Good morning, everyone. Good morning. Okay, everyone awake? Day two? Okay, well, very exciting for me to be here. I got up this morning. I had a whole bunch of media and some press stuff today, so I had to wear a jacket. So I apologize. I'm probably slightly overdressed for this audience, especially in a startup conversation, but thrilled to be here. So just by way of introduction, my name is Oliver Parker, and I lead our go-to-market for cloud for generative AI. So very excited to have this panel here. It is, when we did our prep call, I will tell you not only was it lively, but I had zero control over the conversation. So bear with me today as sort of this rambunctious crew. We're going to cross a lot of topics, but very specifically, I believe today's session is about agents. So I only have like four or five questions, but I think you'll probably see us just based on our prep session, sort of navigate, and you'll be hearing from all of us along this conversation. So hopefully it's a meaningful dialogue for all of you to hear, and excited for the next sort of 40 minutes or so as we get into it. So before I jump in, obviously I'm very excited to have these founders here with us. I'm going to ask each of them to introduce themselves, and then I will get into the first topic. So Akash, why don't we start with you? Good morning, everyone. I'm Akash, co-founder and CEO of Bellum. We are a product development platform for product and engineering teams to build AI applications for production use. Super excited to be here. Hopefully you all have had your coffee. We're ready with some spicy takes. Spicy takes. Spicy takes. Just starting. Maya, on to you. Thanks, Akash. I'm Maya Gunima. I'm the CTO and co-founder of Thread AI. We're an infrastructure company building the AI enablement layer to help enterprises and customers build workflows and agents in highly regulated and air-gapped environments. Before starting Thread, I used to lead ML and AI infrastructure with my co-founder right here at Pound here. Thanks, Mark. Harrison, to you. Thanks for having us. My name is Harrison, co-founder and CEO of Langchain. We build developer tools to make it as easy as possible to build intelligent agentic applications. Good morning. My name is Kahal. I am the strategy officer for Core AI. We're a platform company, and we're operating with many of our clients at scale. We're focused very much on agentic AI. Many of you may have known us as a conversational AI company. We've been around for a decade, but we made this significant transition over the past few months, so I'm looking forward to having your questions and hearing the troublemakers here speak. Troublemakers, rambunctious. Thank you. Pick your analogy or adjective. Okay, so again, this topic is very much sort of agent, agentic AI and sort of what this means. Lots of conversations we're going to traverse. Quite frankly, we're going to start with a definition, which we thought would be a helpful place to start. I've had more definitions than I can possibly imagine at this conference. Then we're going to get into sort of more around some of the ROI conversations that, I mean, obviously myself and my team are very involved in it, and I'm sure we are here. We're then going to talk about building agentic systems and some of the work that this team have done. And then we're going to sort of start to talk about more what it means for startups and really where the future goes. So again, that's a lot to cover, but hopefully it'll be a fun conversation. So I'm going to start off with the definition quiz. Agents, agentic AI and Cajal, I'm going to ask you to sort of provide your perspective and then any of the other panelists, feel free to jump in and just so we ground everybody in the audience on really how we're framing this conversation. I just think it's a good place to start. Yeah, no, no, no, absolutely. Thanks. So, you know, when we think about this, we think about this as it's a piece of software, which has a couple of LLMs attached to it. And it's got access to tools. And then you as a startup get to decide what level of agency that you want to apply to those tools. And then it can solve some complex or very simple problems. But ultimately, it's software built on top of LLMs. Is a chat bot an agent then? That's software built on top of LLMs. Yeah. Oh, I think good question. Here we go. Yeah. Okay. See what I mean? And here goes the prep session. No, that's a question. That's a question. That's a question. That's a question we really do get from many clients. And it's a real one. And we often ask it in the context of, well, why? Not, you know, most people are focused on kind of a what and the how, but why? And if you have a solution or a problem where you need it to understand and provide reasoning and planning and then orchestrate the next step, then it's probably agentic. We don't see chat bots as really been in the agentic space because they really can't decipher a complex problem. So we think chat bots could be, but they really deal with very simplistic linear responses. So we see this as why do you consider agentic meeting those four criterias? And then you as a company deciding what level of agency or freedom that you want to apply to those complex situations. I think the level of agency is, I love that call out. I think Andrew Ng has a good quote where he basically said rather than talk about whether something's an agent, we should talk about how agentic it is and where it is on the spectrum and self-driving. There's different levels of autonomy there. I think I like that a lot. I think the more, maybe more technical definition of an agent that I like is kind of like the more agentic something is, the more the LLM decides the control flow of what actually happens inside the application. And I think that's in the same, like similar to what you were saying, people should choose that level of agency depending on what they need for a given application. I think in practice, like with a lot of the developer tools we see out there, most people probably, when they say agent, they probably mean something that runs in a loop and calls tools. I think like that's what most people mean in practice. And so this is something that I struggle with a little bit because some of the tools we build, like LaneGraph, allow for creating much more complex agents than just that loop. But that's what people mean when they say agents. And so I think there, I don't really know how to square those two things. I think, yeah, I think it's worthwhile to ground some of the conversation around whether or not it is an LLM-based agent. Because I think the term agent has been really bastardized in computer science and has meant a lot of different things. We just describe an intelligent system which may or may not have some level of autonomy and may or may not improve over time. But I think, yeah, to your point, Harrison, a lot of the existing excitement is around language model-based agents, which, again, I guess perhaps at the risk of sounding reductive are a loop around with a terminating condition, which might be a task or a goal, with access to external or internal systems, we can call them tools, and potentially some form of guardrails and, ideally, some level of compensating actions. And because when these agents misbehave or produce an incorrect output, there are ways to contain that. I remember writing a blog post about trying to define an agent, and a bunch of cognitive scientists got mad at me on Twitter because I didn't cite papers from 1980 or something like that. But I think that speaks to the point that the definition of agents has been around for a while, and, yeah, I think it's absolutely worth calling out that it's all up. I think for startups, I'd love to hear your opinion. Sorry for cutting it off. No worries. But, you know, for startups, really deciding on the level of agency, small and medium businesses, because there's a lot of startups inside of here, I think they may have the most interesting opportunity and flexibility to decide on the level of agency versus large enterprises. I don't know what you're seeing there. Oh, yeah, I think I completely agree. I also think that's where probably the most interesting applications are. Like, I think the application space is probably the most interesting space, and if I was building it, I would, I think there's a lot of, I think it's really hard to build, like, agents that are more autonomous, and it's not just, like, the models need to get better. There's also a lot around the UX and how you interact with them, how you put them in. But I would 100% be building towards that. I think that's the most interesting space. I think one thing that I'll add to this, so let's start with one of my observations. Oliver, when we were preparing for the session last week, you mentioned that Gartner has no, like, the hype cycle concept that Gartner created, agents have broken that concept. Like, there's so much hype around agents that it doesn't make sense in the hype cycle paradigm anymore. And we want to ground this in, like, just more structure on what exactly is an agent. So the way we wrote a blog post about, like, defining agentic behavior, kind of similar to what Harrison was saying on levels of agentic behavior. So the best way to think about this is if you model an AI system as a graph, the most basic agent is, like, a prompt that has access to tools. The next level of agency is where it actually controls the execution flow, the control flow with reasoning, tool calling, looping. The next level would be it has access beyond the workflow. So think cron jobs, scheduling, MCP. It has access beyond. The next level would be something that Google came out with yesterday, the A to A concept. This is agents having control across different workflows, and they can interact with each other. And the last level would be agents have full creativity. They can just do whatever. We don't know what that looks like. That's a very futuristic state, but it might come sooner than we expect. Okay. Well, I think I feel, actually, a lot more intelligent than listening to these four descriptions and, quite frankly, definitions. Hopefully that gives you all a good common framework for the next part of this conversation. Return on investment, a wonderful three-letter acronym that many of us have lots of conversations around. Akash, I'll start with you. Maybe just give us your view around, as you're building, you know, the products across your company and then sort of thinking of this, obviously, founders in the room or people that are maybe adopting your platforms and others, how to think about this concept with ROI and the role of agents and sort of the framework that you're using for building as well as the conversations you're having with existing customers or even potential customers. Yeah, absolutely. Let's put agents and AI aside for a hot second. Why do we build product? Like, why do we write software? To create, like, real business value. This could be higher revenue, more usage, lower cost. Like, usually it falls into one of those three categories. That's why we write software. Now, AI is no different. AI is also just a piece of software, and we need to use that to build product, which can either increase revenue, improve usage, or lower cost. And the interesting thing about ROI here is it actually creates an existential risk sometimes for incumbents because incumbents who are – I'll take, like, a random industry, accounting software. There's a whole industry of accounting software companies who've built workflows to help accountants and, like, in-house accountants, auditors with their own existing workflows using traditional software, traditional machine learning models. But there are dozens of startups out there that are going with a very AI-first, agentic approach, which will completely disrupt how that industry works. So for that incumbent, this is an existential risk. So forget about, like, revenue, cost, usage. If they don't adapt, they will likely die. It's a big risk. So sort of taking that sort of – that paradigm, which is an existing, much more structured, deterministic workflow and logic inside of an application in terms of what it delivers to then completely reimagining that workflow sort of through the lens of AI. And then – but that is the value statement, which will deliver the ROI versus an old legacy approach, which is sort of maybe ROI-centric at the time, but it's no longer. Yeah, I would just say start with what the ROI might be of this new use case that you're building, how it falls into those three buckets or the existential risk, and then work backwards on what product is needed to be built to achieve that ROI. Maya, I'd like to get your perspective on sort of the conversation as well as sort of the realistic expectations of agents and ROI and sort of what you're seeing. So typically the approach that we use with our customers is understanding whether they're building a new workflow or a new product that hasn't been possible before AI. And for that, obviously the ROI and metrics are measured very differently and mostly centered around the output of what this workflow, what new value it is creating. But in many other cases, our customers are using AI to enhance or replace existing workflows. So for those cases – so for example, common pattern, we work with law enforcement, something called after-action reporting, which used to be a very manual process and involve a lot of analysts who would listen on incident audio, transcribe them, summarize them, join them with external data, and potentially produce reports, which used to take days, but being able to do this securely and durably with AI could shorten the period of time to about a few minutes. And for these kinds of workflows, there is tangible metrics against existing workflows. But I think the core – I think the fundamental thing is since a lot of the AI workflows are experimental by nature, investing in a lot of the experimentation infrastructures so that you can compare how the workflow is doing against an existing workflow. But obviously, yeah, to your point also, a lot of what AI is going to enable is fundamentally going to change the way we work, which, I mean, in the short term, yes, some jobs are going to go away, but the idea is that people can apply that time into other kinds of work, so getting better at reviews or distilling information, not information aggregation. I think that idea of, like, applying the time elsewhere is pretty interesting. I was talking to an executive yesterday who was talking about the software engineering tools that they were bringing in, and I think the result that they were seeing is, like, yes, great, it made their engineers more productive, but they didn't work – they just worked less. That was kind of, like, what they were seeing. So they were having a tough time quantifying that kind of, like, ROI. And I think the places – some of the places where we have seen it take off are where – I think customer support is, like, a pretty obvious example of where it's pretty easy to kind of, like, quantify that ROI as well. You have deflection rates. You have people doing this before. A lot of that is measured in kind of, like, saving headcount and increased kind of, like, efficiency gains there. I'm curious whether this is different from previous kind of, like, NLP applications. Like, you said you were building chatbots before, agents and AI. Have you seen a change in how people measure ROI there? I think the conversation – you're spot on. We've seen ROI show up first in customer support, software development. And the conversation has been built around cost takeout. That's evolving. And I don't think the end game can win with cost takeout. When I talk to clients, cost takeout is still part of the equation. But sometimes it's for talent, right? How can I have AI solutions on the desktop so I can compete? Part of it is employee satisfaction. How can I take some folks who might work 12, 14 hours a day and just have them work 10? So that's never going to show up in cost takeout. But it will show up in employee satisfaction and your ability to compete to source talent. And then I think the ultimate game is where is the ROI going to show up in revenue? And I'm not sure too many conversations are taking place there at scale. There are some there. So I think it's really critical for a company, as they think through the ROI, to pick the metric that really matters to them. Like the most recent case I came across this morning, we've got a bank coming in to visit us. And they want us to look at how can we speed up the process for bereavement inquiries. So very sensitive. Interesting. You know, very, you know, and if you think about it. I wasn't expecting that one. Not that one, but I'll surprise you more as we get up. But it's such an empathetic experience. How do you get that data as fast? And there's so much anxiety around that. The metric here can be just speed to market. And that's an ROI so you can solve a lifetime client or their beneficiaries. But it's still kind of around, like, efficiency of getting an existing product to market. How do you see people thinking about, like, evaluating ROI of, like, net new revenue kind of, like, opportunities? You're probably getting to question five that I was going to answer, but I'll answer here. So we've got a client. You're actually supplying this client as well. So we do work together on this. You have 15,000 wealth managers. And their traditional way of going to work was listen to the research analysts for two, two and a half hours. And then digest what that means. And then figure out, oh, who are my clients with this profile? And then they might write to that client by the end of the day. The opportunity to be in market by whatever time the stock market opens on the East Coast, at 6.30 West Coast time, they've missed a day. We can have them, through RAG, through automation of an email, have that decision or recommendation to a client by, like, 6.31. Their turnaround time was the metric. That turnaround time allowed them to get into market, allowed their clients to make decisions. And obviously increased their fees that they managed. So we see revenue showing up there. But it was turnaround time was the metric. And we also saw this huge, almost two and a half hours of capacity created for labor. So think about the redeployment and your ability to manage more clients, manage more clients effectively, and secure your fees. I think Maya said something for me that just resonated and sort of, you know, I did a panel with the CEO of Verizon this week. And they've been on our, what is our customer engagement platform? It used to be called CCI, sort of a contact center AI platform for a while. And he's like, you know, they've been super instrumental as a build with partner. He's like, the whole focus on this was, you know, call deflection, call containment. And he's like, as we've done that and we've seen higher satisfaction, because it was fundamentally it was an efficiency play. We're also using that now as a revenue play. He said that started off as cost efficiency, cost takeout, which led to better customer experience, better customer experience, better NPS scores, better NPS scores is now. And it's now becoming one of their primary revenue channels. So I think a lot of these, what started off as cost efficiency sort of parlayed into sort of productivity to capability to customer experience will lead to. But the one thing that Maya said that I think is that I've noticed is new workflows I still think are not at scale. I'm seeing a lot of existing ways people do business that is completely being reimagined. But new businesses that are not yet or complete new workflows or if you're a product company, complete new products, that still for me still feels quite nascent. I think that's where we'll see an even bigger acceleration where it becomes much more revenue starts versus it starting in efficiency that leads more towards revenue. I think the word containment was a bad word for about a decade. And it may be a good word going forward because it had so many negative connotations about customers ending up in the loop. And I think that's an indication of where the models have evolved to. One small point I'll add on this is revenue also ties to market share. So we have a major customer in the real estate space. You guys may have used that product. But they are building more and more AI-first applications in their core product. And they're winning market share. And that leads to more transactions that happens on their platform. That's fascinating just to see increased usage leading to more market share over competitors. And these are adjacency businesses that they're now moving into. Yeah. Okay. Good start on ROI. We're sort of on time. I'm going to transition to building agents. I'll start with you, Harrison, because I'm the moderator, not you, just so you know. I'm changing as I go through this. In simple steps, maybe just highlight your perspective, I think, for the audience. The fundamental steps involved in creating an AI agent and what you're seeing with your client base. Yeah. I think if you do it right, step one is, like, really focusing on the use case you want to build, the thing you want to do. It sounds kind of basic. But I think a lot of people see LLMs and hear about agents and just want to go applying. It's everything. And that's great for experimentation. And there's a place for that. But if you actually want to deliver something, I think really scoping down the problem that you want is a really crucial first step. I think if you do this right, this can look like, you know, if there's a task that you can write, like, kind of, like, step by step how a human would do it, I think that's a great thing to be automated by some of these agents. And so writing that down and the tools you would need and the logic you would need to tell a smart intern how to do this, like, really scoping that down well is a great first step. From there, I think it's making sure, I think a lot of building agents comes down to communication, actually. Communicating to the LLM what it's supposed to do. If we bring in a really smart intern, I wouldn't just expect them to show up and be able to do all the things without us telling them how to do it, right? We have to give them, you know, a Google Doc that walks them through steps on how to do things. We have to give them access to different systems so they can check things. So I think, like, making sure that you have all these different aspects of communication, whether that be, like, instructions or tools or things like that, I think that's kind of, like, a second step. Then you kind of build it. I think it depends, going back to, like, the levels of agency, depends on the problem. How much do you need? Start simple, then get more complex if you need. After you build it, I think then it's really about testing it out and making sure that it works. I think LLMs are great because they're so general. That also provides a bit of a problem because people might try to use your solution in ways that you didn't first anticipate. And so having that visibility into how users are using it, building test cases to test for the cases that you care about, and also maybe putting guardrails around it to guard against things that you don't care about. I think that's when you get to something that, by that point, you've got something that you can show to people. And there's more stuff after that. It's a long journey. It's not easy. It also, besides that, people seem to think there's a silver bullet for just building agents super quickly. There's not. You see it takes real engineering teams and real subject matter experts working with those engineering teams. And so it's not an easy process that you can just do by filling out a prompt and connecting it to an MCP server or something like that. I guess the approach that we took when we built out our platform was learn from a lot of the workflow orchestration companies. They've solved for a lot of the hard durability problems, so it didn't make sense for us to recreate a lot of these primitives. So there's a lot of value in modeling some of these problems as workflows. So for us, distilling these into a series of steps, we call them states. Each state has a function. A function could be gRPC, could be REST, could be GraphQL, and then you apply some of the durability guarantees. And every data flow that runs through a system is a run. The idea is you scope the memory to that particular run so that if you have multiple runs, you're not sharing data unintentionally across state. And you still follow the same fundamentals of fine-grained auth and different kinds of authentication. And the key for us, even if you want to build some of these more agentic workflows, is being able to have these building blocks to potentially unfurl this recursion. Because in a lot of the spaces that we operate on, we can't just have a magic agent black box. We have to be able to narrow basically the unreliability, the non-determinism, to purely the language models. And everything around it should be traceable, unobservable, and potentially repeatable. So things like time travel or being able to undo certain actions. So for us, basically taking an approach of a fundamentals, building blocks first, and then adding maybe some UX or SDK sugar, syntactic sugar niceties for people who just want to build an agent with, again, like, I guess, focusing on the workflow orchestration fundamentals. It's interesting that you started with workflow and mimicking existing workflow products and how they think. I think that's spot on. I mean, our approach is also very similar, like workflow-oriented. The way we think about it is, like, AI development should be, like, a test-driven development approach. So imagine, like, a circle. The top part of the circle would be experimentation. So defining the logic of the application. I'll get to it in a second. Next is evaluation. So those two kind of go hand-in-hand, evaluating your definition. Then deployment into a staging or production environment. And then monitoring that application once in production to identify edge cases. This feedback loop is super important because in the experimentation phase, you're trying out different models, prompts, tool call definitions, orchestration. And then the evaluation logic, that needs to be tightly coupled with an eval suite, which has test cases, metrics. You might be testing individual nodes or the whole system end-to-end. It's an iterative process to get the definition right. And then once you have the application in a staging or production environment, edge cases happen all the time. There's no ‑‑ AI is sometimes still very unpredictable in production. And identifying those edge cases quickly so you can add them back into your offline eval suite. So the next time you make a change to your definition, you just move a lot faster. I mean, you're sort of talking about a completely new way of building agentic-based systems versus traditional application development. And I'm sure that's probably what a lot of you are living in. But if I think about my conversations with traditional industries, they're trying to rethink complete new app development cycles almost as an AI development cycle with an agentic framework. So there's actually complete new paradigms. A small point of that, and then I'll let everyone speak. Traditional software is linear. You start with a spec. You build for a bit and test at the end. AI is nonlinear. It flips the paradigm around. You are trying out stuff, evaluating it, getting cross-functional stakeholders involved in the development process. It flips the paradigm entirely. And engineering teams need to start adapting to that. Okay. Gahal, obviously you referenced how long Core AI has been around, but also what you've done to completely rethink your products. Maybe some context around this, around sort of building agents and what you've done at a systems level. Yeah. I'm probably going to approach this a little bit from the business side because your question was on where do you start. You've got to have a line of sight to where is this going to end. And what I mean by that is so many companies are, let's call it, tinkering in the experimentation phase. The responsibility we all have is to be able to compete better in the marketplace and differentiate our company. So when you get into a proof of value or proof of concept, I think you have to have your eye on a proof of scale. And there are so many companies who are stuck in the experimentation. We just did some research and like only one out of four get out of experimentation. So peace, I agree with everything that has been said here. I would probably add two things. Whenever you start, think about how you get the proof of scale from the proof of value. And then I would also suggest that you bring in governance earlier in the process if you want to get to scale. We operate in very regulated environments, banking and healthcare. So bringing them in earlier. And then I think there's a major decision. Forget about build versus buy. That's a fun conversation for another day. Every day. For later. Every day. Every day. It's do you want to have a point solution or do you want to have a platform? Because that's ultimately going to inform the ROI. It's going to inform the use case scaling across the enterprise. So yes, start, experiment. But be one of the four that gets out of that phase into scale. So you can truly differentiate for your company. Anything more for many of you before I jump into sort of the next topic, which is really around adoption, integration. Anything else around building that's helpful for the audience you want to share? We've seen adoption come. It's very often driven by the philosophy of the company. Like we've won just amazing prospect we're talking today. They're operating in the creative space. And they are really about democratization. Give it to the team. We'll create the walled garden for them to thrive. And that's driven almost cultural. It's a cultural thing. Adoption is tricky. We were talking to one company just this week. They've seen a 10% lift in total productivity. But underneath that, they've only seen a 5% adoption. 60% have never logged in. 20% playing away with it. And a full 5% are driving this amazing productivity, you know, 7x return. So I think the ROI metric is interesting to look under the hood. Adoption will drive the ROI. There is the fear of, you know, how does this impact my work, my position. And then I think there is very much a cultural aspect to it as well. How does this allow the creativity or not inside of an organization. Do you think the sort of the fear factor, sort of the normal knowledge worker, do you think that's only heightened with fundamentally sort of the rise of these agentic-based systems? And it's just elevating that. I mean, there was always a lot of fear just around knowledge retrieval, chatbot, assistant type, okay, question, answer. Now you're getting into sort of these assistants. Then you start moving into more sort of semi-autonomous, autonomous systems. Do you think that will increase the fear? Do you think some of the adoption is actually just having people actually embrace it more? What's your perspective on that topic? I think kind of related to building. It feels like a lot of enterprises and just companies or people are caught up in the hype and fear. Hype of what agents can do and fear of what happens if they do the thing they do. But my take is just start somewhere. Like, get a simpler use case into production. Build the reps. Understand how this new piece of technology is very different from traditional software. And then move forward. And going back to the ROI point, like, get the ROI from your simpler use cases. And then get the reps to go out and build more advanced use cases. I think there's going to – it's an interesting space around there will be some fundamental parts that do replace knowledge work. But at the same time, if done incorrectly, you might be creating more work for that knowledge worker. So, for example, grounding it back to an example, workflows where you're automating answering to questionnaires. That used to be a person going and sifting through different disparate sources of information. But even if folks decide to adopt AI and want to have that human-in-the-loop review motion, you have to – the product has to give them the right pieces where there is an easy citation, where they can go back and actually review. Because you can't expect the human-in-the-loop to also brute force and redo the work of AI. So, I think it's going to be interesting also an arms race around who has the best dev-ex around some of these products. Again, another point, Maya, made is I think sort of – and I've actually just hired a whole bunch of UX developers as part of my technical team. I have a whole bunch of architects and sort of – but they're more of the systems and the infrastructure layer. But I'm now hiring more dev and UX people because I think – and my sense is sort of when you start thinking about enterprise adoption, scale adoption is going to happen through much simpler user interfaces and workflows being integrated in a much more user-intuitive experience. So, I'm seeing a higher demand right now than I ever have for just a different UX to take advantage of some of these capabilities. Okay. Threading a little bit further, adoption integration. You know, we talked a little about the hype, some of the fear, and sort of some of the misconceptions to what agents are. Again, some of the conversations I'm in, and hopefully this will be a good tee-up, and Maya, I'll come to you first. Security is becoming increasingly relevant as well as just sheer proliferation, especially on the agent side. Again, I forget who it was. We – for those of you in the keynote yesterday, we launched our agent developer kit, which is really us sort of pushing in, and we have a whole bunch of partners in the ecosystem with our systems integrators and third-party ISVs starting to think about protocols, frameworks, the agent-to-agent stuff. That's some of the, I would say, questions that we're getting sort of on a broad ecosystem level. And then, obviously, industry standards and all the regulatory requirements by industry, by region. I'd love to hear from any of you, and Maya, let's start with you, just around some of the adoption and integration challenges and questions you're getting and how you're thinking about it. Yeah, again, to pull it back to fundamentals, I guess a lot of it is understanding that when you're operating with some of these enterprises, they have already invested in a number of systems, whether it's for security, if all of their flavors of models are, say, behind Okta or any other provider, being able to provide them with a tool that can provide value at the right insertion points. So you don't want to reinvent authentication for them. You want to be able to still follow if they have security groups and their own notion of what access control looks like. You want to be able to build a system that can weave these AI or orchestrate across these systems, but still following these fundamentals. And again, a lot of our customers where we have to operate in air-gapped environments, being able to create potentially these agents or workflows that don't take a hard dependency on a particular provider. So you still need to be able to create that agent with different kinds of models. But obviously, yeah, like for folks who are in particular cloud providers, you want them to take advantage of the best in class of the tools that are available. And, yeah, I think mostly... Really thinking about existing security platforms, obviously authentication identity platforms, but then also not hooking yourself to specific technology. Exactly. And probably hyperscaler candidly, they may be either one way or another depending on the application it's interfacing with. Yep. Harrison. I still think the biggest blocker for a lot of people is just building agents that work, to be honest. We did a survey end of last year, and we asked people what the biggest challenge was, and the biggest one by an order of magnitude was just building, just getting it to work, reliability. And then after that, it was latency and cost, and then after that it was kind of like security. So I think the biggest blocker there is honestly probably just having the know-how inside the company. I think there is a massive overhang in what you can do with these models and all the applications that exist today. I think if model progress stopped, we would still be able to build a ton of very interesting applications. I think the issue is just a new technology and that kind of like knowledge and know-how isn't as prevalent as it needs to be to enable. It's great to start talking about these multi-agent things and we're very interested in this multi-agent protocol, but I also think it is a little bit ahead of where we are right now. You mentioned one second, you said, okay, it's all starts with reliability, that's the biggest issue, you've got security and then you've got cost. Do you think once we start to solve the reliability issue, those things just are now things that we have to go unblock, or do you actually seeing progress against all of those areas? I think there are things that will have to go unblock, yeah. I think like, you know, I'm kind of a simple guy. I like to focus on like eliminating the blocker at hand and that's kind of how we've thought about our product development. Yeah. Like I think like LaneChain tried to make it easy to get started. LaneSmith, we saw the blocker being, okay, it's easy to start, but people don't actually know what's happening inside. Okay, great, build good observability. Now people know and they want more control and LaneChain didn't give them that. Okay, great, build LaneGraph. Now they can build an agent that's reliable, how do I deploy it? LaneGraph platform. And I think, yeah, after that, like, you know, I think security is still a massive issue. And we're not going to solve all of these, but I think at least the approach that we take is a little bit more focus on the blocker at hand. That's not to say that like focusing on things in the future is bad or anything like that. And hopefully when, hopefully others will solve those so that by the time we catch up there, they're kind of solved. But I think practically speaking, I think if you asked most people in enterprises what the biggest challenge today is, it's still building agents that work reliably. I think Harrison's spot on. Protocols are important because agents ultimately need access to tools and having one place to get all the tools would be great. But we're not there yet because LLMs are still making mistakes with basic tasks. For example, we were working with a customer on some use case. And one of the nodes in the graph was a multi-class classification problem, which had a prompt with 50,000 tokens. And it was working just fine. But suddenly something happened and all the eval cases failed. Like, wow, what's going on here? And after some debugging, we figured out that it was a single non-visible blank space token that just threw the whole prompt off on one simple multi-class classification problem. That's crazy. And we can't have, like, if that's what models do, that's what they do. And we can't expect them to just call tools arbitrarily in a protocol. Yeah, no, I think Maya touched on an important subject maybe 10 minutes ago, and that's traceability. You know, security, you're either going to prevent or you're going to recover fast. Recover fast is very much driven by, you know, traceability. Prevention, you know, when we worry, we worry about, you know, how many point solutions is a company really going to bring into the enterprise? And then the more point solutions you get, I think the security issues compound. So you really have to think about what is that orchestration layer? What is your platform choice? But I agree with Maya. There are security protocols in existence inside of companies. You've got to leverage it. I think I mentioned it earlier. Bring in your governance really early on in the process. And when we think of security, you think of it in many levels. But also you have to start thinking very, certainly in regulated businesses and deregulated, you know, the customer privacy aspect of security. Because we're using customer data a lot more. Yeah. And the ability perhaps to make sure your platform anonymizes that data, I think is really, really important consideration as well. Okay. We're going to transition into the last topic. By the way, big plug. If you haven't got your camera out, see the QR code. So it's really, and we had a couple of inputs from Maya and Harrison in our future of AI perspectives for startups. So I put it in Gemini this morning as a refresher for myself and did a quick summary. Just a plug for Gemini 2.5. You can use Flash, by the way. It's just as good and it's cheaper. It wasn't. The requirements of 2.5.5 were a little bit overloaded relative to doing a quick summary in a document. I'll leave it at that. Okay. This is sort of a, we'll go whistle-stop tour of the last few moments sort of for each of you. The future of AI agents and how you think that will actually reshape the startup and broader ecosystem. You can get really tactical. We can go philosophical. I will, based on the rest of this, my sense is you'll go wherever you want to go anyway. But we'd love just to get your perspective on that, on that topic. Agents and what it means for the startup and broader ecosystem, where you think this goes. We're redefining how business is done. It's nuts. It's such an exciting time to be developing software right now. Startups are coming at it to display incumbents. And try to change what they're doing to survive. And I think the industry or just how business works and has worked over the last 100 years is going to look very different in the next 10 years. So this rate of change is unprecedented. And it's a very exciting time to be alive. That's awesome. Thank you. I think it's exciting that there is consolidation around protocols and people are, I guess, excited about frameworks like MCP. But I think it's also alarming that a lot of the push is coming from an AI enthusiast environment. Which makes sense because a lot of it is contextual. Folks who have, if you're running everything on your desktop and you're just using MCP to Vibecode on cursor, it's perfect. But I think the problem. That is not the normal world for most companies. But if you are. I was just waiting for when Vibecoding was going to show up. It took 43 minutes and 26 seconds. But I think, yeah, on a serious note, the problem is a lot of the fundamentals. I guess we need to bring in the distributed systems community and the security community, especially if some of these protocols are going to have a stance on authentication. And it's not just about how you're prompting the language model. So, like, specifically, I know, like, a few weeks ago, MCP introduced the concept of a tool annotation. Which, if you read the spec, I guess at the heart of it, you are hinting the model and giving it some hints about what tools to use. But the parameters that are passed are, is the tool destructive? Should the tool access the internet? Which is obviously crazy sauce if you don't have an external process that's governing your ingress and egress. So, like, a lot of these concepts are fine as long as, like, folks understand the context and the nuance of when to apply some of these. And I think it's just, yeah, as long as, like, there isn't a case where someone puts an agent in a mission-critical financial transaction and causes a big mess, I think. But it's broader input into these standardization frameworks and protocols with all industries, not necessarily some of the leading model providers or whoever. Yeah. But I guess it is fun for folks who are in security. I guess good for Wiz. And, again, that also took almost 45 minutes before Wiz came up. Harrison. I think you touched on it earlier, Oliver. The UX, I think, is the most interesting place for, kind of, like, the future of these agents. I think there's a big overhanging capabilities and trying and discovering new UXs will unlock a lot of them. Yeah. Yeah, look, this is the ultimate accelerant. And I would encourage people to think about how do you make trust your moat? And I think there's a unique opportunity for younger companies to make trust their moat with AI. It's a great thing to finish on, trust. Okay. Well, listen, please give a round of applause for our panel. Thank you very much. Thanks. Thanks. Thank you. Thank you. Bye.