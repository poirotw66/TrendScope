 Hello, Next. Thank you for being here. We're going to get started with Fireside Chat. I'll begin with introductions. As mentioned, my name is Kevin Lockridge, and I am Deloitte's Lead Alliance Partner for Google, which basically means I get to have a lot of fun with Google technology as we take it to our most important clients. I'm here with Parth and Ramnik as we're going to do a little bit of a Fireside Chat. Maybe we start with intros. Ramnik, over to you. Thank you, Kevin. Wonderful to be here. Wonderful to be in the spotlight, if I can say that. I'm the Chief Data Analytics and AI Officer at USAA. Lead the enterprise teams that support all of our businesses. We have a property and casualty business, a bank, and a life insurance company. And we support those teams with data platforms, data engineering, data analytics, and increasingly generative AI and AI development that we do out of the enterprise. I've been doing that for my career and prior to this with Wells Fargo and many other financial services companies. Very good. Thank you. Parth, over to you. Good morning, everyone. Parth Patwari. I lead Deloitte's AI and data business. Grew up doing a lot of financial services, data, analytics, and AI work over the period of time. And what it really means that leading this business, it's threefold developing strategy for as we go to market, providing tools, capabilities, and making sure our practitioners are ready to make an impact for our clients. And then lastly, we do a lot of Deloitte and Deloitte work, especially for Gen AI, and our team supports that. So happy to be here. Great. Before we get into the questions, I'll just reflect for a moment about the keynote. So for those of you that were able to be there or at least watched it on YouTube, I was really excited. Things like Ironwood, Agent Space was announced. We're big. We're very excited about Agent Space within Deloitte. We're also excited about the new agent-to-agent protocol. So I think there's a lot of great things that are happening with Google all around AI and cyber. And so we're going to talk a little bit about that today. So the first topic is really around AI and agentic innovation at USAA. So Romnik, we know USAA and customer experience is an anchor. It is a North Star for your institution. How do you think about customer experience as it relates to AI? And how do you make the decisions around where you should apply AI and how does it support that experience? Yeah, Kevin, I think to understand our approach to AI for customer service, you have to understand a little bit of the business context of our company. We are a very unique company, 103-year-old company formed by 25 army officers to ensure each other, to ensure each other's financial security. And it's that mission at our core, which is to help our members. We call our customers members because we are an association. It's to help our members with their financial security. And we are a differentiated company in a very commoditized market. Our products are largely commoditized. But we have the honor of having the highest NPS scores year over year. We are the number one bank in the country, rated by American banker Forbes and others. And so we have this very differentiated offering in a very commoditized market because of how we serve our customers, our members. And so our approach to AI has been to retain that differentiation that we have of serving our customers with excellence and really using the power of AI to make ourselves even better at how we do that. And so a lot of the focus and solutions that we've had in the company are oriented based on us doing that. This is just an image of how we serve our customers after there's a catastrophe. For example, the Los Angeles wildfires. We are not just available on phones to pick up our members' calls. We are out there. We have a mobile unit. We call it Eagle One that's deployed wherever there's a catastrophe. And our member service representatives are out there being the empathetic human beings in times of need for our member and being there for our members to assure them of financial security in some of their worst times. And our vision rally with AI is how can we free up our member service representatives our secret sauce to do what they do best, which is connect with our members, be the empathetic human being on the other end of the phone line or in person, and not be focused on where to find the information on what the member is asking or what forms to fill out or what buttons to click, how to navigate our systems and platforms. So our vision rally is with AI to have our member service representatives work without touching the keyboard. The KPI for success for this part of our vision is what if we take away the keyboard? How many MSRs can be effective at completing the intent of the customer without a keyboard at their desk? Of course, we are not there yet, but we have started down that journey. We have enabled AIs that can answer the question that the member is asking through the MSR. So the MSR is not reading up documents, trying to find the right procedure or the right information to answer the question the customer is asking, but they can have a natural language conversation with all of our knowledge bases and be able to address the need of the customer. And that's a powerful way in which we can enable our representatives. Of course, we'll be extending that to then automate what they have to do. So the MSR doesn't have to do anything. They have to just be present and be there in the conversation while the AI is listening and doing all of the things that need to be done to fulfill the customer's intent. So along that path, there's this aspect of improving customer service through AI, but we have core products that we can improve through AI as well. And what you see here is after unfortunate incidents like wildfires, many of the homes that we ensure for our members are completely destroyed. Why does the member have to file paperwork and wait for weeks to get a payment when from aerial imagery, we can certify, verify, be 100% sure that the home is completely destroyed. So that's where the power of AI comes in. We can use aerial images such as this to identify our members' homes, identify that it's a total loss, and make the claim payment even before the claim is filed. And that's powerful because after an event like this, you're trying to reconstruct your life. Having money in your pocket is a massive reassurance to you. You can be first in line to get the contractors that you need to rebuild your home, first in line to get temporary housing because you're armed with that claim payment. And you might think, well, one should be able to do this with aerial images without AI. Why do you even need AI to say it's a total loss? You can see it. Obviously, we can do this at scale because of AI. But at the bottom images, you see after a wildfire, there's smoke that's obfuscating the view. There's also vegetation, typically, that's obfuscating the view of the house. And we've trained models that can actually filter out the vegetation and the smoke in the scene so that you can even see the home, which on the bottom right you can see is again a total loss, even through vegetation and through thick smoke. So all of this helps us to pay out claims faster without adjusters actually being on the ground when it's unsafe to do so. So after the Los Angeles wildfires, which right around Jan 31st is when we finally got control of the wildfires, by Feb 5th, that's five days after we had paid out 86% of our claims and we had paid out over a billion dollars in claims payments. So that's how we are out there for our members to serve them in their time of need. And AI is a massive opportunity for us to do all of that even better and at higher scale. So I really like those examples. Thank you. I think the part... So we talk so much about AI being focused on efficiency. And you explained at USA really it's focused around that customer experience and customer service and how do you do those roles better. So I appreciate those examples. They're fantastic. Yeah. Hey Parth, maybe you could talk a little bit about your perspectives on how other companies are approaching AI to support this similar to what USAA is doing, maybe something different. Yeah, I think, you know, what Romney was talking about, using AI for the moments that matter is the right sentiment. For us, you know, it has played out, I think, two different ways. One is using AI for the right full set of instances where there's a value generation, there's a value measurement to that. So, for example, if you were to go to a bank and if you are a non-US citizen and you provide an identification card, they are going to check that, you know, is that an acceptable form of ID or not. Now, how do they check? They don't... Every single banker that sits in the front of you, they don't know everything. So they are going to go and make a call or they are going to look up somewhere. And you would not believe with the large banks, they have like 500, 700 different types of instructions that capture in which forms, instances, which type of ID is applicable. So for one of the banks, we ended up building this utility that allows them to just type the question rather than call one 800 number internally. And now there is suddenly $30 million of savings on the back of it. Similarly, for Deloitte, we are in a business of making our customers' life easier and creating value for that. But to do so, if you were to look at data as a fabric that you can stitch across different industries and different utilities, Kroger or any of the grocery stores, there are hundreds of them. And if every single grocery stores, their energy utilization is massive. If you were to create a utility that says, well, I'm going to figure out, based on the geo-special data, where this store is sitting, how much energy they are consuming, because smart meters will tell you that. And then you can go back and figure out, is there any other different form of energy consumption ways you can utilize, and subsequently work with a bank to create a leasing vehicle. Now, that's a very different type of business one can structure on the back of it. But that gives value to grocery stores, to the financial institutions, to the energy company as well. And that creates putting data at the midst of everything. So that's the way we have approached using Gen.AI to create value. Very cool. Let's pull that thread more around value. And so, Romnick, the AI hype has been incredible. I think of it at times as we're on a hype curve with rocket engines. Some people have thrown out there that maybe there's not value in it. That's not me. I'm just saying that it could be. How do you and your team at USAA think about a scenario and whether you should apply AI to it? And think about the value that can be created with it? So let me take it to my industry, to property and casualty insurance, and take an example. There will be a time, I can't predict how far out, when the cars all have enough sensors in all of their parts, in the body of the car and so forth. And there's enough video recording by every car, the one that's involved in an accident and the ones around it. And all of this information, if there is an accident, an AI agent in the car will transmit that to an AI agent at the insurance company, which will then analyze it, determine if the accident is covered, and relay that information to an AI agent at a repair shop. And then the car will be instructed to maybe even self-drive to the repair shop, right? That will happen. It'll happen five years out, 10 years out, hard to predict. But today we, and I would put doing that today in the category of AI hype. But doing what we do today, which is we get thousands of pages of unstructured data, video captured from the accident scene, photos of the accident scene, the verbatim report that we call it the first notice of loss that the insured conveys to us, the police reports. All of this unstructured data is very tractable now with the power of the AIs that we have at our hand. To take a call transcript of a conversation with a customer and to pull out some upsell, cross-sell, or unique opportunities to even give advice to the customer, that's here and now. We saw that in the demo during the keynote as well. So I think there's a lot of things that companies do, ourselves included, which is very much in the realm of tractable by AIs of today to a degree of reliability that we can actually roll it out. So I think there's incredible value to be had from these technologies. We have set up a value framework. We look at how we can either impact revenue or expense or experience, which we do value a lot and we assign value to improving customer experience. Or even lastly, to improving how we manage risk. After all, we are in the business of managing risk. And if AI can enable us to manage our risk better, that's a huge value as well. So we track every AI project through this value framework. We, not just do we say we expect it to have this value, we actually measure it on the back end of it through telemetry and instrumentation to say, is it producing the impact we thought it would produce? And that's how we are trying to make sure that the work we are doing, the investments we are making in building AI solutions are giving us value today. So maybe just a moment on that value framework. Has that value framework shifted at all since you started doing some of the AI development and deployment, as you and the team have learned a bit? The framework itself, so what we assign value to, revenue, expense, risk, or experience, hasn't really changed. It's what we have been applying to our technology projects. But the way that we do the telemetry and the way that we measure that value, I think we are learning a lot in that space. To arm one of our back office teams with a tool that can save them 30 minutes a day, you have to measure that, right? You can't just say, because now I have an AI assistant that can answer my question. Well, so how much did that improve your productivity? And that's some of the challenges that we are working through for software code writing assistants, for workplace AI, just knowledge work assistants, for our back office assistants, to see how can we measure that value in a way that is real to us in terms of revenue or expense. But it's also real to the employee, as in they can truly do five more cases a day because now they have the AI assistant. Very good. I'm a big fan of the measurement of that impact and monitoring it. Let's shift a little bit towards AI platforms and solutions. So we've talked a little bit about some of the solutions you've deployed, whether it was things like the, I really like the wildfire example that we have just shared. How do you think about deploying AI architecture and look Google powers into USAA? And you mentioned over 100-year-old companies. So obviously there was some legacy technology in there. So how do you plug those two together? Yeah. Look, I think this is a constantly moving space. And with every announcement, including today's, there are more tools at our disposal. And we definitely re-look at how we are architecting our solutions. For the 25-plus solutions that we've already deployed with generative AI, I would say most fall into the category of either standalone RAG solutions or pipeline of RAG solutions. We have, I mentioned, arming our MSRs with a natural language tool to search our knowledge bases. For that, we are using Vertex AI search. And we have vectorized a lot of our unstructured data. And these are the architectures that are real today. I think a lot of the agentic architectures that are coming through now, we are already experimenting with them. And we'll be deploying those. We have to get to that point. We are somewhat in the web analogy. The first phase was static websites that just gave you information, right? No buttons to click. We are obviously so far from that now. Agentic is somewhat the same way, right? The first generation of tools just gives you information back. But arming the AI to be able to then take the actions, giving it all the tools, giving it the power to think through which tool to invoke when. That is definitely the next step which will open up so many more use cases for us. And we are hard at work to do that now. I remember those static web pages and flashing HTML was the big excitement. All right. So, Bibi, we've talked about customer experience. How about are you using this to do any of that data management work and analytics? Yeah. So, we certainly don't want it to be a case of, you know, the cobblers' children have no shoes. And as a data analytics team, we are looking for opportunities to help ourselves with what we do. And there's a lot that can be done for metadata generation, right? Writing business metadata. Writing good, usable, meaningful business metadata. In my career, I have never seen anyone do that comprehensively. This is our first opportunity to actually take all of the data that we have and assign it good business metadata. But not with humans doing it, with AIs doing it for the most part and humans reviewing it or reviewing some subset of it. And I think that's a huge unlock as well for how the world at large uses data. Unstructured data is now, I call it first class data, right? We all did analytics on tables, on tabular data forever. We now have the opportunity to do real insightful analytics on unstructured data. Take CRM, for example. In any CRM system of today, you're capturing a few structured data elements out of a very rich human conversation you had with a prospect or with a customer. And that captures barely anything of the richness of the tone of the voice. You know, was there excitement? Was there conversation about any aspect of the customer's operations and so forth? But with AIs, all of that conversation is now data, right? Six months from now, you can be querying it back to understand what the discussion was or how the discussion went. And draw real insights from it, which can lead to real revenue. And so I think unstructured data for us as a data team has become nearly as important, if not more important, than structured data. And we are doing a lot of work to just govern that better and then use that better. There's gold in that unstructured data. It's incredible. Absolutely, yeah. So Parth, this is a great approach. Can you talk a little bit about other clients and what we're doing within Deloitte to help them also use AI to drive data management capabilities? Yeah, certainly. So if you really think about the data value chain, how do you source, how do you map, how do you profile, how do you govern, how do you transform, and how do you consume data? That's the key stages of the data supply chain. There is an opportunity to embed Gen AI in every single facet of that. So if you were to go in any financial institution, commercial banking organizations, they were to have AFS or a loan-Iguest-like platforms. And they will have massive number of contracts sitting out there, commitments sitting out there. And you were to look at, well, how do I get the right set of data out to generate my regulatory report? Or if I do profitability calculations on the back of it. All of that calculations, the processes can be automated. Matadata and governing the data battery, that's a very good example because many organizations don't have things documented at a degree which will allow you to write the glossary in a meaningful way. Now, there will be images. There will be visual diagrams. We all have seen that. Can you use that and create a glossary on the back of it? There is an art of possibility to do that. So as we look at not just our clients and even within Deloitte, so by no means we are perfect. We have our own sort of complexities. And as we looked at it, we applied the same exact approach to ourselves. That can I manage my data much differently? Can I organize data? And by the way, we consume a massive amount of unstructured data. USA and any other insurance organizations, they will have PNC or life and annuity policy or documents which vary by state to state and sometimes county to county. How do you pull all of that together? How do you organize that data and create right set of embeddings and vectorization such that the data can be accessed and consumed for any of the use cases? Gen AI is right in the middle of that. So in my mind, Gen AI is a tool in your toolkit that you have to figure out how to best utilize it. It's not just, by the way, Gen AI. There is cloud. There is data management principles. There is on-prem versus cloud, whichever approach that you take. The right set of LLMs. But using it through the end-to-end data supply chain and applying what I call reimagination to that, that allows you to drive value. Yeah. Yeah. That's fantastic. And I think that consistency of process, and I like the data quality rules and the metadata, is really of great value that we get out of this. But Parth, what do you think is the biggest myth that's out there right now that the industry is talking about? I think agents is an overused word. And I'm sure, I don't know how many times, I didn't count that how many times the keynote they used about agents. But, you know, in people's mind, agent can be an RPA. Agent can be, I just open an email and the dashboard is telling me that what happened yesterday. But, you know, people have simplified the use of agents in a low-code, no-code, but there is a lot of work that goes in front of it prior to even reaching that last mile. To understand and agentize any of the processes, one has to understand what does the process entail? What does it contain? What are the steps within that? What are the different roles within that? Who are these humans who are making such decisions? What is the impact of those decisions? And then subsequently, as those decisions are made, when the point of escalation comes in, when it will be VAU as a process. So one has to do a massive amount of knowledge management, the underlying data, the experience work. And then subsequently, you can suddenly go and agentize it. And then while you do so, of course, there is a process re-engineering, process re-imagination component. So you apply those lens, and that gives you the right value out. Other than that, all you have really done is you have created the degree of automation. But you haven't really changed the way process in today's world is going to work tomorrow. Right. Oh, and by the way, you've got to keep humans in loop. We are not there yet in the autonomous world. So I'm sure there is a degree of automation that's going to come in in the future. But the human in loop and validating that at what point this decision needs to be certified or no, please go back and revisit it. That needs to be included. We'll talk about human in a loop here in a little bit more because I think it's a great point. But I want to keep going on that, what you mentioned. And there's no, my words, there's no silver bullet, right, to a process automation. We actually, you know, in Deloitte, we call it a string of pearls. And exactly as you mentioned, there's an RPA, there's data management, there's actually AI that gets pulled in. You mentioned a little bit about re-imagining and re-engineering business processes. How, when you're working with clients, where do you see clients run into the most challenges associated with this? And how do you help them stitch these string of pearls scenarios together to actually get that value? Yeah, the string of pearls is a concept where you look at the end-to-end business process. And, you know, for example, you want to go and make a next best offer to a customer as in when they open up your app. But to do so, you need to go back all the way in the Salesforce or whichever your CRM system is to identify what are the customer segments. And for these customer segments, I'm going to make these kinds of offers. Or let me also analyze their transaction patterns and figure out will they be applicable or not. And then subsequently in your front-end platform make these offers available. So string of pearls is a concept that we came out with which analyzes your end-to-end business processes and connects the dots and says, well, in today's world, you are doing it in this particular manner. And to create next best offer, it takes you two days. Could I do that in a very simplified way in less than a day or even less than a few hours? So we are reimagining the business processes, and that has allowed us to change the dialogue very differently. If you go to a bank and, you know, any net new product introduction for a consumer bank, it's a months-long effort. You've got to identify the characteristics. You've got to figure out why is it different than today's product. And you need to do a beta testing on that, get the customer sentiments. All of that, at least 50% to 80% of that, you can simulate using Gen.AI in today's world. So do you really need to spend three to six months to roll out a new product? Probably not. And that's another string of pearls example. But that's the way to, you know, think about as you go into the future that how can you reimagine or reengineer. Very cool. You brought the word up or the term human in the loop. And that goes along with adoption. So Ramnik, I'm going to bring it back to you. Talk maybe a little bit about USAA. You mentioned the MSRs, and clearly there are people that are part of the AI implementation process and the AI usage process, exactly as we would assume. How has it gone at USAA to get adoption? Have you run into any headwinds, or how do you manage that? Yeah, Kevin, I think when I think of all the capabilities that the AIs have and increasingly have more of them, there's a, for a conservative industry and conservative enterprise like ours, there's always a question of assessing the capability reliability gap. As in, yes, it can do it, but can it do it reliably? Can it do it to the 99% accuracy level that we would need in order to feel like, yes, this is an automated solution that we can put into production and not really have that human in the loop, right? And there are some areas where we are getting to that point and we are comfortable putting the AI, for example. Not everything we do has to be in that high-risk category, right? We answer 200,000 calls a day. 25% of them are purely informational, right? It's what happened to my claim? I made an application. Where is it, right? What is, these are pure informational calls. So can we address that? Do we feel like we can address those to the 99% accuracy level, reliability level? And that gives us the opportunity to isolate use cases where we are comfortable not having a human in the loop, figure out which use cases we still do need to have a human in the loop, but it's not that every answer that an AI produces will be reviewed by a human, because then, first of all, why are we doing it? And second, the human is probably going to start rubber stamping very soon, because there's an automation bias, right? The AI set it, so it must be right. What do I have to rethink and redo, right? So that kind of human in the loop approach doesn't really help. What we are looking at is observability of the AI produced output through either other LLMs as a judge or other ways of having statistical observability on AI outputs. And the human in the loop is really looking at the outliers in, you can think of it in vector space, and if the answer is too far from what we typically expect the answer to be, something has gone wrong, and that's an escalation. Or we build it into the AI's process to say, if you get these types of questions, you're authorized to answer them, but if you get this question, you're escalating to the human in the loop, right? So it's thinking about human in the loop very differently, and then figuring out the low-risk or highly reliable AI applications where we don't need the human in the loop, right? And that we can feel comfortable, and we can assure ourselves and all our stakeholders, right? We are in a regulated industry, after all. We have to, the burden of proof is on us to say it is performing to the level of reliability. It's not even enough to exceed the human reliability, because often humans make errors too, right? But if you're going to put a machine in the system, you've got to prove that it's performing to the highest levels of reliability. Yeah, unfortunately humans are not infallible, right? Quickly, we've all been part of projects in AI as a tool, and we think it's a silver bullet, and so we walk around to the enterprise and say, well, there's 350 use cases that are out there. How does USAA prioritize initiatives for AI across the organization? Yeah, I think there are certainly hundreds of use cases and hundreds of opportunities to deploy AI. The technology is so broad in its reach, and so much of the work we do, knowledge work as knowledge workers every day, back office work, which is essentially information processing on unstructured data. A lot of that is within the reach of this technology. So for us, we, first of all, we have a very structured approach to gather all of these ideas, whether they're top-down or bottoms-up coming from the field, and then to put them through a process of assessing first the feasibility, because to our earlier discussion, there are many things that we might imagine AI can do reliably, but it really can't, at least not yet. And so our first assessment is, is it even feasible for a conservative company to roll out the solution? If it is feasible, then we proceed to our value framework to assess the value from it. And then the last dimension is, is it within a manageable risk level from a legal risk compliance perspective, right? Because there are things that AI could do today, but it would cost us so much to just establish the risk and compliance framework around it, it's not worth undertaking it, right? So we put it through all of those filters, and ethics is part of that last filter as well, right? We want to be transparent in our use of AI. So if our consumer, our member, knew that we were using AI to do X, Y, Z, does that raise any ethical concerns or any concerns for trusting us as a company, right? Because that's the core of all of it, is do our members trust us? Well, we've got about 12 minutes left. We're going to go into Mythbusters. So we're going to do about 30, I'm going to ask a question, we'll do 30 second answers. At the same time, we're going to take some audience questions. We've got mic runners. So if you have a question as we go along, please put your hand up, and we'll have a mic brought up to you. But let's start, well, so again, if you have a question, put your hand up. We're going to start here. Romnick, we're going to go back to Humans in the Loop. A lot of myths out there. We talked a little bit more. Are we always going to need Humans in the Loop? No, I don't think so. It's as we narrow that capability reliability gap for more and more of the use cases, I think we'll be able to establish beyond doubt that the models are performing. the observability and how we solve for that through technology, I think that'll be the key on top of that, and that'll allow us to work without Humans in the Loop. Very good. Parth, AI agents make completely fair and unbiased decisions. What's your take? 100%. Not. Not yet. It'll come there. Not yet. I think there's a degree of guardrails that needs to be built in. Even all the keynote things that we talked about today, there's a guardrails concept that was embedded in that. Unless and until we, as humans, get comfortable with the decision, then the outcome that is coming out, and that time will tell, the experience and the volume of agents will tell us. But I think subsequent to that, I think there is an autonomous decision-making and the biasness will come into play. Very good. Do we have any questions out there? I don't know if we've got a mic. Maybe if you can... Oh, there we go. There we go. There we go. There we go. Hello, everyone. I'm Sanjana. I'm a student of information security. So this entire topic is very intriguing for me. And my question is about explainability of the AI. Yes, you have AI embedded in the claims process, and there's a decision made. And while we rely on it, how important is the explainability of the AI and the hidden layer for USA and even Deloitte at the same time? And what's the kind of on-ground work that is going into analyzing the explainability, if there is? Yeah. I think that, first of all, traditional machine learning isn't going away. It's very valuable in a lot of the problems that we continue to tackle with AI, and we'll continue to do that, right? And there's a well-established explainability framework for that. I think that that same framework can't just be copied over to generative AI solutions. It's not the right way to think about explainability with generative AI solutions. Obviously, we will never unravel, you know, how two trillion parameter model really derived the answer that it did. But I think the emerging ways to tackle that are going to prove effective. So, first of all, restricting the domain that the AI has access to. By that, I mean, if you wanted to answer questions only on a certain corpus of documentation, only give it access to that documentation. Obviously, you put the guardrails to not answer based on its general knowledge. You kind of restrict it to, if we want our AI to reliably answer what is my account balance, then only give it the API to get the account balance, right? So, instead of one model that can answer all your customers' questions, create a smaller solution that can only answer a particular question and only give it access to the tools to be able to do that. And then you can have a model that will direct the question to the right model, right? So, techniques like that, I think from the AI itself, the chain of thought reasoning and asking for the chain of thought that is going to be a good way to establish explainability for how the model derived the answer that it did, and then the observer models on top of that, right? Yeah, and I think there's one additional aspect to that where incrementally, we will pivot towards a small language model specific to a given domain, and then on top of that, you build in the right sort of trustworthiness and the secure parameters. That should give you the right sort of explainability. Especially for financial services clients, the degree of transparency is paramount. So, regulators are going to come and ask you questions. You will have customers come and ask you these questions. And, you know, if you were to do business in Europe where GDP, AC, CPR comes into play, that becomes quite critical. I think we had a question over here. As clients adopt AI and build internal consultants like agents, how is Deloitte evolving its role and value proposition as AI becomes more accessible for everyone? Sorry, could you... You have a question? I have a question. Sorry, there's an echo. Can you speak up? Yeah. As clients adopt AI and build internal consultants like agents, how is Deloitte evolving its role and value proposition as AI becomes more accessible? I think you're asking about precision of what AI agents do. Is it better now? Should it... Yeah? I'll speak out loud. Yes, that's great. So, as AI becomes more accessible to clients, how do you company evolving or what's the market change since the market is the whole consultant-like agency Okay. I think my question is that how does the consulting's proposition changes with the agents providing what the capabilities they are providing? I think, you know, we don't see that as the consulting declining and the agents increasing. We see it as a complementary set of capabilities. You would be, you know, fascinated by the number of clients that actually, number one, they want Deloitte's assistance with providing an AI strategy, creating a value framework that Ramnik was talking about, similar to that, looking at, you know, which dimension using which the use cases should be prioritized. Is it cost efficiency? Is this productivity gain? Is it, you know, top-line revenue growth? Is it net new product introduction? And then lastly, I would call it that embedding AI, so certainly you can go and, you know, write net new business processes in the string of polls that I was talking about. The embedding AI into day-to-day tasks and activities becomes paramount. So the way you do write the code and the way I write the code are 100% going to be different. Our styles will be different. The way you have written comments will be different. Could I write degree of standardization while doing so? And consulting firms such as Deloitte, we provide massive amount of lift as our clients go through such kind of exercises. Yeah. And I think you can pose that question for any jobs that people do today, right, and say, is AI going to do those and therefore why do we need people to be doing those jobs? I think fundamentally the pace of innovation in the world will increase increase to the point where we still need the people thinking about what we need the AI to do, right? The innovation will move from actually doing, executing, to thinking about what should be done because we don't anticipate AI is doing that, right? What we want to do with technology, we will have to be the deciders of that. So I think as coding becomes faster because we can have AI as assistant coding jobs, we'll have more software being written. If you could generate your own application to do whatever you need to do, CRM, messaging amongst your employees, if you could create that app and call it three days, you wouldn't go license that app, right? You would just create it and you would create many more of these apps, right? So I think the pace of innovation to stay ahead, to stay competitive in the market, all of us will need to be innovating faster, all of us will need to be doing more now that we can do more with the AI at our disposal. And for many jobs, I think the nature of the work will change drastically, right? So how we do software engineering or how we create enterprise class applications will look very different from what it does today. Very good. So we've got about three minutes left. I think we'll go here. I'm going to ask one more final myth. Romnick, do you think customers are going to prefer to avoid AI agents? In several blind studies where customers did not know if they were interacting with an AI or if they were interacting with a human, and the ones, at least, I have read through are in the medicine, in the field of medicine. And overwhelmingly, patients who received their diagnosis from an AI found it to be more empathetic, more thorough, and more patient in explaining what it means than human doctors, right? So I think AIs will turn out to be a better experience than talking to most humans because of human limitations. And for that reason, I think we'll all prefer to talk to an AI and only want to talk to a human if we can't talk to an AI. Very good.