 VASU SHARMAHURAJANI Hello, everyone. Good morning. Welcome to this session. My name is Vasu. I'm going to be hosting the panel of experts here. And today, we are going to be talking about what it says there, delivering business value in new agentic era. So I lead at Google. I lead what we call as architectures and industries function. It's part of global cloud consulting organization, which means I spend my days working with some of the large customers to unlock business value from Google Cloud products. I also help them drive AI journeys in a safe and secure manner. At a personal level, I deal with a different kind of AI management at home. As a dad to a curious four-year-old boy and a rapidly evolving 13-year-old girl, I have first-hand experience of dealing with hallucinations. So if you want any tips, I'm there backstage after this to give you some tips. Now, the agentic era, the technological wave that we all are riding is something else. It's truly phenomenal. It is disruptive. Yet, it's brimming with opportunity. And that brings to the core question that the panelists are going to answer here. Are you getting real ROI and business value from your AI investments? Now, before I invite the panelists, let me paint a picture of how we see AI landscape, AI agentic landscape from a Google perspective. This is largely subjective because, as you all would appreciate, we are in maybe early stages of the adoption. But nonetheless, we feel it's going to be relevant for your journey. I'll talk about it in three key points. The first one is, is agentic AI really happening in enterprises? Or is it just a buzz? We have strong evidence that customers who are nimble, who are cloud native, and who are less regulated are adopting agentic AI at scale and driving business value. As I said, it's still early stages. But the floodgates are going to open very soon for all of us. The story is slightly different in more regulated industries. And we'll talk about that through the panel in a bit. In more regulated industries, we are seeing successful proof of concepts and pilots. And now there is an emphasis in this year to productionize them and drive business value. That takes me to the second question. How relevant are the models? Do we think models are still relevant in the agentic AI era? Absolutely. Models are the brains behind these workflows and the agents themselves. But what we are valuing in these models is evolving. It's not just about the sheer size and scale of the models. It's also about how good they are in understanding certain domains and verticals. It's also about can they reason well? Can they understand nuances? And can they also work in creative contexts? And in agentic AI space, we are also looking at multiple models working together in harmony to deliver a real business value. Now, these shiny new tools are not good enough for you to drive business value. Organizations are looking at or are realizing a solid cloud and data foundations are non-negotiable for you to adopt agentic AI. And it doesn't end there. One has to also look at some of the operational capabilities. Very traditional things like DevOps, MLOps, and now agentic AI ops to scale agentic AI at scale. Now, that brings me to the final point, which is non-technical. What are organizations doing in order to adopt to this change? We are seeing leaders are talking about how to incubate agents into their organization structures into truly creating a hybrid workforce. How do you think about roles and responsibilities of agents and your human talent? How does the end-to-end process work? And that takes me to a fundamental question that we all need to grapple with. What are the cultural shifts we all need to think about in order to make sure human talent and AI agents can work in harmony and don't compete with each other? But I'll leave you with that question. And we'll get a bit deeper into some of these points with the panel. Before I introduce the panel, I'll tell you what we are going to cover as part of the panel discussion. We are going to talk about how you can maximize ROI with your AI investments. How should you think about building foundation with some real examples? And how does the future look like in the agentic AI space? Right? So with that, let me warmly and please join me in welcoming the panel. Tim Ignacio Perry, please join me here. I think you're here, right? Okay. Could I, before we get into the questions, could I ask three of you to introduce yourself, please? Talk about your role and the work that you do in your respective organizations. Tim, please. Our office. Yeah, my name's Tim Mason. I run our innovation group and our AI program. Our AI program had one clear goal. I think a couple of years back we looked at this when generative AI came about. And we knew there was hundreds of use cases. Your real big problem is how can you do it fast? And anybody here who's from banking will recognize this issue. Huge amounts of controls all over the place that keeps saying no. Our entire journey was how do we build an environment that we can then enable to go, everybody just to go very, very fast. Thank you, Tim. Ignacio. I'm Ignacio Garcia. I work for Vodafone. I'm the CTO of Vodafone business, our enterprise business globally. And I also run the AI for the whole company. Vodafone is a telecommunication company. And in terms of scales, yeah, we have a lot of data. 300 million, 360 million customers, 200 millions of IoT devices, operations in Europe and Africa. We also do banking, so 150 million bank customers in Africa. And the reason why I'm saying this is because then when we talk about regulations, data, and the importance of having platforms to actually do the things at a scale, it's important that you understand the context and why we move in the way how we move. And we'll get into that very soon. Yeah. And Perry? Yeah. My name is Perry Nightingale. I'm SVP of Creative AI at WPP. I've had this role for five years and I had to spend the first year explaining what head of Creative AI was, but now I don't need to do that anymore, which is good. And I look after anything that touches kind of creative and generative AI across the business. WPP is one of the world's largest marketing services organizations, about 110,000 people spread like you over a wide geographic area. So yeah, like a large scale business. Yeah, and it's great to have all three of you here. I think this is one of the very few sessions where we have a cross industry panelists and two industry pioneers coming together. So let's get into the questions. Tim, let me start with you. I think on the question of ROI, I know we have discussed a lot about how DB need to think about, Deutsche Bank need to think about return on investment. Could you talk about what are the distinctions between traditional automation and agentic AI? Yeah. And how do these differences translate to tangible business outcomes for Deutsche Bank? Tangible business outcomes. I think the first thing when you think about agentic AI, you've got to start to define it a little bit about what they actually mean. And each different type has got a different type of value proposition that you're really trying to go after. The first type of agent we're thinking about is the discovery agent. It's agent space, go connect, get information. That's your productivity type benefit. But for us, the ROI really ramps up as we start to the next step. The next one is a decision type. As you're starting to ask it to make questions and answers to say, take unstructured information, but make a recommendation and a decision for me. And then the last one is the action. If you're able to get it to make a decision, it can then take the action for you. But let's put some concrete examples around that from a banking perspective. Account opening is a very common process. We can apply RPA so that as long as you've got the data to make the decision to actually open the account. But it can get very complicated in a world of, say, business banking. We've got loads of SME customers in Germany. And an example may be what happens is they go bankrupt and there's a court order for a company or a legal firm to take it over. Our people have then got to read the legal requests that come through the court order document to make a decision. Can AI do that? Now, we know it can. We've tested it and AI can go do that. But now I'm making a material decision to open an account and do I know it's accurate or not? That's the type of agentic behavior for us which is hugely valuable because I've shifted from a world of the human having to do it where the information is unstructured into a world of AI can go do it. We see loads of those examples. That's where we're trying to go get the value because there's a workflow. You know, workflow is great if you can get predictive information, but it has to be driven by decisions. We see thousands of those examples everywhere. And the last thing we're really thinking about there is to then drive ROI from that means you have to control it. The phrase of what is it? Power is nothing without control. Yeah, Pirelli. Exactly. Yeah, it was Pirelli, wasn't it? Yeah, yeah, Pirelli. And to think about that, you need to make sure that how do I know the decision's right? How do I test that decision? How do I know it's accurate? So really getting value out of this, you then got to think about I can get the AI to make a decision, but should I? Can I control it? And what happens if it goes wrong? And if the benefits case of that works out, you can then just roll those out. And that's where we're really focusing our tools to really drive out those types of agents, the decision and the action ones. Thank you, Tim. That's very insightful. Let me switch gears a bit. Let me come to Ignacio. With you, I think under your sponsorship, Google and Vodafone teams have been working for the last number of years in building solid data foundation. Eight years now. Yeah. And I don't know if you had a grand plan to build the data foundations in the run-up to agentic AI, but could you talk to the audience about what do you think are the right data foundational capabilities that we need to have in place to scale agentic AI? And how did you go about bringing energy and teams together to do that? No, I cannot claim that I predict the future, but it was the right thing to do. It was the right thing to do. I think in terms of context, the telecom industry has grown to acquisitions and mergers. And that brings a lot of complexity by default because every time that you do an acquisition or a merge, you have technical depth, you have landscapes that you need to integrate, you have data that have different schemes, you name it. Yeah. So it's not easy what we fund and we operate in multiple countries, multiple locations, and you need to keep running the business while you do the transformation. So point number one, the starting point was super complex. Point number two, it was obvious that we were not getting the most and we were not able to serve our customers in a proper way considering all the information that we had. So in an intuitive way, we say we need to put order on this. But we made a lot of mistakes in that journey. And then it is important because we started saying we need to consolidate all the data and that is okay. And our KPI was how much data do we have in this platform. And guess what? That was a complete wrong KPI. Yeah, we were super happy. We were migrating like crazy. But then that data platform had a lot of data, but it was like a library with a lot of books that you cannot find. So that is the first thing that we understood is that it's not only about the size, it's about the quality of the data and how you bring that. And we put a lot of engineering with your teams also to resolve real problems. So volumes of data, real time injection, building tools to bring quality of data, doing the tagging in automatic where it's possible. Because there are problems of volumes that we have to fix. But when that was fixed and that took multiple years because you have to do that at the same time that you are bringing value. It's not that you have money, infinite money to do this because it's the right thing to do. You need to find use cases and do retirement and modernizing of the platform at the same time. So it's difficult to get the numbers to work. But when you do that, you have a superpower. Because then you have the data, the data is cataloged, the data is encrypted, the data is under the European regulation, which is super important. And we have been doing AI for many years, but the AI was siloed and fragmented country by country, division by division. For example, churn models, for example, the network team doing network deployment analysis on where to put the network. And the power of having the data has changed that. So you then got data science that have access to data from different countries, but equally from different lines of business. And that makes the models by far more accurate, better, and then we can do great things for the customer and we will talk about what they are. But to enable that, we create another platform. We call it the AI booster based on Vertex AI that is connected to our data. We have all the framework of regulation that Europe requires. And I did allow our traditional AI data science to be super efficient. So rather than building the models in notebooks and spending a lot of time and doing data engineering and trying the things, we have a feature store, they share, they run, and they do data science. They don't have to do all the data engineering and all the things. Hence, when we arrive to generative AI, for us was a blessing. Because then we had the right use cases to unlock a lot of value, but we were ready. Yeah. And then we can talk about that. Yeah, let's talk about how you were able to do this while also delivering value the second round. But let me come to you, Perry, here. Unlike the other panelists and other organizations here, if I may say, you are less regulated. So hopefully the boundaries that you have are far-fetched. So from your perspective, how does the creative industry look at agentic AI world? And what is it that you're doing in creative industry? And what are the emerging trends that you're observing? Yeah, I mean, in some ways we get everybody's regulations. So, you know, like in some ways it's the most highly regulated industry of them all. Because we have to put out banking adverts on behalf of Tim, and we have to, you know, Vodafone adverts on behalf of you. And, you know, we, our product fidelity has to be perfect, for example. That's highly regulated. And when it comes to AI, that's actually really, really hard. That's the area I work in. But in some senses our sort of business function is less regulated. Right. And we launched an agent builder, you know, in mid last year. And we, my boss likes to say, skate where the puck is going. So, you know, as an organization we try and predict, you know, as you did some time ago, where this was going. So we launched an agent builder. And we've had 28,000 agents created. Wow. And are still being created. So it's difficult to hone in on precise ROI from each of those agents, but they're still being created. And they span a wide range across pricing and checking legal documents. And, you know, I said 28,000 agents to Tim and he had a small heart attack, didn't he? And so, you know, it's true that we do probably have to, you know, it's less regulated in terms of what those agents are doing. But they are out across the business doing a lot of work. On the content side, on that side of regulatory, you know, in the EU we have to declare if, you know, if we're using deepfakes or synthetic humans or these kind of things. And we have, we work with Oxford University to understand how people felt about that. And it turns out people trust deepfakes in advertising more than real people. So, which was a surprise. So we try and stay ahead of regulation generally. But the agents have been a huge success. You know. Could you, for the benefit of the audience, give an example of an agent in the creative space? Yeah, we, you know, we think of agents really in kind of three layers. And asking which or what agent is probably the wrong question. We think of them as intelligent AI systems. So we start with what's the right model. And really underneath that, what's the right data foundation. And there are many parallels between WPP and Vodafone in terms of, you know, acquisition growth. The profile of business we are makes it hard to make big changes. You have to deliver, you know, consistent returns to shareholders. And you can't just, you know, throw everything away. So we start with a solid data foundation, which in itself has to span thousands of different entities in many ways. And then comes the model. Then comes, you know, what do you want the behavior to be? Is it sort of chain of thought, sort of reasoning? And then on top of that is the knowledge and the context. And we found that to be the most important thing. And then, you know, as we're a large flat organization, our sort of, we call them expert agents, really allow our, you know, our sort of behavioral science experts or our legal experts or our sustainability experts to scale across the business. So that's one example. We have an amazing behavioral science unit, Rory Sutherland. He's a bit of a kind of social media star in his own right. And that agent is heavily used for behavioral economics across the group. Okay. Interesting. And we'll get into some of that in the second part of the question. But let me latch on to the point that you made, Ignatio, about delivering foundations while also driving value in your business. Could you talk about what were the challenges you faced and how did you navigate that? And secondly, could you also talk about how did you solve for the problem of continuous data feed into the model so the models can learn as the organization is evolving as opposed to staying constant? There are two questions there, but if you could pick up those. No, no, absolutely. But to do that, and now we'll fast forward from where we went in 2017, 2018 to where we are now. Yeah. Because I think it's a different problem than one that we're trying to crack. And many of the people here is trying to do the second one. So how do we get my agents? How do I get real value out of AI? The first is the philosophy that we have. So we have three buckets. Three is a good number always. One is to enable our employees to be more productive in general. So that's one category. The second category is to rewire our company processes to do things better for our customers, to improve the way how we operate, to do things faster, to do things cheaper. And the last bucket is how do we make money. So it's three completely different categories. In the three, we are making progress. The one where we started to focus at a scale was the one in the middle. Because there is where the ROI is bigger. Very quickly, we realized that we had to move on the first one as well. In terms of training and in terms of giving access to the people, to the AI, because then they were the ones that were feeding us. The ones that were feeding us ideas on how we could be better on rewiring the business. But if we go to the one in the middle, so how do we make our company better, rewire our business. In a telco, you have four categories. You have either customer service, and that is a big problem for a telco. I mean, I don't know how many people love customer service in a telco, but we're trying to make that good. Yeah, and it was not. And I've been hearing many, many people talking about call deflection. No, it's how do we get our MPS to go up? How do we get the people to self-serve and to get the problems resolved? And now how we contain the calls, yeah? So it's a completely different problem. But that area costs a lot of money and equally creates churn because the customers are not happy. Yeah. So if we do that well, our customers will stay with us. Things will cost less. And it is a difficult problem to crack, but it's the one that is an obvious big, big ROI area for us. The second one is operations. IT operations, network operations. In both areas, look, it's like customer operations. It's another area where you are treating with a lot of volumes of data. You have big rotation in your people. So you have a lot of things to solve. And finally, the last category that is another big area is all about internal processes. Your HR, your finances, how you do the closing. So those are the categories. There is where the money is. The coolest thing is the customer because we want to improve our customer. And I tell you what we did. What we did is we found the use cases based on what the value was. We did a big list of assessment and also feasibility in terms of what data we have and what technology was available. It was a big job in terms of avoiding the disease of dying by POCs. We have every vendor talking with every line of business in every country doing POCs. Zero value was generated. A lot of energy was going there. And then we say, okay, we need to put governance and understand where to put the focus. We did the governance. We understood. We have a procedure for people to try and do that. But the ones that are the big ones were identified. And so if I take the example on customer operations, we say, okay, we have one area that is obvious. That is the chat bot. Yeah. We need to improve that. Not on contention of calls, but on resolution of problems. The second big problem is if you cannot fix it because it's not one of your key journeys, like my invoice is wrong. I got a question because I'm in a roaming. Then a normal human agent needs to pick up the call. What happened there is we have agents that typically do not speak the language because it's in a cheaper location as a first language. In Europe, we speak one language per country, so it's more complex. And the second problem is the churn is very high. So you have 30 to 40% rotation. So you don't have the ability to have a very good agent that can fix the problem. And the last one is we had a very traditional way to understand where the problems of the customers were, which is surveys. And guess what happened is we did our financial model. The reality is we started with the brain. So we started with that one. Why? Because the data was available. Yeah. And it was easy to implement. My guys were not technically excited about that particular one. It was cheap. But the value that we unlocked when we got the transcription of every single call in every single contact center. So say, Italy, that was the country that was running at the time. 100,000 calls every day. And then you know every single conversation and every single problem. And then you change completely your approach because then you can fix problems and start building small agents to fix problems in automatic. And take the pain points. So the starting point was just opportunistic, less cost, rapid time to market. But we didn't thought that was really a higher ROI. That thing has become a machine. Because now we train agents with that information based on the conversation. We do compliance exercise. We raise incidents immediately in the incidents because we detect problems where we say that we will come back. We find patterns of problems. So for example, if you have an issue in a cell and customers are calling you because they have no connectivity there. Every call is a small call. So you don't detect that you have a problem because those calls are going to go to different call centers agents. Now, we do think, real time, you get it and you raise a high priority incident in that cell. Why? Because we know exactly what the customers are saying. So the one that we pick up, which was opportunistic, low time to market because we have the data. So you have the data in place. Yeah. And not sexy from technology point of view, has become a super important one. And that is the one that is giving us the key on what agents we are doing. So we changed the philosophy from these big things to a small agent that fix the problems that we have. Sure. And now what you have is you have a very well orchestrated deal. But why we can do that? Because we have the data sorted. We have a platform that allows us to have multi-LLMs, multi-cloud. And we allow the teams that are building to be the business team. Yeah. Because we have the platform. So we don't build agents in a central way. We have a platform where the knowledge expert, so the customer agent in the service, in this case, are the ones building. Net-net, we are producing benefits on year one. We did produce benefits on year one. And we went live with 16 million customers, all our customers based in Italy. Wow. Yeah. And that's why I'm saying we won't run the formula. Yeah. We try to first avoid dying. So the recipe will be avoid dying for POCs. Get some kind of control. Make your own assumptions. But go to something that you can really deliver. That's high value. And then learn. Let the people learn and tell you exactly. And that's the link with the first one. Because if your people know AI and the power of AI, they will give you ideas on what to do. Yeah. You give them the platform and they build the value. So our ROI is going up. It's perfect, no? But I think we have the method. I think that's a great point. Picking up something where you have everything in place and driving a networking effect from there. A great point. Let me get to you, Tim, more around the ROI point. And we discussed about this on multiple programs that we were working on. How do you balance the need for immediate ROI, given you're in a constrained environment, with the long-term strategic value of agentic AI? And what are the patient strategies that are paying off for your organization? I guess it's worth talking about where we've been and where we're going now. Because agents are pretty new, but generative AI has been about a couple of years. When we started the journey, one thing we looked at, you know, you mentioned customer services. It was quite obvious people were saying customer services where it benefits. Operations is where it benefits. I could look at finance. I could look at software code. And I think people very quickly honed in on those kinds of value propositions to really pick up and deliver early-stage use cases. But when you pick it under the covers, what you tend to see is patterns of use cases, which are the same and the same and the same. Yeah. And as soon as you recognize from a control perspective that every time you do a use case, technically it's not hard to do, it's really hard to get everybody to agree and to prove it. When I've got model risk management regulations in the US and the UK, I've got EU AI Act coming in and so on. And we've got 30 different risk and regulations that we've got to worry about. So we took an approach a couple of years back really doubling down on one or two areas where we said, let's lead there, build the solution. It's a pattern and then we'll roll it out. So, in fact, somebody, one of our other colleagues is talking here about Paula, our chatbot, customer services, generative AI, same kind of thing. Which, yes, it's called deflection and it's about better customer experience. But once you've built that and you have an approved solution, I can repeat that into my business banking. I can repeat that for HR and everybody else very, very rapidly. So my ROI suddenly goes up because my cost of implementation is down. You probably also heard about DB Lumina. Our CEO was on the opening speech talking about that. That's our ability to give our analysts a very quick ability to summarize documents in a very, very accurate way. Accuracy is so important here. The cost of being wrong is really huge to the business. You summarize an annual report, you get the numbers wrong, and that can be really fatal for somebody sending out an analyst report. So we have got a high performance, highly tuned solution there that enables our analysts to have a lot of confidence. But we know that's something that we can repeat across multiple other business sectors. So what we've now done, again, global approvals, we're now going wide with that. We've also got so many documents coming the door. This is something that I'm sure you will see. Still, the world runs on unstructured documents coming in the door. People got to scan them. Scanning accuracy kind of varies. One of our early stage programs wrapping up the DocAI solution into a secure solution for us, dealing with all the country regulations and so on. And now we can do, I can't remember how many pages now, well over millions of pages a day. But that solution when we first did it, we're looking at around a 40% reduction in document handling time, simply because you're not creating downstream work for the people to deal with. You can take that off the pace. So what we've been doing is following approaches saying, build the pattern, take a lead use case, drive out the value, and then rinse and repeat that. That gets you so far because you run out of patterns and you start to have to look at the next bit, which is, as you described, underpinning platform because everybody wants to now do their own, and a layer of trust over the top to allow them to go and do their own. So going forward from the agentic approach, what we're going to start to really look at is how we create those layers and how we really focus at the next set of business problems we want to solve, which is a move into automation. And that's really shifting away from just saying, this is productivity type stuff, into fundamental transformation. And I think most of generative AI, we can talk about the productivity challenge. We actually know from all of our solutions, even software code, what's the typical productivity you should get. I can measure all the usage. I can tell you on a daily basis how many productivity days we think we've created. I'm not sure our COOs like it, but I can actually add it up, and it's a good thing to go and do. You can say, how much have we saved? If this is 10%, that's 20%, that's 40%, what would it actually be, and does it equate to the money you spend? But at some point, you've got to actually flip, and you've got to flip to looking at fundamental transformations of business groups where all of the AI comes together. And then that, for us, is where the agentic value is really, really going to play. I think that on that one, I will add, and it's a good example. So we were trying to do the use case, the business case by individual agent on the customer service. And what we found is that we created a program that was called Ask Once. So the customer only has to ask once, and we'll fix it. And why that was good? Because then the combination of all the solutions is what is paying off. Because you cannot get it 100% right. But the other thing in the framework that we discussed is testing. One thing that nobody talks about it, but in general AI, is no deterministic. So testing and no deterministic application is something that the engineers of software like me never had to face in the past. So we have invested a lot on creating a framework of testing. And now we can do A-B testing on multiple LMS on the platform. And that is what allows us to change. And why change is important? It's because this technology is completely different to any other technology. The latest is cheaper and better. So if you can test that the new one keep working with the same level of standard, deliver the result, typically you will get a cheaper process and a better result. So your ability to win in this area depends on your ability to change. And that is if you have your data well, you have your platform, and you have a testing framework underneath. So if you have that, you are ready to win. I echo that 100%. It's all about because it's probabilistic, you need to get the testing layer. Because if you're down, everybody can build whatever they want, but your testing layer says, is it the right answer? And an important point, Tim, you said, I want to make sure that it's not lost, is you use the initial use case to create a capability that you believe can help the wider organization. And then you amplify the ROI impact by, to some extent, open sourcing that to your organization as a whole. But also to bring communication. You need to be very good on telling narrative and success history. Right. Because it's not only money, it's equally, honestly, knowing all the conversation of your customers, that's priceless. We didn't know what is the value that we were putting into that use case. Yeah. Now we have 14 use cases that are adding by far more value than what we could predict, because we don't know. Yeah. And this is important. We gave an application of the narrative AI to every single employee. And that was a leap of faith. Yeah. The discussion that I had to have was know about the ROI is, look, if we put this in everybody, everybody will first gain some productivity. And that's linear. You can say a few hours, whatever. We are not going to restructure the company like this. But they will know. They will be engaged. You will get more talent. They will bring ideas. Yes. They do. They do. I echo that. They really do. How do you put that? Yeah. It was a leap of faith on that, but that is paying off then on the other big things. Yeah. And you need them to adopt the things, the solutions that get created. We democratized it in our business and saw the same thing. And businesses have different profiles of people, but we put the tools in their hands and they created agents and they use them to do their jobs. You know. Now that you've got your mic now, Perry, so let me ask you one question that is very important. Like we have heard about the use cases around chatbots, research agents, and maybe some use cases around the operational tasks. Now, could you talk about the potential problems that could be addressed by providing AI agents with certain user interfaces like the visual and auditory modalities? Can you talk about what's the art of possible in this space? Yeah. I mean, we see like in like in video, agentic AI on a, you know, sitting on a curve that began with generative AI moving to agentic AI and then ultimately to physical AI. So, you know, I work in a division of the business that is looking at, you know, the future of production, really. Like how are we actually going to make stuff? At the end of the day, in our industry, this, these agents eventually have to create content, right? Or they need to be a part of creating content. And often that content is created in the real world, right? It's film. It's film. It's adverts. It's, you know, it's stuff that you see on your phones and your TV screens every day. Yeah. So this, this was a R&D shoot. What? Okay. We did about three weeks ago with Boston Dynamics. So this is Atlas. The, this is the first electric robot that they've created. The first and last time Atlas will leave the lab. So this is Atlas 2. So this is the first physical AI agent that we've used at WPP. Okay. And it's not plugged into our wider AI ecosystem. It's an incredible piece of AI in its own right. But partly because of how grateful they are for this project, we were the first people to actually show this robot outside of the lab in a, in a real world use case. They're creating us a custom version of spot that will ultimately be the first physical AI agent at WPP. And the strength, I mean, Boston Dynamics has gone with strength. Chinese unitary have gone with a sort of lower priced smaller model. Atlas is big and strong. Boston Dynamics have said, why create a robot that's, that's not stronger than a human. That's a 10 kilo camera. And to hold that up like that for a prolonged period of time is something incredibly difficult to do. So, you know, we are seeing just the very first glimpses of physical AI in our industry in particular. So, you know, I, my role is to think about how we, how we integrate those systems into, into our wider, our wider ecosystem, basically. That's fascinating. I think that's a great video. I'm thankful that you're positioned on keeping that video on. Boston Dynamics say, our intelligence is in our hands. And they, you know, really it's about how you actually, how these things go out and deliver in the real world. And that's where the regulatory stuff also plays into part for us. The, the consequences of getting a logo wrong for a client is catastrophic. And logos are not probabilistic. That's not, you know, we don't make a guess, you know, what Vodafone logos should be. It has to be perfect every time. And so, you know, the, the sort of task is, is really around that. How do we get that to happen? Thank you. That's super useful and inspiring as well. Look, we are in the last leg of the panel discussion. I just want to leave this as a very open question to all three of you. How are you feeling about agents playing an active role in business processes? Maybe Tim, starting with you, imagine you walk into office and you don't see anybody. You, right, like how, how, how are you feeling? Because a lot of this is the technology being ready, but it's also the human emotions that need to buy into this, right? How are you feeling about it? And as part of that, if you could share a bit of a takeaway for the audience? Yeah. How am I feeling? Well, as the person doing the AI, I'm feeling quite excited. I mean, perhaps the people on the other side, left side. And I think, I think, you know, we think about our business cases in three, three terms. And there's the business cases, which will augment people, right? Agents are the discovery agents. They really help people on that. People are hugely excited in our company about those deep research that you've got, the ability to give that to our analysts and people and connect the organization. I think, I think is phenomenal. I think that's going to really, really change things. You need to shift into the automate to drive the business case. Exactly what you're doing. Choose the areas in multiple, multiple cases. And I think that's for us is where agents can make decisions and actions. And that's going to be transformational. I think what it does to the people is it elevates them. You're not going to get away with no human in the loop. It's going to change the role of people to sitting above this to be saying, are these agents making the right decisions? Is your point the test framework? You have to have the framework running in production that people can see the answers. I think that's going to be transformational to banking. And the thing we've got to figure out is make sure we've got the right test frameworks, everything's safe and controlled and so on. So I'm quite excited about the possibilities as always at Deutsche Bank. I mean, you know, our logo, it's Deutsche Bank logo growth in a controlled environment. We're all about the control and then you can grow. As soon as we've got that controlled environment, we'll just go, go for it. And I think it will just scale hugely. And Ignatius, same question to you, please. Oh, it is, it's similar. I will not only talk about that because that part I'm excited. I think that we'll be humans. It will be a hybrid environment. That's the reality. I don't think there will be no humans. Yeah. Because if there's no humans, I also won't be in the office because an agent will be doing my job. So the reality is it will be a hybrid environment with superpowers because we will take complexity out and we will be able to focus on the right things. But I'm also super excited about what the opportunities are. I will give you one example of one use case that you will say, but how are you doing that? Look, we have all of these towers in the territory, yeah? These towers were there and we have equipment to do what that equipment needs to do, which is to send signals and do mobile. But for years, the people are slightly older like me. Do you remember when it was raining and you were watching TV that you have interference? Then you have to move the antenna and try to catch the interference. The reality is we have tons of data on how rain interferes with signals. Right. Okay. And we have a lot of towers everywhere where we have frequency, yeah? So we did a reverse logic and now we have agents that are really, really helping without any extra cause, because we have all the towers there predicting rain and capturing rain at every single point. So we have to know a satellite level granularity based on a model. And we didn't have to deploy anything. With something that exists, you create something that is good for society, because with those models, then you can raise alarms on flooding, you can change agriculture patterns. So the amount of new opportunities that we can create with things that already exist, if you have the right mentality, it's amazing. And then everything that you say, I agree. Thank you. And Perry, same question to you. Maybe you want to end us with something more creative in terms of what are you doing for future? Like what do you think you and your team are going to work in the agent space? Yeah, I mean, I've been working on this for five years, and I've spent half the budget on humans. So I still think that's where the future lies. And I think you see something similar to the smartphone era where, you know, people are expecting that these tools that work for them at home should work for them at their job, you know? And they use ChatGPT. I mean, we have kids growing up, you know, who, our kids, right, who use ChatGPT for hopefully not all their homework, right? They're not going to stop using that, right? It's going to go from homework to college dissertations to analyst reports. I guarantee that, right? And they are going to expect to use those tools. And that's what we saw when we opened these tools up. You know, these were things they were coming to ask us for. But we work in content generation. Obviously, there's been a proliferation of that over the last kind of couple of years. And I will say, just to sort of end on, just because something, you know, you saw something on LinkedIn doesn't mean it's a solved problem. Like, actually, you know, it's very easy to, you know, to put an astronaut riding a cat on LinkedIn. It's much harder to get the Vodafone logo right in every market every day in 100,000 pieces of content, right? So, you know, these things are big opportunities to differentiate your business. Right. That's how you should look at it. And they take years to solve and crack. Thank you. I think those are very valuable insights. I think the points that you all mentioned about ROI, thinking about testing framework, I think that's a new point that I'm sure everyone will find it useful. And the work you're doing in terms of building some physical modalities onto agents is also quite interesting. Look, we are on time. I hope you all found it very useful. Yes, I will. I want to thank everyone here. I know you all are busy. Thanks for coming over and sharing your valuable insights here. Thank you, everyone. Pleasure.