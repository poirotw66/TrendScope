 and so I super excited I think to share some things with you today I think this is a really really interesting session especially for people that are in the security industry or security practitioners that really want to understand how real-world incidents are mitigated really want to understand how we track threat actors on a regular basis you know at the end of the day I think we have probably the world's most renowned threat research team out there and we track threat actors threat campaigns threat activity every single day and so I think this is a really interesting session to kind of show how a lot of that happens in practice so I'm joined by Nicole Oppenheim she's a director in our Mandiant security research team so our Google threat intelligence research team so she'll help walk through some things that we do from the Mandiant side in terms of how we track threat actors how we track campaigns how we kind of action a lot of this data and a lot of this information I'm also joined by Paul and Caroline they're from the Deloitte incident response team in the UK and so the other thing that we'll be able to do during this session is actually walk through a real-world incident right and how the Deloitte team actually went about handling mitigating managing that incident and obviously using really cool and powerful products and tools along the way and so I think really really good session to really dive into some depth on on these topics so I think one of the core themes that you know we wanted to talk about as part of this overall discussion is how threat intelligence is used really alongside event data and data inside of your sim in order to effectively try to track manage mitigate threat actor activity right and the reality is like people have been trying for a long time to take sim technologies things that are collecting event data overlay threat intelligence information and try to make sense out of that it's a very common workflow that happens every single day but I think you know honestly the status quo is very much you know non advanced technology at the end of the day if you think about what the daily workflow is for most organizations inside of you know every single large scale you know security operation center out there there's typically people that are doing manual evaluation and download of threat intelligence data you know somebody like us mandiant will publish a threat intelligence report will publish things we know about that specific threat actor or threat campaign and then there's people on the other side of that equation who have to dig it up manually kind of download the artifacts or the IOC's that they care about and then try to basically create their own detections to try to match against that event data and that is a very inefficient process like at best it's an inefficient process at worst it's an ineffective process meaning that you can actually you know miss some things that you're supposed to you know or you want to be able to catch and so we have to be able to kind of move this technology forward and kind of drive into a better model to really unlock the power of threat intelligence across all your event data in order to really make use out of some of the powerful powerful things that we're doing on the research side you have to be able to apply that over event data as quickly as possible and so what has kind of gone wrong I think in in previous iterations on how people apply threat intelligence data the first is there's just usually too much noise and so when you think about most corpus of intel information it's a large amount of data that's being tracked managed managed looked at maintained on a regular basis like you know if you look at any kind of threat actor tracking or IOC database you might have a large amount of indicators raw indicators that you have to try to track and manage and when you try to apply that over event data at scale the reality is you get a lot of noise like you know someone downstream could have used a power shell you know as an attack vector somewhere along the line if you just blindly try to take that indicator and throw it on top of your event data you're going to get a whole bunch of data you're going to get a whole bunch of data that's being tracked and then you're going to get a whole bunch of matches that you don't really want so that aren't super relevant to you and so the first thing you have to be able to do is try to figure out how you filter through all the noise and how you actually make the indicators that you're trying to track more useful the second piece is in many cases indicators that you might be tracking in a generic sense are not really relevant to you or your organization or what matters to your vertical or your geography and so not every threat actor is doing you know ubiquitous attacks across every geo that people that are trying to do specialized attacks against the healthcare vertical or financial services vertical and so you have to try to find a way of taking raw intelligence information and try to map that to something that's relevant to you to your organization and what you need to care about versus just blindly trying to apply things everywhere and then the third issue is that to actually find malicious activity if you go beyond just indicators of compromise like if you think about it in the world of it's one thing to match a a file name or an ip address or a file hash it's a whole other thing to be able to do actual detailed detection engineering when you're looking for specific behavior and trying to find certain activity threat actor activity against behaviors and to ask most people in organizations to do that on their own and try to create complex detections that are looking for deep threat actor activity it's a very difficult task that is it's in many cases almost impossible for organizations to do on their own and so we have to be able to solve these three challenges in order for us to actually make this work at scale and to make it relevant so to promote true organizations to be able to fight back so how do we do that so the first is I think by having really the world's best threat intelligence to start with so if you can you can have you know you can try to apply threat intelligence data from the ground up and you can try to apply threat intelligence over all your event data at scale but if you're not doing it with really quality intel to begin with then you have kind of a garbage garbage in garbage out problem and you don't really want that and so the first thing you have to be able to do is have really comprehensive and quality intel and so we do that with google threat intelligence so with google threat intelligence we have you know really combined I think a unprecedented breadth if you think about the google reach across billions of users across our products every single day we've owned virus total for 13 years which is the world's largest malware database there's 50 billion files in virus total and we've combined that with depth coming from mandiant and and Nicole will talk about that depth but effectively think about the depth as having really world class researchers and incident responders out there going deep into each individual actor and campaign so that that's the first half is just being able to have the world's best intel the second piece is how do we apply that over your event data at scale and we do that inside of google security operations by taking that intel and effectively overlaying it on top of all event data that comes into the system and just to give you a sense of scale DAVID specific campaign. You have that overlaid on top of your events that you can quickly and easily see those threat actors. But then we also, on top of that, prioritize those intel hits. So we look beyond just a simple hit and we say, hey, is this something that I need to be concerned about? And if so, why? And so we do that by, like I said, matching these campaign tags. So it's kind of moving away from IOCs and moving more into campaigns and kind of behavioral based monitoring. And so in this screenshot you can see a few areas where we have matched these associations on the right hand side of the screenshot. And so instead of thinking about the world in terms of an IP address you can think about the world in terms of a critical campaign that you might be tracking. And we'll talk about a few examples of those today. The other thing is how we score those indicator hits. And so when we actually look and see an indicator hit, you have to then be able to prioritize, going back to the too much noise problem, is this something I should really be concerned about? And that really takes into account two vectors. The first vector is how malicious is the indicator? Meaning, is it really bad? And we do that through this concept of an IC score, an indicator confidence score. The second piece is what about the event that used the indicator? How do I then prioritize the event itself to see if the event is doing something malicious that I need to be concerned about? And it's the combination of those two that allow us to create these prioritization scores inside of Google SecOps to then make sure that you're getting the right levels of IOC indicators bumped up to the top of what you need to look at. The last thing that we do is we also provide behavioral detections for critical campaigns, critical threat actor activity, critical things that you need to be concerned about. And so if you want to move beyond IOCs, you also want us, with our expertise, to be able to publish actual behavioral detections in practice so that you can deploy those detections, which are going to be much more complex kind of detection chains versus just a simple IOC match. And so that's the other thing we do inside of SecOps is we actually have Mandiant authored, Mandiant delivered complex behavioral detections that are mapped against critical campaigns and critical associations so that in practice you can actually get to a detection coverage as quickly as possible. All right. So with that, I also want to give Nicole some time to talk about how our research team goes about performing this research and how that pipeline begins before we start getting data into SecOps. So with that, welcome Nicole. All right. Thank you, Chris. Hi, my name's Nicole Oppenheim and I work in our Google Threat Intelligence Group. I am a director of our threat operations. Google Threat Intelligence Group is really the combination of these two really big powerhouses and decade old teams. On one side, you have the Mandiant Intelligence Team where we look and what Chris was referring to, that depth inside attackers where we've had intelligence right alongside IRs for many years now looking at what attackers do, how they operate, what they're doing, and what their motivations are, and trying to pull the research out of that. On the other side, we have our threat analysis group that has been in Google defending Google and its users for multiple years, looking at the highest end nation state cyber crime criminals that are using the platform and trying to figure out how to mitigate it. We've pulled these teams together to unify them under one umbrella, we call it GTIG for short, to really maximize our ability to have that depth and breadth and have kind of a unified single picture. Our mission statement is really relentlessly defend Google, our users, and our customers by building the most complete threat picture to disrupt adversaries. So if we really kind of pull that apart, the first part is defend, right? And that's what we're talking about here. What's the point of having threat intelligence if you're not going to action it? If you're not going to be able to put it into motion, if you're not going to be able to defend the things that matter most, and that's one of our core principles in why we exist and why we're here. We want to be able to bring that intelligence in multiple forms between IOCs, TTPs, campaigns, how do you slice up the intelligence we have to deliver it to our stakeholders and our customers in a way that's most impactful, to defend what matters most to them. The next is building our complete threat picture. We can't really defend if we don't understand attackers. Everything that we do is really focused on what do we know about threats, who it is, and what they're doing. We try to spot trends. We try to get in front of it and to mitigate risks. So we really need to look at all of our visibility. How do we pull it together and how do we cluster these things to understand attackers themselves? And finally, we're really looking at disrupting adversaries. We're really looking at standing up a holistic, coordinated disruption effort. And what that means to us is how do we start to eliminate entire classes of threat actors or techniques? How do we work with products and remediate different ways attackers use products? How do we coordinate with law enforcement? How do we partner with governors, strategic partners, so that we all can coordinate together to start to take proactive action in stopping and mitigating things and disrupting their operations before they start? And so we really look at defending and disrupting by knowing the most about attackers. When we look at we have a global worldwide operation, right? And I break that down into a couple things of what that means to us. The first is we have global experts. We have about 460 analysts and experts and researchers across the globe. We're in about 30 plus different countries. We speak multiple different languages. And that's really important to a threat intelligence business to understand regional threats, to understand cultural nuances, to understand what is happening in different local environments and bring that into our operation. The next is global visibility. And Chris touched on it a little bit is we can't know the best or we can't have that comprehensive threat picture if we do not have a global visibility into what that looks like. So it's looking at what we organically have, what we have to partner with and really trying to look at how do we find evidence of what attackers are doing and where they have it and bring that in. The last kind of global thing that we have is really looking at coverage. So what are our threat priorities? What are the things we should go after? How do we understand just because we have visibility and experts, do we have the coverage on the right things at the right time to make sure that we can get actionable intel out? So if we kind of take a step back even further and really looking at behind the scenes of how we run our threat ops organization, I break it down in a couple different categories. The first is we do analysis and research on threat actors. So it's really looking at kind of the criminal, so to speak, about what's happening and trying to learn everything we can about them. We have two core ways we look at that. We really focus on nation state and we focus on cyber crime. When we look at nation state, while it might not be super widespread, but they end up being very impactful to the people that they compromise. On the other hand, we have cyber crime. We look at those in two different buckets. We have an intrusion-based cyber crime, so monetizing intrusions. That's where you see extortion, ransomware, and there's a lot of current trends. On the other hand, we also have mass distribution. So looking at how you can get scale and monetize the scale of your compromises to making money. And so we have researchers very heavily dedicated to having that day-to-day research in these different core areas to provide that dynamic update to do that defense. When we learn something, our products learn something, and we're constantly depending. The next is if you kind of look at attackers in one direction, but if you kind of turn it, we're looking at not only the threat actors, but the attack surfaces of which they come over here. Particularly in different merging technologies, right? We have how do we look at threats to cloud? So not just looking at from the attacker, but then looking at where they go and what does that look like? We have threats to AI, right? As we really look at this emerging landscape, we're looking at how these attackers are using these technologies to integrate them into their operations. We have IoT, cyber-physical type stuff. We're looking at all the vulnerabilities coming in, trying to figure out what is the most impactful, if they've been exploited in the wild. Additionally, we look at attacker methodologies. So if I look at these missionaries and these very impactful threat actors, how can I learn from what they're doing? How do I look at their techniques, pull out those techniques, look for those across all our visibility, and start to look for emerging threats that we may not even be tracking or know of just yet? The next slice I would look at from the same kind of pool of threat actors is current events, right? It's this campaign concept that what is happening here and now? It's really good, and we have very many years of looking at, hey, I can tell you 10 years of this particular attacker, but what's happening today, right? What is the time-boundness of it? And so we get that from a couple different areas. You know, that's where we spend a lot of time side-saddling and partnering with our IR investigations. When you look at different SOC alerts that are coming in, that's a really good indication of what people are trying to go after and what they're going for now. We have significant events, so when the Atlantis Zero Day breaks, how do we have people really looking at all angles of how do we know what has happened, what has occurred as fast as we possibly can? And then really looking at, from a threat actor perspective, what are they doing now? With the visibility that we have, we can see them concurrently moving through different environments, and they typically are using the same techniques or the same infrastructure in the same kind of day structure. So by having such grand global visibility, being able to glue the story back to create a little bit more of an MO of the attacker and an MO of their current campaigns to make it as impactful as possible. The next is something I call function or different operations, and it goes really into what we're going to do about stuff. I mentioned disruption, right? How do we have this idea of coordinated disruption? How do we learn from the three things and the pillars that we have where our research happens, and how do we apply it back out and have a good, like, what do we know the goal is, and how do we know what the impact is, and how do we go after that? The next is how do we really look at malware collection, right? We know much about what malware these different teams are using. How do we do emulation? How do we pull and auto-pull out a lot of the configuration? How do we do auto-discovery of new C2s? So we have a whole kind of operation around how do we go after what we know and bring it to the next edge to kind of constantly make sure that we're pulling in the latest information. The next is we have a pretty big operation around underground. We're in dark web forums, right? Really, how do we look at, we go extract information out. How do we understand what people are talking about, what the current risks are, what people are selling access to so that we can try to mitigate it and bring that forward for our customers. And finally, when we look at all of this, it's really about that delivery, that actionability, that defending, disrupting. How do we bring it to all our stakeholders to ensure they're getting it in the form that they want? When I look at layering these together, I look at this is kind of how we do the operations. On the last slide, we need to do it at a global with the right experts, the right visibility, the right coverage. That's how we build our threat, like our complete threat picture to do the defending and the disruption. Awesome. So yeah, I think it's, in many cases, I think it's somewhat difficult to imagine the pipeline of sort of effort that goes in. You see an indicator score inside of a product and you see that indicator score just kind of, you know, saying it's bad or not bad. But it's impressive the amount of stuff that bleeds into that pipeline, just the amount of effort that goes into each and every indicator we track, every threat actor we track, and all those kind of things behind the scenes. So one thing I did want to point out, because we haven't hit the buzzword yet, is how this all matters from an AI-driven or automation-driven security operations lens. And so the reality is, like, all of the things we just talked about, all of that pipeline helps even when you're providing detailed levels of automation at the front end of the curve. And so one of the things that we announced, if you were able to hit the security spotlight or able to see the demo that we did in the keynote, was the ability for us to do alert triage, agentic alert triage, where you actually have an AI agent that's looking at an alert that's coming in and trying to determine whether or not it's a true positive or false positive. And so the way that basically works, as you can see here at the top end, it shows a high severity, which basically means it's been marked as a true positive. But what's happening is the AI agent is actually looking at the context of the alert. And all of the things on the right-hand side here, each one of those additional analysis steps, see it says an analyzed hash, then it went through and investigated additional events around that time window. Then it might go and look at specific things around the command line activity. All of those things that it's actually doing, each step that it's taking, is leveraging the underlying intelligence pipeline that we feed in and overlay on top of the event data itself. Right? So the more that we're able to overlay and place this intelligence kind of information directly as part of the events, the better off the AI model is in terms of actually being able to reason and understand about how these things work in practice. Okay. So I want to go back to Nicole and talk a little bit how this actually works in some real world activities and real world practice. Thanks, Chris. On October 24th, we saw another headline that looked like another edge device was compromised with a zero or had a zero day and was being exploited in the wild. This was a trend we saw in 2024 that attackers were moving. One of the biggest trends that we were starting to see is attackers are getting caught, right? And so they're moving to different technical places to avoid visibility. And so edge devices are one of them. There's not as much detection capabilities that are looking at these edge devices. They're doing what we call living off the land. So how do they get passwords? How do they use what is in your environment for deploying malware? They're trying to hide their infrastructure. We have a lot of research out on orb networks that are really relay boxes that constantly change, right? So there's a big trend that has happened in the last couple of years of really looking at how do we evade visibility. So October 24th was no different. We point out a joint blog of a joint investigation that we did with Fortinet on a zero day into one of their products. And really, if you look at the scenario, October 24th is when it was announced, right? And a blog went out. That's not the day our investigation started. That's the day that everybody else did. So as leadership around the world woke up, read the headlines, they see, oh, my gosh, what do I know? Are we impacted? Do we have those devices? What are the attackers doing? Do I know if anybody's in my network, right? But for us, it starts the minute we get the call for the initial investigation. And so that's where IR kicks off. That's where we partner with the people who call us to figure out what has happened. And that's where we really look at. Like if you think about it as a crime scene, right? You look at it in the sense of, all right, you get a phone call from the police. You go in. You have to figure out what happened. You've got to sort for your evidence. You have to understand how to do research. And your whole point is to look at what happened at this crime. Who committed it? Concurrently, that's where we come in. We don't look at, we let that up to the investigators to figure out what happened in that exact scenario to do the remediation. What we come in is look at, do we know who did it? Do we have any indications that we know who this was? Because what we want to do as very fast as possible is if we can figure out who we think it might be, we may understand where they've been or what they're currently doing and to provide that back to have a really Intel-led IR. But sometimes you don't know what it is. So what we have to do is look at all the different aspects of what we know. And that's where our concurrent investigation into who starts. And so we want to be able to, do we know who it is? Yes or no? Can we provide that information? If not, for the emerging intelligence coming out of that IR, how do we start to look at what do we know? So that's taking infrastructure and looking for it. It's trying to figure out, has anybody else been impacted? So as we get different artifacts and TTPs of what has been happening and how this exploitation occurs, we want to use our global visibility to understand what it is. And in this particular case, we saw that it was happening and different exploitation happened. And in this one, what we know about it is you were able to exploit these edge devices and you were able to get configurations and passwords, which means what happens next? What do they do with that information? And that might be where we lose visibility. But what we could tell after looking through our SecOps products is that we did have multiple people who are impacted and exploited. And so we reach out as fast as possible because the faster you can reach out to them to let them know that this information is out there, that they have been exploited, they can start their own investigation of what has been the impact. Did anything more happen? Has the attackers gotten in my network? And so concurrently, these different things start to happen. And so as we look at how we put that scenario together, that's when we get to do we have enough information to get out for a blog. So going back to October 24th. Like I said, that's not where it started for us. We use our investigators to figure out what's happening. We use our intelligence teams to really look at and refine who and what and where and what else is happening. And we do proactive notifications, defenses, and releasing that information out to have that best protection as we go through. And that's, you know, this was one example but many more. We've talked about campaigns a lot. This is really where our campaigns shine. These are a couple headlines from our GTI product of different campaigns that we've had. Snowflake was a big one. That didn't start with an IR. It did start with dark web data of someone selling initial access. And so how do we start to look at, well, what else do we know about this? What else have we seen posting? So it's really looking at a different angle and working hand-in-hand with our defenders and our instant responders to really look at what is happening now. How do we clump that information to make it most impactful and useful? What we don't want to do is show up and be like, we've seen them for 10 years. Here's kind of abstractly everything we know in a dump of lists of indicators that may have all aged off. We want to really slice down the information to make it as useful and impactful and get to the point to get in front of the attackers and to stop them when we can. Thank you, Nicole. So it's great to be here, everyone. We're going to start off with some intros. I'm Paul. I've spent the last 15 years designing, building, managing SOCs, 20 or 30 of them across Europe. I currently run our cyber and security operations consultancy function in the UK for Deloitte. Great. Thanks, Paul. Likewise, it's really great to be here. So I'm Caroline. I've got 17 years' experience in cyber and intelligence roles and also co-lead our security operations team. But I also lead our technical cyber response team. So I help clients both proactively but also reactively respond to cyber incidents. Awesome. So before we start, everyone's favorite, we're going to do a bit of forced audience participation here. So can I get a show of hands? Who here has lived through a cyber incident before? Decent number of you. So put them back up if actually the entire incident was fairly chaotic, you never had the data you needed, the threat intelligence you wanted, and the capabilities to respond properly. About the same again. Awesome. So what we're going to do is going to take you through a cyber incident response that we responded to last year with a major European government organization. But what we're not going to do is just do the standard incident response walkthrough. You've heard that before. No one wants to go through that again. But what we are going to cover is what the circumstances and the threat actor meant we had to evolve our entire IR playbook. We needed to respond faster than we ever have at a scale we couldn't before and with a depth of insights that was game-changing for us. And this was given to us by Google SecOps and Google Threat Intelligence. And, most importantly, what lessons we've learned that you guys can take back to your organizations. So, as Paul said, what I'm not going to do is talk you through a typical incident response investigation. But I do want to talk through how the attack unfolded just to set the scene. So we were called by our client because they had noticed some suspicious activity possibly related to credential harvesting. They also thought it could have been a red team as well. This is what we call our day zero. So this is when we invoked our retainer with them and our response. As soon as we started the investigation, we very quickly realized that it wasn't actually a red team and it was actually malicious activity. The threat actor had exploited a zero-day vulnerability in the client's remote access solution. They gained a foothold, established persistence, kept re-entering the environment, and they were also exfiltrating very highly sensitive data. It was at this point that we would say that they had complete and utter full control over the whole environment. And at this part of the investigation, we thought initial access was around three weeks prior. So that's sort of the starting point that we were dealing with. So at this point, we've started to understand the attacker's initial movements. It's a fairly small cloud estate and we're starting to build a plan on how to respond. The client was initially in a panic, but it started to calm. We've contained key compromised assets and beginning to do a manual deep dive analysis and forensics of them. However, those of you who have already been through an incident would know things never go as according to plan. So we had a number of challenges, but before I sort of touch on exactly what those challenges were, the environment was also undocumented, uncontrolled, and unmanaged. And we deployed some NDR tooling as part of the incident response to try and gain that visibility of the network that we just didn't have. It was around this point that we started to realize that perhaps the environment is not quite so small as we originally thought. And then started to use ASM to understand what we were actually dealing with. So we had been sort of informed that it was multi-cloud. They had one Azure tenant when actually ASM identified they had four. They had one GCP project when actually they had over 700. And ASM also identified a number of other cloud vendors. So we were dealing with quite a complex environment. We also realized that the GCP environment was a mix of prod, dev, and test. So it was quite complex, one would say. We had also identified that the threat actor had deployed a number of backdoors in the environment. So whilst we now have started to realize the environment is pretty large, we now need to work out, well, is it really unmanaged? Where are they? What have they done? And how widespread is this compromise? So, yeah, the threat actor at this point could really be anywhere and everywhere. So at this point, we've realized that the problem is potentially much larger than we first expected. And it's going to take time to investigate all of these environments using our standard IR approach. Time we didn't have. The CTO has been on the phone, already getting in a panic again. We've taken down key public services, and we can't even pay our staff. How can we get back online? We can throw more resources at the problem, but ultimately, we're hitting the ceiling of what we can achieve with our standard IR process, particularly in the timeline the client needs us to. So, as you can probably imagine, we're now, like, the investigation and being able to respond is slightly hindered. We also had some significant gaps in the sort of logging. There were misconfigurations in the security tooling. There was a lack of network segmentation. So, I mentioned the sort of mix of dev, prod, and test. Well, there was no network segmentation at all. They did have Sentinel, and the Sentinel instance, the logs that were going in there, some were parsed, some weren't unparseed. So, it was also adding to the complexity. But ultimately, all of the data that we did have or didn't have was not integrated with threat intelligence. We did, however, have a bit of a breakthrough. And we found a security logging bucket, which had 18 months' worth of security logs in it. So, this data had never been ingested, monitored, or analyzed. However, this was what we considered our lifeline, and we just, at this point, just needed to grab it. So, this is where we first brought Google in, starting with Google threat intelligence. We started to run the indicators we did have to see if we could identify who the threat actor may be and what they may have or still be doing. This was our first key win since that day 10. We were able to confirm this was not an opportunistic, financially motivated, semi-sophisticated actor, but instead, highly likely, a nation-state sponsored APT. So, Caroline, what was our plan? Well, so we've now got an environment which is a lot larger, in fact, sort of 10 times larger. We've got significant gaps in visibility, and we've got billions and billions of logs. We've also got an APT, and we know that they're using, you know, living-off-the-land tools. They're likely to deploy bespoke tooling. But ultimately, we needed to take back control of the environment and kick them out. So, what did we do? Well, we evolved our step-by-step forensic approach, otherwise we'd probably still be there. And we deployed Google SecOps and used GTI in order to detect and hum. So, we've got these billions of logs, but we need somewhere to analyze them, and we need to do this quickly. Our first step was getting the logs into Google SecOps. Next, using the applied threat intelligence at the point of ingestion, and particularly the value pyramid Chris referred to earlier, we were able to start identifying areas to prioritize for our analysts and investigators. We then began to ingest all other logs, building on the value that we were already seeing from Google SecOps, and deploy additional security tooling throughout the environment to give us better data going into SecOps, and better quality of capabilities to respond. But here's the real kicker. We had to do all of this in less than 28 days. So, the example that you're seeing on screen right now is just an example of how we leveraged and used the graph capability within GTI. So, we've now got the data that's going into Google SecOps, and we've also got the applied threat intelligence within SecOps, and we've got the indicators that we had initially from the very start of the investigation. So, we used all of these, put them into the graph capability within GTI, and started to understand or find other additional associations. This ultimately helped us try and expand our scope and hunts in order to try and find the threat actor in the environment. So, this was great at getting billions of logs down to just thousands of alerts and points of investigation. However, we didn't have time to go through every single one. We needed to be able to quickly understand and prioritize which ones were related to our threat actor. For this, we turned to Gemini. Here's an example from our own internal security operations lab, we are not the actual client environment for confidential reasons. But this starts to give you a bit of a feel for some of the questions and prompts we were feeding Gemini, looking at the output it was returning, and then taking that further into really narrowing down exactly what it was we wanted to look for. This started to give us IOCs we hadn't previously detected, and we used this to start to build a picture of the likely TTPs the threat actor would deploy to enable hypothesis-based threat hunting further down the line. This essentially helps us reduce days, if not weeks, of analyst effort into minutes. So, this is where a lot of the bulk of the work came from, and this is where we sort of, what we call hypothesis-led threat hunting. So, we've got the indicators of compromise, but now we want to go that one step further. So, we knew we were dealing with, like, an APT. We knew they were advanced. We needed to understand their behaviors, their TTPs, etc. So, we used the MitreAttack framework and then used GTI in order to help build out what we understood the threat actor that we knew we were dealing with, what their TTPs were, but also other threat actors that we knew were likely to target the organization. And this is where we then created custom detection logic. The example that you're seeing on this screen is actually where we also, in order to help sort of create this detection logic, we used Gemini in order to help this. So, this particular example, we knew that the TA was known, the TA, the slang for it, the threat actor was known to load malicious DLLs by executing legitimate Windows binaries. This is just one example of many that we deployed, and we would run these live and also retro hunt within the environment. So, ultimately, I guess to summarize, if you remember back to the very start when I said the initial access was around three weeks, well, thanks to Google SecOps and the applied threat intelligence within Google SecOps, we actually detected them nearly four months earlier than we had initially identified. We also identified them in the prod and dev and test environments, and they had deployed multiple backdoors within those areas. So, I guess, if it was to summarize, through the use of Google SecOps, we identified, contained, and evicted the threat actor, ultimately taking back sole control. Awesome. So, in conclusion, what did we learn, and what lessons can you take back to your organizations? Well, first of all, speed. We needed to operate at a speed we'd never done before. For this, we used Google Applied TI and Gemini. This was an absolute game changer in the number of alerts and logs we could hunt over in a very short amount of time. Second, scale. The ability to ingest, normalize, parse vast quantities of data, retro hunt and search over them allowed us to make the amount of data we had to deal with actually became a benefit and an opportunity, not a challenge. Finally, depth. As Nicole's already said, we had to leverage strategic, tactical, and operational threat intelligence to properly hunt this threat actor across the entire environment. This meant everything from actionable IOC matching within SecOps itself all the way to breakdown of the threat actors' TTPs. So, if you want me to take one thing away from today, it's this. Enable your most valuable resources, your team. Give them all the data they need, the threat intelligence up front, and use AI to streamline their workflow to allow them to make better, quicker decisions. Thanks. Chris, back to you. Awesome. Great. Yeah, as a product person, you know, I just love stories like that when you can actually see how your product operates in real-world activity. It's just energizing to me to be able to hear that. So, thanks. Thank you, Paul. Thank you, Caroline. And, obviously, thank you, Nicole, for being able to walk through the way our research team operates. You know, plus, you know, Paul and Caroline speak in fancy English accents, so you have to listen to what they have to say, I think. So, a few things just to follow up here. Obviously, we talked a lot about SecOps. If you are interested in learning a little bit more about other places where either our portfolio or other parts of the security portfolio are being highlighted, there is a few sessions left here listed on the left if you want to be able to kind of dig deeper. You can also see some of the things that we've done on previous sessions through either the security spotlight. We did one on AI agent workflow. We did one on how to get data efficiently into SecOps. All those happened either yesterday or earlier today. But if you are able to go look those up online and kind of catch up on them, I highly recommend it. The other thing that I would also say is go check out the demos in the showcase floor and the expo floor, both the Deloitte booth as well as the Google booth itself. So, we have a security hub at the Google booth. It's got a whole bunch of interactive workflows, capture the flag type things, really cool ways of interacting with our products. So, I highly recommend you go take a look at that as well. Last thing, I'm required to ask for feedback. So, by all means, everyone submit feedback. Hopefully, this was very informative and hopefully you got a lot out of it.