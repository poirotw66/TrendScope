 . Welcome to Breakout 235, from portal to platform and unlock the power of backstage and Google Cloud. My name is Ruan Badawi, and I'm a Google Cloud Consultant Cloud Engineer. I specialize around reliability engineering, so I help our customers improve the reliability engineering best practices as well as helping them with their platform engineering initiatives, which we all love and know as automation. Before I joined Google, I played numerous roles at startups, such as SRE, Product Manager. Then I transitioned to become a principal DevSecOps engineer at NASA. So let's get started. Our agenda today will be around backstage overview, how you can host that in Google Cloud, the HCGKE multi-tenant self-service strategy, an architecture overview, the implementation. Then we'll stop with a demo and outcomes and resources. So let's talk about backstage. Against common belief, it's not a developer portal. It's more of a framework that can help you build your developer portal. It's also not a platform. So if you think that you're going to get this large button that says deploy to cloud, that's not going to happen. You have to build your platform as well. It's a framework specifically made to build developer portals, and it's extensible and customizable. It's developed by Spotify to accelerate and improve the developer experience. As a framework out of the box, backstage includes few main pieces functionality that can really help. The software catalog, which is your enter point to the portal. So you can actually provide relations between your APIs and downstream dependencies, such as your components and infrastructure. Software templates, which HCA used heavily in their implementation, it offers a way to create and expose golden patterns to your customers and your end users, which are your developers, and execute actions to integrate with third-party tooling with custom actions. Plugins allow you to deeply extend and integrate backstage into the rest of your environment, and tech docs prove a way to provide consistent documentation in the convenience of your Git repository. So here's a high-level diagram of backstage if you would like to host it on Google Cloud. As a high-level, there is the HTTP load balancer, and you can front it with identity-aware proxy that actually allows you to authenticate into backstage. Artifact registry allows you to store containerized containers of backstage and host it either on GKE, and we've heard implementations on Cloud Run. Cloud Storage is used to host tech docs, and Cloud SQL is used as a data store for backstage and other plugins. Secret Manager enables you to actually store secrets such as GitHub authentication and APIs. The reference architecture with a Terraform module, which my coworker, Paul Ravello, who's not with us this year, he was with us last year, created for you. So if you want to snap that QR code, feel free to do so. Now I'm going to hand it off to Cameron to talk about the architecture overview of their GKE multi-tenant service with Backstage. Cameron, over to you. Awesome. Thank you, Rowan. How's everybody doing? It's good to be here with you today. I have multiple managers in the back. That's where the noise is coming from. Very enthusiastic people. But my name is Cameron Farmer. I head our developer platforms team at HGA and our developer experience at HGA Healthcare. We're located in Nashville, Tennessee. My team is focused on enabling and supporting self-service initiatives and Backstage, as well as application development standards for the enterprise. I also support our low-code, no-code technology solution as well. So just so I can get a feel in the room, how many people have Backstage going on in their company and thriving? Half the room. Half the room. All right. So the other half is how many people have stood up and still trying to figure out Backstage or if Backstage is going to even be good for you. All right. It's 50-50. All right. Cool. Awesome. I know how to direct my points now. So just a little bit about HGA. At HGA, we truly believe that above all else, we're committed to the care and improvement of human life. And I'm lucky to be able to leverage technology to create better outcomes for our patients, our clinicians, and our colleagues. HGA is the largest for-profit healthcare system in the country and one of the largest in the world. We're a Fortune 62 company with 190 hospitals, over 2,500 sites of care in over 20 states, the UK and India. And just the other day, actually, a press release came out. Fortune named HGA Healthcare one of the most admired companies by Fortune. So it could be a great place to work. But we're on an application development and application modernization journey. And we've used Backstage to accelerate that journey, accelerate us into cloud, actually, and reduce our time to Hello World. We're about 2,000 developers or my customer or our customers. So, a lot of people we saw that work at HGA Healthcare, often that leaves a lot of room for different opinions and perspectives. So, like, what is the role of an engineer or developer? And I would categorize that as this. You know, we want them to engage in what the company is building. We want them to take business requirements, turn that into logic, and then make impactful solutions and applications. So, to do this at scale, for us, meant that we had to standardize our technology and build golden paths. We actually discovered that we spent way too much time in sprint zero. So, choosing our tech stack, getting CICD pipelines built out, figuring out our DevOps processes, and on top of that, introducing cloud to a historically on-prem organization added an additional level of complexity. So, we had to find ways to get our engineers going quickly, while also shifting the focus of building and deploying applications from IIS to a containerized approach. So, today, we're going to talk about how we did that with GKE. So, last year, we did this talk on how to build an Ontario developer platform on Backstage, and that focused primarily on our organizational structure and challenges and Cloud Run. We made a decision, you know, whether through Cloud Run or GKE, we decided that every custom-built application needs to be containerized. So, first, we enabled self-service creation of GCP projects. Then, we extended that to our Cloud Run containerization platform through self-service and Backstage. We made a decision to move away from our current, or at the time, private on-prem container application platform to Google Distributed Cloud, otherwise it's Anthos and GKE. And so, that meant that any new use cases that were going, microservice architectures, distributed architectures, we would need to create self-service and standards for our engineers and developers to consume and build at scale. So, this is the 30,000-foot view of kind of what we had to decide. So, we built our platform based on CNCF platform architectures, which means that some of our tooling is open source, so there's no secret sauce. If you think through a strategy and leverage CNCF tooling, everything that we describe here today, you can take back with you to your organizations and find a way to implement. So, I want to give you a picture of what that means. And in no way do you have to follow this order, but just kind of give you an idea of the order that we kind of went through things. So, we started with foundations, so network policies, and IAM, identity access management. We then moved to infrastructure and leveraging infrastructure scope. We made enterprise architecture decisions on when and how we incorporate messaging and how data moves throughout our environment. We doubled down on an SRE strategy that we continue to refine today. We doubled down on security and how we manage secrets. We designed our pipelines to start shifting left and to incorporate as much of these things as possible in our infrastructure and our application pipelines. So, then we started building Golden Pass. Started off with documentation, that being our first step to building Golden Pass. And then, obviously, the developer platform and Backstage were the way in which we kind of enforced and navigated people through these workflows. So, we're at a Google conference. Obviously, this slide represents that you can do these same things using a Google-first approach. That did not work for our use case. But for some of you, it might. We had to distribute tooling over a lot of different tooling. Some of that tooling we worked with, some of it was new to the organization. We had already a heavy Confluence use. And so, we figured out a way to pump our Confluence data into TechDocs as that's one of Backstage's components. And it proved to be very valuable to us. Obviously, Backstage is our internal developer platform. And GitHub Actions is our enterprise standard for CI-CD pipelines. Argo CD was heavily ingrained in our culture already from our previous on-prem containerization platform. So, we continued to use it. Nexus was, again, another platform we used. And we ingrained and was heavily ingrained for image repository management. So, we carried that over as well. We had already made heavy investments into Infrastructure's Code and Terraform and HashiCorp Vault for secret management. And Dynatrace for alerting and monitoring and observability. So, we'll demo a little bit later how all that works and connects together. But Rewan is going to dive a little bit more into the implementation and show you what's under the hood. So, Rewan? Thank you. Can you talk about implementation over here? My mic audible? Okay. So, I wish we had all day, but we're keeping you from happy hour and we really appreciate it. So, let's just keep our scope to, as a developer, I would like to ship code to a multi-tenant GKE cluster and have my data stores, Cloud SQL memory store and optional cloud storage, and provide CI CD pipelines. So, I'm highlighting this journey with the tools that we have in front. Again, there are other parts in our platform that we have integrated, but just so we can keep this short and sweet for your time. The requirements stay somewhat the same regardless of the tooling and pretty standard across other customers and your environments as well with variations. And to support the different use cases, some additional implementation might be needed like API endpoints or setting up SSO or even creating a pull request in a GitOps repository. And all these can be executed with custom actions that are wrapped with JavaScript or TypeScript in Backstage as well. However, it boils down to, first of all, you need to create your foundations, your landing zone implementation. As you know, the applications can't just be deployed in the air. So, you'll need to create your multi-tenant clusters and where those workloads will land and manage via GitOps. Then provide an enterprise standard application IAC blueprints. So, we've partnered with the data folks, our data engineers, our DBAs as well, as well as other teams such as security to provide enterprise best practices for that. Finally, we need to create pipelines, standard pipelines that we deploy to the enterprise to deliver code, dockerize it, container it, put it into a Nexus repository. And also provide Argo CD to deploy the GitOps workloads there. As well as we templatize those app code and Terraform templates and provide CI CD pipelines for Terraform. Finally, we render the templates based on inputs and call APIs through Backstage tooling in the terms of creating templates. So, the previous flow implementation can be summarized in three major components, the portal orchestrator, the cloud platform, and application workloads. Let's talk a bit about our portal and orchestrator. So, HCA relied heavily on templates in their self-service capability, which boiled down to the ability to input parameters and execute actions. Two portions that really help that are out of the box is, for example, creating a fetch template is an action. As well as the ability to scaffold the steps in terms of steps. Now, bear in mind that if you have an asynchronous call, the scaffolder will not wait for it at that point. So, you might need to actually tie in other work floor or orchestrator in the back end if you have a multi-step process that you would like to follow through as well. The extensibility of Backstage also allows you to create your own custom actions. So, you can actually, if you have developers that are knowledgeable in TypeScript, you can wrap your API endpoints with TypeScript and execute custom actions. Let's talk a bit about the software catalog. HCA also created customizations for the software catalog. As the software catalog in Backstage by default is in the purview of the developer to add and tie additional CI components there. However, we needed to store additional metadata such as the product app code, which topology of the network that this landing zone implementation would be in, as well as the GKE cluster that each work will tie to, which is tied to their line of business. And that is actually decoupled from the catalog info that is stored with the application in a separate data store. The GKE plugin also that is integrated into Backstage also pulls in information from the cluster labels that we provide on our clusters in our multi-tenant solution. And that provides us the ability to fetch this data in the backend and actually tie and derive information without having to ask the developer for the input themselves. So let's talk about the cloud platform. In general, you'll need multiple IEC layers. So you'll need your foundation that's your foundation. And ideally, that should be implemented in infrastructure as code, as well as creating your GKE blueprints of multi-tenant clusters. From that perspective, you can leverage the GitHub repository that is created by Google Cloud Consulting that has an opinionated approach of best practices to actually accelerate building that platform for you. You can actually fork it and actually create additional customizations of your own. Project Factory covered last year in our session, and I have a link that would actually send you to our last year's talk. It's the YAML-style factory-based input of actually creating a consumer project. And then finally, you'd have to create infrastructure as code for your application golden print, having your opinionated approach there as well. So I do want to mention that HCA, this is more of a day zero of creating the templates for Terraform and adding the inputs. However, if you want to leverage backstage to edit the Terraform golden path templates, bear in mind that it's actually written in HashiCorp configuration language. HashiCorp does support adding JSON or even their CDK that is currently in beta. Now, we kept it in a human readable format because we're covering 80% of the use cases. The developer has the ability to import additional private registry modules to complete their user journey as well. However, you can use HCL write library to edit the Terraform if needed or decouple your files into separate files that you can do a pull request to overwrite it with backstage. A common pattern that we see other customers do is actually using some, if they are a multi-cloud strategy, using cloud cross-plane. If they're in Google, there is Kubernetes resource model, which is more of KRM, which is more of a YAML-based, similar to how you would deploy to GKE, of deploying your cloud resources. And that is actually more editable from a programming perspective because you can just use JQ or YQ to edit it. Crow is another new model that is now being developed. However, it's not in production yet, but it's a very good dependency management to actually build out these golden path patterns as well. Now, the last part, which is the application workloads. Before we can even develop an onboard a developer or an application to their GKE clusters, we need to agree on the level of isolation. Is this application going to be deployed in one cluster, in a single region, or multi-region? Or even having it in different zones as well. So, for HCA, we standardized on each application, it could be one multi-service or multiple multi-services to be in a namespace. And they have separate isolated environments for DevQA and prod per line of business. And the way that we leverage how to provide this kind of standardization with GKE is using Kubernetes labels. So, we actually label the clusters with active and the line of business and fetch that in the catalog data to actually identify which cluster we need to add the workload or create a namespace in. This is also a discussion that you will need to have internally based on your compliance and regularity compliance agreements that you have. So, there are two layers of GitOps repositories. You might have multiple that the container team will have to create to bootstrap clusters, as well as the GitOps repository that you will need to provide for the developer to actually provision and deploy their workloads. But out of the box, it's just actually organizing your GitOps repositories and managing the variations, either with customized or the value template of a Helm chart. And then using config sync or Argo CD to actually bootstrap the clusters. So, in this example, we're showing how you can actually create a GitOps repository to actually create new namespaces. If the developer needs to variate or deviate or add, for example, any type of modification for the limits, they can do so through a pull request that gets reviewed by the platform team. And that's how we simplified the configuration. We also needed to provide a way to map applications into Argo CD for the workloads. So, application sets or apps of apps is the model that to do so. And this is for specifically for the GitOps repo for the workloads itself. We also provided standard templates of CI CD pipelines. So, in an automated fashion, we can actually update the image tag that would actually deploy to the GitOps repository. At HCA, as soon as you merge to the stable branch, and this is not push on dev kind of scenario or pushed and deployed scenario. As HCA, they do have change windows that they have to adhere to. So, they adopted the Git flow model, which is driven by varying levels of team maturity and deploying stable code to lower environments first. So, they have two stable branches, develop and main. And once they sync to develop, automatically, the image tag will get deployed to the customization of dev. And then once they actually merge to main, it gets deployed to QA. And then they have a release workflow that deploys to prod. Argo CD will pick those changes and deploy to the cluster. So, you'd have your latest image there. We've also built in security. So, Wizz I.O. does scan the container period to deploying and pushing into their Nexus repository. Now, I'm going to hand it off to Cameron for the demo. Thank you, Ruan. So, we all want to see this happen in action, right? It's still not going. Here's an overview of kind of how a developer is able to use Backstage and deploy applications to GKE. So, like Ruan said, we use a shared cluster model, which is using namespaces to separate application and environments. And at the cluster level, we separate a line of business as HCA has multiple lines of businesses. And needs of separation exists there. So, there are three templates a user has to run to then get a deployed Hello World application to a dev environment. The first one is a GCP project. You always have to start with a GCP project, which will give you your Terraform workspace, your network foundations, your cloud identity access, your ISE repo, as well as your CICD pipelines for your infrastructure. And then we'll move on to our GKE onboarding template, where we get our namespace. They'll have to run this for every environment. But it creates a namespace, Argo CD app, and a GitOps repo. And then finally, off to the fun part, is adding our Hello World. So, they can run this as many times as they need to, deploy as many services as they need to. And that's application code with CICD pipelines or CI pipelines and any needed service accounts. So, let's see this in action. So, reminder, Backstage is just the tool that stitches it all together. This is what our GKE onboarding template looks like. We have populated a lot of information already for the automation from our catalog, our app code, our AD groups, networking, et cetera. Naming conventions are already in place. User only has to select their already registered app from the dev creation that was earlier. Selecting additional services like Cloud SQL storage, memory storage. We're not using that in this exercise, but as we can see, we're off to the races. So, these steps or actions, Ruan mentioned custom actions. We build a lot of custom actions. And that is what you see in this run right here. And those custom actions or actions in general can pretty much mean quite a number of things. External API calls, combining of information, importing data from various sources. But in this case, the automation creates the namespace, get ops repo with overlays in the customized file. Permissions to the shared cluster for their namespace, Nexus repository, and Argo CD app. We house a governance repo that manages the namespace. So, that's a PR that gets created and auto-merged on behalf of the user. And then at the end of this run, we give everyone links to their artifacts. So, their GitOps repository in GitHub, their Argo CD app, and their Nexus repository. The next step is a short run just to connect their, or inject their Nexus repository secrets into HashiCorp Vault, which then allows, or makes aware of that happening at their repo when they do their deployment. So, now to the fun part. We're off to our third step in the chain, adding our first service, a Hello World app. And so, we spend a lot of time creating and developing schema of the catalog, and building out our catalog, which makes a lot of this stuff reusable and very seamless for the user, so that they don't have to put in a lot of information. But this template pulls in all that information from the catalog, the user's created in the previous steps, injects the inputs, so that the user doesn't have to think about it, and not have to answer too many questions. And the user really only has to name their application, say they do or don't need an ingress, answer a few other questions related to Google services that they may or may not use, like Cloud SQL and Memorystore. But the main thing that this automation is doing, and all of the custom actions that you see here, are creating the repo for the code base with CI pipelines, as well as doing a PR to the GitOps repo to register configuration map. So, at the end of this, we again give them the artifacts. We see that there are a few pull requests that have to happen, and we also give them the next steps. So, after this step, we'll run our Hello World locally. You know, we have all our code. We want to run it locally. We'll check the pods, and we'll check our Argo CD app, and then we'll visit the ingress. So, that is what we'll do here. So, as a former front-end developer, the first thing I get when I have code is I want to run it locally. Does it work, or is it going to bomb out on me? And in this case, it works. So, hello, Google Next. Then we'll check our pods to see if the thing actually deployed those services to our namespace. So, we'll check the pods, and we see that we have two replicas. There's a Python API I ran outside this demo. And we'll check our ingress, and then we'll use that ingress and go visit it to see if that application actually got deployed, and it did. And so, our local and our deployed match, and here's our Argo CD, our Argo app that is pretty healthy, and everything looks great. So, outcomes. This was the work. This was really the work. The workflows, the diagrams, figuring out the order of events that need to happen to actually make self-service in GKE happen. Backstage, the backstage template, yes, took a few weeks, and there's continual conversation on how we structure our catalog. But for GKE and any other automation we've built, the satisfaction comes with the underlying standardization and the automations to build it. And so, at the end of this, we've effectively reduced the weeks of a process down to hours, or a hour. So, key takeaways, if you're a developer, look for the frustrating things. Look for the things that frustrate you and your team. Cold sprawl, build times, figure out ways to reduce. If you're an executive, a little short story, our organization is very distributed, and every team has their own process. Our leaders realized to accelerate our efforts into the cloud that we would all have to work together. So, we invested heavily in platform engineering, engineering best practices, which allowed our company to scale our service offerings, and now we're able to solve bigger challenges. So, for example, infrastructure engineer helping teams manually spin up GCP projects and help teams figure out, you know, which GCP services to use. That same engineer writes Terraform modules, which are reusable, they write backstage templates, and they create DevOps pipelines, assisting developers on building in the cloud instead of trying to get to the cloud. So, my advice to you is to treat developer experience like a product. Continually try to find ways to get feedback and insights. Measure developer productivity and rehydrate your automation efforts based on that feedback. Backstage can definitely help you stick everything together and offer you a single pane of glass like it has done for us today. And we'll continue to invest time, energy, and resources providing our developers and our engineers and our organization everything that they need to be successful. So, I'm going to pass it back to Ruan. She's going to provide some tips and tricks and resources, and we'll have you on a happy hour. So, we did mention the HCA scenario of using GitOps repositories with Argo. There is an Argo CD plug-in that other customers are using today with GKE Fleets, which will simplify your platform journey as well. So, please feel free to check out this blog. The backstage reference architecture that we previously demoed or talked about that QR code, there's the short URL link for it. Foundation fabric for that opinionated approach where you can jumpstart your journey and fork and actually make it your own. As well as that YAML file of Project Factory to provision consumer projects will actually really accelerate your journey. Our talk from last year, that's highlighted there as well. Now, Google Cloud Consulting partnered with HCA to actually build this solution, but we extend beyond just platform engineering. So, we can help you with your reliability engineering efforts, which is my team, as well as others across the globe. AI and data engineering. So, we actually have at HCA data migration team as well, as well as the ML AI journey that they're doing. They're currently working on building their ML Ops platform as well. So, if you'd like to learn more about our services, feel free to visit us in our booth either tomorrow or the day after. In the next nearond camp. In the next two minutes,ania and the more sustainable software industry attend 225 publishers應該 2434gart大概 1206 2017. Rexxpf GOVERNITY BOE. 3. Subscribe on 위한 platform here and the more sustainable solutions include newsblicities, and kann. With官arius Campbell that meet us at the University of Michigan. That means we'll be all we'll be at the University of Phoenix learning today. And that's gonna be going for you. Katepal PERRY, I'll have a question quickly. Let's get a question about the new especially when we want to see the cost candidate might be genvidaeously miteinander.