 I'm the essence of what we're talking about is really what are the the major strategies are the five big strategies that companies are successfully using or should be using to be successful with with enterprise AI and so I'm gonna ask everybody to introduce themselves and if you don't mind guys I'd also like you to answer a question for me which is what about AI has surprised you either something you expected to happen that didn't or something that has happened and you didn't expect that so Michael perhaps you could start yeah absolutely thank you for having me so much and thank you everybody for being here I'm Michael Grisnaber I'm a VP of product management for the API platform at Anthropic where we develop the Claude family of models I think one of the most exciting things that the thing that surprised me over the last year and change that that I've been working at Anthropic is that the the model intelligence and what people are doing it doesn't express like a linear curve the way that I was sort of expecting or a smooth curve I should say even an exponential and there are these threshold moments that we've seen after which like code that was generated could actually go to production or or people could use an agent to write code for 45 minutes or or that sort of thing and and and it was really these threshold moments that afforded that to engineers that that I've seen that surprised me the most yeah some days yeah thanks for being here my name is Kambi Zagili I'm vice president of product management at OCI and also in charge of multi-cloud really thrilled to be here one of the surprises for me is just like how AI is pushing everybody to think about data architecture differently when you look at the infrastructure stack all the data stack to the application stack it helps bring everything together and challenge us and all the providers in a way that makes the value to the customer having to be readily available in ways that we haven't seen before so I'm super excited to be in the forefront of it that the core of it and working alongside the companies to try to innovate on behalf of the customers great Naveen everyone thanks for having me here and attending my name is Naveen Rao I I was previously the CEO of mosaic ml which was acquired by Databricks just under two years ago so at Databricks I actually had up all the AI products and and research teams and stuff like that so it's been pretty exciting over the last couple years seeing how that scales up with the kind of data architectures that are coming together and one surprising thing for me I actually been in this field for a very long time I'll date myself a little bit but officially I've been in the field for almost 20 years and before it was cool and even before then in the 90s I studied what was we now call AI I would I would say that it was like creative algorithms and you know back then I was it was like impossible to do things like go and that got essentially cracked and you know what 2018 timeframe so that was kind of an amazing moment but I think the bigger picture the thing is very surprising is how hard it is to define what intelligence is it's not a simple problem and every iteration of technology kind of exposes cracks in the definition that we've come up with so and I think we're still experiencing that a little bit so I think that's a that's something we're gonna see more iteration on great how it is yeah I'm hard as I'm at SAP and I work in the business data cloud unit and I focus on product management mostly focused on the integrations with ecosystem partners yeah wonderful wonderful so we said there are five big strategies that the first of those is to start with a strong data foundation and for those of us that work with enterprise customers every day around this AI topic inevitably it comes around to this topic of us of a strong data foundation and so the question really for for the panel is what are the big challenges around around the data foundations and and and what are the best answers that we've seen be successful and her readers I probably ask you first to address that yeah maybe I'll I'll answer that by painting a little picture for you so like when we as vendors when we go into customers I get to two viewpoints when I'm talking to the executives they'll tell you you need to fit as a node into my beautiful mesh yeah so that's the thinking there then you go there's a beautiful mission there let me go find out what the elements are and you get down to the to the leaf level the guys were working there and their answer is it is beautiful indeed but it's a beautiful mess with just about works right so don't come come and tell me something that'll upset the apple carton we quite don't know but it all hangs together so that's that's one perspective the the second thing is something that's probably happening in a lot of accounts you know a scenario is can we get a good updated view of the landed cost and I'm sure at many customers given the given the situation tariff that's a question being asked and the guy who has to do it if you take the scenario the boss calls them up hey do you have an update on the landed cost he goes well we have best of breed systems and these systems don't talk to each other and I had to update something in SAV I had to update something in another system just to get a view and it'll take me some time and the boss turns around and I say but didn't you know liberation day was coming like a month ago yeah so where are you and then the guy goes you know I my boss always wants to me to read his mind as opposed to give me directions right that's he that's interaction takes place and then then he has to go do it they do something they crank out something and there is a solution and everybody high-fives and now they get it but across these two scenarios the one question that you need to ask is meaning being derived before truth is established yeah so this truth before meaning is a super important contact concept as you think about a data foundation and if you don't focus on that all the meetings you derive like in the case in the second scenario highlighted you may have cranked up something a solution where the guy who has implemented it is struggling to figure out whether he's got the truth so really one way to look at it is what many organizations are still trying to do with it is really think in terms of a data product where the data owner is ensuring that the truth is established and you land a foundational data model of these data products from where in your use modeling then to then to go upstream to share with but but you have to establish the truth first then then you can be a bit more confident about the meaning yeah jump in a little bit on that one actually as well so I think I like that framing because I think that actually is something that a lot of people don't quite or haven't quite grasped is that the data in your organization it's not really the fuel of AI it's actually a set of samples of what your AI maybe should or can do and it's a way to potentially guide that into ways that can derive insight but it itself is not insight right there has to be something else on top of it so data is a sampling of some sort of noisy vector of truth within your organization so actually denoising that figuring out how what's good data what's bad how to put it into a form that can actually be consumed by some kind of intelligent system I think these are the things that people are now learning in the enterprise before it was like this promise over the last 20 years hey I gather all this data put it down on disk somewhere and then magically I'll be able to transfer my business that's not really true there's actually still a fair bit of engineering work left to do I also think there's a split between like application teams and platform teams here where the platform team knows what's in their data store who should have access to it how it should be formatted the application teams know what they want from it but in the world of AI applications a lot of the time the application team has to owns all of the product requirements and building a framework for teams to work together is is difficult and important also the one element I would just add to that is that kind of there are a lot of problems when you think about data architecture or kind of data foundation I will just add two data points one is that if you look at customer workloads the data store database workloads 81% is still on-prem if you look at 80% of customers they are in multiple different clouds so that what that means is that the data is located across different clouds with different governance and security it's across different deployment models and and you need a lot of ETL and you know a bunch of stuff and so from a customer perspective it's very very difficult to think about what my data is where and how do I utilize structured semi-structured relational transactional all kinds of data that I have stored for 30 40 years and sort of one one problem the customers constantly come to us for is that how can I have from a foundational level a centralized intelligent data management control plane where you simplify the security data governance you know observability and all of that on behalf of a customer you provide an access point to the data that could be in and across multiple different clouds seamlessly natively interoperable with one another so that AI models however wherever you were deploying it it's going to be really easy to see the entire data state and the last thing is just co-location of data stores databases and applications where AI models are operating to be really next to one another so that you're maxim minimizing the latency and all of that because you need really fast response time to get to the truth and so at the architectural level at the foundation level those are the problems that we are faced with and solving for says the database guy I was actually going to ask the database question companies because Google takes the view that probably we're going through the single biggest change in core database technology in 50 years because of AI and and and the nature of the new application stack what is your view on how AI is going to impact databases it's it's giving that abstraction layer to to abstract the complexity of managing the data regardless of data types regardless of data models regardless of whatever purpose built data operating model makes sense for that type of data as well as unifying and natively all the operational modernization elements around security governance around observability around giving customers the flexibility of a storage so for instance we were working on solutions with you in terms of giving customers different storage choices or different backup options that was never been available so from a database standpoint it used to be a company and these companies were all siloed from one another now the AI has really forced all of us to think through what that multi cloud cross cloud interoperability could look like so that's the biggest innovation that we see in front of us right right okay you know the second big theme is around around identifying the right business problems and the metrics from that from measuring those and I was just wondering Michael if you if you had some thoughts about about that about how customers are focusing on on what to apply AI to versus you know kind of the latest toys that makes sense there is a lot of play with the latest toys out there right there's a lot of CEOs that are saying AIFI the organization and it really falls to product managers and and and engineering managers who who know what problems they're trying to solve to articulate that and it's it's funny how frequently just basic product management like skills fly out the window right they want to grope around about for what it is possible rather than start with a business problem clearly articulate that figure out how to evaluate what good looks like and then back into a solution to a well known problem and I think going back to that is actually like quite important am I trying to transform a business process so that it happens automatically rather than reactively do I want to keep many people on the same team are we trying to increase productivity like even starting with with with high level goals is very important but then like I say knowing how to evaluate the success of your product knowing what good looks like so that you can back test you can use the evaluation techniques and evaluation techniques and you can use offline evaluation techniques to know what you're doing is working and allow you to iterate on that it's extremely important I think one one point was actually embedded in what you're saying is that the the way you consume AI is something that's not simple this is one thing we find over and over again within organizations you know we talk about looking like Quarna when they filed their S1 they said they had all these gains from from AI that have actually successfully leveraged it is that they figured out what that business process is how to deliver the insight to whom when and that's that's a product management problem right so it's almost like even for internal teams who have to consume this stuff it's not like here's a chat bot go knock yourself out that never works in fact that was kind of the one of all of this AI stuff and it all failed because a chat bot can be the worst possible interface like text is a general a fast or efficient way for all different types of intent. So you need to understand what the intent of the business owner or business process flow person is, figure out how to interject something that accelerates it, and AI is a technology to get you there. I'll speak to that, I think, another example about the intent. So I give an example of a customer we have, like one of our most valuable customers at OCIS, Uber, which you all know very well. And so we really work back from the product management in terms of the KPIs, what was most important to their business, and work back from how can we innovate and utilize AI. Give an example. So they're utilized over a dozen different models running on our AI infrastructure. One of the key KPIs have been really optimized on, that they can now run 14 million predictions per second. What that really means for the business is that they can really guide the drivers based on where they see the demand is coming to be where they need to be. More proactively, that means less fuel, that means faster response time, getting the driver to you instead of being four or five minutes to seven minutes to be an average of three minutes. So those things, at those number of transaction scales and predictability per second, means so much to the business. So we work back from what it means to the business, how the business can innovate, and get ahead of the competition as the way to really try to figure out where you can fit in AI to help that business particularly. No, I was just going to offer that. The good thing about the curve of the intelligence of the models is that more and more non-chatbot use cases are just extremely possible, and it just takes the engineering manager and the product manager to think about how to use it. But this is where a process that is driven by a human could bring a human into the loop or remove them from the loop entirely, and that doesn't require a chat interface. Coding IDEs have really taken off, and I think that's driving a good part of your revenue at Anthropic, and I think this is the reason. We're nailing the UI. And it's the difference between a tab completion and here, fix this PR and come back to me in 45 minutes whenever it's done. And both of those are valid at different times. I'll take you back to a more basic story. I used to work with the messaging outfit, and there you're focused on trying to understand churn. The marketing guys wondered, hey, we need a better churn algorithm. I had a data science team, and they said, hey, Ari, we'll get you a great churn model. We went and built out a great churn model. The problem was, I never asked the question of the marketing guy is, how will you use it, and do you have a way to reach those customers who are on the list of being churned? And so we cranked out the churn model, beautiful, 87% accuracy, and then we went to the marketing. The marketing guy goes, you know, I have no way to wake up that customer on the phone. They signed up without a phone number, so I can't send them an SMS, and those days, this was eight, nine years ago, the push messaging wasn't, so the app has to be woken up in order to get that. So it is important to first understand, if you create something, does the other party, can they even use it effectively? The why aspect before you get to the what and the... Yeah. Yeah, very much what we see as well. A good example is Target is a Google Databases customer, and if you're familiar with that search bar and Target, where you can look for products, and they had a very specific requirement, which was to get more successful searches, and when that's very clear up front, we need much more successful searches, what are we going to do to do that? In this case, it's like, well, we need to do some vector searching, and they do that, and they get a sort of a 20% benefit, but there you've got the we're targeting something, we're after a particular goal, we know what we're trying to do, we're measuring that goal, we're delivering it, that's typically the thing that we've seen is where it's most successful. So the third area that I wanted to talk about is really about people, and it's about building a culture of experimentation, and of learning, and investing in talent and skills. Quite often, when we're working with customers, the single biggest barrier is that they don't have any AI people, and so they can't really start because they don't know where to start, they don't know what the landscape looks like, they don't know what kinds of tools could be used, and you can't get that until you've actually got this kind of upskilling of the organization, and then once you've done that, trying to kind of roll it out across the organization, so that everybody is kind of focused on how can AI help me in my job. So in that context, I was just wondering if, Haridis, if you had experience of this, and what your thoughts are on upskilling and culture development around AI. So I'll take a different tack on that, in that some of the basic principles have to be in place in an organization, and what I mean by that is the execution discipline, yeah? And the execution discipline, if I explain, you know, many companies have the notion of these semester plans. You do the semester plan, you properly plan out, and at that point, you have documented what you do, but more importantly, you have to document the who, what, why. Who are you building for? What are you building, and why? That why aspect is very important. So once you have documented, you know what you're doing in the semester plan with some buffer for the incoming from the CEO and incoming from other parties, right? And within that framework, if you now experiment on the AI, because you have documented the why, it becomes very clear why you're doing. You know, I've seen our organization, other organizations sometimes, go through, hey, AI is new, everybody's got the project. You know, two months before, engineering had no capacity, now engineering has super-final capacity to try all these experiments, and you wonder how that happens. So that's because you haven't put the discipline of the who, what, why in the semester plan. So if you get that, that co-discipline has to be in place first to then encourage the experimentation, and then the second part is, yes, you experiment, but it's okay to fail. They got to have that confirmation that try it out, iterate fast, but always define the why are we doing this. Yeah. There's a point on accepting failure also. In a lot of cases, and I'm going to ground this in a customer support customer that we have, that actually allows their customer support agent to go ahead and transact returns between merchants and that merchant's customer. And since money flows, it's actually like a high-stakes endeavor. You have to look up policy, you have to apply a policy correctly. A human agent who does this does get it wrong a certain amount of the time, but when a robot agent gets it wrong, the end customer is furious. The merchant can do some calculation, the platform can do some calculation that some percent of the time, human gets it wrong, robot gets it wrong, robot is better than human on average. It's definitely better for the end customer, but that doesn't help when you can't return your shoes because a robot said no, right? Yeah. And so in the UX, they make it fail open. They make it so that if there's a failure, it's always transacting the return so that the merchant and the platform eats the cost, but on average, it's actually much better for them and everybody is happy. So thinking through these failure scenarios and what risk looks like to your organization is actually quite important to facilitate this kind of experimentation at low risk. And to do that, that decision is not made by the engineer or the UI designer. That's a business decision which requires those business people to have those kinds of trade-offs in their heads, I guess. Yeah, yeah. I think a lot of this is also removing the complexity of AI from the end user who is using a product that happens to incorporate AI and bringing that in to the professionals and letting engineers steer the model as much as possible in the application at the client layer before exposing a customer to it. So that customer has to learn very little. They can just get what they want out of the application. Yeah, yeah. Well, I think this reminds me of a, I don't know who said it, but it's a culture eats strategy for lunch. Right? So it's one of these things I think getting culture right is obviously not a simple thing to do, but to me, it's actually not a culture of experimentation. It's a culture of discipline on how you test those experiments, but also it's a culture of continuous improvement. Right? AI is a way that I can do my job better. That's the way we should think about it for the next couple of years. I mean, at some point that might shift when we get better at it and can actually do full automation, but right now the most successful implementations I see are when, you know, some set of people who are doing some set of tasks can improve those tasks by some percentage. Right? That is where the impact is coming. That's the way you should think about it today. So really, the culture is, hey, is there a way I can use this tool to make my job easier? Are there places, basically, you feed that back into the product manager, right? It goes back to building the right tools, but it has to come from the person who's doing the job, right? Yeah. If you're not doing the job, you don't know those points of integration. This is also critical because an attorney has never sat with a scrum team, but it's extremely useful in legal research. Every legal research company is using AI to aid with legal research, but a change in the sampling, a change in the outputs from the model could be material to the law or could not be material to the law, and the engineer doing the evaluation often isn't credentialed to know that. And so you have to break down these silos in the organization so that, like you say, the person who you're trying to help is in the room for you and can help evaluate whether or not they're succeeding more. That, to me, is a good definition of a requirement, but have you seen ways to get that to happen? Because it sounds like quite a hard thing to make those changes in an organization. It is hard. It's super hard. And I think that's what you just said, getting the right people in the room and getting them to talk to each other. That is the cultural principle of a company, right? I think, I mean, we can go into whole organizational principles and things like that, but small teams tend to work very well when you're solving these things. Like, something bigger than 10 people, the communication becomes the bottleneck. Five people sitting in a room who understand different aspects of the problem will solve something, at least to a first order that others won't. And then it can be scaled and, you know, put into an organization and that kind of a thing. But I think getting that initial definition right of what you're trying to solve, what success metrics look like, defining all that up front, I think is really done in a small team, less than 10 people. Yeah. Canbiz, are there lessons from Oracle on this issue? So I think, yeah, yeah, I think for us, we have been working with DBAs and DBEs for over 40 years and it's kind of embedding many of the AI and vector database capabilities embedded within the database and providing all the certifications and knowledge base for the DBAs, DBEs, and CIOs to be able to utilize that in terms of embedding into the existing workload has been really, really helpful. So we also have provided natural language interface to the SQL, which kind of makes the job of these, like, folks that are in the field and IT folks really, really easier and they can work at the next level of how they can utilize the data or data architecture in ways that they couldn't do before. From a support perspective, not have to get a call at 4 a.m. in the morning, all the way to what else can they do with the data, how they can have vectorized data readily available to them seamlessly and so that's been really exciting to the folks we are working with. So we haven't seen a little cultural shift, but we have seen people being more excited about the advent and availability of such technologies embedded into the knowledge base and tool set that they were already familiar with. So a related question is really about whether or not AI is going to be democratized, at least the kind of development of AI systems is going to be, is going to remain the sort of domain of specialized AI practitioners or in fact whether other people are going to be able to get into it. And I was wondering, I know, Michael, you're probably quite close to this. Perhaps you could kick us off on what you think there. I mean, the future is extremely hard to see, to be honest. But I do believe that with the success of meta-prompting, of prompt generation, of code generation, of the AI able to do its own work to build its own applications and with the advent of what we're calling vibe coding and all of that, we see it clearly that people can get started without being a professional, without being in the inside, without having 20 years of engineering experience, without a classical CS degree. One of my favorite examples is a Google Cloud customer, Replit, and they have a story about a man in India who started coding on his cell phone. And he was able to produce an app with Replit and start selling a product and through that, buy a laptop and just keep iterating from there. And it's just like a wonderful story. And I believe a lot of that will be, like right now, the code going to production for the enterprise is being written by people holding pagers who keep it up, who maintain it, who have, you know, understand DevOps and all of that. But I believe with the intelligence of the model, we're going to go a long way to democratizing that sort of thing. Yeah. It's sort of happening now from a democratized perspective. if you think about the holy grail of text to SQL in the database world, that's already here to be realized, right? People now, the average person can type it in text and get the SQL generated and get the answers. Because for the average person to understand what an outer join, inner join, what do the table structures look like? Impossible. But that is feasible now. So that democratization is already in play. And same for data management people, pipeline people. The tools are embedding data quality people. The tools and the rules are getting embedded through AI right in the workflow where people are. Yeah? Where these two. So the key thing I feel is you have to meet the folks where they are. Whether they're in the tools or whether they're in any of the applications with AI being supportive of their day-to-day workflow. Yeah. I think to your point, actually, people also, the enterprise especially, needs to decide very carefully when to procure a tool and when to build a tool for this very reason. Sorry, you were going to say? Yeah. I mean, in terms of democratization, I think you've got to look in what does that really mean. It means removing blockers. I mean, the economics are one part of it. We saw this, actually, at Mosaic in 2021. We basically saw that we were going to have this pretty drastic cost reduction year-on-year, driven somewhat by hardware, but actually more on the algorithmic side, like size of models, how do we make the models behave the right way and all of that. And we estimated it was about 4x year-on-year. That's been holding up so far. So that's one aspect of friction. The other part of it is really how do I wield it? How do I customize it? How do I make it do the thing I need it to do? And, you know, what's interesting, I'm actually a neuroscientist and, you know, study reward systems quite a lot in that field. And evolution over the last 4 billion years has actually come up with a pretty nice UI. It's like, how do you train your dog? Right? You get them to do the thing, you give them a reward. So I think at some point we're actually going to start moving towards systems that can learn like that. We start to show them some examples, let them fill in the gaps, get some feedback on how they're doing it and keep iterating with them. We're already starting to see that. And within Databricks actually we built a whole framework for how you can create an agent, see how that agent behaves on some test data, give it feedback, it goes and modifies itself, tell it if you want to go faster, it'll go and fine-tune something, it'll go do some re-ranking, it'll do a bunch of stuff on the back end, so it's basically trying to learn what you're asking it to. Yeah, yeah. So I think this is going to be how we start to democratize intelligence. Now, I think there's always going to be a stratification, there'll be people who wield that better than others, just like they're better dog trainers than probably me, right? So I think this is, we are going to see that reduction of friction in these technologies over time. The other thing that we see is that with every, you know, linear increment in intelligence, however you define it, which is, like you say, messy, we see, like sort of an exponential difference in the kind of work, the value of the work it can do. So like a lot of the old work that people are getting very good at doing is information retrieval bound, credential bound, stuff like that. And the new stuff does require you to think deeply about what AI is possible of doing and establish new pattern so that other people can see those patterns. And so both kind of problems will continue to exist for the foreseeable future, I think. Okay. I'm going to move on just to really the fourth of the strategies which enterprises are adopting, which is around ensuring security and privacy. And I suppose the question there really is kind of with, by the way, a lot more kind of requirement for compliance and a lot more sort of legal challenges around these things. what is the implication for the typical organization of AI and how that intersects with security? You can maybe start on this one, yeah. I mean, this is kind of core to what we do every day at Databricks. We built something called Unity Catalog, which actually is a centralized point for this coordination. And really, I think this was one of the big unlocks. In fact, I presented this as like a Maslow's hierarchy in some other talks where if you don't get this right, you can't get to the other stuff. Like you can't build the UI. You can't use intelligence because you have to make sure that only certain people who are allowed to see data can actually use AI that acts upon that data. You have to make sure that those things are done in compliance with, you know, GDPR type regulations where data, data residency and data sovereignty. You have to make sure that there's lineage, there's observability, monitoring. If you don't have these basic pieces in place, all of what we're saying is for naught. It won't happen. And I think that's something that we're just now seeing kind of climb out of the out of the primordial mist, if you will, you know. I'll try to give you a story. I mean, we have a partnership at Databricks and I was at this event presenting what we have with the data cloud, business data cloud. And this guy comes up to me, you know, Hari, today I'm responsible for the SAP landscape and we have a data science center of excellence and they come and ask me for all the data. And then when they have done all the work they have to do with the data, when I go ask for that data back because I'm responsible for compliance, the data science boys tell me you can't even get to it. Yeah? And this is a huge problem. So the next time they come around, I tell them, do you understand SOX compliance? Data science guys go, maybe, maybe not. Well, respectfully, please go away and come back to me. This is the tension in the organization. and we've done with Databricks is like, can you combine those personas together in one environment where they can collaborate seamlessly, the data analyst, data scientist, data engineer. So that's the, that is, that governance has to be in place because today the centers of excellence are different and they just don't understand the data and the semantics whereas the data, the application guy understands the semantics, the data science guy doesn't quite. He just wants all the data at the fidelity of the role level in a big, flat, wide table. And that's a big part of why we have this partnership between SAP and Databricks is to bring that, that kind of governance layer for models and data combined with some of the most important data in the world, ERP data and SAP. That governance, kind of unified governance and interoperable is really key to us as well and that if you look at the past 40 years, the, the major enterprises have grown. There've been a lot of M&A that have happened. So line of businesses, they're all very different on one another from a security, from a data governance, from access control. And so when you think about data scientists or any of those personas, they're dealing with all these that are as good as the weakest link in that chain. And so how do you create that control plane? How do you create that governance? How do you create that control plane or whatever that is at that abstraction level that from a data scientist or whoever the developers are at whatever persona, they don't have to think about all the complexities going underneath because it's actually very, very complex and difficult to deal with, right? Deal with that at a technology level is probably the answer. It's just really, really hard. Really hard. I think that security is a topic I know we could talk about all day and I'm going to, I'm going to move us on because we've got other things to talk about as well. That's okay. And really, the fifth of the, of the five areas is around integrating AI into existing systems and it doesn't, it doesn't work for AI systems to be kind of silos. They need, they need to be part of your overall sort of enterprise, enterprise fleet and so I suppose the question there is what sort of strategies do you see customers using to integrate AI-based systems into the stuff that they've been building for decades? I mean, I know you just pulled us off of security but this is like obviously extremely relevant here. The thing that makes 130 year old legal research company, 130 year old legal research company is the legal research they have done on common law for 130 years, right? The, the thing that makes a pharma company able to get approval for drugs is access to their proprietary research. So much of the integration is who is allowed to talk to what data, query what data, how two agents might discuss with one another, right? And if they have different levels of credentials and that sort of thing. And then it's also prepping the data for access by the rest of the organization. I think it turns out that analytical models are still really useful. In fact, I would say most quote unquote AI compute in the world is probably still in that regime rather than the LLM kind of stuff. I mean, that's probably changing very rapidly but I think you don't want to throw that away and say, okay, now I have this giant LLM and I'm going to use that to do my analytics. That's a dumb way to do it, right? We have first principles, models, some, you know, based on some sort of call it physics or whatever you want to call it of your business and those are still valid. Now we just need to figure out ways to plug those in in the appropriate times. And I think, you know, tool backends, actually we work with Anthropic very closely on this, like how do we plug in all the stuff you've built inside of Databricks or whatever other platform to be able to leverage it, right? You've got to build upon. We don't want to replace everything. There's a lot of good stuff that's been built. I mean, I think that's, you know, part of what's behind the question is that it's easy to think about these AI systems as being, you know, greenfield, new systems but actually a lot of them are going to be ways of enhancing existing things and I think, Naveen, you were saying earlier about kind of optimization. There's going to be a lot of AI implementation that's really optimizing existing things rather than whole new kinds of things. Gary, to that point, I can share a story, right? And you used the keyword silo and it's a story where there is a manufacturer of chocolate and there is a logistics provider. Yeah? The manufacturer is trying to optimize for full truck loads. He doesn't want to send a truck which is half full. Logistics provider is trying to optimize that he doesn't get fined by the retailer because he's 30 minutes late. Yeah? These two guys are working in their own domain but the data exchange is very difficult because the logistics guy has a very outdated system whereas these guys are trying to use ML and all try to optimize that full truck load but without the data from the logistic provider coming into this side, they really can't decide should I send the truck half full or should I take the fine? Yeah. This is a question you have to resolve and without the data coming together, any amount of AI done just in silo here versus silo here isn't going to solve that problem. You really need to get that fundamentally that data foundation has to get sorted out and then you apply the AI on top. Just on that data foundation, I think one of the things that's really important to understand is that there is no one large or small language model can solve for or good for every problem so part of that for us is to make it easy for customers to think through between we've created these interconnects between the different clouds, right? So it's OCI Fast Connect and Google Clouds Interconnect and sort of how do you make it easy for customers to be able to utilize our vector database capabilities right alongside Gemini Foundation models and Vertex AI in a way that is built and connected through a direct fiber link and all of that where you don't have to move data. So how do you make give customers a choice depending on the use case to be able to utilize different models and that makes sense for them for their metrics as again, we talked about. So that to us thinking, combining and aeroportably across the choices of the models and data architecture is one that we really committed to. So I kicked off asking what surprised you in recent months about AI and just to kind of finish off here I wanted to get a feel from everyone about what you feel might be happening in the next year or so. So I'm just wondering if people have views about the future, about what's going to happen over the next 12 or 18 months. Should we start on this? Yeah, I mean, so one of the things that surprised me very recently was the rapid adoption of an open source product that we just started called Model Context Protocol. And a lot of what we're talking about here is I think why it got so popular so quickly, right? It pushes access to the data stores and the data preparation to the edge to the platform teams to expose it to applications. And the fact that it's getting so popular I think shows like a very short-term future in which the enterprise is able to start building LLM agents, put them in the field and distribute the work and the expertise across their organization and access to data across their organization very, very, very successfully. Like I think what we're going to see in this short period of time. Great. And please. What I'm really excited about is that how this accelerates cloud migrations. So for us, we invest across every layer of the tech stack, AI. So at the infrastructure level, GPUs and all of that and we constantly try to, you know, launch data centers and regions with a smaller and smaller and smaller footprint because customers want all these services to be available to them anywhere they need it and they want these to be across the deployment models to be able to connect with one another very seamlessly. At the data level, is the data architecture level we continue to invest to make sure that interconnect or otherwise syncing the data with one another is really, really important. The last thing is at the application level. Either the existing ERP, CRM, all these applications that we have had for like 40 years, how do they utilize AI directly in their operations? But two, how do we bring a dev stack available to customers that is sometimes ours, sometimes yours? But how do you give that flexibility to the customers to utilize the best dev stack that means for them to modernize their application stack? So when you look at the entire tech stack, super excited about what it enables, how it challenges us to think in different ways and it enables customers to look at the different avenues to innovate. Yeah, I think over the next couple of years, we're seeing a big focus on correctness and grounding. I think that's kind of needed to make these agents utilize the intelligence in a way that's actually useful. And so we've now started building things where we can actually make the system self-improve or self-label. Labeling data is super intensive and actually a crappy, noisy process. And I think that was version one of AI world in a sense of like here's a way to label a whole bunch of data and call that truth. But I think now we can actually start to observe these systems kind of in the wild, how they're being used and say like where those errors are. And now we have ways of automating, okay, this is actually the error mode that we're seeing. How do I update my system accordingly? Either that, you update the model, you update the way you do retrieval, whatever piece of the system. So I think that is what we're going to see the next couple of years is going to get pretty good and to a point where people will start to trust it. It'll start to really start impacting those business workflows. On a longer term basis, I actually do think there's going to be more of a breakthrough. We've gone from this phase of using massive amounts of data, which again are observational points of truth, but we need something that can actually start to build its own source of truth, its own model of what the world looks like and how it works and use the data as a corroboration or a refutation mechanism. And I think we're going to see an evolution in the next five, six years. Yeah, I'll give it, take a more prospects approach. Like every product manager who's focused on the jobs to be done and how he's thinking about it, they'll have to think about how to incorporate AI into that, right? That would be the role of the product manager. And by thinking about it and by thinking about the why, almost everyone will now be focused on meeting the user where they are with the AI they are incorporating into the jobs to be done for. Yeah, that is at the heart of it. So product managers have to be very, very keen in terms of how will they incorporate this into the frameworks they're using. so that, and they have to, it's not just the who and the what, but the why has to be clearly defined if they're going to add AI to one of the jobs to be done for the customer. Yeah. Yeah, that's interesting. I suppose, you know, if I were to pick something, I'd say, we'll be sitting here at next 26 and what we're going to be seeing is a lot more in terms of actual enterprise successes with the technology. And I think we're past that point where people are trying things out, building a chat bot, maybe getting things a bit wrong or whatever it is. And we're at the point now where people are really deploying serious enterprise systems. We're going to start seeing those stats coming out in the next year and looking forward to doing that. So with that, I want to thank everybody for coming. I want to thank the panel for their time and for their expertise. Thank you very much. Thank you. Thank you.