 Hi, my name is Soumya Banerjee. I'm at Google. And today I'll be discussing about how we can unify different types of data, like relational data, vector embeddings, into a single LIDB database. And for that, we will use the use case of Neuro, which is a great startup with which we help them to integrate their data and break their data silos. So those who don't know about Neuro, Neuro is an autonomous driving company that uses end-to-end AI driving capabilities, and they bring it to any vehicle on road, which is pretty awesome. So Neuro ingests massive amount of data from all their connected vehicles. And it also does very large-scale simulation to produce data and metadata. And then they use those to produce insights on top of the data on various ML models. So when we started working at Neuro, they had this architecture where the data was siloed. So they had their relational data in one LIDB instance, and then they had their all the vector embeddings in a separate LIDB instance. And that led to multiple issues, like there were application complexity increased because the data was fragmented across databases. There was performance degradation increase in latency. It impacted real-time data analysis. Also, the overall development process was complex because you have to always keep on joining between two databases, and it took longer development cycles. And on top of that, there were increased management overhead and cost because you have to maintain those two databases and patch them and maintain security and all of that. So with our solution, we basically integrated into a single database. One major factor that helped us to do that was the release of scan indexes. Earlier, the indexes being used were H and SW, which took a very long time to rebuild the indexes. But with scan indexes, the index rebuild time was much quicker and faster. And this helped into, when we consolidated them into a single database, it broke the data silos. It was much more efficient data analysis and insights. It simplified the overall management and the development process, increased performance, and also optimized cost. We'll go over some of the performance metrics. So we ran it on N-C2 machines. And there were two separate machine types. One was a 16 vCPU, 128 gig memory, and the other was 32 vCPU and 256 gig memory. What we found is that for 10,000 and 5,000 concurrent users with a better or higher machine type, the performance, like transactions per second was almost three times. And also the p95 and p50 numbers for the latency was pretty phenomenal. They were in milliseconds, which was definitely the benchmark we wanted to achieve. So with this integration of the relational and the vector database into a single instance, we were able to achieve sub-second latency. We found that quarterly partitions actually provided better latency than monthly partitions. We were able to achieve significant improvement in transactions per second with the higher machine type of 32 vCPU and 256 gigs of memory. And then even though the latency increased with the number of users from 5,000 to 10,000, even then the latency numbers were pretty great and were in milliseconds. So, yeah, I mean, AlloyDB is a great product for all of the data needs and will be most happy to use them for you. Thank you.